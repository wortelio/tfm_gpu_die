{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a01e4ef-8c3c-4ac1-b5a9-7207f732df90",
   "metadata": {},
   "source": [
    "# Folders setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c48cecf-6faf-4092-b12b-50f26c5ee209",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = './step_by_step_models'\n",
    "ori_filename = models_folder + '/BNN_BED_classifier__best_mean_F1=8757__QONNX.onnx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62467796-f923-4641-aea9-f27720817207",
   "metadata": {},
   "source": [
    "# Model Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ce3e63-8792-41a6-8b31-486dca7d843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showSrc, showInNetron\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7286b856-b37b-42ab-a07b-b01ae0f11a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "qonnx_clean_filename = models_folder + '/01_clean.onnx'\n",
    "qonnx_cleanup(ori_filename, out_file=qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d097b8c-37d6-4745-afab-b924eb46f04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './step_by_step_models/BNN_BED_classifier__best_mean_F1=8757__QONNX.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f7a0b20fdc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(ori_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32a2061d-8a23-478c-bfe8-57dd0bff238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_models/01_clean.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f7a60e8e830>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268926d7-65d1-4c9d-9788-7ec8eb978435",
   "metadata": {},
   "source": [
    "# Dummy Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea79dcc1-8ec3-408f-bb60-f8c3f66c5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "import qonnx.core.onnx_exec as oxe\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30887ba6-8764-469c-9baf-6dbd14026f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ip = np.random.randint(low=0, high=256, size=(1, 3, 224, 224)) / 255.\n",
    "test_ip = test_ip.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f9336f4-ff2a-44af-8dbf-0a241c420d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_model = ModelWrapper(qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b56d5680-a591-47d3-8995-ad60d7f27eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.270301 , -6.0525727]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict = {\"global_in\": test_ip}\n",
    "output_dict = oxe.execute_onnx(clean_model, input_dict)\n",
    "produced_clean_qonnx = output_dict[list(output_dict.keys())[0]]\n",
    "produced_clean_qonnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a391c5-af4f-4426-ac7f-345bf0a1310b",
   "metadata": {},
   "source": [
    "# Convert to FINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3392e878-1927-4360-8d58-75402552e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66c7d74d-229d-44e8-a0c4-35bb38951a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(RemoveStaticGraphInputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fea521a-b39a-405d-8181-cf306a167b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_tidy = models_folder + '/02_finn_tidy.onnx'\n",
    "model.save(finn_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f93b85f6-2a27-46ed-92fa-d2fa605fadae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_models/02_finn_tidy.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f7a0b013cd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a074441-ef76-4836-bcaa-769972124fe3",
   "metadata": {},
   "source": [
    "# PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fd0bf51-cc0f-47fc-8d2c-6ed3fe805d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from finn.util.pytorch import ToTensor\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.core.datatype import DataType\n",
    "from brevitas.export import export_qonnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "173b59a6-8897-4d57-b25e-d818d4ca65dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/merge_onnx_models.py:70: UserWarning: [MergeONNXModels] opsets for models to merge differ: 14 vs 17, output model will use opset 17\n",
      "  warnings.warn(\n",
      "/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(finn_tidy)\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "# preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "totensor_pyt = ToTensor()\n",
    "chkpt_preproc_name = models_folder + \"/prepro_node.onnx\"\n",
    "export_qonnx(totensor_pyt, torch.randn(ishape), chkpt_preproc_name)\n",
    "qonnx_cleanup(chkpt_preproc_name, out_file=chkpt_preproc_name)\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "pre_model = pre_model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "# join preprocessing and core model\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "# add input quantization annotation: UINT8 for all BNN-PYNQ models\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c9bb0bd-a9b6-42ee-b792-9bbb3b4801b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.infer_datatypes import InferDataTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800e6b66-af2f-4ae8-a1b6-90336c6909f4",
   "metadata": {},
   "source": [
    "### Save prepro after tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6eb18cc8-eef6-45ee-a2be-597ef399a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fa559ff-31f3-42ad-8273-ddf6d9a0759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_prepro = models_folder + '/03_finn_prepro.onnx'\n",
    "model.save(finn_prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d380614-f8d7-4b2b-86df-106ba43ab349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_models/03_finn_prepro.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f7a0b133fa0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_prepro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57348031-895c-4f9f-a0d1-22ed7969f60f",
   "metadata": {},
   "source": [
    "# Streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8100a86a-9402-4991-85ab-3b06b9d70da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "\n",
    "from qonnx.transformation.change_datalayout import ChangeDataLayoutQuantAvgPool2d\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "from finn.transformation.streamline import Streamline\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MoveScalarLinearPastInvariants\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2aeeda85-a2cb-4210-86a8-4bddcc03acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(finn_prepro)\n",
    "# model = model.transform(MoveScalarLinearPastInvariants())\n",
    "# model = model.transform(Streamline())\n",
    "# model = model.transform(LowerConvsToMatMul())\n",
    "# model = model.transform(MakeMaxPoolNHWC())\n",
    "# model = model.transform(ChangeDataLayoutQuantAvgPool2d())\n",
    "# model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "# model = model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "# model = model.transform(RoundAndClipThresholds())\n",
    "\n",
    "# model = model.transform(Streamline())\n",
    "# model = model.transform(InferDataLayouts())\n",
    "# model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d8f0c15b-df62-4050-a7b0-e3daaa2316cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "from finn.transformation.streamline.sign_to_thres import ConvertSignToThres\n",
    "from qonnx.transformation.batchnorm_to_affine import BatchNormToAffine\n",
    "\n",
    "from qonnx.transformation.general import (\n",
    "    ConvertSubToAdd,\n",
    "    ConvertDivToMul,\n",
    "    GiveReadableTensorNames,\n",
    "    GiveUniqueNodeNames,\n",
    "    SortGraph,\n",
    "    RemoveUnusedTensors,\n",
    "    GiveUniqueParameterTensors,\n",
    "    RemoveStaticGraphInputs,\n",
    "    ApplyConfig,\n",
    ")\n",
    "\n",
    "from finn.transformation.streamline.absorb import (\n",
    "    AbsorbAddIntoMultiThreshold,\n",
    "    AbsorbMulIntoMultiThreshold,\n",
    "    FactorOutMulSignMagnitude,\n",
    "    Absorb1BitMulIntoMatMul,\n",
    "    Absorb1BitMulIntoConv,\n",
    "    AbsorbConsecutiveTransposes,\n",
    "    AbsorbTransposeIntoMultiThreshold,\n",
    ")\n",
    "\n",
    "from finn.transformation.streamline.collapse_repeated import (\n",
    "    CollapseRepeatedAdd,\n",
    "    CollapseRepeatedMul,\n",
    ")\n",
    "\n",
    "from finn.transformation.streamline.reorder import (\n",
    "    MoveAddPastMul,\n",
    "    MoveScalarMulPastMatMul,\n",
    "    MoveScalarAddPastMatMul,\n",
    "    MoveAddPastConv,\n",
    "    MoveScalarMulPastConv,\n",
    "    MoveScalarLinearPastInvariants,\n",
    "    MoveMaxPoolPastMultiThreshold,\n",
    ")\n",
    "\n",
    "from qonnx.transformation.remove import RemoveIdentityOps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6baca284-48e5-4fc3-bf2a-77b32826bff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_resnet50_streamline_linear(model: ModelWrapper):\n",
    "\n",
    "    streamline_transformations = [\n",
    "        ConvertSubToAdd(),\n",
    "        ConvertDivToMul(),\n",
    "        RemoveIdentityOps(),\n",
    "        CollapseRepeatedMul(),\n",
    "        BatchNormToAffine(),\n",
    "        ConvertSignToThres(),\n",
    "        MoveAddPastMul(),\n",
    "        MoveScalarAddPastMatMul(),\n",
    "        MoveAddPastConv(),\n",
    "        MoveScalarMulPastMatMul(),\n",
    "        MoveScalarMulPastConv(),\n",
    "        MoveScalarLinearPastInvariants(),\n",
    "        MoveAddPastMul(),\n",
    "        CollapseRepeatedAdd(),\n",
    "        CollapseRepeatedMul(),\n",
    "        AbsorbAddIntoMultiThreshold(),\n",
    "        FactorOutMulSignMagnitude(),\n",
    "        MoveMaxPoolPastMultiThreshold(),\n",
    "        AbsorbMulIntoMultiThreshold(),\n",
    "        Absorb1BitMulIntoMatMul(),\n",
    "        Absorb1BitMulIntoConv(),\n",
    "        RoundAndClipThresholds(),\n",
    "        ]\n",
    "    for trn in streamline_transformations:\n",
    "        model = model.transform(trn)\n",
    "        model = model.transform(GiveUniqueNodeNames())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2e193eb3-6b2e-4752-bb21-c9404c65eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finn_streamline = models_folder + '/04_finn_streamline.onnx'\n",
    "# model.save(finn_streamline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5ab482f9-a66a-4ba6-8f2f-894f53192f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(finn_streamline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45d011e-d2be-409f-a673-ba50aed16514",
   "metadata": {},
   "source": [
    "### Non Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f38030cf-424f-47b3-a924-14660d46f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for not linear\n",
    "from finn.transformation.streamline.reorder import (\n",
    "    MoveLinearPastEltwiseAdd,\n",
    "    MoveLinearPastFork,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "58faeb18-24ea-40e5-ad97-be0e477e5387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(finn_streamline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a59e82a0-6b51-4ec0-9975-8f563f6c5e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_resnet50_streamline_nonlinear(model: ModelWrapper):\n",
    "    streamline_transformations = [\n",
    "        MoveLinearPastEltwiseAdd(),\n",
    "        MoveLinearPastFork(),\n",
    "    ]\n",
    "    for trn in streamline_transformations:\n",
    "        model = model.transform(trn)\n",
    "        model = model.transform(GiveUniqueNodeNames())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "06949f90-d0ef-4e54-b7c8-b2d0bb1915a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finn_streamline_non_linear = models_folder + '/05_finn_streamline_non_linear.onnx'\n",
    "# model.save(finn_streamline_non_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5a44273e-85fe-49c2-92e0-654b714c06ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(finn_streamline_non_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a316e7-318f-4f5b-8afd-7ee1fb3cc949",
   "metadata": {},
   "source": [
    "# Streamline Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "afd5594d-ed6d-4bae-bfd2-6ed6cbed50de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.double_to_single_float import DoubleToSingleFloat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "65d9a2b4-ac2e-4286-aa37-af0be58a8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_resnet50_streamline(model: ModelWrapper):\n",
    "    for iter_id in range(3):\n",
    "        model = step_resnet50_streamline_linear(model)\n",
    "        model = step_resnet50_streamline_nonlinear(model)\n",
    "\n",
    "        # big loop tidy up\n",
    "        model = model.transform(RemoveUnusedTensors())\n",
    "        model = model.transform(GiveReadableTensorNames())\n",
    "        model = model.transform(InferDataTypes())\n",
    "        model = model.transform(SortGraph())\n",
    "\n",
    "    model = model.transform(DoubleToSingleFloat())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2960ebdb-cbe7-42d7-8652-155f0daefe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a0dfe438-9c2d-43f4-ade2-9341af45d3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = step_resnet50_streamline(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "de73684b-af01-4997-98f2-e8b4ff581367",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_streamline = models_folder + '/04_finn_streamline.onnx'\n",
    "model.save(finn_streamline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4174a38c-4da3-47f2-baaa-95d4c5feb6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_models/04_finn_streamline.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f7927cb50c0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_streamline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb38327-33bd-4506-ac2c-323c8c632f0f",
   "metadata": {},
   "source": [
    "# HW Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca2691fb-64db-456f-8397-5862940d9d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.basic import pynq_part_map\n",
    "# change this if you have a different PYNQ board, see list above\n",
    "pynq_board = \"Pynq-Z1\"\n",
    "fpga_part = pynq_part_map[pynq_board]\n",
    "target_clk_ns = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fa7030e-e5d7-48b1-9573-8744043dcccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ultra96': 'xczu3eg-sbva484-1-e', 'Ultra96-V2': 'xczu3eg-sbva484-1-i', 'Pynq-Z1': 'xc7z020clg400-1', 'Pynq-Z2': 'xc7z020clg400-1', 'ZCU102': 'xczu9eg-ffvb1156-2-e', 'ZCU104': 'xczu7ev-ffvc1156-2-e', 'ZCU111': 'xczu28dr-ffvg1517-2-e', 'RFSoC2x2': 'xczu28dr-ffvg1517-2-e', 'RFSoC4x2': 'xczu48dr-ffvg1517-2-e', 'KV260_SOM': 'xck26-sfvc784-2LV-c'}\n",
      "xc7z020clg400-1\n"
     ]
    }
   ],
   "source": [
    "print(pynq_part_map)\n",
    "print(fpga_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "024e8167-ceaa-4a34-b120-460e903a89e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "\n",
    "from qonnx.custom_op.registry import getCustomOp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f186e83-05e0-4b12-8b22-c7c0a60dbc08",
   "metadata": {},
   "source": [
    "### Change last Bipolar Node to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7c870c7b-a916-4f2d-a96e-62ef2b42f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_streamline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1c8d1859-ce8d-495a-8d92-63924a696f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multithreshold_node = model.get_nodes_by_op_type(\"MultiThreshold\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ad93dfa6-8f04-4d93-9745-236dd49ebddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiThreshold_24 converted from Bipolar to Binary\n",
      "input: \"Add_4_out0\"\n",
      "input: \"MultiThreshold_24_param0\"\n",
      "output: \"MultiThreshold_24_out0\"\n",
      "name: \"MultiThreshold_24\"\n",
      "op_type: \"MultiThreshold\"\n",
      "attribute {\n",
      "  name: \"out_dtype\"\n",
      "  s: \"BINARY\"\n",
      "  type: STRING\n",
      "}\n",
      "attribute {\n",
      "  name: \"out_scale\"\n",
      "  f: 1.0\n",
      "  type: FLOAT\n",
      "}\n",
      "attribute {\n",
      "  name: \"out_bias\"\n",
      "  f: 0.0\n",
      "  type: FLOAT\n",
      "}\n",
      "domain: \"qonnx.custom_op.general\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in Multithreshold_node:\n",
    "    if node.name == \"MultiThreshold_24\":\n",
    "        node_inst = getCustomOp(node)\n",
    "        if node_inst.get_nodeattr(\"out_dtype\") == \"BIPOLAR\":\n",
    "            node_inst.set_nodeattr(\"out_dtype\", \"BINARY\")\n",
    "            node_inst.set_nodeattr(\"out_scale\", 1.0)\n",
    "            node_inst.set_nodeattr(\"out_bias\", 0.0)\n",
    "            print(f'{node.name} converted from Bipolar to Binary\\n{node}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fd450e0d-8166-4eb4-8056-c445dae4aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_out_name = model.graph.output[0].name\n",
    "# global_out_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "305bff06-b6f9-43a1-8c74-11a7fb5f67b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.set_tensor_datatype(global_out_name, DataType[\"BINARY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "402c8184-8e14-4294-b32d-645f433bd8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finn_bipolar_to_binary = models_folder + '/05_finn_bipolar_to_binary.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9838e02a-25bb-4196-828c-0d6a351542d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(finn_bipolar_to_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7e66c3a2-50e8-49a6-80a2-016a166450cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(finn_bipolar_to_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f930e3-a725-474c-9b50-0573df8f2a22",
   "metadata": {},
   "source": [
    "### Standlone Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e411e32-f8dd-4295-9b00-eb05759c5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(finn_bipolar_to_binary)\n",
    "\n",
    "# model = model.transform(to_hw.InferThresholdingLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "df0946a5-0673-476b-bfcf-2de3f16879df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finn_std_alone_thres = models_folder + '/06_finn_std_alone_thres.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "801cbcd7-21de-4e58-bc48-be3626c9a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(finn_std_alone_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "40976fc2-1593-49e3-9c8c-e2a92a27e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(finn_std_alone_thres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e500c22a-13ea-45c6-822d-f4b24ad0da6d",
   "metadata": {},
   "source": [
    "### Rest of the Streamline Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bf6b2865-4fad-483a-ba60-a06342a5e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(finn_streamline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27171b2c-d0ea-4119-a54b-ed12eeb24a96",
   "metadata": {},
   "source": [
    "### Multithresholds to INT32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6edb87f2-a0ca-4fb8-baf5-6eb2c289ea9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiThreshold_1: node with Float32 annotation\n",
      "MultiThreshold_1: changed to datatype INT32\n",
      "MultiThreshold_6: node with Float32 annotation\n",
      "MultiThreshold_6: changed to datatype INT32\n",
      "MultiThreshold_14: node with Float32 annotation\n",
      "MultiThreshold_14: changed to datatype INT32\n",
      "MultiThreshold_21: node with Float32 annotation\n",
      "MultiThreshold_21: changed to datatype INT32\n",
      "MultiThreshold_24: node with Float32 annotation\n",
      "MultiThreshold_24: changed to datatype INT32\n"
     ]
    }
   ],
   "source": [
    "Multithreshold_node = model.get_nodes_by_op_type(\"MultiThreshold\")    \n",
    "\n",
    "for node in Multithreshold_node:\n",
    "    if model.get_tensor_datatype(node.input[1]) == \"FLOAT32\":\n",
    "        print(f'{node.name}: node with Float32 annotation')\n",
    "        model.set_tensor_datatype(node.input[1], DataType[\"INT32\"])\n",
    "        print(f'{node.name}: changed to datatype {model.get_tensor_datatype(node.input[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "73225ec5-3a59-4e88-914b-9d86d0791489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_resnet50_convert_to_hw(model: ModelWrapper):\n",
    "    # model.set_tensor_datatype(model.graph.input[0].name, DataType[\"UINT8\"])\n",
    "    model = model.transform(InferDataLayouts())\n",
    "    model = model.transform(DoubleToSingleFloat())\n",
    "    model = model.transform(InferDataTypes())\n",
    "    model = model.transform(SortGraph())\n",
    "\n",
    "    to_hw_transformations = [\n",
    "        to_hw.InferAddStreamsLayer,\n",
    "        LowerConvsToMatMul,\n",
    "        to_hw.InferChannelwiseLinearLayer,\n",
    "        # to_hw.InferPool,\n",
    "        AbsorbTransposeIntoMultiThreshold,\n",
    "        RoundAndClipThresholds,\n",
    "        to_hw.InferQuantizedMatrixVectorActivation,\n",
    "        to_hw.InferBinaryMatrixVectorActivation,\n",
    "        to_hw.InferThresholdingLayer,\n",
    "        AbsorbConsecutiveTransposes,\n",
    "        to_hw.InferConvInpGen,\n",
    "        to_hw.InferDuplicateStreamsLayer,\n",
    "        to_hw.InferLabelSelectLayer,\n",
    "    ]\n",
    "    for trn in to_hw_transformations:\n",
    "        model = model.transform(trn())\n",
    "        model = model.transform(InferDataLayouts())\n",
    "        model = model.transform(GiveUniqueNodeNames())\n",
    "        model = model.transform(InferDataTypes())\n",
    "\n",
    "    model = model.transform(RemoveCNVtoFCFlatten())\n",
    "    model = model.transform(GiveReadableTensorNames())\n",
    "    model = model.transform(RemoveUnusedTensors())\n",
    "    model = model.transform(SortGraph())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "292b78b5-0afb-40bc-a822-53ff69ebb23b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "MultiThreshold_0: Signed output requires actval < 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mstep_resnet50_convert_to_hw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[151], line 24\u001b[0m, in \u001b[0;36mstep_resnet50_convert_to_hw\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      8\u001b[0m to_hw_transformations \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     to_hw\u001b[38;5;241m.\u001b[39mInferAddStreamsLayer,\n\u001b[1;32m     10\u001b[0m     LowerConvsToMatMul,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     to_hw\u001b[38;5;241m.\u001b[39mInferLabelSelectLayer,\n\u001b[1;32m     22\u001b[0m ]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trn \u001b[38;5;129;01min\u001b[39;00m to_hw_transformations:\n\u001b[0;32m---> 24\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(InferDataLayouts())\n\u001b[1;32m     26\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(GiveUniqueNodeNames())\n",
      "File \u001b[0;32m/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/core/modelwrapper.py:140\u001b[0m, in \u001b[0;36mModelWrapper.transform\u001b[0;34m(self, transformation, make_deepcopy, cleanup)\u001b[0m\n\u001b[1;32m    138\u001b[0m model_was_changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m model_was_changed:\n\u001b[0;32m--> 140\u001b[0m     (transformed_model, model_was_changed) \u001b[38;5;241m=\u001b[39m \u001b[43mtransformation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m    142\u001b[0m     transformed_model\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m/home/gmoreno/uav/finn/src/finn/transformation/fpgadataflow/convert_to_hw_layers.py:248\u001b[0m, in \u001b[0;36mInferThresholdingLayer.apply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# a signed activation should always have a negative bias,\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# but BIPOLAR uses the -1 as 0 encoding so the assert does not apply\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m odt \u001b[38;5;241m!=\u001b[39m DataType[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBIPOLAR\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m odt\u001b[38;5;241m.\u001b[39msigned()) \u001b[38;5;129;01mor\u001b[39;00m (actval \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m), (\n\u001b[1;32m    249\u001b[0m         node\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: Signed output requires actval < 0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m     )\n\u001b[1;32m    252\u001b[0m new_node \u001b[38;5;241m=\u001b[39m helper\u001b[38;5;241m.\u001b[39mmake_node(\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThresholding\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    254\u001b[0m     [thl_input, thl_threshold],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThresholding_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m node\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    267\u001b[0m )\n\u001b[1;32m    269\u001b[0m graph\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39minsert(insert_point, new_node)\n",
      "\u001b[0;31mAssertionError\u001b[0m: MultiThreshold_0: Signed output requires actval < 0"
     ]
    }
   ],
   "source": [
    "model = step_resnet50_convert_to_hw(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e0a4d861-4f25-4fd1-bc1d-5257f5e5d8db",
   "metadata": {},
   "outputs": [
    {
     "ename": "InferenceError",
     "evalue": "[ShapeInferenceError] (op_type:RandomNormal, node name: Thresholding_MultiThreshold_6): [ShapeInferenceError] Inferred shape and existing shape differ in dimension 1: (32) vs (56)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInferenceError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#model = model.transform(to_hw.InferVectorVectorActivation()) # Only if DW convs\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# input quantization (if any) to standalone thresholding\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(to_hw\u001b[38;5;241m.\u001b[39mInferThresholdingLayer())\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_hw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInferConvInpGen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/core/modelwrapper.py:140\u001b[0m, in \u001b[0;36mModelWrapper.transform\u001b[0;34m(self, transformation, make_deepcopy, cleanup)\u001b[0m\n\u001b[1;32m    138\u001b[0m model_was_changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m model_was_changed:\n\u001b[0;32m--> 140\u001b[0m     (transformed_model, model_was_changed) \u001b[38;5;241m=\u001b[39m \u001b[43mtransformation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m    142\u001b[0m     transformed_model\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m/home/gmoreno/uav/finn/src/finn/transformation/fpgadataflow/convert_to_hw_layers.py:178\u001b[0m, in \u001b[0;36mInferConvInpGen.apply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    176\u001b[0m         graph_modified \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m graph_modified:\n\u001b[0;32m--> 178\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mInferShapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(InferDataTypes())\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (model, graph_modified)\n",
      "File \u001b[0;32m/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/core/modelwrapper.py:140\u001b[0m, in \u001b[0;36mModelWrapper.transform\u001b[0;34m(self, transformation, make_deepcopy, cleanup)\u001b[0m\n\u001b[1;32m    138\u001b[0m model_was_changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m model_was_changed:\n\u001b[0;32m--> 140\u001b[0m     (transformed_model, model_was_changed) \u001b[38;5;241m=\u001b[39m \u001b[43mtransformation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m    142\u001b[0m     transformed_model\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/infer_shapes.py:90\u001b[0m, in \u001b[0;36mInferShapes.apply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     88\u001b[0m hidden_ops \u001b[38;5;241m=\u001b[39m _hide_finn_ops(model)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# call regular ONNX shape inference\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m model \u001b[38;5;241m=\u001b[39m ModelWrapper(\u001b[43msi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# bring back hidden ops\u001b[39;00m\n\u001b[1;32m     92\u001b[0m _restore_finn_ops(model, hidden_ops)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/onnx/shape_inference.py:40\u001b[0m, in \u001b[0;36minfer_shapes\u001b[0;34m(model, check_type, strict_mode, data_prop)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, (ModelProto, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[1;32m     39\u001b[0m     model_str \u001b[38;5;241m=\u001b[39m model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mSerializeToString()\n\u001b[0;32m---> 40\u001b[0m     inferred_model_str \u001b[38;5;241m=\u001b[39m \u001b[43mC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_shapes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_prop\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m onnx\u001b[38;5;241m.\u001b[39mload_from_string(inferred_model_str)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;31mInferenceError\u001b[0m: [ShapeInferenceError] (op_type:RandomNormal, node name: Thresholding_MultiThreshold_6): [ShapeInferenceError] Inferred shape and existing shape differ in dimension 1: (32) vs (56)"
     ]
    }
   ],
   "source": [
    "# model = model.transform(to_hw.InferAddStreamsLayer())\n",
    "\n",
    "# model = model.transform(to_hw.InferBinaryMatrixVectorActivation())\n",
    "# model = model.transform(to_hw.InferQuantizedMatrixVectorActivation())\n",
    "# #model = model.transform(to_hw.InferVectorVectorActivation()) # Only if DW convs\n",
    "\n",
    "# # input quantization (if any) to standalone thresholding\n",
    "# model = model.transform(to_hw.InferThresholdingLayer())\n",
    "\n",
    "# model = model.transform(to_hw.InferConvInpGen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "21eb9846-997c-4cbc-b9b2-6a51ab3237f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_hw_layers = models_folder + '/07_fin_hw_layers.onnx'\n",
    "model.save(finn_hw_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4bc042f1-5b8d-44fb-b7d5-ce402294fae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_models/07_fin_hw_layers.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f79288c14b0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_hw_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7b546-5615-4cbd-8202-a6d43d685652",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(to_hw.InferPool())\n",
    "model = model.transform(to_hw.InferStreamingMaxPool())\n",
    "model = model.transform(to_hw.InferConvInpGen())\n",
    "\n",
    "# get rid of Reshape(-1, 1) operation between hw nodes \n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "\n",
    "# get rid of Tranpose -> Tranpose identity seq\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "# infer tensor data layouts\n",
    "model = model.transform(InferDataLayouts())\n",
    "\n",
    "model = model.transform(Streamline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f6581c2-b961-4544-97bf-d67acc6c0040",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_hw_layers = models_folder + '/07_fin_hw_layers.onnx'\n",
    "model.save(finn_hw_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b23bd3ad-9e1c-44b9-8107-f867688694f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_models/07_fin_hw_layers.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f09045edd80>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_hw_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c05f983-59b8-4e86-bb05-6abfac036a86",
   "metadata": {},
   "source": [
    "# Dataflow Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bef29c49-b692-4833-bdce-86b7c661e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_hw_layers)\n",
    "parent_model = model.transform(CreateDataflowPartition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b12ea7e0-99c8-47dd-ae6d-2d78617c0c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_parent_filename = models_folder + '/00_finn_dataflow_parent.onnx'\n",
    "parent_model.save(finn_parent_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8dcd845-4380-4573-b822-d081ddd1c6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_models/00_finn_dataflow_parent.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f09045eebf0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_parent_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72d9ac0b-66e7-4369-9845-4e40e395d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_filename = sdp_node.get_nodeattr(\"model\")\n",
    "dataflow_model = ModelWrapper(dataflow_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b9153-30ca-4c0a-a352-ea557fb9452a",
   "metadata": {},
   "source": [
    "# Specialize Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "51f62b04-9c4e-42f2-aebc-8c10a81f4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce2cc8-6845-4753-9717-99258b5e4a6c",
   "metadata": {},
   "source": [
    "### Change Padding Nodes to HLS, so Auto Folding can be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc8c05ff-aec6-4dff-846a-671bfaf68286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node FMPadding_0 forced to HLS\n",
      "Node FMPadding_1 forced to HLS\n",
      "Node FMPadding_2 forced to HLS\n",
      "Node FMPadding_3 forced to HLS\n",
      "Node FMPadding_4 forced to HLS\n",
      "Node FMPadding_5 forced to HLS\n",
      "Node FMPadding_6 forced to HLS\n",
      "Node FMPadding_7 forced to HLS\n",
      "Node FMPadding_8 forced to HLS\n",
      "Node FMPadding_9 forced to HLS\n",
      "Node FMPadding_10 forced to HLS\n"
     ]
    }
   ],
   "source": [
    "FMPadding_node = dataflow_model.get_nodes_by_op_type(\"FMPadding\")\n",
    "\n",
    "for node in FMPadding_node:\n",
    "    node_inst = getCustomOp(node)\n",
    "    node_inst.set_nodeattr(\"preferred_impl_style\", \"hls\")\n",
    "    print(f'Node {node.name} forced to HLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dcaf1258-b22c-4b9f-bfd4-47a21bbc6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataflow partition with a different name for easier access\n",
    "# and specialize the layers to HLS variants\n",
    "dataflow_model = dataflow_model.transform(SpecializeLayers(fpga_part))\n",
    "\n",
    "dataflow_model = dataflow_model.transform(GiveUniqueNodeNames())\n",
    "dataflow_model = dataflow_model.transform(GiveReadableTensorNames())\n",
    "\n",
    "finn_dataflow_filename = models_folder + '/20_finn_dataflow_model.onnx'\n",
    "dataflow_model.save(finn_dataflow_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "733f7c1f-a632-4531-a1a9-651ab6386dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_models/20_finn_dataflow_model.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f09045eec20>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_dataflow_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c124c8b-e399-4e42-b3aa-bfc526c568f0",
   "metadata": {},
   "source": [
    "### Check execution???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed28cd42-2fdf-4482-8732-b103519945ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_dataflow_model = ModelWrapper(finn_parent_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5db2df8-b5ce-4136-bd07-6db6586839f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dict = {\"global_in\": test_ip*255}\n",
    "# output_dict = oxe.execute_onnx(parent_dataflow_model, input_dict)\n",
    "# produced_clean_qonnx = output_dict[list(output_dict.keys())[0]]\n",
    "# produced_clean_qonnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519407a4-c9cb-4a41-9ad2-9e539e5af923",
   "metadata": {},
   "source": [
    "# Folding Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c17f2a8d-2186-47f0-beae-258b50133bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.set_folding import SetFolding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff9d2ae-2345-46c8-b90e-258c12eb23de",
   "metadata": {},
   "source": [
    "**Taregt Cycles Per Frame**\n",
    "\n",
    "If target is 25 FPS, inference time is $\\frac{1}{25}=40ms$\n",
    "\n",
    "If $clk = 10 ns$:\n",
    "$$\n",
    "Target~Cycles~Per~Frame = \\frac{40\\times 10^{-3}}{10\\times 10^{-9}}= 4\\times 10^{6}\n",
    "$$\n",
    "\n",
    "No se tiene en cuenta el tiempo de preprocesado, que en realidad debería ser inexistente, ya que está embebido en el preprocess del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96b60113-5133-488d-93ea-fb09df218e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_dataflow_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1358a51-11ac-46ea-896f-96893d395b69",
   "metadata": {},
   "source": [
    "apply method of SetFolding returns (model, False), so model is [0]\n",
    "\n",
    "maybe it is easier to do: model, _ = folder.apply(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fdd92cef-a6b5-4174-aaad-8e3bdd12ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(SetFolding(\n",
    "    target_cycles_per_frame=4000000,\n",
    "    mvau_wwidth_max=36,\n",
    "    two_pass_relaxation=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96500d41-ef99-47f1-b306-cb129ecc5611",
   "metadata": {},
   "outputs": [],
   "source": [
    "folding_filename = models_folder + '/30_finn_folding.onnx'\n",
    "#model[0].save(folding_filename)\n",
    "model.save(folding_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7d32ab3-c906-4918-9690-18c0267fe4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_models/30_finn_folding.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f09390d6500>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(folding_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3597a82-86be-44b0-8524-bc6bcc600c31",
   "metadata": {},
   "source": [
    "### Check Total Estimated Cycles, looping over each node attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56fd5ac7-d477-4977-936a-0dadb41669c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = model.get_finn_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "60bbdff5-c927-43b6-b3e2-5621d4191c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 estimated cycles: 150528\n",
      "Node 1 estimated cycles: 153228\n",
      "Node 2 estimated cycles: 340053\n",
      "Node 3 estimated cycles: 3612672\n",
      "Node 4 estimated cycles: 401408\n",
      "Node 5 estimated cycles: 415872\n",
      "Node 6 estimated cycles: 3620064\n",
      "Node 7 estimated cycles: 3612672\n",
      "Node 8 estimated cycles: 401408\n",
      "Node 9 estimated cycles: 3211264\n",
      "Node 10 estimated cycles: 100352\n",
      "Node 11 estimated cycles: 1605632\n",
      "Node 12 estimated cycles: 200704\n",
      "Node 13 estimated cycles: 207936\n",
      "Node 14 estimated cycles: 504144\n",
      "Node 15 estimated cycles: 451584\n",
      "Node 16 estimated cycles: 50176\n",
      "Node 17 estimated cycles: 802816\n",
      "Node 18 estimated cycles: 50176\n",
      "Node 19 estimated cycles: 1605632\n",
      "Node 20 estimated cycles: 100352\n",
      "Node 21 estimated cycles: 107648\n",
      "Node 22 estimated cycles: 906976\n",
      "Node 23 estimated cycles: 903168\n",
      "Node 24 estimated cycles: 100352\n",
      "Node 25 estimated cycles: 1605632\n",
      "Node 26 estimated cycles: 50176\n",
      "Node 27 estimated cycles: 1605632\n",
      "Node 28 estimated cycles: 100352\n",
      "Node 29 estimated cycles: 107648\n",
      "Node 30 estimated cycles: 255760\n",
      "Node 31 estimated cycles: 225792\n",
      "Node 32 estimated cycles: 25088\n",
      "Node 33 estimated cycles: 602112\n",
      "Node 34 estimated cycles: 18816\n",
      "Node 35 estimated cycles: 903168\n",
      "Node 36 estimated cycles: 37632\n",
      "Node 37 estimated cycles: 43200\n",
      "Node 38 estimated cycles: 341712\n",
      "Node 39 estimated cycles: 338688\n",
      "Node 40 estimated cycles: 37632\n",
      "Node 41 estimated cycles: 903168\n",
      "Node 42 estimated cycles: 18816\n",
      "Node 43 estimated cycles: 1806336\n",
      "Node 44 estimated cycles: 75264\n",
      "Node 45 estimated cycles: 86400\n",
      "Node 46 estimated cycles: 196892\n",
      "Node 47 estimated cycles: 169344\n",
      "Node 48 estimated cycles: 18816\n",
      "Node 49 estimated cycles: 602112\n",
      "Node 50 estimated cycles: 6272\n",
      "Node 51 estimated cycles: 802816\n",
      "Node 52 estimated cycles: 25088\n",
      "Node 53 estimated cycles: 32768\n",
      "Node 54 estimated cycles: 230272\n",
      "Node 55 estimated cycles: 225792\n",
      "Node 56 estimated cycles: 25088\n",
      "Node 57 estimated cycles: 802816\n",
      "Node 58 estimated cycles: 6272\n",
      "Node 59 estimated cycles: 802816\n",
      "Node 60 estimated cycles: 25088\n",
      "Node 61 estimated cycles: 32768\n",
      "Node 62 estimated cycles: 230272\n",
      "Node 63 estimated cycles: 225792\n",
      "Node 64 estimated cycles: 25088\n",
      "Node 65 estimated cycles: 802816\n",
      "Node 66 estimated cycles: 6272\n",
      "Node 67 estimated cycles: 401408\n",
      "Node 68 estimated cycles: 12544\n",
      "Node 69 estimated cycles: 16384\n",
      "Node 70 estimated cycles: 115136\n",
      "Node 71 estimated cycles: 112896\n",
      "Node 72 estimated cycles: 12544\n",
      "Node 73 estimated cycles: 802816\n",
      "Node 74 estimated cycles: 12544\n",
      "Node 75 estimated cycles: 1605632\n",
      "Node 76 estimated cycles: 25088\n",
      "Node 77 estimated cycles: 32768\n",
      "Node 78 estimated cycles: 230272\n",
      "Node 79 estimated cycles: 225792\n",
      "Node 80 estimated cycles: 25088\n",
      "Node 81 estimated cycles: 1605632\n",
      "Node 82 estimated cycles: 12544\n",
      "Node 83 estimated cycles: 1605632\n",
      "Node 84 estimated cycles: 25088\n",
      "Node 85 estimated cycles: 75123\n",
      "Node 86 estimated cycles: 25088\n",
      "Node 87 estimated cycles: 256\n",
      "Node 88 estimated cycles: 2\n",
      "\n",
      "Total estimated cycles: 45081378\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "total_cycles = []\n",
    "for node in all_nodes:\n",
    "    my_node = getCustomOp(node)\n",
    "    node_cycles = my_node.get_nodeattr(\"cycles_estimate\")\n",
    "    total_cycles.append(node_cycles)\n",
    "    print(f'Node {i} estimated cycles: {node_cycles}')\n",
    "    i += 1\n",
    "print(f'\\nTotal estimated cycles: {np.array(total_cycles).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346b1a9-d48e-409c-a316-828f3350f502",
   "metadata": {},
   "source": [
    "# Minimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5528e3a-c5fe-46b7-91d2-cb9a4ce5b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.minimize_accumulator_width import (\n",
    "    MinimizeAccumulatorWidth,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.minimize_weight_bit_width import (\n",
    "    MinimizeWeightBitWidth,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6cb4d663-2497-4e2e-a375-9cc6b0060434",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(folding_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a6bffa3-db61-4bf9-ba52-b9fa1c47b23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_1: INT32 -> INT15 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_2: INT32 -> INT10 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_3: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_4: INT32 -> INT10 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_5: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_6: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_7: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_8: INT32 -> INT10 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_9: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_10: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_11: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_12: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_13: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_14: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_15: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_16: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_17: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_18: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_19: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_20: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_21: INT32 -> INT13 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_22: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_23: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_24: INT32 -> INT13 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_25: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_26: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_27: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_28: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_29: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_30: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_31: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_32: INT32 -> INT21 \n",
      "  warnings.warn(warn_str)\n"
     ]
    }
   ],
   "source": [
    "model = model.transform(MinimizeAccumulatorWidth())\n",
    "model = model.transform(MinimizeWeightBitWidth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6653c288-15f1-4972-bbfa-101cdffed607",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize_filename = models_folder + '/31_finn_minimize.onnx'\n",
    "model.save(minimize_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1a85c57-19c4-4b87-a918-345b58160385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_models/31_finn_minimize.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0939110520>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(minimize_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6d687b-0494-4cd1-80ac-070d14553677",
   "metadata": {},
   "source": [
    "# HW IP Generation: PrepareIP and HLSSynthIP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "81b8ccc6-0fe0-4bde-824f-e6f0bd51ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from finn.transformation.fpgadataflow.prepare_ip import PrepareIP\n",
    "# from finn.transformation.fpgadataflow.hlssynth_ip import HLSSynthIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce0be8cf-bb21-41f0-9f6a-cc55edadd683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(minimize_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "76818f0f-02d5-43aa-b65d-9d052db23336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.transform(PrepareIP(fpga_part, target_clk_ns))\n",
    "# model = model.transform(HLSSynthIP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "63c37ba9-8d8b-4083-80c5-6b1967980bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hw_filename = models_folder + '32_finn_hw_ipgen.onnx'\n",
    "# model.save(hw_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d82f9a23-1a14-44f7-94b9-52f3f60f5eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(hw_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b224fe1f-5886-4439-b572-223bceb0ba16",
   "metadata": {},
   "source": [
    "# FIFO depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "576e559b-d622-40ed-8132-fad3107b02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.set_fifo_depths import InsertAndSetFIFODepths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1f029018-824e-4303-965e-3428cabd53a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ModelWrapper(hw_filename)\n",
    "\n",
    "# model = ModelWrapper(minimize_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ad09844f-392b-4abc-b2ae-895862cb5448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.transform(InsertAndSetFIFODepths(\n",
    "#     fpgapart=fpga_part,\n",
    "#     clk_ns=10.0,\n",
    "#     max_qsrl_depth=256,\n",
    "#     max_depth=None,\n",
    "#     swg_exception=False,#True, # Used to optimize convolution FIFOs, splitting in several with Power of Two\n",
    "#     vivado_ram_style=\"auto\",\n",
    "#     force_python_sim=False)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e6c427a1-5ff2-4083-9695-ab7742683ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifo_filename = models_folder + '31_finn_fifo.onnx'\n",
    "# #model[0].save(fifo_filename)\n",
    "# model.save(fifo_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "23b843e2-0bc4-4929-817d-eca89b65a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(fifo_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3322c539-37d1-4fa1-ae08-dcd8d916f7e3",
   "metadata": {},
   "source": [
    "### Streamline FIFOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a7a18232-1569-4130-9b7a-15026bc8583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.set_fifo_depths import SplitLargeFIFOs\n",
    "from finn.transformation.fpgadataflow.set_fifo_depths import RemoveShallowFIFOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "af7381a6-5cdd-4875-9e1e-8395c8549d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model[0].transform(SplitLargeFIFOs())\n",
    "\n",
    "# model = model.transform(SplitLargeFIFOs())\n",
    "# model = model.transform(RemoveShallowFIFOs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fe072021-5b59-49e0-85dc-ca0d1e2fd84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after FIFOs are ready to go, call PrepareIP and HLSSynthIP again\n",
    "# this will only run for the new nodes (e.g. FIFOs and DWCs) -> DWCs for Mobilenet\n",
    "# model = model.transform(PrepareIP(fpga_part, target_clk_ns))\n",
    "# model = model.transform(HLSSynthIP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8cb88151-c03d-4b1c-8c01-bd1dae5fae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifo_streamline_filename = models_folder + '33_finn_fifo_streamline.onnx'\n",
    "# model.save(fifo_streamline_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec70cde2-09ba-4fdd-b6f8-454121ff6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(fifo_streamline_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e049589-e6f3-4ba2-9a89-dd8a7a947b50",
   "metadata": {},
   "source": [
    "# PYNQ Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c5ee6904-e30e-4a68-978b-59571c1edc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db01d436-01ed-4a5e-aca6-d992ad5edea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(fifo_streamline_filename)\n",
    "# model = model.transform(ZynqBuild(platform = pynq_board, period_ns = target_clk_ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d4726f80-8fbb-4991-b7cb-937b38e8f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8e466a10-dc61-499c-aacc-d56e0a34a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.transform(MakePYNQDriver(\"zynq-iodma\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "399688a0-b838-4752-9b41-d989c28123d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pynq_driver_filename = '/40_pynq_driver.onnx'\n",
    "# model.save(pynq_driver_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
