{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae273e97-e39a-4f34-bc2e-ae81be921187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet\n",
    "from brevitas.export import export_qonnx\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdc67a5-2c42-4b2e-bb71-36ceacf8beaf",
   "metadata": {},
   "source": [
    "# Model and Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7411d5e8-0636-4808-a8cd-f7bb7942e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = resnet.quant_resnet18().to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be5160df-c134-4fc6-92ff-7eca38ddfdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 3, 32, 32)\n",
    "dummy_in = torch.randn(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "baf626f0-1b49-4473-8c87-72067d1254d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = resnet18(dummy_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "addfd751-284d-492d-b227-985a03105502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.0170, -1.6568,  2.6768,  3.4622,  6.6536,  1.1862,  2.1534, -6.0321,\n",
       "          6.0447, -3.0883]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff104a64-9c32-4c00-9bb2-6f2bf8c09652",
   "metadata": {},
   "source": [
    "# Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "776e982b-2f9a-4a94-bc55-ae14d3a2fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_filename = './resnet18/resnet18_model.onnx'\n",
    "resnet18.eval();\n",
    "export_qonnx(resnet18, torch.randn(input_shape), resnet18_filename);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b185cbb1-408d-41b4-91d0-2ccd442e6696",
   "metadata": {},
   "source": [
    "# Netron visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "265087f4-8630-4e66-a742-f1123d04b357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showSrc, showInNetron\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19fdc523-56e9-4e46-8646-64e91e7bbf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './resnet18/resnet18_model.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f28073b9720>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(resnet18_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22003136-77e4-4940-afb6-2a496c2987f5",
   "metadata": {},
   "source": [
    "# Tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2690d941-47d4-42a3-8687-18b5ab9a6499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "\n",
    "from qonnx.transformation.general import (\n",
    "    ConvertSubToAdd,\n",
    "    ConvertDivToMul,\n",
    "    GiveReadableTensorNames,\n",
    "    GiveUniqueNodeNames,\n",
    "    SortGraph,\n",
    "    RemoveUnusedTensors,\n",
    "    GiveUniqueParameterTensors,\n",
    "    RemoveStaticGraphInputs,\n",
    "    ApplyConfig,\n",
    ")\n",
    "\n",
    "from finn.transformation.streamline.absorb import (\n",
    "    AbsorbScalarMulAddIntoTopK,\n",
    "    AbsorbAddIntoMultiThreshold,\n",
    "    AbsorbMulIntoMultiThreshold,\n",
    "    FactorOutMulSignMagnitude,\n",
    "    Absorb1BitMulIntoMatMul,\n",
    "    Absorb1BitMulIntoConv,\n",
    "    AbsorbConsecutiveTransposes,\n",
    "    AbsorbTransposeIntoMultiThreshold,\n",
    ")\n",
    "\n",
    "from finn.transformation.streamline.collapse_repeated import (\n",
    "    CollapseRepeatedAdd,\n",
    "    CollapseRepeatedMul,\n",
    ")\n",
    "\n",
    "from finn.transformation.streamline.reorder import (\n",
    "    MoveAddPastMul,\n",
    "    MoveScalarMulPastMatMul,\n",
    "    MoveScalarAddPastMatMul,\n",
    "    MoveAddPastConv,\n",
    "    MoveScalarMulPastConv,\n",
    "    MoveScalarLinearPastInvariants,\n",
    "    MoveMaxPoolPastMultiThreshold,\n",
    ")\n",
    "\n",
    "from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "from finn.transformation.streamline.sign_to_thres import ConvertSignToThres\n",
    "from qonnx.transformation.batchnorm_to_affine import BatchNormToAffine\n",
    "\n",
    "# just for not linear\n",
    "from finn.transformation.streamline.reorder import (\n",
    "    MoveLinearPastEltwiseAdd,\n",
    "    MoveLinearPastFork,\n",
    ")\n",
    "\n",
    "from qonnx.transformation.double_to_single_float import DoubleToSingleFloat\n",
    "from qonnx.transformation.remove import RemoveIdentityOps\n",
    "from qonnx.core.datatype import DataType\n",
    "\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.insert_topk import InsertTopK\n",
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "\n",
    "from finn.builder.build_dataflow_config import (\n",
    "    DataflowBuildConfig,\n",
    "    ShellFlowType,\n",
    ")\n",
    "\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fa8a767-92ab-4d33-904f-d03d2749f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(resnet18_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74736966-c38e-4cf4-ad26-a5665184a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(GiveUniqueParameterTensors())\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(InsertTopK())\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12d57411-6f0b-42a9-a2e6-06f8ed6aa7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_tidy = './resnet18/02_finn_tidy.onnx'\n",
    "model.save(finn_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf1c86f5-ab7a-499f-8d33-c0dad38e4318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './resnet18/02_finn_tidy.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f28042552a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89df064-b78e-4752-8348-11849299ddd4",
   "metadata": {},
   "source": [
    "# Streamline Linear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be0c4e31-59f3-406f-ad2e-af3d4659eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_resnet50_streamline_linear(model: ModelWrapper):\n",
    "    streamline_transformations = [\n",
    "        AbsorbScalarMulAddIntoTopK(),  # before MoveAddPastMul to avoid int->float\n",
    "        ConvertSubToAdd(),\n",
    "        ConvertDivToMul(),\n",
    "        RemoveIdentityOps(),\n",
    "        CollapseRepeatedMul(),\n",
    "        BatchNormToAffine(),\n",
    "        ConvertSignToThres(),\n",
    "        MoveAddPastMul(),\n",
    "        MoveScalarAddPastMatMul(),\n",
    "        MoveAddPastConv(),\n",
    "        MoveScalarMulPastMatMul(),\n",
    "        MoveScalarMulPastConv(),\n",
    "        MoveScalarLinearPastInvariants(),\n",
    "        MoveAddPastMul(),\n",
    "        CollapseRepeatedAdd(),\n",
    "        CollapseRepeatedMul(),\n",
    "        AbsorbAddIntoMultiThreshold(),\n",
    "        FactorOutMulSignMagnitude(),\n",
    "        MoveMaxPoolPastMultiThreshold(),\n",
    "        AbsorbMulIntoMultiThreshold(),\n",
    "        # Absorb1BitMulIntoMatMul(),\n",
    "        # Absorb1BitMulIntoConv(),\n",
    "        RoundAndClipThresholds(),\n",
    "    ]\n",
    "    for trn in streamline_transformations:\n",
    "        model = model.transform(trn)\n",
    "        model = model.transform(GiveUniqueNodeNames())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab133aa-e404-4dda-b58b-a3dcb693c48e",
   "metadata": {},
   "source": [
    "# Streamline Non Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "378006eb-6bea-45df-a167-22054feea2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_resnet50_streamline_nonlinear(model: ModelWrapper):\n",
    "    streamline_transformations = [\n",
    "        MoveLinearPastEltwiseAdd(),\n",
    "        MoveLinearPastFork(),\n",
    "    ]\n",
    "    for trn in streamline_transformations:\n",
    "        model = model.transform(trn)\n",
    "        model = model.transform(GiveUniqueNodeNames())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfcc0da-383a-48e5-a952-f140b42f5acf",
   "metadata": {},
   "source": [
    "# Streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f85411c-193f-424f-be84-0cdd6dd4bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_resnet50_streamline(model: ModelWrapper):\n",
    "    for iter_id in range(4):\n",
    "        model = step_resnet50_streamline_linear(model)\n",
    "        model = step_resnet50_streamline_nonlinear(model)\n",
    "\n",
    "        # big loop tidy up\n",
    "        model = model.transform(RemoveUnusedTensors())\n",
    "        model = model.transform(GiveReadableTensorNames())\n",
    "        model = model.transform(InferDataTypes())\n",
    "        model = model.transform(SortGraph())\n",
    "\n",
    "    model = model.transform(DoubleToSingleFloat())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3dc3df0-7dab-4329-9984-4375fe2f8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be7c3f73-e414-4289-8e8a-18d39586d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = step_resnet50_streamline(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5de8bf2c-8ebd-45f7-b5e4-0a08b4f5522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_streamline = './resnet18/03_finn_streamline.onnx'\n",
    "model.save(finn_streamline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0d24954-bee7-4be6-8d1b-f506ac1056ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './resnet18/03_finn_streamline.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f2806f734c0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_streamline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983d3a1a-d836-49d3-89fc-e9f4233936f9",
   "metadata": {},
   "source": [
    "# To HW Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1de651df-69dd-43ee-bdca-5ca22e39daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_resnet50_convert_to_hw(model: ModelWrapper):\n",
    "    model.set_tensor_datatype(model.graph.input[0].name, DataType[\"UINT8\"])\n",
    "    model = model.transform(InferDataLayouts())\n",
    "    model = model.transform(DoubleToSingleFloat())\n",
    "    model = model.transform(InferDataTypes())\n",
    "    model = model.transform(SortGraph())\n",
    "\n",
    "    to_hw_transformations = [\n",
    "        to_hw.InferAddStreamsLayer,\n",
    "        LowerConvsToMatMul,\n",
    "        to_hw.InferChannelwiseLinearLayer,\n",
    "        to_hw.InferPool,\n",
    "        AbsorbTransposeIntoMultiThreshold,\n",
    "        RoundAndClipThresholds,\n",
    "        to_hw.InferQuantizedMatrixVectorActivation,\n",
    "        to_hw.InferThresholdingLayer,\n",
    "        AbsorbConsecutiveTransposes,\n",
    "        to_hw.InferConvInpGen,\n",
    "        to_hw.InferDuplicateStreamsLayer,\n",
    "        to_hw.InferLabelSelectLayer,\n",
    "    ]\n",
    "    for trn in to_hw_transformations:\n",
    "        model = model.transform(trn())\n",
    "        model = model.transform(InferDataLayouts())\n",
    "        model = model.transform(GiveUniqueNodeNames())\n",
    "        model = model.transform(InferDataTypes())\n",
    "\n",
    "    model = model.transform(RemoveCNVtoFCFlatten())\n",
    "    model = model.transform(GiveReadableTensorNames())\n",
    "    model = model.transform(RemoveUnusedTensors())\n",
    "    model = model.transform(SortGraph())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df17d7fe-1a9d-42a9-a633-6da05727e432",
   "metadata": {},
   "source": [
    "# Modify Add Nodes for Int Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13be5b5-1d6d-4266-aeb6-b8f881eeec92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9b7b636-8c12-4022-8cd0-bdaba4a14c30",
   "metadata": {},
   "source": [
    "# Custom Add to HW with prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc80b1b5-af0b-49c5-86f1-7de4e6bed7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qonnx.core.data_layout as DataLayout\n",
    "import warnings\n",
    "from onnx import TensorProto, helper\n",
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "from qonnx.transformation.base import Transformation\n",
    "from qonnx.transformation.general import SortGraph\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.util.basic import get_by_name\n",
    "from qonnx.util.onnx import nchw_to_nhwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "da5d6883-dc54-4feb-bab6-3e1ce498df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_InferAddStreamsLayer(Transformation):\n",
    "    \"\"\"Convert any Add into a AddStreams HW layer.\"\"\"\n",
    "\n",
    "    def apply(self, model):\n",
    "        graph = model.graph\n",
    "        node_ind = 0\n",
    "        graph_modified = False\n",
    "        for node in graph.node:\n",
    "            node_ind += 1\n",
    "            if node.op_type == \"Add\":\n",
    "                in0 = node.input[0]\n",
    "                in1 = node.input[1]\n",
    "                result = node.output[0]\n",
    "                in0_shape = model.get_tensor_shape(in0)\n",
    "                in1_shape = model.get_tensor_shape(in1)\n",
    "                in0_static = not (model.get_initializer(in0) is None)\n",
    "                in1_static = not (model.get_initializer(in1) is None)\n",
    "\n",
    "                # skip if different shapes on inputs\n",
    "                if in0_shape != in1_shape:\n",
    "                    print(f'Skipping node {node.name} due to different shapes')\n",
    "                    continue\n",
    "                # skip if any of inputs have initializers\n",
    "                # (this node is meant for adding two dynamic streams)\n",
    "                if in0_static or in1_static:\n",
    "                    print(f'Skipping node {node.name} due to static input')\n",
    "                    continue\n",
    "\n",
    "                idt0 = model.get_tensor_datatype(in0)\n",
    "                idt1 = model.get_tensor_datatype(in1)\n",
    "\n",
    "                # skip if different data types on inputs\n",
    "                if idt0 != idt1:\n",
    "                    print(f'Skipping node {node.name} due to different input datatypes')\n",
    "                    continue\n",
    "\n",
    "                idt = idt0\n",
    "\n",
    "                skip conversion for layers with float input\n",
    "                if not idt.is_integer():\n",
    "                    print(f'Skipping node {node.name} due to float input datatype')\n",
    "                    continue\n",
    "\n",
    "                # check layout and convert if necessary\n",
    "                in0_layout = model.get_tensor_layout(in0)\n",
    "                in1_layout = model.get_tensor_layout(in1)\n",
    "                result_layout = model.get_tensor_layout(result)\n",
    "\n",
    "                if in0_layout == DataLayout.NCHW:\n",
    "                    in0 = nchw_to_nhwc(in0, model, node_ind)\n",
    "                    node_ind += 1\n",
    "                    in0_shape = model.get_tensor_shape(in0)\n",
    "\n",
    "                if in1_layout == DataLayout.NCHW:\n",
    "                    in1 = nchw_to_nhwc(in1, model, node_ind)\n",
    "                    node_ind += 1\n",
    "                    in1_shape = model.get_tensor_shape(in1)\n",
    "\n",
    "                # keep track of where we need to insert the HW Op\n",
    "                # it has to be ahead of the output transform\n",
    "                insert_point = node_ind\n",
    "\n",
    "                if result_layout == DataLayout.NCHW:\n",
    "                    result = nchw_to_nhwc(result, model, node_ind, reverse=True)\n",
    "                    node_ind += 1\n",
    "\n",
    "                # now safe to assume num_channels is size of last dimension\n",
    "                num_channels = int(in0_shape[-1])\n",
    "                # create node with no parallelization first\n",
    "                pe = 1\n",
    "\n",
    "                # create and insert new AddStreams node\n",
    "                new_node = helper.make_node(\n",
    "                    \"AddStreams\",\n",
    "                    [in0, in1],\n",
    "                    [result],\n",
    "                    domain=\"finn.custom_op.fpgadataflow\",\n",
    "                    backend=\"fpgadataflow\",\n",
    "                    NumChannels=num_channels,\n",
    "                    PE=pe,\n",
    "                    inputDataType=idt.name,\n",
    "                    numInputVectors=in0_shape[:-1],\n",
    "                    name=\"AddStreams_\" + node.name,\n",
    "                )\n",
    "                graph.node.insert(insert_point, new_node)\n",
    "                # remove old node\n",
    "                graph.node.remove(node)\n",
    "                graph_modified = True\n",
    "\n",
    "        if graph_modified:\n",
    "            model = model.transform(InferShapes())\n",
    "            model = model.transform(InferDataTypes())\n",
    "        return (model, graph_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12e63cd4-6230-4235-84ca-6dba0538fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_streamline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b16f7dd-049b-4e7c-9fa5-b3f949e9912b",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Undefined for ScaledIntType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCustom_InferAddStreamsLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/core/modelwrapper.py:140\u001b[0m, in \u001b[0;36mModelWrapper.transform\u001b[0;34m(self, transformation, make_deepcopy, cleanup)\u001b[0m\n\u001b[1;32m    138\u001b[0m model_was_changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m model_was_changed:\n\u001b[0;32m--> 140\u001b[0m     (transformed_model, model_was_changed) \u001b[38;5;241m=\u001b[39m \u001b[43mtransformation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m    142\u001b[0m     transformed_model\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "Cell \u001b[0;32mIn[58], line 92\u001b[0m, in \u001b[0;36mCustom_InferAddStreamsLayer.apply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m graph_modified:\n\u001b[1;32m     91\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(InferShapes())\n\u001b[0;32m---> 92\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mInferDataTypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (model, graph_modified)\n",
      "File \u001b[0;32m/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/core/modelwrapper.py:140\u001b[0m, in \u001b[0;36mModelWrapper.transform\u001b[0;34m(self, transformation, make_deepcopy, cleanup)\u001b[0m\n\u001b[1;32m    138\u001b[0m model_was_changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m model_was_changed:\n\u001b[0;32m--> 140\u001b[0m     (transformed_model, model_was_changed) \u001b[38;5;241m=\u001b[39m \u001b[43mtransformation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m    142\u001b[0m     transformed_model\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/infer_datatypes.py:153\u001b[0m, in \u001b[0;36mInferDataTypes.apply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    151\u001b[0m graph_modified \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mnode:\n\u001b[0;32m--> 153\u001b[0m     graph_modified \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m_infer_node_datatype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (model, graph_modified)\n",
      "File \u001b[0;32m/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/infer_datatypes.py:90\u001b[0m, in \u001b[0;36m_infer_node_datatype\u001b[0;34m(model, node)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# lookup op_type in registry of CustomOps\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     inst \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mgetCustomOp(node)\n\u001b[0;32m---> 90\u001b[0m     \u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_node_datatype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# exception if op_type is not supported\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustom op_type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is currently not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m op_type)\n",
      "File \u001b[0;32m/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/addstreams.py:101\u001b[0m, in \u001b[0;36mAddStreams.infer_node_datatype\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_nodeattr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputDataType\u001b[39m\u001b[38;5;124m\"\u001b[39m, idt\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# enforce output data type (calculated based on idt)\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m odt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_output_datatype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m model\u001b[38;5;241m.\u001b[39mset_tensor_datatype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monnx_node\u001b[38;5;241m.\u001b[39moutput[\u001b[38;5;241m0\u001b[39m], odt)\n",
      "File \u001b[0;32m/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/addstreams.py:118\u001b[0m, in \u001b[0;36mAddStreams.get_output_datatype\u001b[0;34m(self, ind)\u001b[0m\n\u001b[1;32m    116\u001b[0m idt \u001b[38;5;241m=\u001b[39m DataType[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_nodeattr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputDataType\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idt\u001b[38;5;241m.\u001b[39msigned():\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataType\u001b[38;5;241m.\u001b[39mget_smallest_possible(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43midt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataType\u001b[38;5;241m.\u001b[39mget_smallest_possible(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m idt\u001b[38;5;241m.\u001b[39mmax())\n",
      "File \u001b[0;32m/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/core/datatype.py:350\u001b[0m, in \u001b[0;36mScaledIntType.min\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUndefined for ScaledIntType\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Undefined for ScaledIntType"
     ]
    }
   ],
   "source": [
    "model = model.transform(Custom_InferAddStreamsLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "095a35a0-ce30-4f8f-82e7-5881883804ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_infer_adds = './resnet18/04_finn_infer_adds.onnx'\n",
    "model.save(finn_infer_adds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ad58187-541e-450c-8cf0-096ad9a79790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './resnet18/04_finn_infer_adds.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f280599cdc0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_infer_adds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23350f7e-2b47-488e-956c-adb4246bef1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
