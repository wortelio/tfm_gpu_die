{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463c1477-b429-4abe-b16e-f51487ed935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "from torch.nn import BatchNorm1d\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Module\n",
    "from torch.nn import ModuleList\n",
    "\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.nn import QuantIdentity\n",
    "from brevitas.nn import QuantConv2d\n",
    "from brevitas.nn import QuantReLU\n",
    "from brevitas.nn import TruncAvgPool2d\n",
    "from brevitas.nn import QuantLinear\n",
    "\n",
    "from brevitas.quant import TruncTo8bit\n",
    "\n",
    "\n",
    "# from brevitas.quant import Int8ActPerTensorFloat # For Quant ADD node\n",
    "from common_imagenet import CommonIntWeightPerTensorQuant\n",
    "from common_imagenet import CommonUintActQuant\n",
    "from common_imagenet import CommonIntActQuant # For initial Q1.7 Identity Layer\n",
    "from tensor_norm import TensorNorm\n",
    "\n",
    "from brevitas.export import export_qonnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c9011-85ab-4877-b5c8-c6c45e8f53bf",
   "metadata": {},
   "source": [
    "# Custom Quantizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "487e789f-3ca2-454c-8f26-a1102cd55645",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyWeightsQuant_PerTensor(CommonIntWeightPerTensorQuant):\n",
    "    restrict_scaling_type = RestrictValueType.POWER_OF_TWO\n",
    "\n",
    "class MyReLUQuant(CommonUintActQuant):\n",
    "    restrict_scaling_type = RestrictValueType.POWER_OF_TWO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990fce3e-24f8-4e2b-9a92-3ba716faea5f",
   "metadata": {},
   "source": [
    "# Tiny Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91f7262e-c8c8-4b2f-abf8-f7ea70e8e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TINY_RESNET(Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 num_classes = 2, \n",
    "                 weight_bit_width = 4,\n",
    "                 act_bit_width = 4, \n",
    "                 in_bit_width = 8, \n",
    "                 in_channels = 3):\n",
    "        super(TINY_RESNET, self).__init__()\n",
    "        \n",
    "        self.conv_features = ModuleList()\n",
    "        self.conv_branch = ModuleList()\n",
    "        self.linear_features = ModuleList()\n",
    "\n",
    "        # Input 230x230x3\n",
    "        self.conv_features.append(QuantIdentity( # for Q1.7 input format -> sign.7bits\n",
    "            act_quant = CommonIntActQuant,\n",
    "            bit_width = in_bit_width,\n",
    "            min_val = -1.0,\n",
    "            max_val = 1.0 - 2.0 ** (-7),\n",
    "            narrow_range = False, \n",
    "            restrict_scaling_type = RestrictValueType.POWER_OF_TWO))\n",
    "\n",
    "        # CNNBlock 224x224\n",
    "            # conv1\n",
    "        self.conv_features.append(\n",
    "            QuantConv2d(\n",
    "                kernel_size=3, stride=1, padding=1,\n",
    "                in_channels=in_channels,\n",
    "                out_channels=12,\n",
    "                bias=False,\n",
    "                weight_quant=MyWeightsQuant_PerTensor,\n",
    "                weight_bit_width=weight_bit_width))\n",
    "        self.conv_features.append(BatchNorm2d(12))\n",
    "        self.conv_features.append(\n",
    "            QuantReLU(\n",
    "                act_quant=MyReLUQuant,\n",
    "                bit_width=act_bit_width, \n",
    "                return_quant_tensor=True))\n",
    "        \n",
    "        # self.conv_features.append(MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # CNNBlock 112x112\n",
    "            # conv2\n",
    "        self.conv_branch.append(\n",
    "            QuantConv2d(\n",
    "                kernel_size=3, stride=1, padding=1,\n",
    "                in_channels=12,\n",
    "                out_channels=12,\n",
    "                bias=False,\n",
    "                weight_quant=MyWeightsQuant_PerTensor,\n",
    "                weight_bit_width=weight_bit_width))\n",
    "        self.conv_branch.append(BatchNorm2d(12))\n",
    "        self.conv_branch.append(\n",
    "            QuantReLU(\n",
    "                act_quant=self.conv_features[-1].act_quant, #MyReLUQuant,\n",
    "                bit_width=act_bit_width, \n",
    "                return_quant_tensor=True))\n",
    "\n",
    "        self.relu_out =  QuantReLU(\n",
    "                act_quant=MyReLUQuant,\n",
    "                bit_width=act_bit_width, \n",
    "                return_quant_tensor=True)\n",
    "        \n",
    "        self.avg_pool = TruncAvgPool2d(\n",
    "                kernel_size=224,  \n",
    "                trunc_quant=TruncTo8bit,\n",
    "                float_to_int_impl_type='FLOOR')\n",
    "\n",
    "        # Linear 1\n",
    "        self.linear_features.append(\n",
    "            QuantLinear(\n",
    "                in_features=12,\n",
    "                out_features=8,\n",
    "                bias=False,\n",
    "                weight_quant=MyWeightsQuant_PerTensor,\n",
    "                weight_bit_width=weight_bit_width))\n",
    "        self.linear_features.append(BatchNorm1d(8))\n",
    "        self.linear_features.append(\n",
    "            QuantReLU(\n",
    "                act_quant=MyReLUQuant,\n",
    "                bit_width=act_bit_width, \n",
    "                return_quant_tensor=False))\n",
    "\n",
    "        # Linear 2\n",
    "        self.linear_features.append(\n",
    "            QuantLinear(\n",
    "                in_features=8,\n",
    "                out_features=2,\n",
    "                bias=False,\n",
    "                weight_quant=MyWeightsQuant_PerTensor,\n",
    "                weight_bit_width=weight_bit_width))\n",
    "        self.linear_features.append(TensorNorm())\n",
    "\n",
    "        self.bipolar_out = QuantIdentity(\n",
    "            quant_type='binary', \n",
    "            scaling_impl_type='const',\n",
    "            bit_width=1, min_val=-1.0, max_val=1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = 2.0 * x - torch.tensor([1.0], device=x.device)\n",
    "        for mod in self.conv_features:\n",
    "            x = mod(x)\n",
    "\n",
    "        # Branch\n",
    "        x_res = self.conv_branch[0](x)\n",
    "        x_res = self.conv_branch[1](x_res)\n",
    "        x_res = self.conv_branch[-1](x_res)\n",
    "        \n",
    "        x = x + x_res\n",
    "        x = self.relu_out(x)\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        for mod in self.linear_features:\n",
    "            x = mod(x)\n",
    "\n",
    "        x = self.bipolar_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f861ce-1362-4bec-b658-818c517a24c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/deps/brevitas/src/brevitas/nn/mixin/base.py:77: UserWarning: Keyword arguments are being passed but they not being used.\n",
      "  warn('Keyword arguments are being passed but they not being used.')\n"
     ]
    }
   ],
   "source": [
    "model_qnn = TINY_RESNET().to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c34946d-14b2-4802-9dec-a6fd402f3210",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 3, 224, 224)\n",
    "# print(summary(model_qnn, input_size=input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afa1f10b-4eba-4fd1-978b-6448998826ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = './step_by_step_tiny_v2'\n",
    "model_qnn_filename = models_folder + '/TINY_Resnet__QONNX.onnx' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63a098b0-f1db-45dc-89c9-57ceb9f84648",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qnn.eval();\n",
    "export_qonnx(model_qnn, torch.randn(input_shape), model_qnn_filename);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fed44b-915d-4f13-bf47-f09b669a065d",
   "metadata": {},
   "source": [
    "# FINN Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda68f6-24c1-4eb3-8796-62c91f570e47",
   "metadata": {},
   "source": [
    "## Load Model and View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf723b71-f555-490c-b185-776f73396c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showSrc, showInNetron\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dff265e-bed5-4efd-92a6-1ee06471f86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './step_by_step_tiny_v2/TINY_Resnet__QONNX.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa864145ed0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(model_qnn_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52bb090-4801-4cd6-91f4-e86048dfcb11",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2150e426-3ba5-4aab-b680-78cd716e2ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qonnx_clean_filename = models_folder + '/01_clean.onnx'\n",
    "qonnx_cleanup(model_qnn_filename, out_file=qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42d9a172-78a4-404f-be19-334b6747409d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_tiny_v2/01_clean.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa75d4b2c20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e71cacf-447e-4a5e-a628-1e4b5188b6a8",
   "metadata": {},
   "source": [
    "## Convert to FINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c2d3af5-b4df-47ba-af6b-2391ba0950c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89512ff2-3de9-435d-9ac0-459a5b4f30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "622516fa-c609-4dc0-86a4-19aafedaaa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(RemoveStaticGraphInputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b36e1b0a-eec1-476d-ac12-6919a911d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_tidy = models_folder + '/02_finn_tidy.onnx'\n",
    "model.save(finn_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb2c21cb-492c-4cee-8e1b-ec8784405cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_tiny_v2/02_finn_tidy.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa75d4e7b20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f9fec5-a30c-4d6f-8e50-4bfb3a674a3f",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b39deb7-0653-4b54-bb09-ac774320547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.pytorch import ToTensor\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f39b02d-f548-4fb8-baa2-9bd0add11fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(finn_tidy)\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "# preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "totensor_pyt = ToTensor()\n",
    "chkpt_preproc_name = models_folder + \"/prepro_node.onnx\"\n",
    "export_qonnx(totensor_pyt, torch.randn(ishape), chkpt_preproc_name)\n",
    "qonnx_cleanup(chkpt_preproc_name, out_file=chkpt_preproc_name)\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "pre_model = pre_model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "# join preprocessing and core model\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "# add input quantization annotation: UINT8 for all BNN-PYNQ models\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e994573e-3b15-4f90-9e4e-4d82b9288ad0",
   "metadata": {},
   "source": [
    "### Tidy again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87c667fd-97b6-4bf5-bd82-ae0f97353bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c8d211b-0a24-4381-b2fe-cc9e92eac928",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_prepro = models_folder + '/03_finn_prepro.onnx'\n",
    "model.save(finn_prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11e7ee6e-aa4b-4e6b-9b32-4ad8d1a45911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_tiny_v2/03_finn_prepro.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa75d4b37f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_prepro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426532b9-8327-4539-a3da-83dbb47a5899",
   "metadata": {},
   "source": [
    "## Streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "deabcd45-ecb5-4e18-b104-862f4c6a8d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "\n",
    "from qonnx.transformation.change_datalayout import ChangeDataLayoutQuantAvgPool2d\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "from finn.transformation.streamline import Streamline\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MoveScalarLinearPastInvariants\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC\n",
    "from finn.transformation.streamline.reorder import MoveLinearPastEltwiseAdd\n",
    "\n",
    "from finn.transformation.streamline.reorder import MoveMulPastFork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "defe695a-fb96-4440-94f3-f2d3bff6620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_prepro)\n",
    "# model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "# model = model.transform(absorb.AbsorbAddIntoMultiThreshold())\n",
    "\n",
    "model = model.transform(MoveMulPastFork())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0442ce55-9fe5-4a44-9723-f7ef26ef5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_mul_add_to_multithres = models_folder + '/040_finn_mul_add_to_multithres.onnx'\n",
    "model.save(finn_mul_add_to_multithres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8de7f1ba-147e-4c78-a29d-e08adf95e29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_tiny_v2/040_finn_mul_add_to_multithres.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa75d4e7f40>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_mul_add_to_multithres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29ca04a-c83a-4f4a-8587-c1b25ade03fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec27c9d8-02d9-4e9b-8e94-0e4fda8aba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_mul_add_to_multithres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff96a0f7-f81c-4acd-b570-b553b4260d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/src/finn/transformation/streamline/absorb.py:66: UserWarning: Threshold or add bias not constant, skipping\n",
      "  warnings.warn(\"Threshold or add bias not constant, skipping\")\n"
     ]
    }
   ],
   "source": [
    "model = model.transform(MoveLinearPastEltwiseAdd())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3fc3c08-f909-4bbc-a776-cd49cd4de373",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_move_mul_past_add = models_folder + '/041_finn_move_mul_past_add.onnx'\n",
    "model.save(finn_move_mul_past_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef008020-7cd5-4b1e-b4c4-e3da9d22a24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_tiny_v2/041_finn_move_mul_past_add.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa75d4b3940>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_move_mul_past_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4af8f13e-9b51-42ee-b79a-083534209322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from finn.transformation.streamline.reorder import MoveTransposePastFork "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c8e134b-ecdd-4572-87af-24c7a328a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_move_mul_past_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eff18e43-f3e8-47b5-bc3a-6567ee4f3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(to_hw.InferAddStreamsLayer())\n",
    "# model = model.transform(MoveTransposePastFork())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83bab094-fcaf-4961-95c9-a1db0c0102bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_add_to_hw = models_folder + '/042_finn_add_to_hw.onnx'\n",
    "model.save(finn_add_to_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "120eb1d7-afc1-432e-b648-f513b8d8aa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_tiny_v2/042_finn_add_to_hw.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa75d4e6ad0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_add_to_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601f942-f731-4860-865e-6edbe61d8c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1041e015-8ad0-49bb-8bbd-eb1b489ff359",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_add_to_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "504dcc1f-bc9c-4e31-a132-d33ac5d9950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(ChangeDataLayoutQuantAvgPool2d())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51c9f1b7-2bab-40a2-9ec8-a84999f29338",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_avgpool = models_folder + '/043_finn_avgpool.onnx'\n",
    "model.save(finn_avgpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7eca122f-b85e-4e1e-959d-8883fa14e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_tiny_v2/043_finn_avgpool.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa75d4b36d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_avgpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a6ac34-7fed-4233-8b0d-24d7fbea4f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a41ea4-cf49-4000-9dd5-5066548fc8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40e917aa-ebb9-4770-80ee-460cad359a91",
   "metadata": {},
   "source": [
    "# Old Streamline plus some test: it does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d96d965e-7920-4183-b3ac-7e6375911892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(finn_prepro)\n",
    "# # model = model.transform(MoveLinearPastEltwiseAdd())\n",
    "# model = model.transform(absorb.AbsorbAddIntoMultiThreshold())\n",
    "# model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "\n",
    "# model = model.transform(MoveScalarLinearPastInvariants())\n",
    "# model = model.transform(Streamline())\n",
    "# model = model.transform(LowerConvsToMatMul())\n",
    "# model = model.transform(MakeMaxPoolNHWC())\n",
    "# model = model.transform(ChangeDataLayoutQuantAvgPool2d())\n",
    "# model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "\n",
    "# model = model.transform(Streamline())\n",
    "# model = model.transform(InferDataLayouts())\n",
    "# model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "864f1a68-a3be-4aa7-8d18-ae6da439c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finn_streamline = models_folder + '/04_finn_streamline.onnx'\n",
    "# model.save(finn_streamline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb88790d-6012-42bc-93e3-7ec9a5aa4c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_tiny_v2/04_finn_streamline.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f92d881c430>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showInNetron(finn_streamline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98f73da-659c-4885-8f3a-05c45d38d15c",
   "metadata": {},
   "source": [
    "# To HW Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a8179a6-5bce-4bcc-8ea7-5bdfdbe73b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "\n",
    "from qonnx.custom_op.registry import getCustomOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e32052d3-830e-4090-9ac0-877f8ced6e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_avgpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5eebb4d-da1a-4d75-b726-e532ed20df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(to_hw.InferQuantizedMatrixVectorActivation())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fece644c-de0b-4bd0-9b67-56ebbdaaa560",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_hw_mvau = models_folder + '/044_finn_hw_mvau.onnx'\n",
    "model.save(finn_hw_mvau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "438e1ddb-d185-4171-b8d2-a524b5040aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_tiny_v2/044_finn_hw_mvau.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa75c4d5810>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_hw_mvau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f31b9-3e8a-43ea-ba4c-e4c71c72ba26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f937d692-7f4d-49af-b79c-3bdd8cfaaae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_hw_mvau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90c0e32a-bf9b-449f-a71e-d726e94579dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(to_hw.InferConvInpGen())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b91408ab-fcb4-4659-9905-7594d663a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_hw_convs = models_folder + '/045_finn_hw_convs.onnx'\n",
    "model.save(finn_hw_convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb75da93-d4a9-44e5-bf92-a034d955e494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_tiny_v2/045_finn_hw_convs.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa75c407e80>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_hw_convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb56bdc-7393-4ed1-a986-c637e2f1eae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed661dd0-c3ac-4753-a00c-d0a08344d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_hw_convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bea65c16-2cf1-4e88-88bc-7b5002791cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(to_hw.InferPool())\n",
    "model = model.transform(to_hw.InferConvInpGen())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b7ec11c-8a9d-40a0-af5e-73755e5e0e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_hw_pool = models_folder + '/046_finn_hw_pool.onnx'\n",
    "model.save(finn_hw_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e3e6e53-ae7d-4bc5-bfeb-f1cb32fb0f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_tiny_v2/046_finn_hw_pool.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa75c4073d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_hw_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efecb11-f594-49d1-a0d8-44e74e74ab2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6495df43-b7ba-4088-9be0-78676bf8c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_hw_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d08482a4-0205-444d-88f6-23f824a9b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(to_hw.InferThresholdingLayer())\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6cd34c43-5e9e-41db-8281-2cbf7b2acaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_hw_multithres_flaten = models_folder + '/047_finn_hw_multithres_flaten.onnx'\n",
    "model.save(finn_hw_multithres_flaten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a8a5a5c-65ec-4737-8f9e-4c816bbf7060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_tiny_v2/047_finn_hw_multithres_flaten.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa762f1b580>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_hw_multithres_flaten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca1cf6-0fb5-457d-b4ad-4a8ccbcba58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd0bab-d225-44b9-8669-11a6472eed2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fa8e19-c37b-44ea-a0b8-6844587f3363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
