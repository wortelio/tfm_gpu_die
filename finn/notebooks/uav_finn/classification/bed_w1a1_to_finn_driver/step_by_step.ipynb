{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a01e4ef-8c3c-4ac1-b5a9-7207f732df90",
   "metadata": {},
   "source": [
    "# Folders setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c48cecf-6faf-4092-b12b-50f26c5ee209",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_folder = './qonnx_models'\n",
    "ori_filename = ori_folder + '/BNN_BED_classifier__best_mean_F1__BIPOLAR_Out__QONNX.onnx'\n",
    "\n",
    "models_folder = './step_by_step_bipolar'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62467796-f923-4641-aea9-f27720817207",
   "metadata": {},
   "source": [
    "# Model Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8ce3e63-8792-41a6-8b31-486dca7d843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showSrc, showInNetron\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7286b856-b37b-42ab-a07b-b01ae0f11a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "qonnx_clean_filename = models_folder + '/01_clean.onnx'\n",
    "qonnx_cleanup(ori_filename, out_file=qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d097b8c-37d6-4745-afab-b924eb46f04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './qonnx_models/BNN_BED_classifier__best_mean_F1__BIPOLAR_Out__QONNX.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0134323eb0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(ori_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32a2061d-8a23-478c-bfe8-57dd0bff238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_bipolar/01_clean.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f00d447c400>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268926d7-65d1-4c9d-9788-7ec8eb978435",
   "metadata": {},
   "source": [
    "# Dummy Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea79dcc1-8ec3-408f-bb60-f8c3f66c5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "import qonnx.core.onnx_exec as oxe\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30887ba6-8764-469c-9baf-6dbd14026f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ip = np.random.randint(low=0, high=256, size=(1, 3, 230, 230)) / 255.\n",
    "test_ip = test_ip.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f9336f4-ff2a-44af-8dbf-0a241c420d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_model = ModelWrapper(qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b56d5680-a591-47d3-8995-ad60d7f27eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict = {\"global_in\": test_ip}\n",
    "output_dict = oxe.execute_onnx(clean_model, input_dict)\n",
    "produced_clean_qonnx = output_dict[list(output_dict.keys())[0]]\n",
    "produced_clean_qonnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a391c5-af4f-4426-ac7f-345bf0a1310b",
   "metadata": {},
   "source": [
    "# Convert to FINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3392e878-1927-4360-8d58-75402552e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66c7d74d-229d-44e8-a0c4-35bb38951a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(RemoveStaticGraphInputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2fea521a-b39a-405d-8181-cf306a167b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_tidy = models_folder + '/02_finn_tidy.onnx'\n",
    "model.save(finn_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f93b85f6-2a27-46ed-92fa-d2fa605fadae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_bipolar/02_finn_tidy.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f00d444be80>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a074441-ef76-4836-bcaa-769972124fe3",
   "metadata": {},
   "source": [
    "# PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fd0bf51-cc0f-47fc-8d2c-6ed3fe805d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from finn.util.pytorch import ToTensor\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.core.datatype import DataType\n",
    "from brevitas.export import export_qonnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "173b59a6-8897-4d57-b25e-d818d4ca65dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/merge_onnx_models.py:70: UserWarning: [MergeONNXModels] opsets for models to merge differ: 14 vs 17, output model will use opset 17\n",
      "  warnings.warn(\n",
      "/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(finn_tidy)\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "# preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "totensor_pyt = ToTensor()\n",
    "chkpt_preproc_name = models_folder + \"/prepro_node.onnx\"\n",
    "export_qonnx(totensor_pyt, torch.randn(ishape), chkpt_preproc_name)\n",
    "qonnx_cleanup(chkpt_preproc_name, out_file=chkpt_preproc_name)\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "pre_model = pre_model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "# join preprocessing and core model\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "# add input quantization annotation: UINT8 for all BNN-PYNQ models\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c9bb0bd-a9b6-42ee-b792-9bbb3b4801b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.infer_datatypes import InferDataTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800e6b66-af2f-4ae8-a1b6-90336c6909f4",
   "metadata": {},
   "source": [
    "### Save prepro after tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6eb18cc8-eef6-45ee-a2be-597ef399a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fa559ff-31f3-42ad-8273-ddf6d9a0759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_prepro = models_folder + '/03_finn_prepro.onnx'\n",
    "model.save(finn_prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d380614-f8d7-4b2b-86df-106ba43ab349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_bipolar/03_finn_prepro.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f00d4449600>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_prepro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57348031-895c-4f9f-a0d1-22ed7969f60f",
   "metadata": {},
   "source": [
    "# Streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8100a86a-9402-4991-85ab-3b06b9d70da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "from qonnx.transformation.change_datalayout import ChangeDataLayoutQuantAvgPool2d\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "from finn.transformation.streamline import Streamline\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MoveScalarLinearPastInvariants\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2aeeda85-a2cb-4210-86a8-4bddcc03acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_prepro)\n",
    "model = model.transform(MoveScalarLinearPastInvariants())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(ChangeDataLayoutQuantAvgPool2d())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "# model = model.transform(absorb.AbsorbAddIntoMultiThreshold())\n",
    "# model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "# model = model.transform(RoundAndClipThresholds())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2e193eb3-6b2e-4752-bb21-c9404c65eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_streamline = models_folder + '/04_finn_streamline.onnx'\n",
    "model.save(finn_streamline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5ab482f9-a66a-4ba6-8f2f-894f53192f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_bipolar/04_finn_streamline.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f00d4703e80>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_streamline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb38327-33bd-4506-ac2c-323c8c632f0f",
   "metadata": {},
   "source": [
    "# HW Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca2691fb-64db-456f-8397-5862940d9d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.basic import pynq_part_map\n",
    "# change this if you have a different PYNQ board, see list above\n",
    "pynq_board = \"Pynq-Z1\"\n",
    "fpga_part = pynq_part_map[pynq_board]\n",
    "target_clk_ns = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5fa7030e-e5d7-48b1-9573-8744043dcccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ultra96': 'xczu3eg-sbva484-1-e', 'Ultra96-V2': 'xczu3eg-sbva484-1-i', 'Pynq-Z1': 'xc7z020clg400-1', 'Pynq-Z2': 'xc7z020clg400-1', 'ZCU102': 'xczu9eg-ffvb1156-2-e', 'ZCU104': 'xczu7ev-ffvc1156-2-e', 'ZCU111': 'xczu28dr-ffvg1517-2-e', 'RFSoC2x2': 'xczu28dr-ffvg1517-2-e', 'RFSoC4x2': 'xczu48dr-ffvg1517-2-e', 'KV260_SOM': 'xck26-sfvc784-2LV-c'}\n",
      "xc7z020clg400-1\n"
     ]
    }
   ],
   "source": [
    "print(pynq_part_map)\n",
    "print(fpga_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "024e8167-ceaa-4a34-b120-460e903a89e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "\n",
    "from qonnx.custom_op.registry import getCustomOp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f186e83-05e0-4b12-8b22-c7c0a60dbc08",
   "metadata": {},
   "source": [
    "### Change last Bipolar Node to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c870c7b-a916-4f2d-a96e-62ef2b42f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(finn_streamline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d1859-ce8d-495a-8d92-63924a696f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multithreshold_node = model.get_nodes_by_op_type(\"MultiThreshold\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad93dfa6-8f04-4d93-9745-236dd49ebddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for node in Multithreshold_node:\n",
    "#     node_inst = getCustomOp(node)\n",
    "#     if node_inst.get_nodeattr(\"out_dtype\") == \"BIPOLAR\":\n",
    "#         node_inst.set_nodeattr(\"out_dtype\", \"BINARY\")\n",
    "#         node_inst.set_nodeattr(\"out_scale\", 1.0)\n",
    "#         node_inst.set_nodeattr(\"out_bias\", 0.0)\n",
    "#         print(f'{node.name} converted from Bipolar to Binary\\n{node}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd450e0d-8166-4eb4-8056-c445dae4aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_out_name = model.graph.output[0].name\n",
    "# global_out_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305bff06-b6f9-43a1-8c74-11a7fb5f67b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.set_tensor_datatype(global_out_name, DataType[\"BINARY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402c8184-8e14-4294-b32d-645f433bd8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finn_bipolar_to_binary = models_folder + '/05_finn_bipolar_to_binary.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9838e02a-25bb-4196-828c-0d6a351542d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(finn_bipolar_to_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66c3a2-50e8-49a6-80a2-016a166450cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(finn_bipolar_to_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f930e3-a725-474c-9b50-0573df8f2a22",
   "metadata": {},
   "source": [
    "### Standlone Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e411e32-f8dd-4295-9b00-eb05759c5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(finn_bipolar_to_binary)\n",
    "\n",
    "# model = model.transform(to_hw.InferThresholdingLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0946a5-0673-476b-bfcf-2de3f16879df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finn_std_alone_thres = models_folder + '/06_finn_std_alone_thres.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801cbcd7-21de-4e58-bc48-be3626c9a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(finn_std_alone_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40976fc2-1593-49e3-9c8c-e2a92a27e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(finn_std_alone_thres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e500c22a-13ea-45c6-822d-f4b24ad0da6d",
   "metadata": {},
   "source": [
    "## Rest of the Streamline Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f315d0e8-fcfd-462b-8e24-bd10712af988",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_streamline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d1444b-2757-4f9f-9f8b-71386acee793",
   "metadata": {},
   "source": [
    "### Convert Multithreshold to INT32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9558d07e-9c38-474a-a58a-6de8cbbd612d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiThreshold_13: node with Float32 annotation\n",
      "MultiThreshold_13: changed to datatype INT32\n"
     ]
    }
   ],
   "source": [
    "# Multithreshold_node = model.get_nodes_by_op_type(\"MultiThreshold\")    \n",
    "\n",
    "# for node in Multithreshold_node:\n",
    "#     if model.get_tensor_datatype(node.input[1]) == \"FLOAT32\":\n",
    "#         print(f'{node.name}: node with Float32 annotation')\n",
    "#         model.set_tensor_datatype(node.input[1], DataType[\"INT32\"])\n",
    "#         print(f'{node.name}: changed to datatype {model.get_tensor_datatype(node.input[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e0a4d861-4f25-4fd1-bc1d-5257f5e5d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(to_hw.InferBinaryMatrixVectorActivation())\n",
    "# Maybe for the first Conv, which receives UINT8 from the input\n",
    "model = model.transform(to_hw.InferQuantizedMatrixVectorActivation())\n",
    "\n",
    "# input quantization (if any) to standalone thresholding\n",
    "model = model.transform(to_hw.InferThresholdingLayer())\n",
    "model = model.transform(to_hw.InferPool())\n",
    "model = model.transform(to_hw.InferStreamingMaxPool())\n",
    "model = model.transform(to_hw.InferConvInpGen())\n",
    "\n",
    "# get rid of Reshape(-1, 1) operation between hw nodes \n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "\n",
    "# get rid of Tranpose -> Tranpose identity seq\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "# infer tensor data layouts\n",
    "model = model.transform(InferDataLayouts())\n",
    "\n",
    "model = model.transform(Streamline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f6581c2-b961-4544-97bf-d67acc6c0040",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_hw_layers = models_folder + '/05_fin_hw_layers.onnx'\n",
    "model.save(finn_hw_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b23bd3ad-9e1c-44b9-8107-f867688694f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_bipolar/05_fin_hw_layers.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f00d473b8e0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_hw_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c05f983-59b8-4e86-bb05-6abfac036a86",
   "metadata": {},
   "source": [
    "# Dataflow Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bef29c49-b692-4833-bdce-86b7c661e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_hw_layers)\n",
    "parent_model = model.transform(CreateDataflowPartition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b12ea7e0-99c8-47dd-ae6d-2d78617c0c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_parent_filename = models_folder + '/00_finn_dataflow_parent.onnx'\n",
    "parent_model.save(finn_parent_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b8dcd845-4380-4573-b822-d081ddd1c6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_bipolar/00_finn_dataflow_parent.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f00d4703bb0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_parent_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "72d9ac0b-66e7-4369-9845-4e40e395d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_filename = sdp_node.get_nodeattr(\"model\")\n",
    "dataflow_model = ModelWrapper(dataflow_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b9153-30ca-4c0a-a352-ea557fb9452a",
   "metadata": {},
   "source": [
    "# Specialize Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "51f62b04-9c4e-42f2-aebc-8c10a81f4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce2cc8-6845-4753-9717-99258b5e4a6c",
   "metadata": {},
   "source": [
    "### Change Padding Nodes to HLS, so Auto Folding can be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8c05ff-aec6-4dff-846a-671bfaf68286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FMPadding_node = dataflow_model.get_nodes_by_op_type(\"FMPadding\")\n",
    "\n",
    "# for node in FMPadding_node:\n",
    "#     node_inst = getCustomOp(node)\n",
    "#     node_inst.set_nodeattr(\"preferred_impl_style\", \"hls\")\n",
    "#     print(f'Node {node.name} forced to HLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dcaf1258-b22c-4b9f-bfd4-47a21bbc6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataflow partition with a different name for easier access\n",
    "# and specialize the layers to HLS variants\n",
    "dataflow_model = dataflow_model.transform(SpecializeLayers(fpga_part))\n",
    "\n",
    "dataflow_model = dataflow_model.transform(GiveUniqueNodeNames())\n",
    "dataflow_model = dataflow_model.transform(GiveReadableTensorNames())\n",
    "\n",
    "finn_dataflow_filename = models_folder + '/10_finn_dataflow_model.onnx'\n",
    "dataflow_model.save(finn_dataflow_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "733f7c1f-a632-4531-a1a9-651ab6386dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_bipolar/10_finn_dataflow_model.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f00d4353ca0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_dataflow_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c124c8b-e399-4e42-b3aa-bfc526c568f0",
   "metadata": {},
   "source": [
    "### Check execution???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed28cd42-2fdf-4482-8732-b103519945ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_dataflow_model = ModelWrapper(finn_parent_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db2df8-b5ce-4136-bd07-6db6586839f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dict = {\"global_in\": test_ip*255}\n",
    "# output_dict = oxe.execute_onnx(parent_dataflow_model, input_dict)\n",
    "# produced_clean_qonnx = output_dict[list(output_dict.keys())[0]]\n",
    "# produced_clean_qonnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519407a4-c9cb-4a41-9ad2-9e539e5af923",
   "metadata": {},
   "source": [
    "# Folding Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c17f2a8d-2186-47f0-beae-258b50133bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.set_folding import SetFolding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff9d2ae-2345-46c8-b90e-258c12eb23de",
   "metadata": {},
   "source": [
    "**Taregt Cycles Per Frame**\n",
    "\n",
    "If target is 25 FPS, inference time is $\\frac{1}{25}=40ms$\n",
    "\n",
    "If $clk = 10 ns$:\n",
    "$$\n",
    "Target~Cycles~Per~Frame = \\frac{40\\times 10^{-3}}{10\\times 10^{-9}}= 4\\times 10^{6}\n",
    "$$\n",
    "\n",
    "No se tiene en cuenta el tiempo de preprocesado, que en realidad debería ser inexistente, ya que está embebido en el preprocess del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "96b60113-5133-488d-93ea-fb09df218e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_dataflow_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1358a51-11ac-46ea-896f-96893d395b69",
   "metadata": {},
   "source": [
    "apply method of SetFolding returns (model, False), so model is [0]\n",
    "\n",
    "maybe it is easier to do: model, _ = folder.apply(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fdd92cef-a6b5-4174-aaad-8e3bdd12ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(SetFolding(\n",
    "    target_cycles_per_frame=1000,\n",
    "    mvau_wwidth_max=80,\n",
    "    two_pass_relaxation=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "96500d41-ef99-47f1-b306-cb129ecc5611",
   "metadata": {},
   "outputs": [],
   "source": [
    "folding_filename = models_folder + '/20_finn_folding.onnx'\n",
    "#model[0].save(folding_filename)\n",
    "model.save(folding_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a7d32ab3-c906-4918-9690-18c0267fe4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_bipolar/20_finn_folding.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f00d44496f0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(folding_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3597a82-86be-44b0-8524-bc6bcc600c31",
   "metadata": {},
   "source": [
    "### Check Total Estimated Cycles, looping over each node attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "56fd5ac7-d477-4977-936a-0dadb41669c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = model.get_finn_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "60bbdff5-c927-43b6-b3e2-5621d4191c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 estimated cycles: 52900\n",
      "Node 1 estimated cycles: 52902\n",
      "Node 2 estimated cycles: 51984\n",
      "Node 3 estimated cycles: 52442\n",
      "Node 4 estimated cycles: 51984\n",
      "Node 5 estimated cycles: 12998\n",
      "Node 6 estimated cycles: 50176\n",
      "Node 7 estimated cycles: 12770\n",
      "Node 8 estimated cycles: 12544\n",
      "Node 9 estimated cycles: 3136\n",
      "Node 10 estimated cycles: 3138\n",
      "Node 11 estimated cycles: 5832\n",
      "Node 12 estimated cycles: 2916\n",
      "Node 13 estimated cycles: 2918\n",
      "Node 14 estimated cycles: 10816\n",
      "Node 15 estimated cycles: 2810\n",
      "Node 16 estimated cycles: 2704\n",
      "Node 17 estimated cycles: 676\n",
      "Node 18 estimated cycles: 678\n",
      "Node 19 estimated cycles: 2304\n",
      "Node 20 estimated cycles: 576\n",
      "Node 21 estimated cycles: 578\n",
      "Node 22 estimated cycles: 1936\n",
      "Node 23 estimated cycles: 968\n",
      "Node 24 estimated cycles: 486\n",
      "Node 25 estimated cycles: 1600\n",
      "Node 26 estimated cycles: 2379\n",
      "Node 27 estimated cycles: 800\n",
      "Node 28 estimated cycles: 512\n",
      "Node 29 estimated cycles: 32\n",
      "\n",
      "Total estimated cycles: 398495\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "total_cycles = []\n",
    "for node in all_nodes:\n",
    "    my_node = getCustomOp(node)\n",
    "    node_cycles = my_node.get_nodeattr(\"cycles_estimate\")\n",
    "    total_cycles.append(node_cycles)\n",
    "    print(f'Node {i} estimated cycles: {node_cycles}')\n",
    "    i += 1\n",
    "print(f'\\nTotal estimated cycles: {np.array(total_cycles).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346b1a9-d48e-409c-a316-828f3350f502",
   "metadata": {},
   "source": [
    "# Minimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b5528e3a-c5fe-46b7-91d2-cb9a4ce5b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.minimize_accumulator_width import (\n",
    "    MinimizeAccumulatorWidth,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.minimize_weight_bit_width import (\n",
    "    MinimizeWeightBitWidth,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6cb4d663-2497-4e2e-a375-9cc6b0060434",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(folding_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0a6bffa3-db61-4bf9-ba52-b9fa1c47b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(MinimizeAccumulatorWidth())\n",
    "model = model.transform(MinimizeWeightBitWidth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6653c288-15f1-4972-bbfa-101cdffed607",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize_filename = models_folder + '/21_finn_minimize.onnx'\n",
    "model.save(minimize_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c1a85c57-19c4-4b87-a918-345b58160385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_bipolar/21_finn_minimize.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f00d4738880>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(minimize_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6d687b-0494-4cd1-80ac-070d14553677",
   "metadata": {},
   "source": [
    "# HW IP Generation: PrepareIP and HLSSynthIP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b8ccc6-0fe0-4bde-824f-e6f0bd51ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from finn.transformation.fpgadataflow.prepare_ip import PrepareIP\n",
    "# from finn.transformation.fpgadataflow.hlssynth_ip import HLSSynthIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0be8cf-bb21-41f0-9f6a-cc55edadd683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(minimize_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76818f0f-02d5-43aa-b65d-9d052db23336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.transform(PrepareIP(fpga_part, target_clk_ns))\n",
    "# model = model.transform(HLSSynthIP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c37ba9-8d8b-4083-80c5-6b1967980bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hw_filename = models_folder + '32_finn_hw_ipgen.onnx'\n",
    "# model.save(hw_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f9a23-1a14-44f7-94b9-52f3f60f5eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(hw_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b224fe1f-5886-4439-b572-223bceb0ba16",
   "metadata": {},
   "source": [
    "# FIFO depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e559b-d622-40ed-8132-fad3107b02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.set_fifo_depths import InsertAndSetFIFODepths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f029018-824e-4303-965e-3428cabd53a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ModelWrapper(hw_filename)\n",
    "\n",
    "# model = ModelWrapper(minimize_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad09844f-392b-4abc-b2ae-895862cb5448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.transform(InsertAndSetFIFODepths(\n",
    "#     fpgapart=fpga_part,\n",
    "#     clk_ns=10.0,\n",
    "#     max_qsrl_depth=256,\n",
    "#     max_depth=None,\n",
    "#     swg_exception=False,#True, # Used to optimize convolution FIFOs, splitting in several with Power of Two\n",
    "#     vivado_ram_style=\"auto\",\n",
    "#     force_python_sim=False)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c427a1-5ff2-4083-9695-ab7742683ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifo_filename = models_folder + '31_finn_fifo.onnx'\n",
    "# #model[0].save(fifo_filename)\n",
    "# model.save(fifo_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b843e2-0bc4-4929-817d-eca89b65a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(fifo_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3322c539-37d1-4fa1-ae08-dcd8d916f7e3",
   "metadata": {},
   "source": [
    "### Streamline FIFOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a18232-1569-4130-9b7a-15026bc8583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.set_fifo_depths import SplitLargeFIFOs\n",
    "from finn.transformation.fpgadataflow.set_fifo_depths import RemoveShallowFIFOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7381a6-5cdd-4875-9e1e-8395c8549d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model[0].transform(SplitLargeFIFOs())\n",
    "\n",
    "# model = model.transform(SplitLargeFIFOs())\n",
    "# model = model.transform(RemoveShallowFIFOs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe072021-5b59-49e0-85dc-ca0d1e2fd84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after FIFOs are ready to go, call PrepareIP and HLSSynthIP again\n",
    "# this will only run for the new nodes (e.g. FIFOs and DWCs) -> DWCs for Mobilenet\n",
    "# model = model.transform(PrepareIP(fpga_part, target_clk_ns))\n",
    "# model = model.transform(HLSSynthIP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb88151-c03d-4b1c-8c01-bd1dae5fae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifo_streamline_filename = models_folder + '33_finn_fifo_streamline.onnx'\n",
    "# model.save(fifo_streamline_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec70cde2-09ba-4fdd-b6f8-454121ff6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(fifo_streamline_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e049589-e6f3-4ba2-9a89-dd8a7a947b50",
   "metadata": {},
   "source": [
    "# PYNQ Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee6904-e30e-4a68-978b-59571c1edc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db01d436-01ed-4a5e-aca6-d992ad5edea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(fifo_streamline_filename)\n",
    "# model = model.transform(ZynqBuild(platform = pynq_board, period_ns = target_clk_ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4726f80-8fbb-4991-b7cb-937b38e8f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e466a10-dc61-499c-aacc-d56e0a34a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.transform(MakePYNQDriver(\"zynq-iodma\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399688a0-b838-4752-9b41-d989c28123d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pynq_driver_filename = '/40_pynq_driver.onnx'\n",
    "# model.save(pynq_driver_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
