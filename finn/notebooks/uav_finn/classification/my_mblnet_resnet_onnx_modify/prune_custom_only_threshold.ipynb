{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae233f6f-7219-4cbc-96da-03ec5287f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "\n",
    "from finn.util.visualization import showInNetron\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "\n",
    "import onnx.helper as oh\n",
    "import qonnx.util.basic as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32a77bc-2609-463b-a1f5-7749c720ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from onnx import __version__, IR_VERSION\n",
    "# from onnx.defs import onnx_opset_version\n",
    "# print(f\"onnx.__version__={__version__!r}, opset={onnx_opset_version()}, IR_VERSION={IR_VERSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d54340a2-fdb7-4183-912e-09bf2e61ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_folder = './manual_pruning/only_thresholds/Sparse24/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4800263f-4f20-48bd-a650-6d6e4ae957aa",
   "metadata": {},
   "source": [
    "# Load Model and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "067aa6e5-64e7-45cd-b1bb-639407f4310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_file = './onnx_models/MY_MBLNET_V2_RESNET_classifier__best_mean_F1__BIPOLAR_Out__QONNX.onnx'\n",
    "\n",
    "# model_file = './onnx_models/Mobilenetv2_Mini_Resnet_112__best_F1__Bipolar.onnx'\n",
    "\n",
    "# model_file = './onnx_models/Mobilenetv2_Mini_Resnet_4bitINP__best_F1__Bipolar.onnx'\n",
    "\n",
    "model_file = './onnx_models/Mobilenetv2_Mini_Resnet_Sparse24__best_F1__Bipolar.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a08fbe2-1a78-4964-b0cc-1d48e4b907ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "qonnx_clean_filename = prune_folder + '00_prune_clean.onnx'\n",
    "qonnx_cleanup(model_file, out_file=qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "828b8cf7-1403-43d1-8ed1-2e6442925dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './manual_pruning/only_thresholds/Sparse24/00_prune_clean.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5de012d120>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea40e51-a453-4e7c-8a0f-83336935268c",
   "metadata": {},
   "source": [
    "# Analyze layers to prune\n",
    "\n",
    "Check scales of weights that are very close to zero, under epsilon:\n",
    "\n",
    "$$\n",
    "0 < abs(scale) < \\epsilon\n",
    "$$\n",
    "\n",
    "Store all initializers in a list and look for the corresponding convolution afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00603339-56a9-4c8e-9643-2446e1732a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3eb0cee-bfe7-48e0-a8cf-c0185fcbc8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of initializers = 376\n"
     ]
    }
   ],
   "source": [
    "all_inits_names = [init.name for init in model.graph.initializer]\n",
    "\n",
    "print(f'Number of initializers = {len(all_inits_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e953613e-1aa3-4e6a-810a-a69fc10543e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-15\n",
    "\n",
    "layers_to_prune = {}\n",
    "\n",
    "for idx, init_name in enumerate(all_inits_names):\n",
    "    if \"Quant\" in init_name and \"param1\" in init_name:\n",
    "    # It is a scale value, check it\n",
    "        np_init = model.get_initializer(init_name)\n",
    "        np_abs_val = np.abs(np_init)\n",
    "        zero_idx = (np_abs_val < eps) * (np_abs_val > 0)\n",
    "        if np.all(zero_idx == False):\n",
    "            #print(f'Index = {idx}. {init_name} was not appended, as there were no values under epsilon')\n",
    "            continue\n",
    "        else:\n",
    "            zero_layer = np.where(zero_idx == True)[0]\n",
    "            quant_layer_name = init_name.split(\"_param\")[0]\n",
    "            layers_to_prune[quant_layer_name] = {1: {*zero_layer}}\n",
    "            #print(f'Index = {idx}. {init_name} appended, as there were values under epsilon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e1546a7-c519-44a1-bc09-b1a3bcdc1abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers to prune: 15\n",
      "Quant_12 {1: {28}}\n",
      "Quant_13 {1: {28}}\n",
      "Quant_15 {1: {0, 83, 45, 54}}\n",
      "Quant_16 {1: {0, 83, 45, 54}}\n",
      "Quant_18 {1: {64, 33, 2, 99, 102, 7, 40, 41, 12, 13, 112, 51, 20, 89, 59, 94}}\n",
      "Quant_19 {1: {64, 33, 2, 99, 102, 7, 40, 41, 12, 13, 112, 51, 20, 89, 59, 94}}\n",
      "Quant_21 {1: {3, 7, 9, 12, 21, 24, 27, 29, 31, 32, 39, 41, 43, 44, 50, 57, 63, 68, 71, 73, 75, 80, 83, 90, 94, 96, 97, 99, 103, 113, 117, 124, 125}}\n",
      "Quant_22 {1: {3, 7, 9, 12, 21, 24, 27, 29, 31, 32, 39, 41, 43, 44, 50, 57, 63, 68, 71, 73, 75, 80, 83, 90, 94, 96, 97, 99, 103, 113, 117, 124, 125}}\n",
      "Quant_24 {1: {30}}\n",
      "Quant_25 {1: {30}}\n",
      "Quant_26 {1: {10, 51, 14, 7}}\n",
      "Quant_27 {1: {0, 1, 5, 7, 10, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 34, 35, 37, 38, 45, 47, 49, 51, 54, 56, 57, 58, 59, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 78, 79, 82, 85, 89, 92, 93, 97, 98, 100, 103, 104, 109, 110, 111, 112, 115, 117, 118, 121, 126, 127}}\n",
      "Quant_28 {1: {0, 1, 5, 7, 10, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 34, 35, 37, 38, 45, 47, 49, 51, 54, 56, 57, 58, 59, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 78, 79, 82, 85, 89, 92, 93, 97, 98, 100, 103, 104, 109, 110, 111, 112, 115, 117, 118, 121, 126, 127}}\n",
      "Quant_29 {1: {10, 51, 14, 7}}\n",
      "Quant_30 {1: {4, 8, 13, 14, 24, 36, 41, 48, 52, 59, 61, 62, 71, 75, 77, 78, 82, 86, 91, 96, 101, 105, 110, 118, 120, 126}}\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of layers to prune: {len(layers_to_prune)}')\n",
    "for k, v in layers_to_prune.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61a5d18a-a1a5-4792-82b1-1b82ce125966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(layers_to_prune[\"Quant_30\"][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377b7827-013e-4ac4-a544-4004af7525f0",
   "metadata": {},
   "source": [
    "### Get all Convolutions or Linears to be pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00b687c9-1a3b-4a4e-89f5-d7fe1d25e4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All convolutions to prune\n",
      "Conv_12\n",
      "Conv_13\n",
      "Conv_15\n",
      "Conv_16\n",
      "Conv_18\n",
      "Conv_19\n",
      "Conv_21\n",
      "Conv_22\n",
      "Conv_24\n",
      "Conv_25\n",
      "Conv_26\n",
      "Conv_27\n",
      "Conv_28\n",
      "Conv_29\n",
      "Conv_30\n"
     ]
    }
   ],
   "source": [
    "all_nodes = model.graph.node\n",
    "\n",
    "convs_to_prune = []\n",
    "\n",
    "for node in all_nodes:\n",
    "    for key in layers_to_prune.keys():\n",
    "        if key == node.name:\n",
    "            successor_node = model.find_direct_successors(node)[0]\n",
    "            convs_to_prune.append(successor_node.name)\n",
    "\n",
    "print(\"All convolutions to prune\")\n",
    "for conv in convs_to_prune:\n",
    "    print(conv)\n",
    "\n",
    "# # Remove last 5 convs, as they are harder to prune\n",
    "# for i in range(5):\n",
    "#     convs_to_prune.pop()\n",
    "\n",
    "# # Print again\n",
    "# print(\"\\nEasy convolutions to prune\")\n",
    "# for conv in convs_to_prune:\n",
    "#     print(conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c29554-1c21-49be-bd31-024acf0c4b7a",
   "metadata": {},
   "source": [
    "### Get Sparsity to compare after pruning\n",
    "\n",
    "Retrieve all weights from Convolutions and perform:\n",
    "$$\n",
    "Sparsity = \\frac{N_{Zeros}}{N_{Tensors}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1267b596-9bf5-496b-82d0-bd2db02d5490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(model_wrapper, layers_to_prune):\n",
    "    \n",
    "    sparse_dict = {}\n",
    "    \n",
    "    for key in layers_to_prune.keys():\n",
    "        init_name = key + \"_param0\"\n",
    "        np_init = model_wrapper.get_initializer(init_name)\n",
    "        n_zeros = np.count_nonzero(np_init == 0)\n",
    "        total_values = np_init.size\n",
    "        sparsity = round(n_zeros/total_values, 2)\n",
    "        #print(init_name, n_zeros, total_values, sparsity*100)\n",
    "        sparse_dict[init_name] = {\"zeros\": n_zeros, \"total\": total_values, \"sparsity\": sparsity}\n",
    "\n",
    "    return sparse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7f60308-3a4a-4cb0-a938-9ca529fa318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quant_12_param0 {'zeros': 122, 'total': 1152, 'sparsity': 0.11}\n",
      "Quant_13_param0 {'zeros': 37, 'total': 432, 'sparsity': 0.09}\n",
      "Quant_15_param0 {'zeros': 315, 'total': 2304, 'sparsity': 0.14}\n",
      "Quant_16_param0 {'zeros': 86, 'total': 864, 'sparsity': 0.1}\n",
      "Quant_18_param0 {'zeros': 902, 'total': 4096, 'sparsity': 0.22}\n",
      "Quant_19_param0 {'zeros': 211, 'total': 1152, 'sparsity': 0.18}\n",
      "Quant_21_param0 {'zeros': 1358, 'total': 4096, 'sparsity': 0.33}\n",
      "Quant_22_param0 {'zeros': 352, 'total': 1152, 'sparsity': 0.31}\n",
      "Quant_24_param0 {'zeros': 226, 'total': 2048, 'sparsity': 0.11}\n",
      "Quant_25_param0 {'zeros': 56, 'total': 576, 'sparsity': 0.1}\n",
      "Quant_26_param0 {'zeros': 720, 'total': 4096, 'sparsity': 0.18}\n",
      "Quant_27_param0 {'zeros': 5019, 'total': 8192, 'sparsity': 0.61}\n",
      "Quant_28_param0 {'zeros': 642, 'total': 1152, 'sparsity': 0.56}\n",
      "Quant_29_param0 {'zeros': 5004, 'total': 8192, 'sparsity': 0.61}\n",
      "Quant_30_param0 {'zeros': 3045, 'total': 8192, 'sparsity': 0.37}\n"
     ]
    }
   ],
   "source": [
    "sparsity_before_pruning = get_sparsity(model, layers_to_prune)\n",
    "for k, v in sparsity_before_pruning.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f60b7-f62e-4398-981b-cf4e04687b87",
   "metadata": {},
   "source": [
    "# Check Layers with all zero kernels and replace scales\n",
    "\n",
    "## Process:\n",
    "\n",
    "Args: \n",
    "- model: ModelWrapper of the model to prune\n",
    "- conv: string of the convolution layer to prune\n",
    ">**Steps**: <br>\n",
    ">1. Get Conv Node from model.\n",
    ">2. Find direct predecessors: [1] will be the convolution weights, so store it.\n",
    ">3. Modify convolution weights.\n",
    ">4. Find direct successor, which is batch norm layer.\n",
    ">5. Modify batch norm layer: weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84732158-a50b-4fb4-92a1-eb916db68c85",
   "metadata": {},
   "source": [
    "#### Prune weights of convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36399254-8bf3-4981-835c-9631dc3be47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_conv_weights(model, quant_node):\n",
    "\n",
    "    print(f'\\n############ Pruning Weights of {quant_node.name} node ############')\n",
    "    quant_1 = quant_node.input[1]\n",
    "    np_q1 = model.get_initializer(quant_1)\n",
    "    print(f'Quant 1 shape: {np_q1.shape}') \n",
    "\n",
    "    np_q1_abs = np.abs(np_q1)\n",
    "    zero_idx = np.where((np_q1_abs < eps) * (np_q1_abs > 0))[0]\n",
    "    non_zero_idx = np.where(np_q1_abs > eps)[0]\n",
    "    print(\"-------------------------------------\")\n",
    "    print(f'*** Zero IDX, channels to be pruned ({zero_idx.size} elements):\\n{zero_idx}')\n",
    "    print(f'### Non Zero IDX, channels to keep ({non_zero_idx.size} elements):\\n{non_zero_idx}')\n",
    "    print(\"-------------------------------------\")\n",
    "\n",
    "    np_q1_replace = np_q1[non_zero_idx][0] # uses directly the scale of element [0] of non zero idx\n",
    "    np_q1_copy = np_q1.copy() # Original array is read-only, so it must be copied first\n",
    "    np_q1_copy[zero_idx] = np_q1_replace\n",
    "    np_q1 = np_q1_copy\n",
    "    print(f'Value of [0] channel to use it as default for zero elements: {np_q1_replace}')\n",
    "\n",
    "    model.set_initializer(\n",
    "        tensor_name = quant_1, \n",
    "        tensor_value = np_q1)\n",
    "\n",
    "    return non_zero_idx, zero_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64762b6d-e4f9-4ef9-afa5-d610fb3eef2e",
   "metadata": {},
   "source": [
    "##### Test weight pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b2d0096-f31d-4baa-87dc-0a7c21928b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_conv_weights(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "    \n",
    "    non_zero_idx, zero_idx = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "\n",
    "    return non_zero_idx, zero_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eb5c15b-10d5-4959-9607-e38ad823635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_0 node ############\n",
      "Quant 1 shape: (24, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (0 elements):\n",
      "[]\n",
      "### Non Zero IDX, channels to keep (24 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[0.03360252]]]\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "non_zero_idx, zero_idx = test_prune_conv_weights(model, \"Conv_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6499ab3-ffc1-4b27-a3ae-b50d6184e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_weights = prune_folder + \"01_test_prune_weights.onnx\"\n",
    "model.save(test_prune_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b72cdea-05fd-4c9a-b57f-35e18949ad90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/only_thresholds/Sparse24/01_test_prune_weights.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5de012c1c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8844e-3e30-4dc9-82c2-33fd19753cbd",
   "metadata": {},
   "source": [
    "#### Prune batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "392fc9a2-a12e-4edf-8b11-e1048be90338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_bn(model, bn_node, non_zero_idx, zero_idx):\n",
    "\n",
    "    print(f'\\n############ Prune Batch Norm {bn_node.name} node ############')\n",
    "    bn_0 = bn_node.input[1]\n",
    "    bn_1 = bn_node.input[2]\n",
    "    bn_2 = bn_node.input[3]\n",
    "    bn_3 = bn_node.input[4]\n",
    "    np_bn0 = model.get_initializer(bn_0)\n",
    "    np_bn1 = model.get_initializer(bn_1)\n",
    "    np_bn2 = model.get_initializer(bn_2)\n",
    "    np_bn3 = model.get_initializer(bn_3)\n",
    "    \n",
    "    print(\"-------------------------------------\")\n",
    "    print(f'*** Zero IDX, scale value of channels to be pruned:\\n{np_bn0[zero_idx]}')\n",
    "    print(\"-------------------------------------\")\n",
    "\n",
    "    np_bn0_replace = np_bn0[non_zero_idx][0]\n",
    "    np_bn1_replace = np_bn1[non_zero_idx][0]\n",
    "    np_bn2_replace = np_bn2[non_zero_idx][0]\n",
    "    np_bn3_replace = np_bn3[non_zero_idx][0]\n",
    "    \n",
    "    np_bn0_copy = np_bn0.copy()\n",
    "    np_bn0_copy[zero_idx] = np_bn0_replace #0. # Replace ultra small scale with element [0] scale\n",
    "    np_bn1_copy = np_bn1.copy()\n",
    "    np_bn1_copy[zero_idx] = np_bn1_replace\n",
    "    np_bn2_copy = np_bn2.copy()\n",
    "    np_bn2_copy[zero_idx] = np_bn2_replace\n",
    "    np_bn3_copy = np_bn3.copy()\n",
    "    np_bn3_copy[zero_idx] = np_bn3_replace\n",
    "\n",
    "    model.set_initializer(\n",
    "        tensor_name = bn_0, \n",
    "        tensor_value = np_bn0_copy)\n",
    "    model.set_initializer(\n",
    "        tensor_name = bn_1, \n",
    "        tensor_value = np_bn1_copy)\n",
    "    model.set_initializer(\n",
    "        tensor_name = bn_2, \n",
    "        tensor_value = np_bn2_copy)\n",
    "    model.set_initializer(\n",
    "        tensor_name = bn_3, \n",
    "        tensor_value = np_bn3_copy) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f22a0-e13a-4f48-a396-97eb3954e38f",
   "metadata": {},
   "source": [
    "##### Test prune batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86ad3d1b-a52e-4fa6-ac59-94ed24c754da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_conv_bn(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "    # Prune batch norm\n",
    "    bn_node = model.find_direct_successors(conv_node)[0]\n",
    "    prune_bn(model, bn_node, non_zero_idx, zero_idx)\n",
    "\n",
    "    return non_zero_idx, zero_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f7f06c5-b464-4d1c-8fce-1f024afbb7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_0 node ############\n",
      "Quant 1 shape: (24, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (0 elements):\n",
      "[]\n",
      "### Non Zero IDX, channels to keep (24 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[0.03360252]]]\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_0 node ############\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[]\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "non_zero_idx, zero_idx = test_prune_conv_bn(model, \"Conv_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3983475-68f7-49e7-82c0-3d010ba617b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_conv_bn_onnx = prune_folder + \"02_test_prune_conv_bn.onnx\"\n",
    "model.save(test_prune_conv_bn_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11bd15a2-a422-4e31-835d-b34d882f6300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/only_thresholds/Sparse24/02_test_prune_conv_bn.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5de012c280>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_conv_bn_onnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6b762d-c698-4ac8-af23-0ef91d7bc342",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test Pruning of first 2 Convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05ae631c-1631-4126-b584-2ab25540d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(qonnx_clean_filename)\n",
    "# # non_zero_idx, zero_idx, new_ch, new_shape = test_prune_conv(model, \"Conv_0\")\n",
    "# # non_zero_idx, zero_idx, new_ch, new_shape = test_prune_conv(model, \"Conv_1\")\n",
    "\n",
    "# _, _, _, _ = test_prune_conv(model, \"Conv_0\")\n",
    "# _, _, _, _ = test_prune_conv(model, \"Conv_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28345622-19d1-49a2-b7ed-8ad019c5c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_prune_2_conv = prune_folder + \"10_test_prune_2_conv.onnx\"\n",
    "\n",
    "# model = model.transform(InferShapes())\n",
    "# model.save(test_prune_2_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a846942-b86d-4c01-9380-eb6068a3f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(test_prune_2_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751b0cc3-bd79-4ffd-82e6-14febf6efaa3",
   "metadata": {},
   "source": [
    "# Test Pruning the Whole Model - NO MUL 4 or 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c811656f-40b8-45e4-b6d7-be0473cc91c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_12 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_12 node ############\n",
      "Quant 1 shape: (48, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (1 elements):\n",
      "[28]\n",
      "### Non Zero IDX, channels to keep (47 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[0.02151186]]]\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_12 node ############\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.909e-42]\n",
      "-------------------------------------\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_13 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_13 node ############\n",
      "Quant 1 shape: (48, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (1 elements):\n",
      "[28]\n",
      "### Non Zero IDX, channels to keep (47 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[0.02368543]]]\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_13 node ############\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[4.926e-42]\n",
      "-------------------------------------\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_15 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_15 node ############\n",
      "Quant 1 shape: (96, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (4 elements):\n",
      "[ 0 45 54 83]\n",
      "### Non Zero IDX, channels to keep (92 elements):\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 46 47 48 49\n",
      " 50 51 52 53 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[0.02079848]]]\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_15 node ############\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.931e-42  4.940e-42  4.940e-42 -4.914e-42]\n",
      "-------------------------------------\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_16 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_16 node ############\n",
      "Quant 1 shape: (96, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (4 elements):\n",
      "[ 0 45 54 83]\n",
      "### Non Zero IDX, channels to keep (92 elements):\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 46 47 48 49\n",
      " 50 51 52 53 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[0.02857334]]]\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_16 node ############\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.919e-42  4.913e-42 -4.948e-42  4.914e-42]\n",
      "-------------------------------------\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_18 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_18 node ############\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (16 elements):\n",
      "[  2   7  12  13  20  33  40  41  51  59  64  89  94  99 102 112]\n",
      "### Non Zero IDX, channels to keep (112 elements):\n",
      "[  0   1   3   4   5   6   8   9  10  11  14  15  16  17  18  19  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  34  35  36  37  38  39  42  43\n",
      "  44  45  46  47  48  49  50  52  53  54  55  56  57  58  60  61  62  63\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  87  88  90  91  92  93  95  96  97  98 100 101 103 104\n",
      " 105 106 107 108 109 110 111 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[0.02010927]]]\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_18 node ############\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.938e-42 -4.910e-42  4.921e-42  4.944e-42 -4.924e-42  4.933e-42\n",
      "  4.909e-42  4.941e-42  4.941e-42 -4.928e-42 -4.934e-42  4.931e-42\n",
      " -5.925e-42  4.909e-42  4.952e-42 -4.949e-42]\n",
      "-------------------------------------\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_19 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_19 node ############\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (16 elements):\n",
      "[  2   7  12  13  20  33  40  41  51  59  64  89  94  99 102 112]\n",
      "### Non Zero IDX, channels to keep (112 elements):\n",
      "[  0   1   3   4   5   6   8   9  10  11  14  15  16  17  18  19  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  34  35  36  37  38  39  42  43\n",
      "  44  45  46  47  48  49  50  52  53  54  55  56  57  58  60  61  62  63\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  87  88  90  91  92  93  95  96  97  98 100 101 103 104\n",
      " 105 106 107 108 109 110 111 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[0.02297413]]]\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_19 node ############\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.924e-42 -4.940e-42 -4.917e-42  4.923e-42  4.910e-42  4.923e-42\n",
      "  4.935e-42 -4.913e-42  4.909e-42  4.913e-42 -4.928e-42  4.930e-42\n",
      "  4.919e-42  4.914e-42  4.913e-42  4.919e-42]\n",
      "-------------------------------------\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_21 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_21 node ############\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (33 elements):\n",
      "[  3   7   9  12  21  24  27  29  31  32  39  41  43  44  50  57  63  68\n",
      "  71  73  75  80  83  90  94  96  97  99 103 113 117 124 125]\n",
      "### Non Zero IDX, channels to keep (95 elements):\n",
      "[  0   1   2   4   5   6   8  10  11  13  14  15  16  17  18  19  20  22\n",
      "  23  25  26  28  30  33  34  35  36  37  38  40  42  45  46  47  48  49\n",
      "  51  52  53  54  55  56  58  59  60  61  62  64  65  66  67  69  70  72\n",
      "  74  76  77  78  79  81  82  84  85  86  87  88  89  91  92  93  95  98\n",
      " 100 101 102 104 105 106 107 108 109 110 111 112 114 115 116 118 119 120\n",
      " 121 122 123 126 127]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[0.02265112]]]\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_21 node ############\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.954e-42  4.914e-42  4.935e-42  4.942e-42  4.949e-42 -4.914e-42\n",
      " -4.905e-42  4.917e-42  4.926e-42  4.924e-42 -4.933e-42  4.916e-42\n",
      "  4.910e-42  4.937e-42  4.909e-42 -4.938e-42 -4.949e-42 -4.949e-42\n",
      " -4.927e-42 -4.951e-42 -4.951e-42  4.933e-42  4.940e-42  4.935e-42\n",
      " -4.930e-42  4.931e-42  4.923e-42 -4.909e-42  4.927e-42  4.906e-42\n",
      "  4.920e-42  4.952e-42  4.905e-42]\n",
      "-------------------------------------\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_22 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_22 node ############\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (33 elements):\n",
      "[  3   7   9  12  21  24  27  29  31  32  39  41  43  44  50  57  63  68\n",
      "  71  73  75  80  83  90  94  96  97  99 103 113 117 124 125]\n",
      "### Non Zero IDX, channels to keep (95 elements):\n",
      "[  0   1   2   4   5   6   8  10  11  13  14  15  16  17  18  19  20  22\n",
      "  23  25  26  28  30  33  34  35  36  37  38  40  42  45  46  47  48  49\n",
      "  51  52  53  54  55  56  58  59  60  61  62  64  65  66  67  69  70  72\n",
      "  74  76  77  78  79  81  82  84  85  86  87  88  89  91  92  93  95  98\n",
      " 100 101 102 104 105 106 107 108 109 110 111 112 114 115 116 118 119 120\n",
      " 121 122 123 126 127]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[0.02092198]]]\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_22 node ############\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.924e-42  4.907e-42 -4.913e-42  4.919e-42  4.921e-42 -4.949e-42\n",
      "  4.905e-42  4.930e-42  4.931e-42  4.905e-42  4.937e-42  4.930e-42\n",
      "  4.912e-42  4.909e-42  4.937e-42 -4.947e-42 -4.914e-42 -4.916e-42\n",
      "  4.948e-42 -6.300e-42  4.907e-42  4.921e-42  4.919e-42  4.909e-42\n",
      "  4.942e-42  4.937e-42  4.940e-42 -4.940e-42  4.913e-42  4.931e-42\n",
      "  4.923e-42  4.923e-42 -4.937e-42]\n",
      "-------------------------------------\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_24 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_24 node ############\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (1 elements):\n",
      "[30]\n",
      "### Non Zero IDX, channels to keep (63 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[0.0395278]]]\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_24 node ############\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[4.912e-42]\n",
      "-------------------------------------\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_25 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_25 node ############\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (1 elements):\n",
      "[30]\n",
      "### Non Zero IDX, channels to keep (63 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[0.02813869]]]\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_25 node ############\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[4.942e-42]\n",
      "-------------------------------------\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_26 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_26 node ############\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (4 elements):\n",
      "[ 7 10 14 51]\n",
      "### Non Zero IDX, channels to keep (60 elements):\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[0.01414997]]]\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_26 node ############\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.923e-42  4.942e-42 -4.940e-42 -4.951e-42]\n",
      "-------------------------------------\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_27 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_27 node ############\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (67 elements):\n",
      "[  0   1   5   7  10  11  12  13  14  15  16  18  20  21  22  23  24  25\n",
      "  26  27  28  30  34  35  37  38  45  47  49  51  54  56  57  58  59  66\n",
      "  67  68  70  71  72  73  74  75  76  78  79  82  85  89  92  93  97  98\n",
      " 100 103 104 109 110 111 112 115 117 118 121 126 127]\n",
      "### Non Zero IDX, channels to keep (61 elements):\n",
      "[  2   3   4   6   8   9  17  19  29  31  32  33  36  39  40  41  42  43\n",
      "  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77  80  81  83\n",
      "  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107 108 113 114\n",
      " 116 119 120 122 123 124 125]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[0.02123232]]]\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_27 node ############\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 5.420e-42  4.952e-42  4.937e-42  4.944e-42  4.938e-42 -4.923e-42\n",
      " -4.948e-42  4.905e-42  4.909e-42  4.948e-42  4.917e-42  4.914e-42\n",
      "  4.954e-42  4.954e-42  4.928e-42  4.910e-42  4.913e-42  4.937e-42\n",
      " -4.906e-42  4.949e-42  4.954e-42  4.933e-42  4.933e-42  4.940e-42\n",
      " -4.945e-42  4.905e-42  4.910e-42  4.924e-42  4.951e-42  4.938e-42\n",
      "  4.944e-42  4.909e-42  4.912e-42  4.917e-42  4.933e-42  4.947e-42\n",
      " -4.910e-42  4.949e-42  4.920e-42  4.952e-42  4.916e-42 -4.935e-42\n",
      "  4.926e-42  4.931e-42  4.937e-42  4.949e-42  4.938e-42 -4.942e-42\n",
      "  4.928e-42  4.941e-42  4.945e-42  4.928e-42  4.949e-42  4.923e-42\n",
      " -4.930e-42  4.921e-42  5.639e-42  4.948e-42  4.954e-42 -4.913e-42\n",
      "  4.941e-42 -4.909e-42  4.917e-42  4.913e-42  4.951e-42  4.947e-42\n",
      "  4.945e-42]\n",
      "-------------------------------------\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_28 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_28 node ############\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (67 elements):\n",
      "[  0   1   5   7  10  11  12  13  14  15  16  18  20  21  22  23  24  25\n",
      "  26  27  28  30  34  35  37  38  45  47  49  51  54  56  57  58  59  66\n",
      "  67  68  70  71  72  73  74  75  76  78  79  82  85  89  92  93  97  98\n",
      " 100 103 104 109 110 111 112 115 117 118 121 126 127]\n",
      "### Non Zero IDX, channels to keep (61 elements):\n",
      "[  2   3   4   6   8   9  17  19  29  31  32  33  36  39  40  41  42  43\n",
      "  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77  80  81  83\n",
      "  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107 108 113 114\n",
      " 116 119 120 122 123 124 125]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[0.02739516]]]\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_28 node ############\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.934e-42  4.926e-42 -4.944e-42  4.949e-42  4.934e-42  4.947e-42\n",
      "  4.937e-42  4.951e-42 -4.948e-42  4.916e-42  4.948e-42  4.923e-42\n",
      "  4.927e-42  4.954e-42  4.912e-42 -4.910e-42  4.954e-42  4.910e-42\n",
      "  4.914e-42  4.940e-42  4.912e-42 -4.934e-42 -4.912e-42  4.933e-42\n",
      "  4.912e-42 -4.941e-42  4.941e-42  4.949e-42 -4.916e-42  4.937e-42\n",
      "  4.942e-42  4.947e-42  4.921e-42  4.921e-42  4.927e-42  4.940e-42\n",
      " -4.919e-42  4.954e-42 -4.944e-42  4.934e-42 -4.910e-42 -4.941e-42\n",
      " -4.940e-42  4.951e-42  4.941e-42  4.924e-42  4.947e-42 -4.945e-42\n",
      "  4.952e-42  4.951e-42  4.948e-42  4.928e-42  4.917e-42  4.942e-42\n",
      " -4.947e-42  4.938e-42  4.920e-42  4.930e-42  4.944e-42 -4.916e-42\n",
      " -4.926e-42  4.930e-42  4.947e-42  4.912e-42  4.928e-42  4.928e-42\n",
      " -4.917e-42]\n",
      "-------------------------------------\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_29 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_29 node ############\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (4 elements):\n",
      "[ 7 10 14 51]\n",
      "### Non Zero IDX, channels to keep (60 elements):\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[5.016172e-05]]]\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_29 node ############\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.906e-42  4.944e-42  4.913e-42 -4.935e-42]\n",
      "-------------------------------------\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_30 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_30 node ############\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (26 elements):\n",
      "[  4   8  13  14  24  36  41  48  52  59  61  62  71  75  77  78  82  86\n",
      "  91  96 101 105 110 118 120 126]\n",
      "### Non Zero IDX, channels to keep (102 elements):\n",
      "[  0   1   2   3   5   6   7   9  10  11  12  15  16  17  18  19  20  21\n",
      "  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39  40  42\n",
      "  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63  64  65\n",
      "  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87  88  89\n",
      "  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109 111 112\n",
      " 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "-------------------------------------\n",
      "Value of [0] channel to use it as default for zero elements: [[[0.00795446]]]\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_30 node ############\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.945e-42 -4.913e-42 -4.945e-42 -4.912e-42  4.910e-42  4.921e-42\n",
      " -4.926e-42 -4.907e-42 -4.944e-42 -4.919e-42 -4.912e-42  4.935e-42\n",
      " -4.920e-42 -4.945e-42  4.919e-42 -6.283e-42 -4.934e-42 -4.937e-42\n",
      "  4.919e-42 -4.933e-42  4.910e-42 -4.937e-42 -4.919e-42  4.934e-42\n",
      "  4.941e-42  4.923e-42]\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "\n",
    "for conv in convs_to_prune:\n",
    "    print(f'\\n______________________________________________________________________________________________________')\n",
    "    print(f'                                                {conv} ')\n",
    "    print(f'______________________________________________________________________________________________________')\n",
    "\n",
    "    _, _, = test_prune_conv_bn(model, conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50bbd986-b002-4c16-83d2-7c61f42113c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(InferShapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ebb9c89-3213-4b08-bbde-94dbe36f7c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_all_convs_onnx = prune_folder + \"prune_all_convs_only_thres.onnx\"\n",
    "model.save(prune_all_convs_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cfbf4d9-0fc0-4f54-978b-c7008eecbb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/only_thresholds/Sparse24/prune_all_convs_only_thres.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5e04789b70>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(prune_all_convs_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d721bddd-6774-49ce-9b56-78b488c79442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quant_12_param0: \tbefore: 0.11 - after: 0.11\n",
      "Quant_13_param0: \tbefore: 0.09 - after: 0.09\n",
      "Quant_15_param0: \tbefore: 0.14 - after: 0.14\n",
      "Quant_16_param0: \tbefore: 0.1  - after: 0.1 \n",
      "Quant_18_param0: \tbefore: 0.22 - after: 0.22\n",
      "Quant_19_param0: \tbefore: 0.18 - after: 0.18\n",
      "Quant_21_param0: \tbefore: 0.33 - after: 0.33\n",
      "Quant_22_param0: \tbefore: 0.31 - after: 0.31\n",
      "Quant_24_param0: \tbefore: 0.11 - after: 0.11\n",
      "Quant_25_param0: \tbefore: 0.1  - after: 0.1 \n",
      "Quant_26_param0: \tbefore: 0.18 - after: 0.18\n",
      "Quant_27_param0: \tbefore: 0.61 - after: 0.61\n",
      "Quant_28_param0: \tbefore: 0.56 - after: 0.56\n",
      "Quant_29_param0: \tbefore: 0.61 - after: 0.61\n",
      "Quant_30_param0: \tbefore: 0.37 - after: 0.37\n"
     ]
    }
   ],
   "source": [
    "sparsity_after_pruning = get_sparsity(model, layers_to_prune)\n",
    "\n",
    "for k1, k2 in zip(sparsity_before_pruning.keys(), sparsity_after_pruning.keys()):\n",
    "    before = sparsity_before_pruning[k1][\"sparsity\"]\n",
    "    after = sparsity_after_pruning[k2][\"sparsity\"]\n",
    "    assert k1 == k2, f'{k1} is not the same as {k2}'\n",
    "    print(f'{k1}: \\tbefore: {before:<4} - after: {after:<4}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
