{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae233f6f-7219-4cbc-96da-03ec5287f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "\n",
    "from finn.util.visualization import showInNetron\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "\n",
    "import onnx.helper as oh\n",
    "import qonnx.util.basic as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32a77bc-2609-463b-a1f5-7749c720ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from onnx import __version__, IR_VERSION\n",
    "# from onnx.defs import onnx_opset_version\n",
    "# print(f\"onnx.__version__={__version__!r}, opset={onnx_opset_version()}, IR_VERSION={IR_VERSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d54340a2-fdb7-4183-912e-09bf2e61ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_folder = './manual_pruning/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4800263f-4f20-48bd-a650-6d6e4ae957aa",
   "metadata": {},
   "source": [
    "# Load Model and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "067aa6e5-64e7-45cd-b1bb-639407f4310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = './onnx_models/MY_MBLNET_V2_RESNET_classifier__best_mean_F1__BIPOLAR_Out__QONNX.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a08fbe2-1a78-4964-b0cc-1d48e4b907ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "qonnx_clean_filename = prune_folder + '00_prune_clean.onnx'\n",
    "qonnx_cleanup(model_file, out_file=qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "828b8cf7-1403-43d1-8ed1-2e6442925dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './manual_pruning/00_prune_clean.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9d7f2ec6d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea40e51-a453-4e7c-8a0f-83336935268c",
   "metadata": {},
   "source": [
    "# Analyze layers to prune\n",
    "\n",
    "Check scales of weights that are very close to zero, under epsilon:\n",
    "\n",
    "$$\n",
    "0 < abs(scale) < \\epsilon\n",
    "$$\n",
    "\n",
    "Store all initializers in a list and look for the corresponding convolution afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00603339-56a9-4c8e-9643-2446e1732a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3eb0cee-bfe7-48e0-a8cf-c0185fcbc8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of initializers = 376\n"
     ]
    }
   ],
   "source": [
    "all_inits_names = [init.name for init in model.graph.initializer]\n",
    "\n",
    "print(f'Number of initializers = {len(all_inits_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e953613e-1aa3-4e6a-810a-a69fc10543e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-10\n",
    "\n",
    "layers_to_prune = {}\n",
    "\n",
    "for idx, init_name in enumerate(all_inits_names):\n",
    "    if \"Quant\" in init_name and \"param1\" in init_name:\n",
    "    # It is a scale value, check it\n",
    "        np_init = model.get_initializer(init_name)\n",
    "        np_abs_val = np.abs(np_init)\n",
    "        zero_idx = (np_abs_val < eps) * (np_abs_val > 0)\n",
    "        if np.all(zero_idx == False):\n",
    "            #print(f'Index = {idx}. {init_name} was not appended, as there were no values under epsilon')\n",
    "            continue\n",
    "        else:\n",
    "            zero_layer = np.where(zero_idx == True)[0]\n",
    "            quant_layer_name = init_name.split(\"_param\")[0]\n",
    "            layers_to_prune[quant_layer_name] = {1: {*zero_layer}}\n",
    "            #print(f'Index = {idx}. {init_name} appended, as there were values under epsilon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e1546a7-c519-44a1-bc09-b1a3bcdc1abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers to prune: 19\n",
      "Quant_0 {1: {17}}\n",
      "Quant_1 {1: {17}}\n",
      "Quant_6 {1: {31}}\n",
      "Quant_7 {1: {31}}\n",
      "Quant_12 {1: {36, 6, 40, 9, 43, 12, 46, 17, 26, 28}}\n",
      "Quant_13 {1: {36, 6, 40, 9, 43, 12, 46, 17, 26, 28}}\n",
      "Quant_15 {1: {0, 65, 2, 3, 67, 75, 14, 81, 18, 50, 52, 93, 22, 23, 88, 92, 61}}\n",
      "Quant_16 {1: {0, 65, 2, 3, 67, 75, 14, 81, 18, 50, 52, 93, 22, 23, 88, 92, 61}}\n",
      "Quant_18 {1: {3, 6, 8, 9, 11, 16, 17, 18, 25, 26, 33, 37, 39, 42, 52, 54, 62, 63, 71, 72, 74, 82, 84, 86, 90, 92, 93, 94, 99, 100, 102, 107, 111, 113, 116, 123, 124, 125, 126}}\n",
      "Quant_19 {1: {3, 6, 8, 9, 11, 16, 17, 18, 25, 26, 33, 37, 39, 42, 52, 54, 62, 63, 71, 72, 74, 82, 84, 86, 90, 92, 93, 94, 99, 100, 102, 107, 111, 113, 116, 123, 124, 125, 126}}\n",
      "Quant_21 {1: {0, 4, 5, 7, 13, 16, 17, 20, 21, 27, 30, 31, 33, 34, 35, 37, 40, 41, 49, 53, 60, 61, 62, 63, 64, 68, 71, 72, 76, 78, 79, 80, 82, 85, 88, 90, 91, 93, 95, 100, 102, 103, 105, 106, 107, 108, 116, 117, 120, 121, 123, 126}}\n",
      "Quant_22 {1: {0, 4, 5, 7, 13, 16, 17, 20, 21, 27, 30, 31, 33, 34, 35, 37, 40, 41, 49, 53, 60, 61, 62, 63, 64, 68, 71, 72, 76, 78, 79, 80, 82, 85, 88, 90, 91, 93, 95, 100, 102, 103, 105, 106, 107, 108, 116, 117, 120, 121, 123, 126}}\n",
      "Quant_24 {1: {11, 14, 23, 24, 57, 30}}\n",
      "Quant_25 {1: {11, 14, 23, 24, 57, 30}}\n",
      "Quant_26 {1: {2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 17, 18, 20, 23, 26, 27, 30, 32, 36, 41, 43, 46, 50, 51, 55, 57}}\n",
      "Quant_27 {1: {0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 18, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 41, 43, 44, 46, 47, 48, 51, 52, 55, 56, 57, 59, 60, 61, 64, 65, 67, 68, 69, 70, 71, 73, 75, 77, 78, 81, 82, 83, 85, 86, 88, 89, 92, 94, 95, 96, 97, 98, 99, 100, 102, 106, 107, 108, 110, 112, 114, 115, 116, 117, 118, 119, 121, 123, 125, 126, 127}}\n",
      "Quant_28 {1: {0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 18, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 41, 43, 44, 46, 47, 48, 51, 52, 55, 56, 57, 59, 60, 61, 64, 65, 67, 68, 69, 70, 71, 73, 75, 77, 78, 81, 82, 83, 85, 86, 88, 89, 92, 94, 95, 96, 97, 98, 99, 100, 102, 106, 107, 108, 110, 112, 114, 115, 116, 117, 118, 119, 121, 123, 125, 126, 127}}\n",
      "Quant_29 {1: {2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 17, 18, 20, 23, 26, 27, 30, 32, 36, 41, 43, 46, 50, 51, 55, 57}}\n",
      "Quant_30 {1: {0, 2, 6, 7, 8, 10, 11, 13, 14, 17, 20, 21, 26, 30, 32, 33, 35, 42, 43, 47, 49, 50, 52, 55, 58, 61, 63, 65, 66, 67, 68, 69, 70, 73, 78, 79, 85, 87, 88, 90, 91, 95, 98, 100, 101, 102, 103, 104, 106, 107, 109, 110, 112, 113, 114, 117, 119}}\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of layers to prune: {len(layers_to_prune)}')\n",
    "for k, v in layers_to_prune.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61a5d18a-a1a5-4792-82b1-1b82ce125966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(layers_to_prune[\"Quant_30\"][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377b7827-013e-4ac4-a544-4004af7525f0",
   "metadata": {},
   "source": [
    "### Get all Convolutions or Linears to be pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00b687c9-1a3b-4a4e-89f5-d7fe1d25e4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All convolutions to prune\n",
      "Conv_0\n",
      "Conv_1\n",
      "Conv_6\n",
      "Conv_7\n",
      "Conv_12\n",
      "Conv_13\n",
      "Conv_15\n",
      "Conv_16\n",
      "Conv_18\n",
      "Conv_19\n",
      "Conv_21\n",
      "Conv_22\n",
      "Conv_24\n",
      "Conv_25\n",
      "Conv_26\n",
      "Conv_27\n",
      "Conv_28\n",
      "Conv_29\n",
      "Conv_30\n"
     ]
    }
   ],
   "source": [
    "all_nodes = model.graph.node\n",
    "\n",
    "convs_to_prune = []\n",
    "\n",
    "for node in all_nodes:\n",
    "    for key in layers_to_prune.keys():\n",
    "        if key == node.name:\n",
    "            successor_node = model.find_direct_successors(node)[0]\n",
    "            convs_to_prune.append(successor_node.name)\n",
    "\n",
    "print(\"All convolutions to prune\")\n",
    "for conv in convs_to_prune:\n",
    "    print(conv)\n",
    "\n",
    "# # Remove last 5 convs, as they are harder to prune\n",
    "# for i in range(5):\n",
    "#     convs_to_prune.pop()\n",
    "\n",
    "# # Print again\n",
    "# print(\"\\nEasy convolutions to prune\")\n",
    "# for conv in convs_to_prune:\n",
    "#     print(conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c29554-1c21-49be-bd31-024acf0c4b7a",
   "metadata": {},
   "source": [
    "### Get Sparsity to compare after pruning\n",
    "\n",
    "Retrieve all weights from Convolutions and perform:\n",
    "$$\n",
    "Sparsity = \\frac{N_{Zeros}}{N_{Tensors}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1267b596-9bf5-496b-82d0-bd2db02d5490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(model_wrapper, layers_to_prune):\n",
    "    \n",
    "    sparse_dict = {}\n",
    "    \n",
    "    for key in layers_to_prune.keys():\n",
    "        init_name = key + \"_param0\"\n",
    "        np_init = model_wrapper.get_initializer(init_name)\n",
    "        n_zeros = np.count_nonzero(np_init == 0)\n",
    "        total_values = np_init.size\n",
    "        sparsity = round(n_zeros/total_values, 2)\n",
    "        #print(init_name, n_zeros, total_values, sparsity*100)\n",
    "        sparse_dict[init_name] = {\"zeros\": n_zeros, \"total\": total_values, \"sparsity\": sparsity}\n",
    "\n",
    "    return sparse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7f60308-3a4a-4cb0-a938-9ca529fa318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quant_0_param0 {'zeros': 107, 'total': 864, 'sparsity': 0.12}\n",
      "Quant_1_param0 {'zeros': 34, 'total': 288, 'sparsity': 0.12}\n",
      "Quant_6_param0 {'zeros': 54, 'total': 512, 'sparsity': 0.11}\n",
      "Quant_7_param0 {'zeros': 30, 'total': 288, 'sparsity': 0.1}\n",
      "Quant_12_param0 {'zeros': 343, 'total': 1152, 'sparsity': 0.3}\n",
      "Quant_13_param0 {'zeros': 115, 'total': 432, 'sparsity': 0.27}\n",
      "Quant_15_param0 {'zeros': 594, 'total': 2304, 'sparsity': 0.26}\n",
      "Quant_16_param0 {'zeros': 185, 'total': 864, 'sparsity': 0.21}\n",
      "Quant_18_param0 {'zeros': 1573, 'total': 4096, 'sparsity': 0.38}\n",
      "Quant_19_param0 {'zeros': 401, 'total': 1152, 'sparsity': 0.35}\n",
      "Quant_21_param0 {'zeros': 1903, 'total': 4096, 'sparsity': 0.46}\n",
      "Quant_22_param0 {'zeros': 524, 'total': 1152, 'sparsity': 0.45}\n",
      "Quant_24_param0 {'zeros': 393, 'total': 2048, 'sparsity': 0.19}\n",
      "Quant_25_param0 {'zeros': 85, 'total': 576, 'sparsity': 0.15}\n",
      "Quant_26_param0 {'zeros': 2129, 'total': 4096, 'sparsity': 0.52}\n",
      "Quant_27_param0 {'zeros': 6891, 'total': 8192, 'sparsity': 0.84}\n",
      "Quant_28_param0 {'zeros': 825, 'total': 1152, 'sparsity': 0.72}\n",
      "Quant_29_param0 {'zeros': 6863, 'total': 8192, 'sparsity': 0.84}\n",
      "Quant_30_param0 {'zeros': 5810, 'total': 8192, 'sparsity': 0.71}\n"
     ]
    }
   ],
   "source": [
    "sparsity_before_pruning = get_sparsity(model, layers_to_prune)\n",
    "for k, v in sparsity_before_pruning.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f60b7-f62e-4398-981b-cf4e04687b87",
   "metadata": {},
   "source": [
    "# Prune the Layers Manually\n",
    "\n",
    "- Convolution + BN: all convolutions are followed by Batch Norm, so they can be pruned together. Out channels will be pruned, so it impacts the next convolution, which input weights must be adapted.\n",
    "\n",
    "- Convolution + BN + ReLU: if convolution+bn is followed by ReLU, it must be pruned too.\n",
    "\n",
    "- DW Layer: this is a particular case. If a Conv Layer is pruned and next layer is Depth Wise, it must be pruned to, to fit the groups parameter in the output.\n",
    "\n",
    "## Process:\n",
    "```python\n",
    "def prune_conv(model, conv: str)\n",
    "```\n",
    "Args: \n",
    "- model: ModelWrapper of the model to prune\n",
    "- conv: string of the convolution layer to prune\n",
    ">**Steps**: <br>\n",
    ">1. Get Conv Node from model.\n",
    ">2. Find direct predecessors: [1] will be the convolution weights, so store it.\n",
    ">3. Modify convolution weights.\n",
    ">4. Modify the output shape of convolution weights.\n",
    ">5. Modify convolution output shape.\n",
    ">6. Find direct successor, which is batch norm layer.\n",
    ">7. Modify batch norm layer: weights and shape.\n",
    ">8. Find direct successor of batch norm: modify the output shape of ReLU+Quant or only Quant.\n",
    ">9. Find direct successor of last Quant node: it will be next convolution.\n",
    ">10. Prune the weights according to output channel pruned in previous convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84732158-a50b-4fb4-92a1-eb916db68c85",
   "metadata": {},
   "source": [
    "#### Prune weights of convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36399254-8bf3-4981-835c-9631dc3be47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_conv_weights(model, quant_node):\n",
    "\n",
    "    print(f'\\n############ Pruning Weights of {quant_node.name} node ############')\n",
    "    quant_0 = quant_node.input[0]\n",
    "    quant_1 = quant_node.input[1]\n",
    "    np_q0 = model.get_initializer(quant_0)\n",
    "    np_q1 = model.get_initializer(quant_1)\n",
    "    print(f'Quant 0 shape: {np_q0.shape}')\n",
    "    print(f'Quant 1 shape: {np_q1.shape}') \n",
    "\n",
    "    np_q1_abs = np.abs(np_q1)\n",
    "    zero_idx = np.where((np_q1_abs < 1e-10) * (np_q1_abs > 0))[0]\n",
    "    non_zero_idx = np.where(np_q1_abs > 1e-10)[0]\n",
    "    print(\"-------------------------------------\")\n",
    "    print(f'*** Zero IDX, channels to be pruned:\\n{zero_idx}')\n",
    "    print(f'### Non Zero IDX, channels to keep:\\n{non_zero_idx}')\n",
    "    print(\"-------------------------------------\")\n",
    "\n",
    "    new_np_q0 = np_q0[non_zero_idx]\n",
    "    print(f'New Quant 0 shape: {new_np_q0.shape}')\n",
    "    new_np_q1 = np_q1[non_zero_idx]\n",
    "    print(f'New Quant 1 shape: {new_np_q1.shape}')\n",
    "\n",
    "    model.set_initializer(\n",
    "        tensor_name = quant_0, \n",
    "        tensor_value = new_np_q0)\n",
    "    model.set_initializer(\n",
    "        tensor_name = quant_1, \n",
    "        tensor_value = new_np_q1)\n",
    "\n",
    "    ch, k, w, h = model.get_tensor_shape(quant_node.output[0])\n",
    "    print(f'{quant_node.name} output original shape: {ch, k, w, h}')\n",
    "    new_ch = new_np_q0.shape[0]\n",
    "    new_shape = (new_ch, k, w, h)\n",
    "    print(f'{quant_node.name} output new shape: {new_shape}')\n",
    "\n",
    "    model.set_tensor_shape(quant_node.output[0], new_shape) \n",
    "\n",
    "    return non_zero_idx, zero_idx, new_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64762b6d-e4f9-4ef9-afa5-d610fb3eef2e",
   "metadata": {},
   "source": [
    "##### Test weight pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b2d0096-f31d-4baa-87dc-0a7c21928b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_conv_weights(model, conv: str):\n",
    "    \n",
    "    conv_0_node = model.get_node_from_name(conv)\n",
    "    conv_0_node_predec = model.find_direct_predecessors(conv_0_node)\n",
    "    conv_0_weights_node = conv_0_node_predec[1]\n",
    "    \n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_0_weights_node)\n",
    "\n",
    "    return non_zero_idx, zero_idx, new_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eb5c15b-10d5-4959-9607-e38ad823635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_0 node ############\n",
      "Quant 0 shape: (32, 3, 3, 3)\n",
      "Quant 1 shape: (32, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned:\n",
      "[17]\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (31, 3, 3, 3)\n",
      "New Quant 1 shape: (31, 1, 1, 1)\n",
      "Quant_0 output original shape: (32, 3, 3, 3)\n",
      "Quant_0 output new shape: (31, 3, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "non_zero_idx, zero_idx, new_ch = test_prune_conv_weights(model, \"Conv_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6499ab3-ffc1-4b27-a3ae-b50d6184e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_weights = prune_folder + \"01_test_prune_weights.onnx\"\n",
    "model.save(test_prune_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b72cdea-05fd-4c9a-b57f-35e18949ad90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/01_test_prune_weights.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9d7f2ed060>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c922acb-dfd1-4cb6-80e4-abc616917252",
   "metadata": {},
   "source": [
    "#### Prune convolution output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a57b8a6b-280d-439e-a311-4bc499ee8a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_conv_out(model, conv_node, new_ch):\n",
    "\n",
    "    print(f'\\n############ Convert Convolution Output Shape {conv_node.name} node ############')\n",
    "    batch, ch, w, h = model.get_tensor_shape(conv_node.output[0])\n",
    "    print(f'Old Conv output shape: {(batch, ch, w, h)}')\n",
    "    new_shape = (batch, new_ch, w, h)\n",
    "    print(f'New Conv output shape: {new_shape}')\n",
    "\n",
    "    model.set_tensor_shape(conv_node.output[0], new_shape)\n",
    "\n",
    "    # Change groups\n",
    "    conv_group = conv_node.attribute[1].i\n",
    "    if conv_group != 1:\n",
    "        print(f'---> DW Conv found. Group {conv_group}, changed to {new_ch}')\n",
    "        conv_node.attribute[1].i = new_ch\n",
    "    else:\n",
    "        print(f'DW Conv not found. Group = {conv_group}')\n",
    "\n",
    "    return new_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a582026-4c4c-4043-ade3-c7a8bd156db1",
   "metadata": {},
   "source": [
    "##### Test conv output pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "127f03e9-d574-495f-8f4c-0e92db7f9c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_conv_output(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "    # Update conv out shape\n",
    "    new_shape = prune_conv_out(model, conv_node, new_ch)\n",
    "\n",
    "    return non_zero_idx, zero_idx, new_ch, new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "888f9fdc-2cbc-43e8-be01-2d8e9f633a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_0 node ############\n",
      "Quant 0 shape: (32, 3, 3, 3)\n",
      "Quant 1 shape: (32, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned:\n",
      "[17]\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (31, 3, 3, 3)\n",
      "New Quant 1 shape: (31, 1, 1, 1)\n",
      "Quant_0 output original shape: (32, 3, 3, 3)\n",
      "Quant_0 output new shape: (31, 3, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_0 node ############\n",
      "Old Conv output shape: (1, 32, 112, 112)\n",
      "New Conv output shape: (1, 31, 112, 112)\n",
      "DW Conv not found. Group = 1\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "non_zero_idx, zero_idx, new_ch, new_shape = test_prune_conv_output(model, \"Conv_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6a15e82-f724-4052-895b-27bbd2feddc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero IDX: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31]\n",
      "Zero IDX: [17]\n",
      "New Channels: 31\n",
      "New Shape: (1, 31, 112, 112)\n"
     ]
    }
   ],
   "source": [
    "print(f'Non Zero IDX: {non_zero_idx}\\nZero IDX: {zero_idx}\\nNew Channels: {new_ch}\\nNew Shape: {new_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "100caa35-7c4d-47cc-a652-1ece3c9d79e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_conv_out = prune_folder + \"02_test_prune_conv_out.onnx\"\n",
    "model.save(test_prune_conv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1ba000f-4891-4ad0-87da-56e46243461f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/02_test_prune_conv_out.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9d7f35b580>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_conv_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8844e-3e30-4dc9-82c2-33fd19753cbd",
   "metadata": {},
   "source": [
    "#### Prune batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "392fc9a2-a12e-4edf-8b11-e1048be90338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_bn(model, bn_node, new_shape, non_zero_idx, zero_idx):\n",
    "\n",
    "    print(f'\\n############ Prune Batch Norm {bn_node.name} node ############')\n",
    "    bn_0 = bn_node.input[1]\n",
    "    bn_1 = bn_node.input[2]\n",
    "    bn_2 = bn_node.input[3]\n",
    "    bn_3 = bn_node.input[4]\n",
    "    np_bn0 = model.get_initializer(bn_0)\n",
    "    np_bn1 = model.get_initializer(bn_1)\n",
    "    np_bn2 = model.get_initializer(bn_2)\n",
    "    np_bn3 = model.get_initializer(bn_3)\n",
    "    \n",
    "    print(f'BN0 shape: {np_bn0.shape}')\n",
    "    print(f'BN1 shape: {np_bn1.shape}')\n",
    "    print(f'BN2 shape: {np_bn2.shape}')\n",
    "    print(f'BN3 shape: {np_bn3.shape}')\n",
    "\n",
    "    print(\"-------------------------------------\")\n",
    "    print(f'*** Zero IDX, scale value of channels to be pruned:\\n{np_bn0[zero_idx]}')\n",
    "    print(\"-------------------------------------\")\n",
    "    \n",
    "    new_np_bn0 = np_bn0[non_zero_idx]\n",
    "    print(f'New {bn_0} shape: {new_np_bn0.shape}')\n",
    "    new_np_bn1 = np_bn1[non_zero_idx]\n",
    "    print(f'New {bn_1} shape: {new_np_bn1.shape}')\n",
    "    new_np_bn2 = np_bn2[non_zero_idx]\n",
    "    print(f'New {bn_2} shape: {new_np_bn2.shape}')\n",
    "    new_np_bn3 = np_bn3[non_zero_idx]\n",
    "    print(f'New {bn_3} shape: {new_np_bn3.shape}')\n",
    "\n",
    "    model.set_initializer(\n",
    "        tensor_name = bn_0, \n",
    "        tensor_value = new_np_bn0)\n",
    "    model.set_initializer(\n",
    "        tensor_name = bn_1, \n",
    "        tensor_value = new_np_bn1)\n",
    "    model.set_initializer(\n",
    "        tensor_name = bn_2, \n",
    "        tensor_value = new_np_bn2)\n",
    "    model.set_initializer(\n",
    "        tensor_name = bn_3, \n",
    "        tensor_value = new_np_bn3) \n",
    "\n",
    "    model.set_tensor_shape(bn_node.output[0], new_shape)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f22a0-e13a-4f48-a396-97eb3954e38f",
   "metadata": {},
   "source": [
    "##### Test prune batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86ad3d1b-a52e-4fa6-ac59-94ed24c754da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_conv_bn(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "    # Update conv out shape\n",
    "    new_shape = prune_conv_out(model=model, conv_node=conv_node, new_ch=new_ch)\n",
    "    # Prune batch norm\n",
    "    bn_node = model.find_direct_successors(conv_node)[0]\n",
    "    prune_bn(model, bn_node, new_shape, non_zero_idx, zero_idx)\n",
    "\n",
    "    return non_zero_idx, zero_idx, new_ch, new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f7f06c5-b464-4d1c-8fce-1f024afbb7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_0 node ############\n",
      "Quant 0 shape: (32, 3, 3, 3)\n",
      "Quant 1 shape: (32, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned:\n",
      "[17]\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (31, 3, 3, 3)\n",
      "New Quant 1 shape: (31, 1, 1, 1)\n",
      "Quant_0 output original shape: (32, 3, 3, 3)\n",
      "Quant_0 output new shape: (31, 3, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_0 node ############\n",
      "Old Conv output shape: (1, 32, 112, 112)\n",
      "New Conv output shape: (1, 31, 112, 112)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_0 node ############\n",
      "BN0 shape: (32,)\n",
      "BN1 shape: (32,)\n",
      "BN2 shape: (32,)\n",
      "BN3 shape: (32,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[4.913e-42]\n",
      "-------------------------------------\n",
      "New BatchNormalization_0_param0 shape: (31,)\n",
      "New BatchNormalization_0_param1 shape: (31,)\n",
      "New BatchNormalization_0_param2 shape: (31,)\n",
      "New BatchNormalization_0_param3 shape: (31,)\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "non_zero_idx, zero_idx, new_ch, new_shape = test_prune_conv_bn(model, \"Conv_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3983475-68f7-49e7-82c0-3d010ba617b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_conv_bn = prune_folder + \"03_test_prune_conv_bn.onnx\"\n",
    "model.save(test_prune_conv_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11bd15a2-a422-4e31-835d-b34d882f6300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/03_test_prune_conv_bn.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9d7f35a380>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_conv_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e979c3-113b-4dce-b282-f6feb282f914",
   "metadata": {},
   "source": [
    "#### Prune ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd967530-9a98-4c52-b671-bd055fa267b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_relu(model, relu_node, new_shape):\n",
    "\n",
    "    print(f'\\n############ Update output shape of {relu_node.name} node ############')\n",
    "    print(f'New shape: {new_shape}')\n",
    "    model.set_tensor_shape(relu_node.output[0], new_shape)               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8007521f-48c4-4132-bd1c-1164e435b9e1",
   "metadata": {},
   "source": [
    "##### Test update ReLU output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74442899-a877-4776-a3b7-1a80c41afbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_relu(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "    # Update conv out shape\n",
    "    new_shape = prune_conv_out(model=model, conv_node=conv_node, new_ch=new_ch)\n",
    "    # Prune batch norm\n",
    "    bn_node = model.find_direct_successors(conv_node)[0]\n",
    "    prune_bn(model, bn_node, new_shape, non_zero_idx, zero_idx)\n",
    "    \n",
    "    # Find Batch Norm successor\n",
    "    bn_successor_node = model.find_direct_successors(bn_node)[0]\n",
    "    if \"Relu\" in bn_successor_node.name:\n",
    "        # Prune ReLU output\n",
    "        relu_node = bn_successor_node\n",
    "        prune_relu(model=model, relu_node=relu_node, new_shape=new_shape)\n",
    "\n",
    "    return non_zero_idx, zero_idx, new_ch, new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16944251-510f-4680-97bf-934eef885fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_0 node ############\n",
      "Quant 0 shape: (32, 3, 3, 3)\n",
      "Quant 1 shape: (32, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned:\n",
      "[17]\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (31, 3, 3, 3)\n",
      "New Quant 1 shape: (31, 1, 1, 1)\n",
      "Quant_0 output original shape: (32, 3, 3, 3)\n",
      "Quant_0 output new shape: (31, 3, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_0 node ############\n",
      "Old Conv output shape: (1, 32, 112, 112)\n",
      "New Conv output shape: (1, 31, 112, 112)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_0 node ############\n",
      "BN0 shape: (32,)\n",
      "BN1 shape: (32,)\n",
      "BN2 shape: (32,)\n",
      "BN3 shape: (32,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[4.913e-42]\n",
      "-------------------------------------\n",
      "New BatchNormalization_0_param0 shape: (31,)\n",
      "New BatchNormalization_0_param1 shape: (31,)\n",
      "New BatchNormalization_0_param2 shape: (31,)\n",
      "New BatchNormalization_0_param3 shape: (31,)\n",
      "\n",
      "############ Update output shape of Relu_0 node ############\n",
      "New shape: (1, 31, 112, 112)\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "non_zero_idx, zero_idx, new_ch, new_shape = test_prune_relu(model, \"Conv_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d4d10b2-5348-4c17-a6d5-86a46fb291f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_relu = prune_folder + \"04_test_prune_relu.onnx\"\n",
    "model.save(test_prune_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28076b91-9ccf-47ba-9424-acc167fe1286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/04_test_prune_relu.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9d7f379d50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e5b0b-e019-47ff-8165-a90925607792",
   "metadata": {},
   "source": [
    "#### Prune quant Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e554e84-9d6d-4ac5-9690-bf3ced146161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_quant_out(model, quant_node, new_shape):\n",
    "\n",
    "    print(f'\\n############ Update output shape of {quant_node.name} node ############')\n",
    "    print(f'New shape: {new_shape}')\n",
    "    model.set_tensor_shape(quant_node.output[0], new_shape)              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf4400-e683-4802-a43a-f5939d7fb556",
   "metadata": {},
   "source": [
    "##### Test update of quant output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "206b3507-5f87-4ae7-89c5-7c04d8d41b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_quant_out(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "    # Update conv out shape\n",
    "    new_shape = prune_conv_out(model=model, conv_node=conv_node, new_ch=new_ch)\n",
    "    # Prune batch norm\n",
    "    bn_node = model.find_direct_successors(conv_node)[0]\n",
    "    prune_bn(model, bn_node, new_shape, non_zero_idx, zero_idx)\n",
    "    \n",
    "    # Find Batch Norm successor\n",
    "    bn_successor_node = model.find_direct_successors(bn_node)[0]\n",
    "    if \"Relu\" in bn_successor_node.name:\n",
    "        # Prune ReLU output\n",
    "        prune_relu(model=model, relu_node=bn_successor_node, new_shape=new_shape)\n",
    "        # Update successor to ReLU quant node\n",
    "        bn_successor_node = model.find_direct_successors(bn_successor_node)[0]\n",
    "    if \"Quant\" in bn_successor_node.name:\n",
    "        prune_quant_out(model, bn_successor_node, new_shape)   \n",
    "    else:\n",
    "        raise Exception(f'Node following BN is not ReLU or Quant: {bn_successor_node.name}')\n",
    "\n",
    "    return non_zero_idx, zero_idx, new_ch, new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b53f8206-2144-4faf-9af3-d598a195a88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_0 node ############\n",
      "Quant 0 shape: (32, 3, 3, 3)\n",
      "Quant 1 shape: (32, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned:\n",
      "[17]\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (31, 3, 3, 3)\n",
      "New Quant 1 shape: (31, 1, 1, 1)\n",
      "Quant_0 output original shape: (32, 3, 3, 3)\n",
      "Quant_0 output new shape: (31, 3, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_0 node ############\n",
      "Old Conv output shape: (1, 32, 112, 112)\n",
      "New Conv output shape: (1, 31, 112, 112)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_0 node ############\n",
      "BN0 shape: (32,)\n",
      "BN1 shape: (32,)\n",
      "BN2 shape: (32,)\n",
      "BN3 shape: (32,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[4.913e-42]\n",
      "-------------------------------------\n",
      "New BatchNormalization_0_param0 shape: (31,)\n",
      "New BatchNormalization_0_param1 shape: (31,)\n",
      "New BatchNormalization_0_param2 shape: (31,)\n",
      "New BatchNormalization_0_param3 shape: (31,)\n",
      "\n",
      "############ Update output shape of Relu_0 node ############\n",
      "New shape: (1, 31, 112, 112)\n",
      "\n",
      "############ Update output shape of Quant_34 node ############\n",
      "New shape: (1, 31, 112, 112)\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "non_zero_idx, zero_idx, new_ch, new_shape = test_prune_quant_out(model, \"Conv_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3925960f-9f89-4093-a02e-ef904c7025b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_quant_relu = prune_folder + \"05_test_prune_quant_relu.onnx\"\n",
    "model.save(test_prune_quant_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd1b6314-510d-41da-8169-6d9c4cf747c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/05_test_prune_quant_relu.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9d7f37bc40>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_quant_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53396193-b8e0-44fe-96ff-fb9ce4949e54",
   "metadata": {},
   "source": [
    "#### Prune Next Conv In Channels -> Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "869b2bea-f9d0-4e74-94eb-2b7c541ac931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_next_conv_inp(model, conv_node, non_zero_idx, zero_idx):\n",
    "\n",
    "    print(f'\\n............ Pruning Weights of {conv_node.name} node ............')   \n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    quant_node = conv_node_predec[1] # Quant node is [1]     \n",
    "    \n",
    "    quant_0 = quant_node.input[0]\n",
    "    np_q0 = model.get_initializer(quant_0)\n",
    "    print(f'{quant_0} shape: {np_q0.shape}')\n",
    "\n",
    "    new_np_q0 = np_q0[:, non_zero_idx]\n",
    "    new_shape = new_np_q0.shape\n",
    "    print(f'New {quant_0} shape: {new_shape}')\n",
    "    \n",
    "    print(\"-------------------------------------\")\n",
    "    all_weights_zero = np.all(np_q0[:, zero_idx] == 0.)\n",
    "    print(f'*** All weights removed are zero? {all_weights_zero}')\n",
    "    print(f'### Non Zero IDX, channels to keep:\\n{non_zero_idx}')\n",
    "    print(\"-------------------------------------\")\n",
    "\n",
    "    model.set_initializer(\n",
    "        tensor_name = quant_0, \n",
    "        tensor_value = new_np_q0) \n",
    "\n",
    "    print(f'Modify output shape of {quant_node.name} node: {new_shape}')\n",
    "    model.set_tensor_shape(quant_node.output[0], new_shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b559077-1fe2-458a-9f98-892da8200e55",
   "metadata": {},
   "source": [
    "##### Test Prune Next Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4337537-a6ed-41b3-9ef6-1e4c7fe67dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_next_conv_inp(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "    # Update conv out shape\n",
    "    new_shape = prune_conv_out(model=model, conv_node=conv_node, new_ch=new_ch)\n",
    "    # Prune batch norm\n",
    "    bn_node = model.find_direct_successors(conv_node)[0]\n",
    "    prune_bn(model, bn_node, new_shape, non_zero_idx, zero_idx)\n",
    "    \n",
    "    # Find Batch Norm successor\n",
    "    bn_successor_node = model.find_direct_successors(bn_node)[0]\n",
    "    if \"Relu\" in bn_successor_node.name:\n",
    "        # Prune relu output\n",
    "        prune_relu(model=model, relu_node=bn_successor_node, new_shape=new_shape)\n",
    "        # Update successor to relu quant node\n",
    "        bn_successor_node = model.find_direct_successors(bn_successor_node)[0]\n",
    "    if \"Quant\" in bn_successor_node.name:\n",
    "        # Always update the shape of Quant Node: it will be preceded by relu or batch norm\n",
    "        prune_quant_out(model, bn_successor_node, new_shape)   \n",
    "    else:\n",
    "        raise Exception(f'Node following BN is not ReLU or Quant: {bn_successor_node.name}')\n",
    "\n",
    "    # Prune next conv weights, so everything fits\n",
    "    next_successor_node = model.find_direct_successors(bn_successor_node)[0]\n",
    "    if \"Conv\" in next_successor_node.name:\n",
    "        conv_succesor_node = next_successor_node\n",
    "        print(f'\\nNext successor node is a convolution: {conv_succesor_node.name}')\n",
    "        # Check if next conv is DW. If so, skip, as whole pruning process must be done\n",
    "        conv_group = conv_succesor_node.attribute[1].i\n",
    "        if conv_group != 1:\n",
    "            print(f'---> DW Conv found. Group = {conv_group}. Skip')\n",
    "        else:\n",
    "            print(f'DW Conv not found. Group = {conv_group}. Prune Conv Weights')\n",
    "            prune_next_conv_inp(model, conv_succesor_node, non_zero_idx, zero_idx)\n",
    "    # Successor could be Average Pool too, keep in mind\n",
    "    elif \"AveragePool\" in next_successor_node.name:\n",
    "        avgpool_succesor_node = next_successor_node\n",
    "        print(f'\\nNext successor node is average pooling: {avgpool_succesor_node.name}')\n",
    "            \n",
    "    return non_zero_idx, zero_idx, new_ch, new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dece0c96-fba5-4c36-adfd-d5abb2c01fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_0 node ############\n",
      "Quant 0 shape: (32, 3, 3, 3)\n",
      "Quant 1 shape: (32, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned:\n",
      "[17]\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (31, 3, 3, 3)\n",
      "New Quant 1 shape: (31, 1, 1, 1)\n",
      "Quant_0 output original shape: (32, 3, 3, 3)\n",
      "Quant_0 output new shape: (31, 3, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_0 node ############\n",
      "Old Conv output shape: (1, 32, 112, 112)\n",
      "New Conv output shape: (1, 31, 112, 112)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_0 node ############\n",
      "BN0 shape: (32,)\n",
      "BN1 shape: (32,)\n",
      "BN2 shape: (32,)\n",
      "BN3 shape: (32,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[4.913e-42]\n",
      "-------------------------------------\n",
      "New BatchNormalization_0_param0 shape: (31,)\n",
      "New BatchNormalization_0_param1 shape: (31,)\n",
      "New BatchNormalization_0_param2 shape: (31,)\n",
      "New BatchNormalization_0_param3 shape: (31,)\n",
      "\n",
      "############ Update output shape of Relu_0 node ############\n",
      "New shape: (1, 31, 112, 112)\n",
      "\n",
      "############ Update output shape of Quant_34 node ############\n",
      "New shape: (1, 31, 112, 112)\n",
      "\n",
      "Next successor node is a convolution: Conv_1\n",
      "---> DW Conv found. Group = 32. Skip\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "non_zero_idx, zero_idx, new_ch, new_shape = test_prune_next_conv_inp(model, \"Conv_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3228871c-9ce5-4f60-80d5-062c7ea1517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_next_conv_inp_file = prune_folder + \"06_test_prune_next_conv_inp.onnx\"\n",
    "model.save(test_prune_next_conv_inp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb4df960-5c64-4bcd-bac0-08ccd0d0178d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/06_test_prune_next_conv_inp.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9d7f378c10>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_next_conv_inp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7429c9-ea9a-4d78-974d-0fa7662d6597",
   "metadata": {},
   "source": [
    "#### Prune add node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e6a1b03-f608-48f6-8fda-f000019edaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_add_node(model, add_node, new_shape):\n",
    "\n",
    "    print(f'\\n############ Update output shape of {add_node.name} node ############')\n",
    "    print(f'New shape: {new_shape}')\n",
    "    model.set_tensor_shape(add_node.output[0], new_shape)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb7bd7d-8cb1-41c4-9819-4d2c80f7921a",
   "metadata": {},
   "source": [
    "##### Test prune add node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ced1c47-9924-43f4-8fdb-14bc5b4faef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_conv_b4_avgpool(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "    # Update conv out shape\n",
    "    new_shape = prune_conv_out(model=model, conv_node=conv_node, new_ch=new_ch)\n",
    "    # Prune batch norm\n",
    "    bn_node = model.find_direct_successors(conv_node)[0]\n",
    "    prune_bn(model, bn_node, new_shape, non_zero_idx, zero_idx)\n",
    "    \n",
    "    # Find Batch Norm successor\n",
    "    bn_successor_node = model.find_direct_successors(bn_node)[0]\n",
    "    if \"Relu\" in bn_successor_node.name:\n",
    "        # Prune relu output\n",
    "        prune_relu(model=model, relu_node=bn_successor_node, new_shape=new_shape)\n",
    "        # Update successor to relu quant node\n",
    "        bn_successor_node = model.find_direct_successors(bn_successor_node)[0]\n",
    "    if \"Quant\" in bn_successor_node.name:\n",
    "        # Always update the shape of Quant Node: it will be preceded by relu or batch norm\n",
    "        prune_quant_out(model, bn_successor_node, new_shape)   \n",
    "    else:\n",
    "        raise Exception(f'Node following BN is not ReLU or Quant: {bn_successor_node.name}')\n",
    "\n",
    "    # Prune next conv weights, so everything fits\n",
    "    # Check first if it is fork node\n",
    "        # Fork node: \n",
    "            # [0] -> Conv\n",
    "            # [1] -> Add \n",
    "    next_successor_nodes = model.find_direct_successors(bn_successor_node)\n",
    "    next_successor_node = next_successor_nodes[0]\n",
    "    fork_node = False\n",
    "    if len(next_successor_nodes) >= 2:\n",
    "        print(f'This successor node is a fork: {bn_successor_node.name}') \n",
    "        fork_node = True\n",
    "        next_successor_node_fork = next_successor_nodes[1] \n",
    "        print(\"\\n\\t%%%%%%%%%%%%% This is the right branch of the fork\") \n",
    "        if \"Add\" in next_successor_node_fork.name:\n",
    "            add_node = next_successor_node_fork\n",
    "            prune_add_node(model, add_node, new_shape)\n",
    "            quant_add_node = model.find_direct_successors(add_node)[0]\n",
    "            if \"Quant\" in quant_add_node.name:\n",
    "                prune_quant_out(model, quant_add_node, new_shape)  \n",
    "            else:\n",
    "                raise Exception(f'Node following Add is not Quant: {quant_add_node.name}')\n",
    "            conv_after_quant = model.find_direct_successors(quant_add_node)[0]\n",
    "            if \"Conv\" in conv_after_quant.name:\n",
    "                print(f'\\nNext successor node is a convolution: {conv_after_quant.name}')\n",
    "                # Check if next conv is DW. If so, skip, as whole pruning process must be done\n",
    "                conv_group = conv_after_quant.attribute[1].i\n",
    "                if conv_group != 1:\n",
    "                    print(f'---> DW Conv found. Group = {conv_group}. Skip')\n",
    "                else:\n",
    "                    print(f'DW Conv not found. Group = {conv_group}. Prune Conv Weights')\n",
    "                    prune_next_conv_inp(model, conv_after_quant, non_zero_idx, zero_idx)\n",
    "            else:\n",
    "                raise Exception(f'Node following Quant Add is not Conv: {conv_after_quant.name}')\n",
    "        else:\n",
    "            print(f'\\nNext successor node is a fork, but not followed by Add node: {bn_successor_node.name}')     \n",
    "\n",
    "    # Always adjust the input weights of next conv, left side of the Fork if it is the case\n",
    "    if \"Conv\" in next_successor_node.name:\n",
    "        conv_succesor_node = next_successor_node\n",
    "        if fork_node:\n",
    "            print(\"\\n\\t%%%%%%%%%%%%% This is the left branch of the fork\")     \n",
    "        print(f'\\nNext successor node is a convolution: {conv_succesor_node.name}')\n",
    "        # Check if next conv is DW. If so, skip, as whole pruning process must be done\n",
    "        conv_group = conv_succesor_node.attribute[1].i\n",
    "        if conv_group != 1:\n",
    "            print(f'---> DW Conv found. Group = {conv_group}. Skip')\n",
    "        else:\n",
    "            print(f'DW Conv not found. Group = {conv_group}. Prune Conv Weights')\n",
    "            prune_next_conv_inp(model, conv_succesor_node, non_zero_idx, zero_idx)\n",
    "    elif \"Add\" in next_successor_node.name:\n",
    "        add_successor_node = next_successor_node\n",
    "        print(f'\\nNext successor node is add: {add_successor_node.name}. Skip')\n",
    "    # Successor could be Average Pool too, keep in mind\n",
    "    elif \"AveragePool\" in next_successor_node.name:\n",
    "        avgpool_succesor_node = next_successor_node\n",
    "        print(f'\\nNext successor node is average pooling: {avgpool_succesor_node.name}')\n",
    "            \n",
    "    return non_zero_idx, zero_idx, new_ch, new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8cdec6e6-fa67-4871-a4e8-45b2c161d42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_26 node ############\n",
      "Quant 0 shape: (64, 64, 1, 1)\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned:\n",
      "[ 2  3  5  6  7  8  9 11 12 13 17 18 20 23 26 27 30 32 36 41 43 46 50 51\n",
      " 55 57]\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  4 10 14 15 16 19 21 22 24 25 28 29 31 33 34 35 37 38 39 40 42 44\n",
      " 45 47 48 49 52 53 54 56 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (38, 64, 1, 1)\n",
      "New Quant 1 shape: (38, 1, 1, 1)\n",
      "Quant_26 output original shape: (64, 64, 1, 1)\n",
      "Quant_26 output new shape: (38, 64, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_26 node ############\n",
      "Old Conv output shape: (1, 64, 14, 14)\n",
      "New Conv output shape: (1, 38, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_26 node ############\n",
      "BN0 shape: (64,)\n",
      "BN1 shape: (64,)\n",
      "BN2 shape: (64,)\n",
      "BN3 shape: (64,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.928e-42  4.906e-42 -4.942e-42 -4.909e-42  4.949e-42 -4.921e-42\n",
      " -4.928e-42 -4.927e-42 -4.917e-42 -4.916e-42 -4.944e-42  4.919e-42\n",
      "  4.909e-42 -5.204e-42  4.948e-42 -4.942e-42  4.944e-42 -4.924e-42\n",
      "  4.951e-42 -4.916e-42  4.921e-42 -4.945e-42  4.948e-42 -4.951e-42\n",
      "  4.907e-42  4.921e-42]\n",
      "-------------------------------------\n",
      "New BatchNormalization_26_param0 shape: (38,)\n",
      "New BatchNormalization_26_param1 shape: (38,)\n",
      "New BatchNormalization_26_param2 shape: (38,)\n",
      "New BatchNormalization_26_param3 shape: (38,)\n",
      "\n",
      "############ Update output shape of Quant_64 node ############\n",
      "New shape: (1, 38, 14, 14)\n",
      "This successor node is a fork: Quant_64\n",
      "\n",
      "\t%%%%%%%%%%%%% This is the right branch of the fork\n",
      "\n",
      "############ Update output shape of Add_4 node ############\n",
      "New shape: (1, 38, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_68 node ############\n",
      "New shape: (1, 38, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_30\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_30 node ............\n",
      "Quant_30_param0 shape: (128, 64, 1, 1)\n",
      "New Quant_30_param0 shape: (128, 38, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  4 10 14 15 16 19 21 22 24 25 28 29 31 33 34 35 37 38 39 40 42 44\n",
      " 45 47 48 49 52 53 54 56 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_30 node: (128, 38, 1, 1)\n",
      "\n",
      "\t%%%%%%%%%%%%% This is the left branch of the fork\n",
      "\n",
      "Next successor node is a convolution: Conv_27\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_27 node ............\n",
      "Quant_27_param0 shape: (128, 64, 1, 1)\n",
      "New Quant_27_param0 shape: (128, 38, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  4 10 14 15 16 19 21 22 24 25 28 29 31 33 34 35 37 38 39 40 42 44\n",
      " 45 47 48 49 52 53 54 56 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_27 node: (128, 38, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "non_zero_idx, zero_idx, new_ch, new_shape = test_prune_conv_b4_avgpool(model, \"Conv_26\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c81dca23-9b89-4d0b-bd19-492c66061dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_conv_b4_avgpool_file = prune_folder + \"07_test_prune_conv_b4_avgpool.onnx\"\n",
    "model.save(test_prune_conv_b4_avgpool_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98d50b82-51a1-4cdc-94ea-cee35c79d9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/07_test_prune_conv_b4_avgpool.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9d7f37ac50>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_conv_b4_avgpool_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c3a550-f0bb-4e4b-bd3b-f54dc69b9803",
   "metadata": {},
   "source": [
    "##### Test prune convs 26, 27, 28, 29 and 30\n",
    "Check that resnet is pruned properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6772da0e-cba8-4eac-a17a-c41fcb4a8d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_26 node ############\n",
      "Quant 0 shape: (64, 64, 1, 1)\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned:\n",
      "[ 2  3  5  6  7  8  9 11 12 13 17 18 20 23 26 27 30 32 36 41 43 46 50 51\n",
      " 55 57]\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  4 10 14 15 16 19 21 22 24 25 28 29 31 33 34 35 37 38 39 40 42 44\n",
      " 45 47 48 49 52 53 54 56 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (38, 64, 1, 1)\n",
      "New Quant 1 shape: (38, 1, 1, 1)\n",
      "Quant_26 output original shape: (64, 64, 1, 1)\n",
      "Quant_26 output new shape: (38, 64, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_26 node ############\n",
      "Old Conv output shape: (1, 64, 14, 14)\n",
      "New Conv output shape: (1, 38, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_26 node ############\n",
      "BN0 shape: (64,)\n",
      "BN1 shape: (64,)\n",
      "BN2 shape: (64,)\n",
      "BN3 shape: (64,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.928e-42  4.906e-42 -4.942e-42 -4.909e-42  4.949e-42 -4.921e-42\n",
      " -4.928e-42 -4.927e-42 -4.917e-42 -4.916e-42 -4.944e-42  4.919e-42\n",
      "  4.909e-42 -5.204e-42  4.948e-42 -4.942e-42  4.944e-42 -4.924e-42\n",
      "  4.951e-42 -4.916e-42  4.921e-42 -4.945e-42  4.948e-42 -4.951e-42\n",
      "  4.907e-42  4.921e-42]\n",
      "-------------------------------------\n",
      "New BatchNormalization_26_param0 shape: (38,)\n",
      "New BatchNormalization_26_param1 shape: (38,)\n",
      "New BatchNormalization_26_param2 shape: (38,)\n",
      "New BatchNormalization_26_param3 shape: (38,)\n",
      "\n",
      "############ Update output shape of Quant_64 node ############\n",
      "New shape: (1, 38, 14, 14)\n",
      "This successor node is a fork: Quant_64\n",
      "\n",
      "\t%%%%%%%%%%%%% This is the right branch of the fork\n",
      "\n",
      "############ Update output shape of Add_4 node ############\n",
      "New shape: (1, 38, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_68 node ############\n",
      "New shape: (1, 38, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_30\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_30 node ............\n",
      "Quant_30_param0 shape: (128, 64, 1, 1)\n",
      "New Quant_30_param0 shape: (128, 38, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  4 10 14 15 16 19 21 22 24 25 28 29 31 33 34 35 37 38 39 40 42 44\n",
      " 45 47 48 49 52 53 54 56 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_30 node: (128, 38, 1, 1)\n",
      "\n",
      "\t%%%%%%%%%%%%% This is the left branch of the fork\n",
      "\n",
      "Next successor node is a convolution: Conv_27\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_27 node ............\n",
      "Quant_27_param0 shape: (128, 64, 1, 1)\n",
      "New Quant_27_param0 shape: (128, 38, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  4 10 14 15 16 19 21 22 24 25 28 29 31 33 34 35 37 38 39 40 42 44\n",
      " 45 47 48 49 52 53 54 56 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_27 node: (128, 38, 1, 1)\n",
      "\n",
      "############ Pruning Weights of Quant_27 node ############\n",
      "Quant 0 shape: (128, 38, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned:\n",
      "[  0   1   2   3   5   6   7   8  10  11  13  14  15  16  18  20  22  23\n",
      "  24  26  27  28  29  30  31  32  34  35  36  37  41  43  44  46  47  48\n",
      "  51  52  55  56  57  59  60  61  64  65  67  68  69  70  71  73  75  77\n",
      "  78  81  82  83  85  86  88  89  92  94  95  96  97  98  99 100 102 106\n",
      " 107 108 110 112 114 115 116 117 118 119 121 123 125 126 127]\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  4   9  12  17  19  21  25  33  38  39  40  42  45  49  50  53  54  58\n",
      "  62  63  66  72  74  76  79  80  84  87  90  91  93 101 103 104 105 109\n",
      " 111 113 120 122 124]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (41, 38, 1, 1)\n",
      "New Quant 1 shape: (41, 1, 1, 1)\n",
      "Quant_27 output original shape: (128, 38, 1, 1)\n",
      "Quant_27 output new shape: (41, 38, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_27 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 41, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_27 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.937e-42  4.934e-42  4.906e-42  4.924e-42  4.928e-42 -4.949e-42\n",
      "  4.912e-42  4.924e-42  4.937e-42  4.923e-42  4.928e-42  4.938e-42\n",
      "  4.951e-42  4.948e-42 -4.930e-42  4.933e-42  4.928e-42  4.913e-42\n",
      " -4.906e-42  4.919e-42  4.948e-42  4.910e-42  4.951e-42 -4.907e-42\n",
      "  4.916e-42 -4.941e-42  4.905e-42  4.941e-42  4.923e-42 -4.907e-42\n",
      "  4.924e-42 -4.919e-42 -4.934e-42  4.906e-42  4.919e-42  4.931e-42\n",
      "  4.924e-42 -4.920e-42  4.909e-42  4.941e-42  4.934e-42 -4.928e-42\n",
      "  4.933e-42  4.940e-42  4.930e-42 -4.949e-42  4.945e-42  4.940e-42\n",
      "  4.927e-42 -4.910e-42  4.947e-42  4.924e-42  4.909e-42 -4.914e-42\n",
      " -4.938e-42 -4.937e-42 -4.941e-42  4.942e-42 -4.968e-42 -4.949e-42\n",
      " -4.931e-42  4.954e-42  4.928e-42  4.944e-42  4.927e-42  4.917e-42\n",
      " -4.913e-42  4.944e-42 -4.930e-42  4.912e-42  4.947e-42  4.909e-42\n",
      " -4.914e-42  4.928e-42  4.914e-42 -4.909e-42  4.905e-42  4.951e-42\n",
      "  4.937e-42  4.949e-42  4.916e-42  4.907e-42  4.937e-42  4.921e-42\n",
      "  4.920e-42  4.921e-42 -4.931e-42]\n",
      "-------------------------------------\n",
      "New BatchNormalization_27_param0 shape: (41,)\n",
      "New BatchNormalization_27_param1 shape: (41,)\n",
      "New BatchNormalization_27_param2 shape: (41,)\n",
      "New BatchNormalization_27_param3 shape: (41,)\n",
      "\n",
      "############ Update output shape of Relu_18 node ############\n",
      "New shape: (1, 41, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_65 node ############\n",
      "New shape: (1, 41, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_28\n",
      "---> DW Conv found. Group = 128. Skip\n",
      "\n",
      "############ Pruning Weights of Quant_28 node ############\n",
      "Quant 0 shape: (128, 1, 3, 3)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned:\n",
      "[  0   1   2   3   5   6   7   8  10  11  13  14  15  16  18  20  22  23\n",
      "  24  26  27  28  29  30  31  32  34  35  36  37  41  43  44  46  47  48\n",
      "  51  52  55  56  57  59  60  61  64  65  67  68  69  70  71  73  75  77\n",
      "  78  81  82  83  85  86  88  89  92  94  95  96  97  98  99 100 102 106\n",
      " 107 108 110 112 114 115 116 117 118 119 121 123 125 126 127]\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  4   9  12  17  19  21  25  33  38  39  40  42  45  49  50  53  54  58\n",
      "  62  63  66  72  74  76  79  80  84  87  90  91  93 101 103 104 105 109\n",
      " 111 113 120 122 124]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (41, 1, 3, 3)\n",
      "New Quant 1 shape: (41, 1, 1, 1)\n",
      "Quant_28 output original shape: (128, 1, 3, 3)\n",
      "Quant_28 output new shape: (41, 1, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_28 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 41, 14, 14)\n",
      "---> DW Conv found. Group 128, changed to 41\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_28 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.947e-42 -4.940e-42  4.923e-42  4.912e-42  4.906e-42 -4.910e-42\n",
      "  4.952e-42  4.917e-42  4.913e-42  4.938e-42  4.928e-42  4.945e-42\n",
      "  4.938e-42  4.947e-42  4.947e-42  4.923e-42  4.931e-42  4.907e-42\n",
      " -4.942e-42  4.920e-42  4.942e-42 -5.308e-42  4.926e-42  4.906e-42\n",
      "  4.933e-42  4.928e-42  4.906e-42  4.906e-42  4.906e-42 -4.928e-42\n",
      " -4.942e-42  4.931e-42  4.928e-42  4.944e-42  4.909e-42  4.940e-42\n",
      "  4.947e-42 -4.948e-42 -4.914e-42  4.910e-42  4.944e-42 -4.923e-42\n",
      "  4.916e-42  4.920e-42  4.952e-42  4.926e-42  4.930e-42  4.906e-42\n",
      "  4.917e-42  4.949e-42  4.945e-42 -4.942e-42  4.926e-42 -4.912e-42\n",
      " -4.937e-42 -4.933e-42  4.919e-42  4.941e-42  4.944e-42 -5.206e-42\n",
      "  4.947e-42  4.954e-42  4.912e-42  4.910e-42 -4.909e-42  4.921e-42\n",
      " -4.934e-42  4.931e-42 -4.928e-42  4.906e-42  4.907e-42  4.926e-42\n",
      "  4.927e-42 -4.926e-42  4.949e-42 -5.415e-42 -4.914e-42 -4.935e-42\n",
      " -4.934e-42  4.948e-42  4.926e-42  4.927e-42  4.930e-42  4.906e-42\n",
      "  4.938e-42  4.928e-42 -4.923e-42]\n",
      "-------------------------------------\n",
      "New BatchNormalization_28_param0 shape: (41,)\n",
      "New BatchNormalization_28_param1 shape: (41,)\n",
      "New BatchNormalization_28_param2 shape: (41,)\n",
      "New BatchNormalization_28_param3 shape: (41,)\n",
      "\n",
      "############ Update output shape of Relu_19 node ############\n",
      "New shape: (1, 41, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_66 node ############\n",
      "New shape: (1, 41, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_29\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_29 node ............\n",
      "Quant_29_param0 shape: (64, 128, 1, 1)\n",
      "New Quant_29_param0 shape: (64, 41, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  4   9  12  17  19  21  25  33  38  39  40  42  45  49  50  53  54  58\n",
      "  62  63  66  72  74  76  79  80  84  87  90  91  93 101 103 104 105 109\n",
      " 111 113 120 122 124]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_29 node: (64, 41, 1, 1)\n",
      "\n",
      "############ Pruning Weights of Quant_29 node ############\n",
      "Quant 0 shape: (64, 41, 1, 1)\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned:\n",
      "[ 2  3  5  6  7  8  9 11 12 13 17 18 20 23 26 27 30 32 36 41 43 46 50 51\n",
      " 55 57]\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  4 10 14 15 16 19 21 22 24 25 28 29 31 33 34 35 37 38 39 40 42 44\n",
      " 45 47 48 49 52 53 54 56 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (38, 41, 1, 1)\n",
      "New Quant 1 shape: (38, 1, 1, 1)\n",
      "Quant_29 output original shape: (64, 41, 1, 1)\n",
      "Quant_29 output new shape: (38, 41, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_29 node ############\n",
      "Old Conv output shape: (1, 64, 14, 14)\n",
      "New Conv output shape: (1, 38, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_29 node ############\n",
      "BN0 shape: (64,)\n",
      "BN1 shape: (64,)\n",
      "BN2 shape: (64,)\n",
      "BN3 shape: (64,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.926e-42  4.917e-42 -4.933e-42 -4.945e-42  4.942e-42  4.945e-42\n",
      " -4.928e-42 -4.941e-42 -4.912e-42  4.919e-42 -4.942e-42  4.909e-42\n",
      " -4.938e-42 -4.937e-42 -4.944e-42  4.909e-42  4.926e-42 -4.928e-42\n",
      "  4.928e-42  4.934e-42  4.938e-42  4.949e-42 -4.919e-42  4.935e-42\n",
      "  4.916e-42 -4.927e-42]\n",
      "-------------------------------------\n",
      "New BatchNormalization_29_param0 shape: (38,)\n",
      "New BatchNormalization_29_param1 shape: (38,)\n",
      "New BatchNormalization_29_param2 shape: (38,)\n",
      "New BatchNormalization_29_param3 shape: (38,)\n",
      "\n",
      "############ Update output shape of Quant_67 node ############\n",
      "New shape: (1, 38, 14, 14)\n",
      "\n",
      "Next successor node is add: Add_4. Skip\n",
      "\n",
      "############ Pruning Weights of Quant_30 node ############\n",
      "Quant 0 shape: (128, 38, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned:\n",
      "[  0   2   6   7   8  10  11  13  14  17  20  21  26  30  32  33  35  42\n",
      "  43  47  49  50  52  55  58  61  63  65  66  67  68  69  70  73  78  79\n",
      "  85  87  88  90  91  95  98 100 101 102 103 104 106 107 109 110 112 113\n",
      " 114 117 119]\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  1   3   4   5   9  12  15  16  18  19  22  23  24  25  27  28  29  31\n",
      "  34  36  37  38  39  40  41  44  45  46  48  51  53  54  56  57  59  60\n",
      "  62  64  71  72  74  75  76  77  80  81  82  83  84  86  89  92  93  94\n",
      "  96  97  99 105 108 111 115 116 118 120 121 122 123 124 125 126 127]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (71, 38, 1, 1)\n",
      "New Quant 1 shape: (71, 1, 1, 1)\n",
      "Quant_30 output original shape: (128, 38, 1, 1)\n",
      "Quant_30 output new shape: (71, 38, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_30 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 71, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_30 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-5.741e-42  4.930e-42  4.952e-42  4.916e-42  4.920e-42  4.930e-42\n",
      "  4.924e-42  4.938e-42  4.948e-42  4.912e-42 -4.951e-42  4.907e-42\n",
      "  4.951e-42  4.931e-42  4.938e-42 -4.920e-42  4.935e-42  4.940e-42\n",
      "  4.927e-42 -4.914e-42  4.916e-42  4.930e-42 -4.940e-42 -4.912e-42\n",
      " -4.920e-42  4.927e-42 -4.940e-42 -4.948e-42  4.941e-42 -4.937e-42\n",
      "  4.907e-42 -4.941e-42 -6.096e-42 -4.912e-42  4.944e-42  4.933e-42\n",
      "  4.930e-42  4.926e-42 -5.535e-42 -4.948e-42  4.928e-42  4.927e-42\n",
      "  4.951e-42  4.907e-42  4.913e-42  4.942e-42 -4.933e-42  4.912e-42\n",
      " -4.940e-42  4.941e-42 -4.934e-42  4.942e-42  4.941e-42 -4.921e-42\n",
      " -4.921e-42 -4.919e-42 -4.927e-42]\n",
      "-------------------------------------\n",
      "New BatchNormalization_30_param0 shape: (71,)\n",
      "New BatchNormalization_30_param1 shape: (71,)\n",
      "New BatchNormalization_30_param2 shape: (71,)\n",
      "New BatchNormalization_30_param3 shape: (71,)\n",
      "\n",
      "############ Update output shape of Relu_20 node ############\n",
      "New shape: (1, 71, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_69 node ############\n",
      "New shape: (1, 71, 14, 14)\n",
      "\n",
      "Next successor node is average pooling: AveragePool_0\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "_, _, _, _ = test_prune_conv_b4_avgpool(model, \"Conv_26\")\n",
    "_, _, _, _ = test_prune_conv_b4_avgpool(model, \"Conv_27\")\n",
    "_, _, _, _ = test_prune_conv_b4_avgpool(model, \"Conv_28\")\n",
    "_, _, _, _ = test_prune_conv_b4_avgpool(model, \"Conv_29\")\n",
    "_, _, _, _ = test_prune_conv_b4_avgpool(model, \"Conv_30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8afab7a1-080c-490b-b0ee-04f3de3147c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_resnet = prune_folder + \"08_test_prune_resnet.onnx\"\n",
    "model.save(test_prune_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e344426a-be9e-4142-be1e-5bd3f18da2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/08_test_prune_resnet.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9d7f37ba60>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40021505-a4e4-4d57-b86e-9b367376311c",
   "metadata": {},
   "source": [
    "#### Prune Avg Pool and Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f810bf3e-5a96-4509-a6e3-131633b1e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_avgpool_reshape(model, avgpool_node, new_shape):\n",
    "\n",
    "    print(f'\\n############ Update output shape of {avgpool_node.name} node ############')\n",
    "    avgpool_old_shape = model.get_tensor_shape(avgpool_node.output[0])\n",
    "    print(f'Old Avg Pool output shape: {avgpool_old_shape}')\n",
    "    avgpool_new_shape = (new_shape[0], new_shape[1], 1, 1)\n",
    "    print(f'New shape: {avgpool_new_shape}')\n",
    "    model.set_tensor_shape(avgpool_node.output[0], avgpool_new_shape)\n",
    "\n",
    "    mul_node = model.find_direct_successors(avgpool_node)[0]\n",
    "    if \"Mul\" in mul_node.name:\n",
    "        print(f'\\n############ Update output shape of {mul_node.name} node ############')\n",
    "        print(f'New shape: {avgpool_new_shape}')\n",
    "        model.set_tensor_shape(mul_node.output[0], avgpool_new_shape)\n",
    "    else:\n",
    "        raise Exception(f'Node following AvgPool is not Mul: {mul_node.name}')  \n",
    "\n",
    "    trunc_node = model.find_direct_successors(mul_node)[0]\n",
    "    if \"Trunc\" in trunc_node.name:\n",
    "        print(f'\\n############ Update output shape of {trunc_node.name} node ############')\n",
    "        print(f'New shape: {avgpool_new_shape}')\n",
    "        model.set_tensor_shape(trunc_node.output[0], avgpool_new_shape)\n",
    "    else:\n",
    "        raise Exception(f'Node following Mul is not Trunc: {trunc_node.name}')  \n",
    "\n",
    "    reshape_node = model.find_direct_successors(trunc_node)[0]\n",
    "    if \"Reshape\" in reshape_node.name:\n",
    "        print(f'\\n############ Update output shape of {reshape_node.name} node ############')\n",
    "        reshape_shape = (avgpool_new_shape[0], avgpool_new_shape[1])\n",
    "        print(f'New shape: {reshape_shape}')\n",
    "        model.set_tensor_shape(reshape_node.output[0], reshape_shape)\n",
    "    else:\n",
    "        raise Exception(f'Node following Trunc is not Reshape: {reshape_node.name}') \n",
    "\n",
    "    gemm_node = model.find_direct_successors(reshape_node)[0]\n",
    "    if \"Gemm\" in gemm_node.name:\n",
    "        print(f'\\n############ Gemm node found: {gemm_node.name} node ############')\n",
    "    else:\n",
    "        raise Exception(f'Node following Trunc is not Reshape: {gemm_node.name}')     \n",
    "   \n",
    "    return gemm_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41fbcbc-7ab8-4f9c-a159-af3177ee071f",
   "metadata": {},
   "source": [
    "##### Test prune avgpool and reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff7484e0-9f0c-48c4-8acc-c72ae335dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_conv_and_avgpool(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "    # Update conv out shape\n",
    "    new_shape = prune_conv_out(model=model, conv_node=conv_node, new_ch=new_ch)\n",
    "    # Prune batch norm\n",
    "    bn_node = model.find_direct_successors(conv_node)[0]\n",
    "    prune_bn(model, bn_node, new_shape, non_zero_idx, zero_idx)\n",
    "    \n",
    "    # Find Batch Norm successor\n",
    "    bn_successor_node = model.find_direct_successors(bn_node)[0]\n",
    "    if \"Relu\" in bn_successor_node.name:\n",
    "        # Prune relu output\n",
    "        prune_relu(model=model, relu_node=bn_successor_node, new_shape=new_shape)\n",
    "        # Update successor to relu quant node\n",
    "        bn_successor_node = model.find_direct_successors(bn_successor_node)[0]\n",
    "    if \"Quant\" in bn_successor_node.name:\n",
    "        # Always update the shape of Quant Node: it will be preceded by relu or batch norm\n",
    "        prune_quant_out(model, bn_successor_node, new_shape)   \n",
    "    else:\n",
    "        raise Exception(f'Node following BN is not ReLU or Quant: {bn_successor_node.name}')\n",
    "\n",
    "    # Prune next conv weights, so everything fits\n",
    "    # Check first if it is fork node\n",
    "        # Fork node: \n",
    "            # [0] -> Conv\n",
    "            # [1] -> Add \n",
    "    next_successor_nodes = model.find_direct_successors(bn_successor_node)\n",
    "    next_successor_node = next_successor_nodes[0]\n",
    "    fork_node = False\n",
    "    if len(next_successor_nodes) >= 2:\n",
    "        print(f'This successor node is a fork: {bn_successor_node.name}') \n",
    "        fork_node = True\n",
    "        next_successor_node_fork = next_successor_nodes[1] \n",
    "        print(\"\\n\\t%%%%%%%%%%%%% This is the right branch of the fork\") \n",
    "        if \"Add\" in next_successor_node_fork.name:\n",
    "            add_node = next_successor_node_fork\n",
    "            prune_add_node(model, add_node, new_shape)\n",
    "            quant_add_node = model.find_direct_successors(add_node)[0]\n",
    "            if \"Quant\" in quant_add_node.name:\n",
    "                prune_quant_out(model, quant_add_node, new_shape)  \n",
    "            else:\n",
    "                raise Exception(f'Node following Add is not Quant: {quant_add_node.name}')\n",
    "            conv_after_quant = model.find_direct_successors(quant_add_node)[0]\n",
    "            if \"Conv\" in conv_after_quant.name:\n",
    "                print(f'\\nNext successor node is a convolution: {conv_after_quant.name}')\n",
    "                # Check if next conv is DW. If so, skip, as whole pruning process must be done\n",
    "                conv_group = conv_after_quant.attribute[1].i\n",
    "                if conv_group != 1:\n",
    "                    print(f'---> DW Conv found. Group = {conv_group}. Skip')\n",
    "                else:\n",
    "                    print(f'DW Conv not found. Group = {conv_group}. Prune Conv Weights')\n",
    "                    prune_next_conv_inp(model, conv_after_quant, non_zero_idx, zero_idx)\n",
    "            else:\n",
    "                raise Exception(f'Node following Quant Add is not Conv: {conv_after_quant.name}')\n",
    "        else:\n",
    "            print(f'\\nNext successor node is a fork, but not followed by Add node: {bn_successor_node.name}')     \n",
    "\n",
    "    # Always adjust the input weights of next conv, left side of the Fork if it is the case\n",
    "    if \"Conv\" in next_successor_node.name:\n",
    "        conv_succesor_node = next_successor_node\n",
    "        if fork_node:\n",
    "            print(\"\\n\\t%%%%%%%%%%%%% This is the left branch of the fork\")     \n",
    "        print(f'\\nNext successor node is a convolution: {conv_succesor_node.name}')\n",
    "        # Check if next conv is DW. If so, skip, as whole pruning process must be done\n",
    "        conv_group = conv_succesor_node.attribute[1].i\n",
    "        if conv_group != 1:\n",
    "            print(f'---> DW Conv found. Group = {conv_group}. Skip')\n",
    "        else:\n",
    "            print(f'DW Conv not found. Group = {conv_group}. Prune Conv Weights')\n",
    "            prune_next_conv_inp(model, conv_succesor_node, non_zero_idx, zero_idx)\n",
    "    elif \"Add\" in next_successor_node.name:\n",
    "        add_successor_node = next_successor_node\n",
    "        print(f'\\nNext successor node is add: {add_successor_node.name}. Skip')\n",
    "    # Successor could be Average Pool too, keep in mind\n",
    "    elif \"AveragePool\" in next_successor_node.name:\n",
    "        avgpool_succesor_node = next_successor_node\n",
    "        print(f'\\nNext successor node is average pooling: {avgpool_succesor_node.name}')\n",
    "        gemm_node = prune_avgpool_reshape(model, avgpool_succesor_node, new_shape)\n",
    "            \n",
    "    return non_zero_idx, zero_idx, new_ch, new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d59c668-39ec-424c-a209-ff53053c5472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_30 node ############\n",
      "Quant 0 shape: (128, 64, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned:\n",
      "[  0   2   6   7   8  10  11  13  14  17  20  21  26  30  32  33  35  42\n",
      "  43  47  49  50  52  55  58  61  63  65  66  67  68  69  70  73  78  79\n",
      "  85  87  88  90  91  95  98 100 101 102 103 104 106 107 109 110 112 113\n",
      " 114 117 119]\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  1   3   4   5   9  12  15  16  18  19  22  23  24  25  27  28  29  31\n",
      "  34  36  37  38  39  40  41  44  45  46  48  51  53  54  56  57  59  60\n",
      "  62  64  71  72  74  75  76  77  80  81  82  83  84  86  89  92  93  94\n",
      "  96  97  99 105 108 111 115 116 118 120 121 122 123 124 125 126 127]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (71, 64, 1, 1)\n",
      "New Quant 1 shape: (71, 1, 1, 1)\n",
      "Quant_30 output original shape: (128, 64, 1, 1)\n",
      "Quant_30 output new shape: (71, 64, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_30 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 71, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_30 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-5.741e-42  4.930e-42  4.952e-42  4.916e-42  4.920e-42  4.930e-42\n",
      "  4.924e-42  4.938e-42  4.948e-42  4.912e-42 -4.951e-42  4.907e-42\n",
      "  4.951e-42  4.931e-42  4.938e-42 -4.920e-42  4.935e-42  4.940e-42\n",
      "  4.927e-42 -4.914e-42  4.916e-42  4.930e-42 -4.940e-42 -4.912e-42\n",
      " -4.920e-42  4.927e-42 -4.940e-42 -4.948e-42  4.941e-42 -4.937e-42\n",
      "  4.907e-42 -4.941e-42 -6.096e-42 -4.912e-42  4.944e-42  4.933e-42\n",
      "  4.930e-42  4.926e-42 -5.535e-42 -4.948e-42  4.928e-42  4.927e-42\n",
      "  4.951e-42  4.907e-42  4.913e-42  4.942e-42 -4.933e-42  4.912e-42\n",
      " -4.940e-42  4.941e-42 -4.934e-42  4.942e-42  4.941e-42 -4.921e-42\n",
      " -4.921e-42 -4.919e-42 -4.927e-42]\n",
      "-------------------------------------\n",
      "New BatchNormalization_30_param0 shape: (71,)\n",
      "New BatchNormalization_30_param1 shape: (71,)\n",
      "New BatchNormalization_30_param2 shape: (71,)\n",
      "New BatchNormalization_30_param3 shape: (71,)\n",
      "\n",
      "############ Update output shape of Relu_20 node ############\n",
      "New shape: (1, 71, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_69 node ############\n",
      "New shape: (1, 71, 14, 14)\n",
      "\n",
      "Next successor node is average pooling: AveragePool_0\n",
      "\n",
      "############ Update output shape of AveragePool_0 node ############\n",
      "Old Avg Pool output shape: [1, 128, 1, 1]\n",
      "New shape: (1, 71, 1, 1)\n",
      "\n",
      "############ Update output shape of Mul_1 node ############\n",
      "New shape: (1, 71, 1, 1)\n",
      "\n",
      "############ Update output shape of Trunc_0 node ############\n",
      "New shape: (1, 71, 1, 1)\n",
      "\n",
      "############ Update output shape of Reshape_0 node ############\n",
      "New shape: (1, 71)\n",
      "\n",
      "############ Gemm node found: Gemm_0 node ############\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "_, _, _, _ = test_prune_conv_and_avgpool(model, \"Conv_30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcf5a997-0dfd-4a07-af0e-cf8b3ec2800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_avgpool = prune_folder + \"09_test_prune_avgpool.onnx\"\n",
    "model.save(test_prune_avgpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2d6cd25a-fe65-4881-8ee3-8d0a655b8efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/09_test_prune_avgpool.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9d7ef23970>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_avgpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a30356-e474-4329-ac51-064900fa7c29",
   "metadata": {},
   "source": [
    "#### Prune GEMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3e18772e-a539-43d8-9247-8be2e2be73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_next_gemm_inp(model, gemm_node, non_zero_idx, zero_idx):\n",
    "\n",
    "    print(f'\\n............ Pruning Weights of {gemm_node.name} node ............')   \n",
    "    gemm_node_predec = model.find_direct_predecessors(gemm_node)\n",
    "    quant_node = gemm_node_predec[1]  # Quant node is [1]  \n",
    "    \n",
    "    quant_0 = quant_node.input[0]\n",
    "    np_q0 = model.get_initializer(quant_0)\n",
    "    print(f'{quant_0} shape: {np_q0.shape}')\n",
    "\n",
    "    new_np_q0 = np_q0[:, non_zero_idx]\n",
    "    new_shape = new_np_q0.shape\n",
    "    print(f'New {quant_0} shape: {new_shape}')\n",
    "    \n",
    "    print(\"-------------------------------------\")\n",
    "    all_weights_zero = np.all(np_q0[:, zero_idx] == 0.)\n",
    "    print(f'*** All weights removed are zero? {all_weights_zero}')\n",
    "    print(f'### Non Zero IDX, channels to keep:\\n{non_zero_idx}')\n",
    "    print(\"-------------------------------------\")\n",
    "\n",
    "    model.set_initializer(\n",
    "        tensor_name = quant_0, \n",
    "        tensor_value = new_np_q0) \n",
    "\n",
    "    print(f'Modify output shape of {quant_node.name} node: {new_shape}')\n",
    "    model.set_tensor_shape(quant_node.output[0], new_shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dbb78f-039e-477f-93e4-4850379e3eb9",
   "metadata": {},
   "source": [
    "##### Test prune GEMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1cfd66d-7398-41f8-bd43-1ae15f5abcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_any_conv(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "    # Update conv out shape\n",
    "    new_shape = prune_conv_out(model=model, conv_node=conv_node, new_ch=new_ch)\n",
    "    # Prune batch norm\n",
    "    bn_node = model.find_direct_successors(conv_node)[0]\n",
    "    prune_bn(model, bn_node, new_shape, non_zero_idx, zero_idx)\n",
    "    \n",
    "    # Find Batch Norm successor\n",
    "    bn_successor_node = model.find_direct_successors(bn_node)[0]\n",
    "    if \"Relu\" in bn_successor_node.name:\n",
    "        # Prune relu output\n",
    "        prune_relu(model=model, relu_node=bn_successor_node, new_shape=new_shape)\n",
    "        # Update successor to relu quant node\n",
    "        bn_successor_node = model.find_direct_successors(bn_successor_node)[0]\n",
    "    if \"Quant\" in bn_successor_node.name:\n",
    "        # Always update the shape of Quant Node: it will be preceded by relu or batch norm\n",
    "        prune_quant_out(model, bn_successor_node, new_shape)   \n",
    "    else:\n",
    "        raise Exception(f'Node following BN is not ReLU or Quant: {bn_successor_node.name}')\n",
    "\n",
    "    # Prune next conv weights, so everything fits\n",
    "    # Check first if it is fork node\n",
    "        # Fork node: \n",
    "            # [0] -> Conv\n",
    "            # [1] -> Add \n",
    "    next_successor_nodes = model.find_direct_successors(bn_successor_node)\n",
    "    next_successor_node = next_successor_nodes[0]\n",
    "    fork_node = False\n",
    "    if len(next_successor_nodes) >= 2:\n",
    "        print(f'This successor node is a fork: {bn_successor_node.name}') \n",
    "        fork_node = True\n",
    "        next_successor_node_fork = next_successor_nodes[1] \n",
    "        print(\"\\n\\t%%%%%%%%%%%%% This is the right branch of the fork\") \n",
    "        if \"Add\" in next_successor_node_fork.name:\n",
    "            add_node = next_successor_node_fork\n",
    "            prune_add_node(model, add_node, new_shape)\n",
    "            quant_add_node = model.find_direct_successors(add_node)[0]\n",
    "            if \"Quant\" in quant_add_node.name:\n",
    "                prune_quant_out(model, quant_add_node, new_shape)  \n",
    "            else:\n",
    "                raise Exception(f'Node following Add is not Quant: {quant_add_node.name}')\n",
    "            conv_after_quant = model.find_direct_successors(quant_add_node)[0]\n",
    "            if \"Conv\" in conv_after_quant.name:\n",
    "                print(f'\\nNext successor node is a convolution: {conv_after_quant.name}')\n",
    "                # Check if next conv is DW. If so, skip, as whole pruning process must be done\n",
    "                conv_group = conv_after_quant.attribute[1].i\n",
    "                if conv_group != 1:\n",
    "                    print(f'---> DW Conv found. Group = {conv_group}. Skip')\n",
    "                else:\n",
    "                    print(f'DW Conv not found. Group = {conv_group}. Prune Conv Weights')\n",
    "                    prune_next_conv_inp(model, conv_after_quant, non_zero_idx, zero_idx)\n",
    "            else:\n",
    "                raise Exception(f'Node following Quant Add is not Conv: {conv_after_quant.name}')\n",
    "        else:\n",
    "            print(f'\\nNext successor node is a fork, but not followed by Add node: {bn_successor_node.name}')     \n",
    "\n",
    "    # Always adjust the input weights of next conv, left side of the Fork if it is the case\n",
    "    if \"Conv\" in next_successor_node.name:\n",
    "        conv_succesor_node = next_successor_node\n",
    "        if fork_node:\n",
    "            print(\"\\n\\t%%%%%%%%%%%%% This is the left branch of the fork\")     \n",
    "        print(f'\\nNext successor node is a convolution: {conv_succesor_node.name}')\n",
    "        # Check if next conv is DW. If so, skip, as whole pruning process must be done\n",
    "        conv_group = conv_succesor_node.attribute[1].i\n",
    "        if conv_group != 1:\n",
    "            print(f'---> DW Conv found. Group = {conv_group}. Skip')\n",
    "        else:\n",
    "            print(f'DW Conv not found. Group = {conv_group}. Prune Conv Weights')\n",
    "            prune_next_conv_inp(model, conv_succesor_node, non_zero_idx, zero_idx)\n",
    "    elif \"Add\" in next_successor_node.name:\n",
    "        add_successor_node = next_successor_node\n",
    "        print(f'\\nNext successor node is add: {add_successor_node.name}. Skip')\n",
    "    # Successor could be Average Pool too, keep in mind\n",
    "    elif \"AveragePool\" in next_successor_node.name:\n",
    "        avgpool_succesor_node = next_successor_node\n",
    "        print(f'\\nNext successor node is average pooling: {avgpool_succesor_node.name}')\n",
    "        gemm_node = prune_avgpool_reshape(model, avgpool_succesor_node, new_shape)\n",
    "        prune_next_gemm_inp(model, gemm_node, non_zero_idx, zero_idx)\n",
    "            \n",
    "    return non_zero_idx, zero_idx, new_ch, new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d840fd0c-88b4-44cf-a481-e018b91a727c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_30 node ############\n",
      "Quant 0 shape: (128, 64, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned:\n",
      "[  0   2   6   7   8  10  11  13  14  17  20  21  26  30  32  33  35  42\n",
      "  43  47  49  50  52  55  58  61  63  65  66  67  68  69  70  73  78  79\n",
      "  85  87  88  90  91  95  98 100 101 102 103 104 106 107 109 110 112 113\n",
      " 114 117 119]\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  1   3   4   5   9  12  15  16  18  19  22  23  24  25  27  28  29  31\n",
      "  34  36  37  38  39  40  41  44  45  46  48  51  53  54  56  57  59  60\n",
      "  62  64  71  72  74  75  76  77  80  81  82  83  84  86  89  92  93  94\n",
      "  96  97  99 105 108 111 115 116 118 120 121 122 123 124 125 126 127]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (71, 64, 1, 1)\n",
      "New Quant 1 shape: (71, 1, 1, 1)\n",
      "Quant_30 output original shape: (128, 64, 1, 1)\n",
      "Quant_30 output new shape: (71, 64, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_30 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 71, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_30 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-5.741e-42  4.930e-42  4.952e-42  4.916e-42  4.920e-42  4.930e-42\n",
      "  4.924e-42  4.938e-42  4.948e-42  4.912e-42 -4.951e-42  4.907e-42\n",
      "  4.951e-42  4.931e-42  4.938e-42 -4.920e-42  4.935e-42  4.940e-42\n",
      "  4.927e-42 -4.914e-42  4.916e-42  4.930e-42 -4.940e-42 -4.912e-42\n",
      " -4.920e-42  4.927e-42 -4.940e-42 -4.948e-42  4.941e-42 -4.937e-42\n",
      "  4.907e-42 -4.941e-42 -6.096e-42 -4.912e-42  4.944e-42  4.933e-42\n",
      "  4.930e-42  4.926e-42 -5.535e-42 -4.948e-42  4.928e-42  4.927e-42\n",
      "  4.951e-42  4.907e-42  4.913e-42  4.942e-42 -4.933e-42  4.912e-42\n",
      " -4.940e-42  4.941e-42 -4.934e-42  4.942e-42  4.941e-42 -4.921e-42\n",
      " -4.921e-42 -4.919e-42 -4.927e-42]\n",
      "-------------------------------------\n",
      "New BatchNormalization_30_param0 shape: (71,)\n",
      "New BatchNormalization_30_param1 shape: (71,)\n",
      "New BatchNormalization_30_param2 shape: (71,)\n",
      "New BatchNormalization_30_param3 shape: (71,)\n",
      "\n",
      "############ Update output shape of Relu_20 node ############\n",
      "New shape: (1, 71, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_69 node ############\n",
      "New shape: (1, 71, 14, 14)\n",
      "\n",
      "Next successor node is average pooling: AveragePool_0\n",
      "\n",
      "############ Update output shape of AveragePool_0 node ############\n",
      "Old Avg Pool output shape: [1, 128, 1, 1]\n",
      "New shape: (1, 71, 1, 1)\n",
      "\n",
      "############ Update output shape of Mul_1 node ############\n",
      "New shape: (1, 71, 1, 1)\n",
      "\n",
      "############ Update output shape of Trunc_0 node ############\n",
      "New shape: (1, 71, 1, 1)\n",
      "\n",
      "############ Update output shape of Reshape_0 node ############\n",
      "New shape: (1, 71)\n",
      "\n",
      "############ Gemm node found: Gemm_0 node ############\n",
      "\n",
      "............ Pruning Weights of Gemm_0 node ............\n",
      "Quant_31_param0 shape: (2, 128)\n",
      "New Quant_31_param0 shape: (2, 71)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  1   3   4   5   9  12  15  16  18  19  22  23  24  25  27  28  29  31\n",
      "  34  36  37  38  39  40  41  44  45  46  48  51  53  54  56  57  59  60\n",
      "  62  64  71  72  74  75  76  77  80  81  82  83  84  86  89  92  93  94\n",
      "  96  97  99 105 108 111 115 116 118 120 121 122 123 124 125 126 127]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_31 node: (2, 71)\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "_, _, _, _ = test_prune_any_conv(model, \"Conv_30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3af1316e-34ee-4603-888c-b5c7c184f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_any_conv_file = prune_folder + \"10_test_prune_any_conv_file.onnx\"\n",
    "model.save(test_prune_any_conv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "572d5a13-7634-4541-bba4-7bd3e498b1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/10_test_prune_any_conv_file.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9d7ef21330>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_any_conv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37aa7d1-992f-4663-bfbe-b79eaca6641f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d6b762d-c698-4ac8-af23-0ef91d7bc342",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test Pruning of first 2 Convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05ae631c-1631-4126-b584-2ab25540d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(qonnx_clean_filename)\n",
    "# # non_zero_idx, zero_idx, new_ch, new_shape = test_prune_conv(model, \"Conv_0\")\n",
    "# # non_zero_idx, zero_idx, new_ch, new_shape = test_prune_conv(model, \"Conv_1\")\n",
    "\n",
    "# _, _, _, _ = test_prune_conv(model, \"Conv_0\")\n",
    "# _, _, _, _ = test_prune_conv(model, \"Conv_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "28345622-19d1-49a2-b7ed-8ad019c5c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_prune_2_conv = prune_folder + \"10_test_prune_2_conv.onnx\"\n",
    "\n",
    "# model = model.transform(InferShapes())\n",
    "# model.save(test_prune_2_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a846942-b86d-4c01-9380-eb6068a3f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(test_prune_2_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751b0cc3-bd79-4ffd-82e6-14febf6efaa3",
   "metadata": {},
   "source": [
    "# Test Pruning the Whole Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c811656f-40b8-45e4-b6d7-be0473cc91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(qonnx_clean_filename)\n",
    "\n",
    "# for conv in convs_to_prune:\n",
    "#     print(f'\\n______________________________________________________________________________________________________')\n",
    "#     print(f'                                                {conv} ')\n",
    "#     print(f'______________________________________________________________________________________________________')\n",
    "\n",
    "#     _, _, _, _ = test_prune_any_conv(model, conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "50bbd986-b002-4c16-83d2-7c61f42113c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.transform(InferShapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0ebb9c89-3213-4b08-bbde-94dbe36f7c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune_all_convs = prune_folder + \"20_prune_all_convs.onnx\"\n",
    "# model.save(prune_all_convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6cfbf4d9-0fc0-4f54-978b-c7008eecbb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(prune_all_convs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc7c0c-80ef-46be-8b06-50a3b796190a",
   "metadata": {},
   "source": [
    "# Compare Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d721bddd-6774-49ce-9b56-78b488c79442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparsity_after_pruning = get_sparsity(model, layers_to_prune)\n",
    "\n",
    "# for k1, k2 in zip(sparsity_before_pruning.keys(), sparsity_after_pruning.keys()):\n",
    "#     before = sparsity_before_pruning[k1][\"sparsity\"]\n",
    "#     after = sparsity_after_pruning[k2][\"sparsity\"]\n",
    "#     assert k1 == k2, f'{k1} is not the same as {k2}'\n",
    "#     print(f'{k1}: \\tbefore: {before:<4} - after: {after:<4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3d2320-3ab5-46aa-9019-82333d73148f",
   "metadata": {},
   "source": [
    "# Prune Conv 22, as it is multiple of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "67376d0f-8e14-46bb-bcf8-6c05843453c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_21 node ############\n",
      "Quant 0 shape: (128, 32, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned:\n",
      "[  0   4   5   7  13  16  17  20  21  27  30  31  33  34  35  37  40  41\n",
      "  49  53  60  61  62  63  64  68  71  72  76  78  79  80  82  85  88  90\n",
      "  91  93  95 100 102 103 105 106 107 108 116 117 120 121 123 126]\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  1   2   3   6   8   9  10  11  12  14  15  18  19  22  23  24  25  26\n",
      "  28  29  32  36  38  39  42  43  44  45  46  47  48  50  51  52  54  55\n",
      "  56  57  58  59  65  66  67  69  70  73  74  75  77  81  83  84  86  87\n",
      "  89  92  94  96  97  98  99 101 104 109 110 111 112 113 114 115 118 119\n",
      " 122 124 125 127]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (76, 32, 1, 1)\n",
      "New Quant 1 shape: (76, 1, 1, 1)\n",
      "Quant_21 output original shape: (128, 32, 1, 1)\n",
      "Quant_21 output new shape: (76, 32, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_21 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 76, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_21 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.913e-42  4.930e-42 -4.921e-42 -4.942e-42  4.951e-42 -4.914e-42\n",
      "  4.947e-42  4.926e-42  4.948e-42  4.938e-42 -4.930e-42  4.949e-42\n",
      " -4.926e-42  4.905e-42  4.921e-42 -4.934e-42  4.912e-42  4.949e-42\n",
      "  4.938e-42 -4.910e-42  4.935e-42  4.944e-42  4.944e-42 -4.934e-42\n",
      " -5.703e-42 -4.917e-42 -4.912e-42 -5.873e-42  4.949e-42  4.945e-42\n",
      "  4.954e-42  4.938e-42  4.930e-42  4.948e-42  4.914e-42 -4.934e-42\n",
      "  4.923e-42  4.940e-42 -5.225e-42  4.917e-42  4.907e-42 -4.934e-42\n",
      "  4.933e-42  4.921e-42 -4.937e-42  4.928e-42  4.935e-42 -4.945e-42\n",
      "  4.909e-42 -4.934e-42 -4.906e-42 -4.910e-42]\n",
      "-------------------------------------\n",
      "New BatchNormalization_21_param0 shape: (76,)\n",
      "New BatchNormalization_21_param1 shape: (76,)\n",
      "New BatchNormalization_21_param2 shape: (76,)\n",
      "New BatchNormalization_21_param3 shape: (76,)\n",
      "\n",
      "############ Update output shape of Relu_14 node ############\n",
      "New shape: (1, 76, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_58 node ############\n",
      "New shape: (1, 76, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_22\n",
      "---> DW Conv found. Group = 128. Skip\n",
      "\n",
      "############ Pruning Weights of Quant_22 node ############\n",
      "Quant 0 shape: (128, 1, 3, 3)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned:\n",
      "[  0   4   5   7  13  16  17  20  21  27  30  31  33  34  35  37  40  41\n",
      "  49  53  60  61  62  63  64  68  71  72  76  78  79  80  82  85  88  90\n",
      "  91  93  95 100 102 103 105 106 107 108 116 117 120 121 123 126]\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  1   2   3   6   8   9  10  11  12  14  15  18  19  22  23  24  25  26\n",
      "  28  29  32  36  38  39  42  43  44  45  46  47  48  50  51  52  54  55\n",
      "  56  57  58  59  65  66  67  69  70  73  74  75  77  81  83  84  86  87\n",
      "  89  92  94  96  97  98  99 101 104 109 110 111 112 113 114 115 118 119\n",
      " 122 124 125 127]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (76, 1, 3, 3)\n",
      "New Quant 1 shape: (76, 1, 1, 1)\n",
      "Quant_22 output original shape: (128, 1, 3, 3)\n",
      "Quant_22 output new shape: (76, 1, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_22 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 76, 14, 14)\n",
      "---> DW Conv found. Group 128, changed to 76\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_22 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.940e-42  4.930e-42  4.919e-42 -4.951e-42  4.910e-42  4.941e-42\n",
      "  4.910e-42  4.933e-42  4.920e-42  4.937e-42 -4.906e-42  4.914e-42\n",
      "  4.948e-42  4.941e-42 -4.941e-42 -4.935e-42  4.934e-42  4.927e-42\n",
      "  4.927e-42 -4.948e-42  4.940e-42  4.949e-42  4.934e-42  4.930e-42\n",
      "  4.930e-42 -5.211e-42  4.907e-42  4.934e-42 -4.949e-42  4.927e-42\n",
      "  4.933e-42  4.937e-42  4.945e-42  4.937e-42  4.947e-42 -4.913e-42\n",
      "  4.934e-42  4.941e-42  4.928e-42  4.945e-42 -4.912e-42  4.941e-42\n",
      "  4.949e-42  4.952e-42  4.919e-42  4.934e-42  4.913e-42  4.906e-42\n",
      "  4.905e-42  5.527e-42  4.934e-42  4.905e-42]\n",
      "-------------------------------------\n",
      "New BatchNormalization_22_param0 shape: (76,)\n",
      "New BatchNormalization_22_param1 shape: (76,)\n",
      "New BatchNormalization_22_param2 shape: (76,)\n",
      "New BatchNormalization_22_param3 shape: (76,)\n",
      "\n",
      "############ Update output shape of Relu_15 node ############\n",
      "New shape: (1, 76, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_59 node ############\n",
      "New shape: (1, 76, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_23\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_23 node ............\n",
      "Quant_23_param0 shape: (32, 128, 1, 1)\n",
      "New Quant_23_param0 shape: (32, 76, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  1   2   3   6   8   9  10  11  12  14  15  18  19  22  23  24  25  26\n",
      "  28  29  32  36  38  39  42  43  44  45  46  47  48  50  51  52  54  55\n",
      "  56  57  58  59  65  66  67  69  70  73  74  75  77  81  83  84  86  87\n",
      "  89  92  94  96  97  98  99 101 104 109 110 111 112 113 114 115 118 119\n",
      " 122 124 125 127]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_23 node: (32, 76, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "_, _, _, _ = test_prune_any_conv(model, \"Conv_21\")\n",
    "_, _, _, _ = test_prune_any_conv(model, \"Conv_22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ee2d23db-249a-4c31-b5ec-77259c01ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_only_conv_22 = prune_folder + \"50_prune_only_conv_22.onnx\"\n",
    "model.save(prune_only_conv_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f3eb647-8c9f-4337-8dff-5447176c68c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/50_prune_only_conv_22.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9d7f35a230>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(prune_only_conv_22)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
