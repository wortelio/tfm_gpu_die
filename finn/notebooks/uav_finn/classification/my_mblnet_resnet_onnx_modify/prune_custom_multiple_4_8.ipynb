{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae233f6f-7219-4cbc-96da-03ec5287f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "\n",
    "from finn.util.visualization import showInNetron\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "\n",
    "import onnx.helper as oh\n",
    "import qonnx.util.basic as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32a77bc-2609-463b-a1f5-7749c720ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from onnx import __version__, IR_VERSION\n",
    "# from onnx.defs import onnx_opset_version\n",
    "# print(f\"onnx.__version__={__version__!r}, opset={onnx_opset_version()}, IR_VERSION={IR_VERSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d54340a2-fdb7-4183-912e-09bf2e61ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_folder = './manual_pruning/pruning/sparse24_mul8/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4800263f-4f20-48bd-a650-6d6e4ae957aa",
   "metadata": {},
   "source": [
    "# Load Model and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "067aa6e5-64e7-45cd-b1bb-639407f4310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_file = './onnx_models/MY_MBLNET_V2_RESNET_classifier__best_mean_F1__BIPOLAR_Out__QONNX.onnx'\n",
    "\n",
    "model_file = './onnx_models/Mobilenetv2_Mini_Resnet_Sparse24__best_F1__Bipolar.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a08fbe2-1a78-4964-b0cc-1d48e4b907ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "qonnx_clean_filename = prune_folder + '00_prune_clean.onnx'\n",
    "qonnx_cleanup(model_file, out_file=qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "828b8cf7-1403-43d1-8ed1-2e6442925dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './manual_pruning/pruning/sparse24_mul8/00_prune_clean.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5db6d0f9a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea40e51-a453-4e7c-8a0f-83336935268c",
   "metadata": {},
   "source": [
    "# Analyze layers to prune\n",
    "\n",
    "Check scales of weights that are very close to zero, under epsilon:\n",
    "\n",
    "$$\n",
    "0 < abs(scale) < \\epsilon\n",
    "$$\n",
    "\n",
    "Store all initializers in a list and look for the corresponding convolution afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00603339-56a9-4c8e-9643-2446e1732a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3eb0cee-bfe7-48e0-a8cf-c0185fcbc8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of initializers = 376\n"
     ]
    }
   ],
   "source": [
    "all_inits_names = [init.name for init in model.graph.initializer]\n",
    "\n",
    "print(f'Number of initializers = {len(all_inits_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e953613e-1aa3-4e6a-810a-a69fc10543e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-10\n",
    "\n",
    "layers_to_prune = {}\n",
    "\n",
    "for idx, init_name in enumerate(all_inits_names):\n",
    "    if \"Quant\" in init_name and \"param1\" in init_name:\n",
    "    # It is a scale value, check it\n",
    "        np_init = model.get_initializer(init_name)\n",
    "        np_abs_val = np.abs(np_init)\n",
    "        zero_idx = (np_abs_val < eps) * (np_abs_val > 0)\n",
    "        if np.all(zero_idx == False):\n",
    "            #print(f'Index = {idx}. {init_name} was not appended, as there were no values under epsilon')\n",
    "            continue\n",
    "        else:\n",
    "            zero_layer = np.where(zero_idx == True)[0]\n",
    "            quant_layer_name = init_name.split(\"_param\")[0]\n",
    "            layers_to_prune[quant_layer_name] = {1: {*zero_layer}}\n",
    "            #print(f'Index = {idx}. {init_name} appended, as there were values under epsilon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e1546a7-c519-44a1-bc09-b1a3bcdc1abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers to prune: 15\n",
      "Quant_12 {1: {28}}\n",
      "Quant_13 {1: {28}}\n",
      "Quant_15 {1: {0, 83, 45, 54}}\n",
      "Quant_16 {1: {0, 83, 45, 54}}\n",
      "Quant_18 {1: {64, 33, 2, 99, 102, 7, 40, 41, 12, 13, 112, 51, 20, 89, 59, 94}}\n",
      "Quant_19 {1: {64, 33, 2, 99, 102, 7, 40, 41, 12, 13, 112, 51, 20, 89, 59, 94}}\n",
      "Quant_21 {1: {3, 7, 9, 12, 21, 24, 27, 29, 31, 32, 39, 41, 43, 44, 50, 57, 63, 68, 71, 73, 75, 80, 83, 90, 94, 96, 97, 99, 103, 113, 117, 124, 125}}\n",
      "Quant_22 {1: {3, 7, 9, 12, 21, 24, 27, 29, 31, 32, 39, 41, 43, 44, 50, 57, 63, 68, 71, 73, 75, 80, 83, 90, 94, 96, 97, 99, 103, 113, 117, 124, 125}}\n",
      "Quant_24 {1: {30}}\n",
      "Quant_25 {1: {30}}\n",
      "Quant_26 {1: {10, 51, 14, 7}}\n",
      "Quant_27 {1: {0, 1, 5, 7, 10, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 34, 35, 37, 38, 45, 47, 49, 51, 54, 56, 57, 58, 59, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 78, 79, 82, 85, 89, 92, 93, 97, 98, 100, 103, 104, 109, 110, 111, 112, 115, 117, 118, 121, 126, 127}}\n",
      "Quant_28 {1: {0, 1, 5, 7, 10, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 34, 35, 37, 38, 45, 47, 49, 51, 54, 56, 57, 58, 59, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 78, 79, 82, 85, 89, 92, 93, 97, 98, 100, 103, 104, 109, 110, 111, 112, 115, 117, 118, 121, 126, 127}}\n",
      "Quant_29 {1: {10, 51, 14, 7}}\n",
      "Quant_30 {1: {4, 8, 13, 14, 24, 36, 41, 48, 52, 59, 61, 62, 71, 75, 77, 78, 82, 86, 91, 96, 101, 105, 110, 118, 120, 126}}\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of layers to prune: {len(layers_to_prune)}')\n",
    "for k, v in layers_to_prune.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61a5d18a-a1a5-4792-82b1-1b82ce125966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(layers_to_prune[\"Quant_30\"][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377b7827-013e-4ac4-a544-4004af7525f0",
   "metadata": {},
   "source": [
    "### Get all Convolutions or Linears to be pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00b687c9-1a3b-4a4e-89f5-d7fe1d25e4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All convolutions to prune\n",
      "Conv_12\n",
      "Conv_13\n",
      "Conv_15\n",
      "Conv_16\n",
      "Conv_18\n",
      "Conv_19\n",
      "Conv_21\n",
      "Conv_22\n",
      "Conv_24\n",
      "Conv_25\n",
      "Conv_26\n",
      "Conv_27\n",
      "Conv_28\n",
      "Conv_29\n",
      "Conv_30\n"
     ]
    }
   ],
   "source": [
    "all_nodes = model.graph.node\n",
    "\n",
    "convs_to_prune = []\n",
    "\n",
    "for node in all_nodes:\n",
    "    for key in layers_to_prune.keys():\n",
    "        if key == node.name:\n",
    "            successor_node = model.find_direct_successors(node)[0]\n",
    "            convs_to_prune.append(successor_node.name)\n",
    "\n",
    "print(\"All convolutions to prune\")\n",
    "for conv in convs_to_prune:\n",
    "    print(conv)\n",
    "\n",
    "# # Remove last 5 convs, as they are harder to prune\n",
    "# for i in range(5):\n",
    "#     convs_to_prune.pop()\n",
    "\n",
    "# # Print again\n",
    "# print(\"\\nEasy convolutions to prune\")\n",
    "# for conv in convs_to_prune:\n",
    "#     print(conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c29554-1c21-49be-bd31-024acf0c4b7a",
   "metadata": {},
   "source": [
    "### Get Sparsity to compare after pruning\n",
    "\n",
    "Retrieve all weights from Convolutions and perform:\n",
    "$$\n",
    "Sparsity = \\frac{N_{Zeros}}{N_{Tensors}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1267b596-9bf5-496b-82d0-bd2db02d5490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(model_wrapper, layers_to_prune):\n",
    "    \n",
    "    sparse_dict = {}\n",
    "    \n",
    "    for key in layers_to_prune.keys():\n",
    "        init_name = key + \"_param0\"\n",
    "        np_init = model_wrapper.get_initializer(init_name)\n",
    "        n_zeros = np.count_nonzero(np_init == 0)\n",
    "        total_values = np_init.size\n",
    "        sparsity = round(n_zeros/total_values, 2)\n",
    "        #print(init_name, n_zeros, total_values, sparsity*100)\n",
    "        sparse_dict[init_name] = {\"zeros\": n_zeros, \"total\": total_values, \"sparsity\": sparsity}\n",
    "\n",
    "    return sparse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7f60308-3a4a-4cb0-a938-9ca529fa318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quant_12_param0 {'zeros': 122, 'total': 1152, 'sparsity': 0.11}\n",
      "Quant_13_param0 {'zeros': 37, 'total': 432, 'sparsity': 0.09}\n",
      "Quant_15_param0 {'zeros': 315, 'total': 2304, 'sparsity': 0.14}\n",
      "Quant_16_param0 {'zeros': 86, 'total': 864, 'sparsity': 0.1}\n",
      "Quant_18_param0 {'zeros': 902, 'total': 4096, 'sparsity': 0.22}\n",
      "Quant_19_param0 {'zeros': 211, 'total': 1152, 'sparsity': 0.18}\n",
      "Quant_21_param0 {'zeros': 1358, 'total': 4096, 'sparsity': 0.33}\n",
      "Quant_22_param0 {'zeros': 352, 'total': 1152, 'sparsity': 0.31}\n",
      "Quant_24_param0 {'zeros': 226, 'total': 2048, 'sparsity': 0.11}\n",
      "Quant_25_param0 {'zeros': 56, 'total': 576, 'sparsity': 0.1}\n",
      "Quant_26_param0 {'zeros': 720, 'total': 4096, 'sparsity': 0.18}\n",
      "Quant_27_param0 {'zeros': 5019, 'total': 8192, 'sparsity': 0.61}\n",
      "Quant_28_param0 {'zeros': 642, 'total': 1152, 'sparsity': 0.56}\n",
      "Quant_29_param0 {'zeros': 5004, 'total': 8192, 'sparsity': 0.61}\n",
      "Quant_30_param0 {'zeros': 3045, 'total': 8192, 'sparsity': 0.37}\n"
     ]
    }
   ],
   "source": [
    "sparsity_before_pruning = get_sparsity(model, layers_to_prune)\n",
    "for k, v in sparsity_before_pruning.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f60b7-f62e-4398-981b-cf4e04687b87",
   "metadata": {},
   "source": [
    "# Prune the Layers Manually\n",
    "\n",
    "- Convolution + BN: all convolutions are followed by Batch Norm, so they can be pruned together. Out channels will be pruned, so it impacts the next convolution, which input weights must be adapted.\n",
    "\n",
    "- Convolution + BN + ReLU: if convolution+bn is followed by ReLU, it must be pruned too.\n",
    "\n",
    "- DW Layer: this is a particular case. If a Conv Layer is pruned and next layer is Depth Wise, it must be pruned to, to fit the groups parameter in the output.\n",
    "\n",
    "## Process:\n",
    "```python\n",
    "def prune_conv(model, conv: str)\n",
    "```\n",
    "Args: \n",
    "- model: ModelWrapper of the model to prune\n",
    "- conv: string of the convolution layer to prune\n",
    ">**Steps**: <br>\n",
    ">1. Get Conv Node from model.\n",
    ">2. Find direct predecessors: [1] will be the convolution weights, so store it.\n",
    ">3. Modify convolution weights.\n",
    ">4. Modify the output shape of convolution weights.\n",
    ">5. Modify convolution output shape.\n",
    ">6. Find direct successor, which is batch norm layer.\n",
    ">7. Modify batch norm layer: weights and shape.\n",
    ">8. Find direct successor of batch norm: modify the output shape of ReLU+Quant or only Quant.\n",
    ">9. Find direct successor of last Quant node: it will be next convolution.\n",
    ">10. Prune the weights according to output channel pruned in previous convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84732158-a50b-4fb4-92a1-eb916db68c85",
   "metadata": {},
   "source": [
    "#### Prune weights of convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36399254-8bf3-4981-835c-9631dc3be47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_conv_weights(model, quant_node, do_mul_val = True, mul_val = 8):\n",
    "\n",
    "    print(f'\\n############ Pruning Weights of {quant_node.name} node ############')\n",
    "    quant_0 = quant_node.input[0]\n",
    "    quant_1 = quant_node.input[1]\n",
    "    np_q0 = model.get_initializer(quant_0)\n",
    "    np_q1 = model.get_initializer(quant_1)\n",
    "    print(f'Quant 0 shape: {np_q0.shape}')\n",
    "    print(f'Quant 1 shape: {np_q1.shape}') \n",
    "\n",
    "    np_q1_abs = np.abs(np_q1)\n",
    "    zero_idx = np.where((np_q1_abs < 1e-10) * (np_q1_abs > 0))[0]\n",
    "    non_zero_idx = np.where(np_q1_abs > 1e-10)[0]\n",
    "    print(\"-------------------------------------\")\n",
    "    print(f'*** Zero IDX, channels to be pruned ({zero_idx.size} elements):\\n{zero_idx}')\n",
    "    print(f'### Non Zero IDX, channels to keep ({non_zero_idx.size} elements):\\n{non_zero_idx}')\n",
    "    print(\"-------------------------------------\")\n",
    "\n",
    "    # Code added to keep a number of channels multiple of 4 or 8\n",
    "    # It may cause that some zero channels must be kept\n",
    "    print(f'\\n------ Prune to muliple of {mul_val}: {do_mul_val}')\n",
    "    if do_mul_val == True:\n",
    "        non_zero_idx_size = non_zero_idx.size\n",
    "        non_zero_idx_remainder = non_zero_idx_size % mul_val\n",
    "        if non_zero_idx_remainder == 0:\n",
    "            print(f'Elements to keep is multiple of {mul_val}')\n",
    "        else:\n",
    "            # Calculate the mean of the values which are not zero, to use it as a default for other values\n",
    "            # np_q1_mean = np_q1[non_zero_idx].mean()\n",
    "            np_q1_mean = np_q1[non_zero_idx][0] # uses directly the scale of element [0] of non zero idx\n",
    "            np_q1_copy = np_q1.copy() # Original array is read-only, so it must be copied first\n",
    "            np_q1_copy[zero_idx] = np_q1_mean\n",
    "            np_q1 = np_q1_copy\n",
    "            print(f'Mean of channels to keep, to use it as default for zero elements: {np_q1_mean}')\n",
    "            print(f'Elements to keep is not multiple of {mul_val} -> calculate new Non Zero IDX')\n",
    "            n_to_keep = mul_val - non_zero_idx_remainder\n",
    "            zero_idx_to_keep = zero_idx[:n_to_keep]\n",
    "            print(f'{n_to_keep} zero elements must be kept\\n{zero_idx_to_keep}')\n",
    "            non_zero_idx = np.concatenate((zero_idx_to_keep, non_zero_idx))\n",
    "            non_zero_idx.sort()\n",
    "            assert non_zero_idx.size % mul_val == 0, f'Non Zero IDX calculated is not multiple of {mul_val}'\n",
    "            print(f'### Multiple of {mul_val} Non Zero IDX, channels to keep:\\n{non_zero_idx}')\n",
    "            print(\"-------------------------------------\")\n",
    "    \n",
    "    new_np_q0 = np_q0[non_zero_idx]\n",
    "    print(f'New Quant 0 shape: {new_np_q0.shape}')\n",
    "    new_np_q1 = np_q1[non_zero_idx]\n",
    "    print(f'New Quant 1 shape: {new_np_q1.shape}')\n",
    "\n",
    "    model.set_initializer(\n",
    "        tensor_name = quant_0, \n",
    "        tensor_value = new_np_q0)\n",
    "    model.set_initializer(\n",
    "        tensor_name = quant_1, \n",
    "        tensor_value = new_np_q1)\n",
    "\n",
    "    ch, k, w, h = model.get_tensor_shape(quant_node.output[0])\n",
    "    print(f'{quant_node.name} output original shape: {ch, k, w, h}')\n",
    "    new_ch = new_np_q0.shape[0]\n",
    "    new_shape = (new_ch, k, w, h)\n",
    "    print(f'{quant_node.name} output new shape: {new_shape}')\n",
    "\n",
    "    model.set_tensor_shape(quant_node.output[0], new_shape) \n",
    "\n",
    "    return non_zero_idx, zero_idx, new_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64762b6d-e4f9-4ef9-afa5-d610fb3eef2e",
   "metadata": {},
   "source": [
    "##### Test weight pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b2d0096-f31d-4baa-87dc-0a7c21928b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_conv_weights(model, conv: str):\n",
    "    \n",
    "    conv_0_node = model.get_node_from_name(conv)\n",
    "    conv_0_node_predec = model.find_direct_predecessors(conv_0_node)\n",
    "    conv_0_weights_node = conv_0_node_predec[1]\n",
    "    \n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_0_weights_node)\n",
    "\n",
    "    return non_zero_idx, zero_idx, new_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eb5c15b-10d5-4959-9607-e38ad823635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_0 node ############\n",
      "Quant 0 shape: (24, 3, 3, 3)\n",
      "Quant 1 shape: (24, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (0 elements):\n",
      "[]\n",
      "### Non Zero IDX, channels to keep (24 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Elements to keep is multiple of 8\n",
      "New Quant 0 shape: (24, 3, 3, 3)\n",
      "New Quant 1 shape: (24, 1, 1, 1)\n",
      "Quant_0 output original shape: (24, 3, 3, 3)\n",
      "Quant_0 output new shape: (24, 3, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "non_zero_idx, zero_idx, new_ch = test_prune_conv_weights(model, \"Conv_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6499ab3-ffc1-4b27-a3ae-b50d6184e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_weights = prune_folder + \"01_test_prune_weights.onnx\"\n",
    "model.save(test_prune_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b72cdea-05fd-4c9a-b57f-35e18949ad90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/pruning/sparse24_mul8/01_test_prune_weights.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5db6d0d1b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c922acb-dfd1-4cb6-80e4-abc616917252",
   "metadata": {},
   "source": [
    "#### Prune convolution output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a57b8a6b-280d-439e-a311-4bc499ee8a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_conv_out(model, conv_node, new_ch):\n",
    "\n",
    "    print(f'\\n############ Convert Convolution Output Shape {conv_node.name} node ############')\n",
    "    batch, ch, w, h = model.get_tensor_shape(conv_node.output[0])\n",
    "    print(f'Old Conv output shape: {(batch, ch, w, h)}')\n",
    "    new_shape = (batch, new_ch, w, h)\n",
    "    print(f'New Conv output shape: {new_shape}')\n",
    "\n",
    "    model.set_tensor_shape(conv_node.output[0], new_shape)\n",
    "\n",
    "    # Change groups\n",
    "    conv_group = conv_node.attribute[1].i\n",
    "    if conv_group != 1:\n",
    "        print(f'---> DW Conv found. Group {conv_group}, changed to {new_ch}')\n",
    "        conv_node.attribute[1].i = new_ch\n",
    "    else:\n",
    "        print(f'DW Conv not found. Group = {conv_group}')\n",
    "\n",
    "    return new_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a582026-4c4c-4043-ade3-c7a8bd156db1",
   "metadata": {},
   "source": [
    "##### Test conv output pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "127f03e9-d574-495f-8f4c-0e92db7f9c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_conv_output(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "    # Update conv out shape\n",
    "    new_shape = prune_conv_out(model, conv_node, new_ch)\n",
    "\n",
    "    return non_zero_idx, zero_idx, new_ch, new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "888f9fdc-2cbc-43e8-be01-2d8e9f633a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_0 node ############\n",
      "Quant 0 shape: (24, 3, 3, 3)\n",
      "Quant 1 shape: (24, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (0 elements):\n",
      "[]\n",
      "### Non Zero IDX, channels to keep (24 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Elements to keep is multiple of 8\n",
      "New Quant 0 shape: (24, 3, 3, 3)\n",
      "New Quant 1 shape: (24, 1, 1, 1)\n",
      "Quant_0 output original shape: (24, 3, 3, 3)\n",
      "Quant_0 output new shape: (24, 3, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_0 node ############\n",
      "Old Conv output shape: (1, 24, 112, 112)\n",
      "New Conv output shape: (1, 24, 112, 112)\n",
      "DW Conv not found. Group = 1\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "non_zero_idx, zero_idx, new_ch, new_shape = test_prune_conv_output(model, \"Conv_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6a15e82-f724-4052-895b-27bbd2feddc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Zero IDX: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "Zero IDX: []\n",
      "New Channels: 24\n",
      "New Shape: (1, 24, 112, 112)\n"
     ]
    }
   ],
   "source": [
    "print(f'Non Zero IDX: {non_zero_idx}\\nZero IDX: {zero_idx}\\nNew Channels: {new_ch}\\nNew Shape: {new_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "100caa35-7c4d-47cc-a652-1ece3c9d79e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_conv_out = prune_folder + \"02_test_prune_conv_out.onnx\"\n",
    "model.save(test_prune_conv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1ba000f-4891-4ad0-87da-56e46243461f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/pruning/sparse24_mul8/02_test_prune_conv_out.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5db6d9bd00>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_conv_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8844e-3e30-4dc9-82c2-33fd19753cbd",
   "metadata": {},
   "source": [
    "#### Prune batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "392fc9a2-a12e-4edf-8b11-e1048be90338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_bn(model, bn_node, new_shape, non_zero_idx, zero_idx):\n",
    "\n",
    "    print(f'\\n############ Prune Batch Norm {bn_node.name} node ############')\n",
    "    bn_0 = bn_node.input[1]\n",
    "    bn_1 = bn_node.input[2]\n",
    "    bn_2 = bn_node.input[3]\n",
    "    bn_3 = bn_node.input[4]\n",
    "    np_bn0 = model.get_initializer(bn_0)\n",
    "    np_bn1 = model.get_initializer(bn_1)\n",
    "    np_bn2 = model.get_initializer(bn_2)\n",
    "    np_bn3 = model.get_initializer(bn_3)\n",
    "    \n",
    "    print(f'BN0 shape: {np_bn0.shape}')\n",
    "    print(f'BN1 shape: {np_bn1.shape}')\n",
    "    print(f'BN2 shape: {np_bn2.shape}')\n",
    "    print(f'BN3 shape: {np_bn3.shape}')\n",
    "\n",
    "    print(\"-------------------------------------\")\n",
    "    print(f'*** Zero IDX, scale value of channels to be pruned:\\n{np_bn0[zero_idx]}')\n",
    "    print(\"-------------------------------------\")\n",
    "\n",
    "    # Code to calculate real indices with good values, \n",
    "    # as non_zero_idx includes some zero_idx values, to stay in multiple of 4\n",
    "    real_non_zero_idx = np.setdiff1d(non_zero_idx, np.intersect1d(non_zero_idx, zero_idx))\n",
    "    # np_bn0_mean = np_bn0[real_non_zero_idx].mean()\n",
    "    # np_bn1_mean = np_bn1[real_non_zero_idx].mean()\n",
    "    # np_bn2_mean = np_bn2[real_non_zero_idx].mean()\n",
    "    # np_bn3_mean = np_bn3[real_non_zero_idx].mean()\n",
    "    np_bn0_mean = np_bn0[real_non_zero_idx][0]\n",
    "    np_bn1_mean = np_bn1[real_non_zero_idx][0]\n",
    "    np_bn2_mean = np_bn2[real_non_zero_idx][0]\n",
    "    np_bn3_mean = np_bn3[real_non_zero_idx][0]\n",
    "    print(f'Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\\n{real_non_zero_idx}')\n",
    "    real_zero_idx = np.intersect1d(zero_idx, non_zero_idx)\n",
    "    print(f'Real Zero IDX kept:\\n{real_zero_idx}')\n",
    "    print(\"-------------------------------------\")\n",
    "    \n",
    "    new_np_bn0 = np_bn0[non_zero_idx]\n",
    "    new_np_bn0[real_zero_idx] = np_bn0_mean #0. # Replace ultra small scale with element [0] scale\n",
    "    print(f'New {bn_0} shape: {new_np_bn0.shape}')\n",
    "    new_np_bn1 = np_bn1[non_zero_idx]\n",
    "    new_np_bn1[real_zero_idx] = np_bn1_mean #0. # Replace ultra small bias with zero\n",
    "    print(f'New {bn_1} shape: {new_np_bn1.shape}')\n",
    "    new_np_bn2 = np_bn2[non_zero_idx] \n",
    "    new_np_bn2[real_zero_idx] = np_bn2_mean #0. # Replace ultra small mean with zero\n",
    "    print(f'New {bn_2} shape: {new_np_bn2.shape}')\n",
    "    new_np_bn3 = np_bn3[non_zero_idx]\n",
    "    new_np_bn3[real_zero_idx] = np_bn3_mean # Replace ultra small variance with mean variance, to be in the denominator\n",
    "    print(f'New {bn_3} shape: {new_np_bn3.shape}')\n",
    "\n",
    "    model.set_initializer(\n",
    "        tensor_name = bn_0, \n",
    "        tensor_value = new_np_bn0)\n",
    "    model.set_initializer(\n",
    "        tensor_name = bn_1, \n",
    "        tensor_value = new_np_bn1)\n",
    "    model.set_initializer(\n",
    "        tensor_name = bn_2, \n",
    "        tensor_value = new_np_bn2)\n",
    "    model.set_initializer(\n",
    "        tensor_name = bn_3, \n",
    "        tensor_value = new_np_bn3) \n",
    "\n",
    "    model.set_tensor_shape(bn_node.output[0], new_shape)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f22a0-e13a-4f48-a396-97eb3954e38f",
   "metadata": {},
   "source": [
    "##### Test prune batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86ad3d1b-a52e-4fa6-ac59-94ed24c754da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_conv_bn(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "    # Update conv out shape\n",
    "    new_shape = prune_conv_out(model=model, conv_node=conv_node, new_ch=new_ch)\n",
    "    # Prune batch norm\n",
    "    bn_node = model.find_direct_successors(conv_node)[0]\n",
    "    prune_bn(model, bn_node, new_shape, non_zero_idx, zero_idx)\n",
    "\n",
    "    return non_zero_idx, zero_idx, new_ch, new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f7f06c5-b464-4d1c-8fce-1f024afbb7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_0 node ############\n",
      "Quant 0 shape: (24, 3, 3, 3)\n",
      "Quant 1 shape: (24, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (0 elements):\n",
      "[]\n",
      "### Non Zero IDX, channels to keep (24 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Elements to keep is multiple of 8\n",
      "New Quant 0 shape: (24, 3, 3, 3)\n",
      "New Quant 1 shape: (24, 1, 1, 1)\n",
      "Quant_0 output original shape: (24, 3, 3, 3)\n",
      "Quant_0 output new shape: (24, 3, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_0 node ############\n",
      "Old Conv output shape: (1, 24, 112, 112)\n",
      "New Conv output shape: (1, 24, 112, 112)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_0 node ############\n",
      "BN0 shape: (24,)\n",
      "BN1 shape: (24,)\n",
      "BN2 shape: (24,)\n",
      "BN3 shape: (24,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_0_param0 shape: (24,)\n",
      "New BatchNormalization_0_param1 shape: (24,)\n",
      "New BatchNormalization_0_param2 shape: (24,)\n",
      "New BatchNormalization_0_param3 shape: (24,)\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "non_zero_idx, zero_idx, new_ch, new_shape = test_prune_conv_bn(model, \"Conv_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3983475-68f7-49e7-82c0-3d010ba617b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_conv_bn = prune_folder + \"03_test_prune_conv_bn.onnx\"\n",
    "model.save(test_prune_conv_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11bd15a2-a422-4e31-835d-b34d882f6300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/pruning/sparse24_mul8/03_test_prune_conv_bn.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5db6d98520>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_conv_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e979c3-113b-4dce-b282-f6feb282f914",
   "metadata": {},
   "source": [
    "#### Prune ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd967530-9a98-4c52-b671-bd055fa267b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_relu(model, relu_node, new_shape):\n",
    "\n",
    "    print(f'\\n############ Update output shape of {relu_node.name} node ############')\n",
    "    print(f'New shape: {new_shape}')\n",
    "    model.set_tensor_shape(relu_node.output[0], new_shape)               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8007521f-48c4-4132-bd1c-1164e435b9e1",
   "metadata": {},
   "source": [
    "##### Test update ReLU output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74442899-a877-4776-a3b7-1a80c41afbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_relu(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "    # Update conv out shape\n",
    "    new_shape = prune_conv_out(model=model, conv_node=conv_node, new_ch=new_ch)\n",
    "    # Prune batch norm\n",
    "    bn_node = model.find_direct_successors(conv_node)[0]\n",
    "    prune_bn(model, bn_node, new_shape, non_zero_idx, zero_idx)\n",
    "    \n",
    "    # Find Batch Norm successor\n",
    "    bn_successor_node = model.find_direct_successors(bn_node)[0]\n",
    "    if \"Relu\" in bn_successor_node.name:\n",
    "        # Prune ReLU output\n",
    "        relu_node = bn_successor_node\n",
    "        prune_relu(model=model, relu_node=relu_node, new_shape=new_shape)\n",
    "\n",
    "    return non_zero_idx, zero_idx, new_ch, new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16944251-510f-4680-97bf-934eef885fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_0 node ############\n",
      "Quant 0 shape: (24, 3, 3, 3)\n",
      "Quant 1 shape: (24, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (0 elements):\n",
      "[]\n",
      "### Non Zero IDX, channels to keep (24 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Elements to keep is multiple of 8\n",
      "New Quant 0 shape: (24, 3, 3, 3)\n",
      "New Quant 1 shape: (24, 1, 1, 1)\n",
      "Quant_0 output original shape: (24, 3, 3, 3)\n",
      "Quant_0 output new shape: (24, 3, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_0 node ############\n",
      "Old Conv output shape: (1, 24, 112, 112)\n",
      "New Conv output shape: (1, 24, 112, 112)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_0 node ############\n",
      "BN0 shape: (24,)\n",
      "BN1 shape: (24,)\n",
      "BN2 shape: (24,)\n",
      "BN3 shape: (24,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_0_param0 shape: (24,)\n",
      "New BatchNormalization_0_param1 shape: (24,)\n",
      "New BatchNormalization_0_param2 shape: (24,)\n",
      "New BatchNormalization_0_param3 shape: (24,)\n",
      "\n",
      "############ Update output shape of Relu_0 node ############\n",
      "New shape: (1, 24, 112, 112)\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "non_zero_idx, zero_idx, new_ch, new_shape = test_prune_relu(model, \"Conv_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d4d10b2-5348-4c17-a6d5-86a46fb291f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_relu = prune_folder + \"04_test_prune_relu.onnx\"\n",
    "model.save(test_prune_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28076b91-9ccf-47ba-9424-acc167fe1286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/pruning/sparse24_mul8/04_test_prune_relu.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5db6d6be50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e5b0b-e019-47ff-8165-a90925607792",
   "metadata": {},
   "source": [
    "#### Prune quant Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e554e84-9d6d-4ac5-9690-bf3ced146161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_quant_out(model, quant_node, new_shape):\n",
    "\n",
    "    print(f'\\n############ Update output shape of {quant_node.name} node ############')\n",
    "    print(f'New shape: {new_shape}')\n",
    "    model.set_tensor_shape(quant_node.output[0], new_shape)              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf4400-e683-4802-a43a-f5939d7fb556",
   "metadata": {},
   "source": [
    "##### Test update of quant output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "206b3507-5f87-4ae7-89c5-7c04d8d41b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_quant_out(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "    # Update conv out shape\n",
    "    new_shape = prune_conv_out(model=model, conv_node=conv_node, new_ch=new_ch)\n",
    "    # Prune batch norm\n",
    "    bn_node = model.find_direct_successors(conv_node)[0]\n",
    "    prune_bn(model, bn_node, new_shape, non_zero_idx, zero_idx)\n",
    "    \n",
    "    # Find Batch Norm successor\n",
    "    bn_successor_node = model.find_direct_successors(bn_node)[0]\n",
    "    if \"Relu\" in bn_successor_node.name:\n",
    "        # Prune ReLU output\n",
    "        prune_relu(model=model, relu_node=bn_successor_node, new_shape=new_shape)\n",
    "        # Update successor to ReLU quant node\n",
    "        bn_successor_node = model.find_direct_successors(bn_successor_node)[0]\n",
    "    if \"Quant\" in bn_successor_node.name:\n",
    "        prune_quant_out(model, bn_successor_node, new_shape)   \n",
    "    else:\n",
    "        raise Exception(f'Node following BN is not ReLU or Quant: {bn_successor_node.name}')\n",
    "\n",
    "    return non_zero_idx, zero_idx, new_ch, new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b53f8206-2144-4faf-9af3-d598a195a88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_0 node ############\n",
      "Quant 0 shape: (24, 3, 3, 3)\n",
      "Quant 1 shape: (24, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (0 elements):\n",
      "[]\n",
      "### Non Zero IDX, channels to keep (24 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Elements to keep is multiple of 8\n",
      "New Quant 0 shape: (24, 3, 3, 3)\n",
      "New Quant 1 shape: (24, 1, 1, 1)\n",
      "Quant_0 output original shape: (24, 3, 3, 3)\n",
      "Quant_0 output new shape: (24, 3, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_0 node ############\n",
      "Old Conv output shape: (1, 24, 112, 112)\n",
      "New Conv output shape: (1, 24, 112, 112)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_0 node ############\n",
      "BN0 shape: (24,)\n",
      "BN1 shape: (24,)\n",
      "BN2 shape: (24,)\n",
      "BN3 shape: (24,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_0_param0 shape: (24,)\n",
      "New BatchNormalization_0_param1 shape: (24,)\n",
      "New BatchNormalization_0_param2 shape: (24,)\n",
      "New BatchNormalization_0_param3 shape: (24,)\n",
      "\n",
      "############ Update output shape of Relu_0 node ############\n",
      "New shape: (1, 24, 112, 112)\n",
      "\n",
      "############ Update output shape of Quant_34 node ############\n",
      "New shape: (1, 24, 112, 112)\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "non_zero_idx, zero_idx, new_ch, new_shape = test_prune_quant_out(model, \"Conv_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3925960f-9f89-4093-a02e-ef904c7025b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_quant_relu = prune_folder + \"05_test_prune_quant_relu.onnx\"\n",
    "model.save(test_prune_quant_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd1b6314-510d-41da-8169-6d9c4cf747c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/pruning/sparse24_mul8/05_test_prune_quant_relu.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5db6d986d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_quant_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53396193-b8e0-44fe-96ff-fb9ce4949e54",
   "metadata": {},
   "source": [
    "#### Prune Next Conv In Channels -> Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "869b2bea-f9d0-4e74-94eb-2b7c541ac931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_next_conv_inp(model, conv_node, non_zero_idx, zero_idx):\n",
    "\n",
    "    print(f'\\n............ Pruning Weights of {conv_node.name} node ............')   \n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    quant_node = conv_node_predec[1] # Quant node is [1]     \n",
    "    \n",
    "    quant_0 = quant_node.input[0]\n",
    "    np_q0 = model.get_initializer(quant_0)\n",
    "    print(f'{quant_0} shape: {np_q0.shape}')\n",
    "\n",
    "    new_np_q0 = np_q0[:, non_zero_idx]\n",
    "    new_shape = new_np_q0.shape\n",
    "    print(f'New {quant_0} shape: {new_shape}')\n",
    "    \n",
    "    print(\"-------------------------------------\")\n",
    "    all_weights_zero = np.all(np_q0[:, zero_idx] == 0.)\n",
    "    print(f'*** All weights removed are zero? {all_weights_zero}')\n",
    "    print(f'### Non Zero IDX, channels to keep:\\n{non_zero_idx}')\n",
    "    print(\"-------------------------------------\")\n",
    "\n",
    "    model.set_initializer(\n",
    "        tensor_name = quant_0, \n",
    "        tensor_value = new_np_q0) \n",
    "\n",
    "    print(f'Modify output shape of {quant_node.name} node: {new_shape}')\n",
    "    model.set_tensor_shape(quant_node.output[0], new_shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b559077-1fe2-458a-9f98-892da8200e55",
   "metadata": {},
   "source": [
    "##### Test Prune Next Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4337537-a6ed-41b3-9ef6-1e4c7fe67dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_next_conv_inp(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "    # Update conv out shape\n",
    "    new_shape = prune_conv_out(model=model, conv_node=conv_node, new_ch=new_ch)\n",
    "    # Prune batch norm\n",
    "    bn_node = model.find_direct_successors(conv_node)[0]\n",
    "    prune_bn(model, bn_node, new_shape, non_zero_idx, zero_idx)\n",
    "    \n",
    "    # Find Batch Norm successor\n",
    "    bn_successor_node = model.find_direct_successors(bn_node)[0]\n",
    "    if \"Relu\" in bn_successor_node.name:\n",
    "        # Prune relu output\n",
    "        prune_relu(model=model, relu_node=bn_successor_node, new_shape=new_shape)\n",
    "        # Update successor to relu quant node\n",
    "        bn_successor_node = model.find_direct_successors(bn_successor_node)[0]\n",
    "    if \"Quant\" in bn_successor_node.name:\n",
    "        # Always update the shape of Quant Node: it will be preceded by relu or batch norm\n",
    "        prune_quant_out(model, bn_successor_node, new_shape)   \n",
    "    else:\n",
    "        raise Exception(f'Node following BN is not ReLU or Quant: {bn_successor_node.name}')\n",
    "\n",
    "    # Prune next conv weights, so everything fits\n",
    "    next_successor_node = model.find_direct_successors(bn_successor_node)[0]\n",
    "    if \"Conv\" in next_successor_node.name:\n",
    "        conv_succesor_node = next_successor_node\n",
    "        print(f'\\nNext successor node is a convolution: {conv_succesor_node.name}')\n",
    "        # Check if next conv is DW. If so, skip, as whole pruning process must be done\n",
    "        conv_group = conv_succesor_node.attribute[1].i\n",
    "        if conv_group != 1:\n",
    "            print(f'---> DW Conv found. Group = {conv_group}. Skip')\n",
    "        else:\n",
    "            print(f'DW Conv not found. Group = {conv_group}. Prune Conv Weights')\n",
    "            prune_next_conv_inp(model, conv_succesor_node, non_zero_idx, zero_idx)\n",
    "    # Successor could be Average Pool too, keep in mind\n",
    "    elif \"AveragePool\" in next_successor_node.name:\n",
    "        avgpool_succesor_node = next_successor_node\n",
    "        print(f'\\nNext successor node is average pooling: {avgpool_succesor_node.name}')\n",
    "            \n",
    "    return non_zero_idx, zero_idx, new_ch, new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dece0c96-fba5-4c36-adfd-d5abb2c01fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_0 node ############\n",
      "Quant 0 shape: (24, 3, 3, 3)\n",
      "Quant 1 shape: (24, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (0 elements):\n",
      "[]\n",
      "### Non Zero IDX, channels to keep (24 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Elements to keep is multiple of 8\n",
      "New Quant 0 shape: (24, 3, 3, 3)\n",
      "New Quant 1 shape: (24, 1, 1, 1)\n",
      "Quant_0 output original shape: (24, 3, 3, 3)\n",
      "Quant_0 output new shape: (24, 3, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_0 node ############\n",
      "Old Conv output shape: (1, 24, 112, 112)\n",
      "New Conv output shape: (1, 24, 112, 112)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_0 node ############\n",
      "BN0 shape: (24,)\n",
      "BN1 shape: (24,)\n",
      "BN2 shape: (24,)\n",
      "BN3 shape: (24,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_0_param0 shape: (24,)\n",
      "New BatchNormalization_0_param1 shape: (24,)\n",
      "New BatchNormalization_0_param2 shape: (24,)\n",
      "New BatchNormalization_0_param3 shape: (24,)\n",
      "\n",
      "############ Update output shape of Relu_0 node ############\n",
      "New shape: (1, 24, 112, 112)\n",
      "\n",
      "############ Update output shape of Quant_34 node ############\n",
      "New shape: (1, 24, 112, 112)\n",
      "\n",
      "Next successor node is a convolution: Conv_1\n",
      "---> DW Conv found. Group = 24. Skip\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "non_zero_idx, zero_idx, new_ch, new_shape = test_prune_next_conv_inp(model, \"Conv_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3228871c-9ce5-4f60-80d5-062c7ea1517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_next_conv_inp_file = prune_folder + \"06_test_prune_next_conv_inp.onnx\"\n",
    "model.save(test_prune_next_conv_inp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb4df960-5c64-4bcd-bac0-08ccd0d0178d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/pruning/sparse24_mul8/06_test_prune_next_conv_inp.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5db6da1570>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_next_conv_inp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7429c9-ea9a-4d78-974d-0fa7662d6597",
   "metadata": {},
   "source": [
    "#### Prune add node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e6a1b03-f608-48f6-8fda-f000019edaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_add_node(model, add_node, new_shape):\n",
    "\n",
    "    print(f'\\n############ Update output shape of {add_node.name} node ############')\n",
    "    print(f'New shape: {new_shape}')\n",
    "    model.set_tensor_shape(add_node.output[0], new_shape)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb7bd7d-8cb1-41c4-9819-4d2c80f7921a",
   "metadata": {},
   "source": [
    "##### Test prune add node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ced1c47-9924-43f4-8fdb-14bc5b4faef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_conv_b4_avgpool(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "    # Update conv out shape\n",
    "    new_shape = prune_conv_out(model=model, conv_node=conv_node, new_ch=new_ch)\n",
    "    # Prune batch norm\n",
    "    bn_node = model.find_direct_successors(conv_node)[0]\n",
    "    prune_bn(model, bn_node, new_shape, non_zero_idx, zero_idx)\n",
    "    \n",
    "    # Find Batch Norm successor\n",
    "    bn_successor_node = model.find_direct_successors(bn_node)[0]\n",
    "    if \"Relu\" in bn_successor_node.name:\n",
    "        # Prune relu output\n",
    "        prune_relu(model=model, relu_node=bn_successor_node, new_shape=new_shape)\n",
    "        # Update successor to relu quant node\n",
    "        bn_successor_node = model.find_direct_successors(bn_successor_node)[0]\n",
    "    if \"Quant\" in bn_successor_node.name:\n",
    "        # Always update the shape of Quant Node: it will be preceded by relu or batch norm\n",
    "        prune_quant_out(model, bn_successor_node, new_shape)   \n",
    "    else:\n",
    "        raise Exception(f'Node following BN is not ReLU or Quant: {bn_successor_node.name}')\n",
    "\n",
    "    # Prune next conv weights, so everything fits\n",
    "    # Check first if it is fork node\n",
    "        # Fork node: \n",
    "            # [0] -> Conv\n",
    "            # [1] -> Add \n",
    "    next_successor_nodes = model.find_direct_successors(bn_successor_node)\n",
    "    next_successor_node = next_successor_nodes[0]\n",
    "    fork_node = False\n",
    "    if len(next_successor_nodes) >= 2:\n",
    "        print(f'This successor node is a fork: {bn_successor_node.name}') \n",
    "        fork_node = True\n",
    "        next_successor_node_fork = next_successor_nodes[1] \n",
    "        print(\"\\n\\t%%%%%%%%%%%%% This is the right branch of the fork\") \n",
    "        if \"Add\" in next_successor_node_fork.name:\n",
    "            add_node = next_successor_node_fork\n",
    "            prune_add_node(model, add_node, new_shape)\n",
    "            quant_add_node = model.find_direct_successors(add_node)[0]\n",
    "            if \"Quant\" in quant_add_node.name:\n",
    "                prune_quant_out(model, quant_add_node, new_shape)  \n",
    "            else:\n",
    "                raise Exception(f'Node following Add is not Quant: {quant_add_node.name}')\n",
    "            conv_after_quant = model.find_direct_successors(quant_add_node)[0]\n",
    "            if \"Conv\" in conv_after_quant.name:\n",
    "                print(f'\\nNext successor node is a convolution: {conv_after_quant.name}')\n",
    "                # Check if next conv is DW. If so, skip, as whole pruning process must be done\n",
    "                conv_group = conv_after_quant.attribute[1].i\n",
    "                if conv_group != 1:\n",
    "                    print(f'---> DW Conv found. Group = {conv_group}. Skip')\n",
    "                else:\n",
    "                    print(f'DW Conv not found. Group = {conv_group}. Prune Conv Weights')\n",
    "                    prune_next_conv_inp(model, conv_after_quant, non_zero_idx, zero_idx)\n",
    "            else:\n",
    "                raise Exception(f'Node following Quant Add is not Conv: {conv_after_quant.name}')\n",
    "        else:\n",
    "            print(f'\\nNext successor node is a fork, but not followed by Add node: {bn_successor_node.name}')     \n",
    "\n",
    "    # Always adjust the input weights of next conv, left side of the Fork if it is the case\n",
    "    if \"Conv\" in next_successor_node.name:\n",
    "        conv_succesor_node = next_successor_node\n",
    "        if fork_node:\n",
    "            print(\"\\n\\t%%%%%%%%%%%%% This is the left branch of the fork\")     \n",
    "        print(f'\\nNext successor node is a convolution: {conv_succesor_node.name}')\n",
    "        # Check if next conv is DW. If so, skip, as whole pruning process must be done\n",
    "        conv_group = conv_succesor_node.attribute[1].i\n",
    "        if conv_group != 1:\n",
    "            print(f'---> DW Conv found. Group = {conv_group}. Skip')\n",
    "        else:\n",
    "            print(f'DW Conv not found. Group = {conv_group}. Prune Conv Weights')\n",
    "            prune_next_conv_inp(model, conv_succesor_node, non_zero_idx, zero_idx)\n",
    "    elif \"Add\" in next_successor_node.name:\n",
    "        add_successor_node = next_successor_node\n",
    "        print(f'\\nNext successor node is add: {add_successor_node.name}. Skip')\n",
    "    # Successor could be Average Pool too, keep in mind\n",
    "    elif \"AveragePool\" in next_successor_node.name:\n",
    "        avgpool_succesor_node = next_successor_node\n",
    "        print(f'\\nNext successor node is average pooling: {avgpool_succesor_node.name}')\n",
    "            \n",
    "    return non_zero_idx, zero_idx, new_ch, new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8cdec6e6-fa67-4871-a4e8-45b2c161d42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_26 node ############\n",
      "Quant 0 shape: (64, 64, 1, 1)\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (4 elements):\n",
      "[ 7 10 14 51]\n",
      "### Non Zero IDX, channels to keep (60 elements):\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.01414997]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "4 zero elements must be kept\n",
      "[ 7 10 14 51]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (64, 64, 1, 1)\n",
      "New Quant 1 shape: (64, 1, 1, 1)\n",
      "Quant_26 output original shape: (64, 64, 1, 1)\n",
      "Quant_26 output new shape: (64, 64, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_26 node ############\n",
      "Old Conv output shape: (1, 64, 14, 14)\n",
      "New Conv output shape: (1, 64, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_26 node ############\n",
      "BN0 shape: (64,)\n",
      "BN1 shape: (64,)\n",
      "BN2 shape: (64,)\n",
      "BN3 shape: (64,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.923e-42  4.942e-42 -4.940e-42 -4.951e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "Real Zero IDX kept:\n",
      "[ 7 10 14 51]\n",
      "-------------------------------------\n",
      "New BatchNormalization_26_param0 shape: (64,)\n",
      "New BatchNormalization_26_param1 shape: (64,)\n",
      "New BatchNormalization_26_param2 shape: (64,)\n",
      "New BatchNormalization_26_param3 shape: (64,)\n",
      "\n",
      "############ Update output shape of Quant_64 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "This successor node is a fork: Quant_64\n",
      "\n",
      "\t%%%%%%%%%%%%% This is the right branch of the fork\n",
      "\n",
      "############ Update output shape of Add_4 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_68 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_30\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_30 node ............\n",
      "Quant_30_param0 shape: (128, 64, 1, 1)\n",
      "New Quant_30_param0 shape: (128, 64, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_30 node: (128, 64, 1, 1)\n",
      "\n",
      "\t%%%%%%%%%%%%% This is the left branch of the fork\n",
      "\n",
      "Next successor node is a convolution: Conv_27\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_27 node ............\n",
      "Quant_27_param0 shape: (128, 64, 1, 1)\n",
      "New Quant_27_param0 shape: (128, 64, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_27 node: (128, 64, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "non_zero_idx, zero_idx, new_ch, new_shape = test_prune_conv_b4_avgpool(model, \"Conv_26\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c81dca23-9b89-4d0b-bd19-492c66061dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_conv_b4_avgpool_file = prune_folder + \"07_test_prune_conv_b4_avgpool.onnx\"\n",
    "model.save(test_prune_conv_b4_avgpool_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98d50b82-51a1-4cdc-94ea-cee35c79d9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/pruning/sparse24_mul8/07_test_prune_conv_b4_avgpool.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5db6da1450>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_conv_b4_avgpool_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c3a550-f0bb-4e4b-bd3b-f54dc69b9803",
   "metadata": {},
   "source": [
    "##### Test prune convs 26, 27, 28, 29 and 30\n",
    "Check that resnet is pruned properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6772da0e-cba8-4eac-a17a-c41fcb4a8d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_26 node ############\n",
      "Quant 0 shape: (64, 64, 1, 1)\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (4 elements):\n",
      "[ 7 10 14 51]\n",
      "### Non Zero IDX, channels to keep (60 elements):\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.01414997]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "4 zero elements must be kept\n",
      "[ 7 10 14 51]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (64, 64, 1, 1)\n",
      "New Quant 1 shape: (64, 1, 1, 1)\n",
      "Quant_26 output original shape: (64, 64, 1, 1)\n",
      "Quant_26 output new shape: (64, 64, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_26 node ############\n",
      "Old Conv output shape: (1, 64, 14, 14)\n",
      "New Conv output shape: (1, 64, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_26 node ############\n",
      "BN0 shape: (64,)\n",
      "BN1 shape: (64,)\n",
      "BN2 shape: (64,)\n",
      "BN3 shape: (64,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.923e-42  4.942e-42 -4.940e-42 -4.951e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "Real Zero IDX kept:\n",
      "[ 7 10 14 51]\n",
      "-------------------------------------\n",
      "New BatchNormalization_26_param0 shape: (64,)\n",
      "New BatchNormalization_26_param1 shape: (64,)\n",
      "New BatchNormalization_26_param2 shape: (64,)\n",
      "New BatchNormalization_26_param3 shape: (64,)\n",
      "\n",
      "############ Update output shape of Quant_64 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "This successor node is a fork: Quant_64\n",
      "\n",
      "\t%%%%%%%%%%%%% This is the right branch of the fork\n",
      "\n",
      "############ Update output shape of Add_4 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_68 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_30\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_30 node ............\n",
      "Quant_30_param0 shape: (128, 64, 1, 1)\n",
      "New Quant_30_param0 shape: (128, 64, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_30 node: (128, 64, 1, 1)\n",
      "\n",
      "\t%%%%%%%%%%%%% This is the left branch of the fork\n",
      "\n",
      "Next successor node is a convolution: Conv_27\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_27 node ............\n",
      "Quant_27_param0 shape: (128, 64, 1, 1)\n",
      "New Quant_27_param0 shape: (128, 64, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_27 node: (128, 64, 1, 1)\n",
      "\n",
      "############ Pruning Weights of Quant_27 node ############\n",
      "Quant 0 shape: (128, 64, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (67 elements):\n",
      "[  0   1   5   7  10  11  12  13  14  15  16  18  20  21  22  23  24  25\n",
      "  26  27  28  30  34  35  37  38  45  47  49  51  54  56  57  58  59  66\n",
      "  67  68  70  71  72  73  74  75  76  78  79  82  85  89  92  93  97  98\n",
      " 100 103 104 109 110 111 112 115 117 118 121 126 127]\n",
      "### Non Zero IDX, channels to keep (61 elements):\n",
      "[  2   3   4   6   8   9  17  19  29  31  32  33  36  39  40  41  42  43\n",
      "  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77  80  81  83\n",
      "  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107 108 113 114\n",
      " 116 119 120 122 123 124 125]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.02123232]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "3 zero elements must be kept\n",
      "[0 1 5]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[  0   1   2   3   4   5   6   8   9  17  19  29  31  32  33  36  39  40\n",
      "  41  42  43  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77\n",
      "  80  81  83  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107\n",
      " 108 113 114 116 119 120 122 123 124 125]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (64, 64, 1, 1)\n",
      "New Quant 1 shape: (64, 1, 1, 1)\n",
      "Quant_27 output original shape: (128, 64, 1, 1)\n",
      "Quant_27 output new shape: (64, 64, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_27 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 64, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_27 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 5.420e-42  4.952e-42  4.937e-42  4.944e-42  4.938e-42 -4.923e-42\n",
      " -4.948e-42  4.905e-42  4.909e-42  4.948e-42  4.917e-42  4.914e-42\n",
      "  4.954e-42  4.954e-42  4.928e-42  4.910e-42  4.913e-42  4.937e-42\n",
      " -4.906e-42  4.949e-42  4.954e-42  4.933e-42  4.933e-42  4.940e-42\n",
      " -4.945e-42  4.905e-42  4.910e-42  4.924e-42  4.951e-42  4.938e-42\n",
      "  4.944e-42  4.909e-42  4.912e-42  4.917e-42  4.933e-42  4.947e-42\n",
      " -4.910e-42  4.949e-42  4.920e-42  4.952e-42  4.916e-42 -4.935e-42\n",
      "  4.926e-42  4.931e-42  4.937e-42  4.949e-42  4.938e-42 -4.942e-42\n",
      "  4.928e-42  4.941e-42  4.945e-42  4.928e-42  4.949e-42  4.923e-42\n",
      " -4.930e-42  4.921e-42  5.639e-42  4.948e-42  4.954e-42 -4.913e-42\n",
      "  4.941e-42 -4.909e-42  4.917e-42  4.913e-42  4.951e-42  4.947e-42\n",
      "  4.945e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  2   3   4   6   8   9  17  19  29  31  32  33  36  39  40  41  42  43\n",
      "  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77  80  81  83\n",
      "  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107 108 113 114\n",
      " 116 119 120 122 123 124 125]\n",
      "Real Zero IDX kept:\n",
      "[0 1 5]\n",
      "-------------------------------------\n",
      "New BatchNormalization_27_param0 shape: (64,)\n",
      "New BatchNormalization_27_param1 shape: (64,)\n",
      "New BatchNormalization_27_param2 shape: (64,)\n",
      "New BatchNormalization_27_param3 shape: (64,)\n",
      "\n",
      "############ Update output shape of Relu_18 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_65 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_28\n",
      "---> DW Conv found. Group = 128. Skip\n",
      "\n",
      "############ Pruning Weights of Quant_28 node ############\n",
      "Quant 0 shape: (128, 1, 3, 3)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (67 elements):\n",
      "[  0   1   5   7  10  11  12  13  14  15  16  18  20  21  22  23  24  25\n",
      "  26  27  28  30  34  35  37  38  45  47  49  51  54  56  57  58  59  66\n",
      "  67  68  70  71  72  73  74  75  76  78  79  82  85  89  92  93  97  98\n",
      " 100 103 104 109 110 111 112 115 117 118 121 126 127]\n",
      "### Non Zero IDX, channels to keep (61 elements):\n",
      "[  2   3   4   6   8   9  17  19  29  31  32  33  36  39  40  41  42  43\n",
      "  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77  80  81  83\n",
      "  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107 108 113 114\n",
      " 116 119 120 122 123 124 125]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.02739516]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "3 zero elements must be kept\n",
      "[0 1 5]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[  0   1   2   3   4   5   6   8   9  17  19  29  31  32  33  36  39  40\n",
      "  41  42  43  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77\n",
      "  80  81  83  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107\n",
      " 108 113 114 116 119 120 122 123 124 125]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (64, 1, 3, 3)\n",
      "New Quant 1 shape: (64, 1, 1, 1)\n",
      "Quant_28 output original shape: (128, 1, 3, 3)\n",
      "Quant_28 output new shape: (64, 1, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_28 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 64, 14, 14)\n",
      "---> DW Conv found. Group 128, changed to 64\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_28 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.934e-42  4.926e-42 -4.944e-42  4.949e-42  4.934e-42  4.947e-42\n",
      "  4.937e-42  4.951e-42 -4.948e-42  4.916e-42  4.948e-42  4.923e-42\n",
      "  4.927e-42  4.954e-42  4.912e-42 -4.910e-42  4.954e-42  4.910e-42\n",
      "  4.914e-42  4.940e-42  4.912e-42 -4.934e-42 -4.912e-42  4.933e-42\n",
      "  4.912e-42 -4.941e-42  4.941e-42  4.949e-42 -4.916e-42  4.937e-42\n",
      "  4.942e-42  4.947e-42  4.921e-42  4.921e-42  4.927e-42  4.940e-42\n",
      " -4.919e-42  4.954e-42 -4.944e-42  4.934e-42 -4.910e-42 -4.941e-42\n",
      " -4.940e-42  4.951e-42  4.941e-42  4.924e-42  4.947e-42 -4.945e-42\n",
      "  4.952e-42  4.951e-42  4.948e-42  4.928e-42  4.917e-42  4.942e-42\n",
      " -4.947e-42  4.938e-42  4.920e-42  4.930e-42  4.944e-42 -4.916e-42\n",
      " -4.926e-42  4.930e-42  4.947e-42  4.912e-42  4.928e-42  4.928e-42\n",
      " -4.917e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  2   3   4   6   8   9  17  19  29  31  32  33  36  39  40  41  42  43\n",
      "  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77  80  81  83\n",
      "  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107 108 113 114\n",
      " 116 119 120 122 123 124 125]\n",
      "Real Zero IDX kept:\n",
      "[0 1 5]\n",
      "-------------------------------------\n",
      "New BatchNormalization_28_param0 shape: (64,)\n",
      "New BatchNormalization_28_param1 shape: (64,)\n",
      "New BatchNormalization_28_param2 shape: (64,)\n",
      "New BatchNormalization_28_param3 shape: (64,)\n",
      "\n",
      "############ Update output shape of Relu_19 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_66 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_29\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_29 node ............\n",
      "Quant_29_param0 shape: (64, 128, 1, 1)\n",
      "New Quant_29_param0 shape: (64, 64, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  0   1   2   3   4   5   6   8   9  17  19  29  31  32  33  36  39  40\n",
      "  41  42  43  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77\n",
      "  80  81  83  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107\n",
      " 108 113 114 116 119 120 122 123 124 125]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_29 node: (64, 64, 1, 1)\n",
      "\n",
      "############ Pruning Weights of Quant_29 node ############\n",
      "Quant 0 shape: (64, 64, 1, 1)\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (4 elements):\n",
      "[ 7 10 14 51]\n",
      "### Non Zero IDX, channels to keep (60 elements):\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[5.016172e-05]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "4 zero elements must be kept\n",
      "[ 7 10 14 51]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (64, 64, 1, 1)\n",
      "New Quant 1 shape: (64, 1, 1, 1)\n",
      "Quant_29 output original shape: (64, 64, 1, 1)\n",
      "Quant_29 output new shape: (64, 64, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_29 node ############\n",
      "Old Conv output shape: (1, 64, 14, 14)\n",
      "New Conv output shape: (1, 64, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_29 node ############\n",
      "BN0 shape: (64,)\n",
      "BN1 shape: (64,)\n",
      "BN2 shape: (64,)\n",
      "BN3 shape: (64,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.906e-42  4.944e-42  4.913e-42 -4.935e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "Real Zero IDX kept:\n",
      "[ 7 10 14 51]\n",
      "-------------------------------------\n",
      "New BatchNormalization_29_param0 shape: (64,)\n",
      "New BatchNormalization_29_param1 shape: (64,)\n",
      "New BatchNormalization_29_param2 shape: (64,)\n",
      "New BatchNormalization_29_param3 shape: (64,)\n",
      "\n",
      "############ Update output shape of Quant_67 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "Next successor node is add: Add_4. Skip\n",
      "\n",
      "############ Pruning Weights of Quant_30 node ############\n",
      "Quant 0 shape: (128, 64, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (26 elements):\n",
      "[  4   8  13  14  24  36  41  48  52  59  61  62  71  75  77  78  82  86\n",
      "  91  96 101 105 110 118 120 126]\n",
      "### Non Zero IDX, channels to keep (102 elements):\n",
      "[  0   1   2   3   5   6   7   9  10  11  12  15  16  17  18  19  20  21\n",
      "  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39  40  42\n",
      "  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63  64  65\n",
      "  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87  88  89\n",
      "  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109 111 112\n",
      " 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.00795446]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "2 zero elements must be kept\n",
      "[4 8]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  15  16  17  18  19\n",
      "  20  21  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39\n",
      "  40  42  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63\n",
      "  64  65  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87\n",
      "  88  89  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109\n",
      " 111 112 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (104, 64, 1, 1)\n",
      "New Quant 1 shape: (104, 1, 1, 1)\n",
      "Quant_30 output original shape: (128, 64, 1, 1)\n",
      "Quant_30 output new shape: (104, 64, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_30 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 104, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_30 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.945e-42 -4.913e-42 -4.945e-42 -4.912e-42  4.910e-42  4.921e-42\n",
      " -4.926e-42 -4.907e-42 -4.944e-42 -4.919e-42 -4.912e-42  4.935e-42\n",
      " -4.920e-42 -4.945e-42  4.919e-42 -6.283e-42 -4.934e-42 -4.937e-42\n",
      "  4.919e-42 -4.933e-42  4.910e-42 -4.937e-42 -4.919e-42  4.934e-42\n",
      "  4.941e-42  4.923e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  0   1   2   3   5   6   7   9  10  11  12  15  16  17  18  19  20  21\n",
      "  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39  40  42\n",
      "  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63  64  65\n",
      "  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87  88  89\n",
      "  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109 111 112\n",
      " 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "Real Zero IDX kept:\n",
      "[4 8]\n",
      "-------------------------------------\n",
      "New BatchNormalization_30_param0 shape: (104,)\n",
      "New BatchNormalization_30_param1 shape: (104,)\n",
      "New BatchNormalization_30_param2 shape: (104,)\n",
      "New BatchNormalization_30_param3 shape: (104,)\n",
      "\n",
      "############ Update output shape of Relu_20 node ############\n",
      "New shape: (1, 104, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_69 node ############\n",
      "New shape: (1, 104, 14, 14)\n",
      "\n",
      "Next successor node is average pooling: AveragePool_0\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "_, _, _, _ = test_prune_conv_b4_avgpool(model, \"Conv_26\")\n",
    "_, _, _, _ = test_prune_conv_b4_avgpool(model, \"Conv_27\")\n",
    "_, _, _, _ = test_prune_conv_b4_avgpool(model, \"Conv_28\")\n",
    "_, _, _, _ = test_prune_conv_b4_avgpool(model, \"Conv_29\")\n",
    "_, _, _, _ = test_prune_conv_b4_avgpool(model, \"Conv_30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8afab7a1-080c-490b-b0ee-04f3de3147c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_resnet = prune_folder + \"08_test_prune_resnet.onnx\"\n",
    "model.save(test_prune_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e344426a-be9e-4142-be1e-5bd3f18da2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/pruning/sparse24_mul8/08_test_prune_resnet.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5db6da1390>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40021505-a4e4-4d57-b86e-9b367376311c",
   "metadata": {},
   "source": [
    "#### Prune Avg Pool and Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f810bf3e-5a96-4509-a6e3-131633b1e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_avgpool_reshape(model, avgpool_node, new_shape):\n",
    "\n",
    "    print(f'\\n############ Update output shape of {avgpool_node.name} node ############')\n",
    "    avgpool_old_shape = model.get_tensor_shape(avgpool_node.output[0])\n",
    "    print(f'Old Avg Pool output shape: {avgpool_old_shape}')\n",
    "    avgpool_new_shape = (new_shape[0], new_shape[1], 1, 1)\n",
    "    print(f'New shape: {avgpool_new_shape}')\n",
    "    model.set_tensor_shape(avgpool_node.output[0], avgpool_new_shape)\n",
    "\n",
    "    mul_node = model.find_direct_successors(avgpool_node)[0]\n",
    "    if \"Mul\" in mul_node.name:\n",
    "        print(f'\\n############ Update output shape of {mul_node.name} node ############')\n",
    "        print(f'New shape: {avgpool_new_shape}')\n",
    "        model.set_tensor_shape(mul_node.output[0], avgpool_new_shape)\n",
    "    else:\n",
    "        raise Exception(f'Node following AvgPool is not Mul: {mul_node.name}')  \n",
    "\n",
    "    trunc_node = model.find_direct_successors(mul_node)[0]\n",
    "    if \"Trunc\" in trunc_node.name:\n",
    "        print(f'\\n############ Update output shape of {trunc_node.name} node ############')\n",
    "        print(f'New shape: {avgpool_new_shape}')\n",
    "        model.set_tensor_shape(trunc_node.output[0], avgpool_new_shape)\n",
    "    else:\n",
    "        raise Exception(f'Node following Mul is not Trunc: {trunc_node.name}')  \n",
    "\n",
    "    reshape_node = model.find_direct_successors(trunc_node)[0]\n",
    "    if \"Reshape\" in reshape_node.name:\n",
    "        print(f'\\n############ Update output shape of {reshape_node.name} node ############')\n",
    "        reshape_shape = (avgpool_new_shape[0], avgpool_new_shape[1])\n",
    "        print(f'New shape: {reshape_shape}')\n",
    "        model.set_tensor_shape(reshape_node.output[0], reshape_shape)\n",
    "    else:\n",
    "        raise Exception(f'Node following Trunc is not Reshape: {reshape_node.name}') \n",
    "\n",
    "    gemm_node = model.find_direct_successors(reshape_node)[0]\n",
    "    if \"Gemm\" in gemm_node.name:\n",
    "        print(f'\\n############ Gemm node found: {gemm_node.name} node ############')\n",
    "    else:\n",
    "        raise Exception(f'Node following Trunc is not Reshape: {gemm_node.name}')     \n",
    "   \n",
    "    return gemm_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41fbcbc-7ab8-4f9c-a159-af3177ee071f",
   "metadata": {},
   "source": [
    "##### Test prune avgpool and reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff7484e0-9f0c-48c4-8acc-c72ae335dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_conv_and_avgpool(model, conv: str):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_node_weights)\n",
    "    # Update conv out shape\n",
    "    new_shape = prune_conv_out(model=model, conv_node=conv_node, new_ch=new_ch)\n",
    "    # Prune batch norm\n",
    "    bn_node = model.find_direct_successors(conv_node)[0]\n",
    "    prune_bn(model, bn_node, new_shape, non_zero_idx, zero_idx)\n",
    "    \n",
    "    # Find Batch Norm successor\n",
    "    bn_successor_node = model.find_direct_successors(bn_node)[0]\n",
    "    if \"Relu\" in bn_successor_node.name:\n",
    "        # Prune relu output\n",
    "        prune_relu(model=model, relu_node=bn_successor_node, new_shape=new_shape)\n",
    "        # Update successor to relu quant node\n",
    "        bn_successor_node = model.find_direct_successors(bn_successor_node)[0]\n",
    "    if \"Quant\" in bn_successor_node.name:\n",
    "        # Always update the shape of Quant Node: it will be preceded by relu or batch norm\n",
    "        prune_quant_out(model, bn_successor_node, new_shape)   \n",
    "    else:\n",
    "        raise Exception(f'Node following BN is not ReLU or Quant: {bn_successor_node.name}')\n",
    "\n",
    "    # Prune next conv weights, so everything fits\n",
    "    # Check first if it is fork node\n",
    "        # Fork node: \n",
    "            # [0] -> Conv\n",
    "            # [1] -> Add \n",
    "    next_successor_nodes = model.find_direct_successors(bn_successor_node)\n",
    "    next_successor_node = next_successor_nodes[0]\n",
    "    fork_node = False\n",
    "    if len(next_successor_nodes) >= 2:\n",
    "        print(f'This successor node is a fork: {bn_successor_node.name}') \n",
    "        fork_node = True\n",
    "        next_successor_node_fork = next_successor_nodes[1] \n",
    "        print(\"\\n\\t%%%%%%%%%%%%% This is the right branch of the fork\") \n",
    "        if \"Add\" in next_successor_node_fork.name:\n",
    "            add_node = next_successor_node_fork\n",
    "            prune_add_node(model, add_node, new_shape)\n",
    "            quant_add_node = model.find_direct_successors(add_node)[0]\n",
    "            if \"Quant\" in quant_add_node.name:\n",
    "                prune_quant_out(model, quant_add_node, new_shape)  \n",
    "            else:\n",
    "                raise Exception(f'Node following Add is not Quant: {quant_add_node.name}')\n",
    "            conv_after_quant = model.find_direct_successors(quant_add_node)[0]\n",
    "            if \"Conv\" in conv_after_quant.name:\n",
    "                print(f'\\nNext successor node is a convolution: {conv_after_quant.name}')\n",
    "                # Check if next conv is DW. If so, skip, as whole pruning process must be done\n",
    "                conv_group = conv_after_quant.attribute[1].i\n",
    "                if conv_group != 1:\n",
    "                    print(f'---> DW Conv found. Group = {conv_group}. Skip')\n",
    "                else:\n",
    "                    print(f'DW Conv not found. Group = {conv_group}. Prune Conv Weights')\n",
    "                    prune_next_conv_inp(model, conv_after_quant, non_zero_idx, zero_idx)\n",
    "            else:\n",
    "                raise Exception(f'Node following Quant Add is not Conv: {conv_after_quant.name}')\n",
    "        else:\n",
    "            print(f'\\nNext successor node is a fork, but not followed by Add node: {bn_successor_node.name}')     \n",
    "\n",
    "    # Always adjust the input weights of next conv, left side of the Fork if it is the case\n",
    "    if \"Conv\" in next_successor_node.name:\n",
    "        conv_succesor_node = next_successor_node\n",
    "        if fork_node:\n",
    "            print(\"\\n\\t%%%%%%%%%%%%% This is the left branch of the fork\")     \n",
    "        print(f'\\nNext successor node is a convolution: {conv_succesor_node.name}')\n",
    "        # Check if next conv is DW. If so, skip, as whole pruning process must be done\n",
    "        conv_group = conv_succesor_node.attribute[1].i\n",
    "        if conv_group != 1:\n",
    "            print(f'---> DW Conv found. Group = {conv_group}. Skip')\n",
    "        else:\n",
    "            print(f'DW Conv not found. Group = {conv_group}. Prune Conv Weights')\n",
    "            prune_next_conv_inp(model, conv_succesor_node, non_zero_idx, zero_idx)\n",
    "    elif \"Add\" in next_successor_node.name:\n",
    "        add_successor_node = next_successor_node\n",
    "        print(f'\\nNext successor node is add: {add_successor_node.name}. Skip')\n",
    "    # Successor could be Average Pool too, keep in mind\n",
    "    elif \"AveragePool\" in next_successor_node.name:\n",
    "        avgpool_succesor_node = next_successor_node\n",
    "        print(f'\\nNext successor node is average pooling: {avgpool_succesor_node.name}')\n",
    "        gemm_node = prune_avgpool_reshape(model, avgpool_succesor_node, new_shape)\n",
    "            \n",
    "    return non_zero_idx, zero_idx, new_ch, new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d59c668-39ec-424c-a209-ff53053c5472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_30 node ############\n",
      "Quant 0 shape: (128, 64, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (26 elements):\n",
      "[  4   8  13  14  24  36  41  48  52  59  61  62  71  75  77  78  82  86\n",
      "  91  96 101 105 110 118 120 126]\n",
      "### Non Zero IDX, channels to keep (102 elements):\n",
      "[  0   1   2   3   5   6   7   9  10  11  12  15  16  17  18  19  20  21\n",
      "  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39  40  42\n",
      "  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63  64  65\n",
      "  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87  88  89\n",
      "  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109 111 112\n",
      " 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.00795446]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "2 zero elements must be kept\n",
      "[4 8]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  15  16  17  18  19\n",
      "  20  21  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39\n",
      "  40  42  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63\n",
      "  64  65  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87\n",
      "  88  89  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109\n",
      " 111 112 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (104, 64, 1, 1)\n",
      "New Quant 1 shape: (104, 1, 1, 1)\n",
      "Quant_30 output original shape: (128, 64, 1, 1)\n",
      "Quant_30 output new shape: (104, 64, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_30 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 104, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_30 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.945e-42 -4.913e-42 -4.945e-42 -4.912e-42  4.910e-42  4.921e-42\n",
      " -4.926e-42 -4.907e-42 -4.944e-42 -4.919e-42 -4.912e-42  4.935e-42\n",
      " -4.920e-42 -4.945e-42  4.919e-42 -6.283e-42 -4.934e-42 -4.937e-42\n",
      "  4.919e-42 -4.933e-42  4.910e-42 -4.937e-42 -4.919e-42  4.934e-42\n",
      "  4.941e-42  4.923e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  0   1   2   3   5   6   7   9  10  11  12  15  16  17  18  19  20  21\n",
      "  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39  40  42\n",
      "  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63  64  65\n",
      "  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87  88  89\n",
      "  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109 111 112\n",
      " 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "Real Zero IDX kept:\n",
      "[4 8]\n",
      "-------------------------------------\n",
      "New BatchNormalization_30_param0 shape: (104,)\n",
      "New BatchNormalization_30_param1 shape: (104,)\n",
      "New BatchNormalization_30_param2 shape: (104,)\n",
      "New BatchNormalization_30_param3 shape: (104,)\n",
      "\n",
      "############ Update output shape of Relu_20 node ############\n",
      "New shape: (1, 104, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_69 node ############\n",
      "New shape: (1, 104, 14, 14)\n",
      "\n",
      "Next successor node is average pooling: AveragePool_0\n",
      "\n",
      "############ Update output shape of AveragePool_0 node ############\n",
      "Old Avg Pool output shape: [1, 128, 1, 1]\n",
      "New shape: (1, 104, 1, 1)\n",
      "\n",
      "############ Update output shape of Mul_1 node ############\n",
      "New shape: (1, 104, 1, 1)\n",
      "\n",
      "############ Update output shape of Trunc_0 node ############\n",
      "New shape: (1, 104, 1, 1)\n",
      "\n",
      "############ Update output shape of Reshape_0 node ############\n",
      "New shape: (1, 104)\n",
      "\n",
      "############ Gemm node found: Gemm_0 node ############\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "_, _, _, _ = test_prune_conv_and_avgpool(model, \"Conv_30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcf5a997-0dfd-4a07-af0e-cf8b3ec2800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_avgpool = prune_folder + \"09_test_prune_avgpool.onnx\"\n",
    "model.save(test_prune_avgpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2d6cd25a-fe65-4881-8ee3-8d0a655b8efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/pruning/sparse24_mul8/09_test_prune_avgpool.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5db6d6ab00>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_avgpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a30356-e474-4329-ac51-064900fa7c29",
   "metadata": {},
   "source": [
    "#### Prune GEMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3e18772e-a539-43d8-9247-8be2e2be73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_next_gemm_inp(model, gemm_node, non_zero_idx, zero_idx):\n",
    "\n",
    "    print(f'\\n............ Pruning Weights of {gemm_node.name} node ............')   \n",
    "    gemm_node_predec = model.find_direct_predecessors(gemm_node)\n",
    "    quant_node = gemm_node_predec[1]  # Quant node is [1]  \n",
    "    \n",
    "    quant_0 = quant_node.input[0]\n",
    "    np_q0 = model.get_initializer(quant_0)\n",
    "    print(f'{quant_0} shape: {np_q0.shape}')\n",
    "\n",
    "    new_np_q0 = np_q0[:, non_zero_idx]\n",
    "    new_shape = new_np_q0.shape\n",
    "    print(f'New {quant_0} shape: {new_shape}')\n",
    "    \n",
    "    print(\"-------------------------------------\")\n",
    "    all_weights_zero = np.all(np_q0[:, zero_idx] == 0.)\n",
    "    print(f'*** All weights removed are zero? {all_weights_zero}')\n",
    "    print(f'### Non Zero IDX, channels to keep:\\n{non_zero_idx}')\n",
    "    print(\"-------------------------------------\")\n",
    "\n",
    "    model.set_initializer(\n",
    "        tensor_name = quant_0, \n",
    "        tensor_value = new_np_q0) \n",
    "\n",
    "    print(f'Modify output shape of {quant_node.name} node: {new_shape}')\n",
    "    model.set_tensor_shape(quant_node.output[0], new_shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dbb78f-039e-477f-93e4-4850379e3eb9",
   "metadata": {},
   "source": [
    "##### Test prune GEMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1cfd66d-7398-41f8-bd43-1ae15f5abcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prune_any_conv(model, conv: str, do_mul_val = True):\n",
    "    \n",
    "    conv_node = model.get_node_from_name(conv)\n",
    "    conv_node_predec = model.find_direct_predecessors(conv_node)\n",
    "    conv_node_weights = conv_node_predec[1]\n",
    "\n",
    "    # Prune weights\n",
    "    non_zero_idx, zero_idx, new_ch = prune_conv_weights(model=model, quant_node=conv_node_weights, do_mul_val=do_mul_val)\n",
    "    # Update conv out shape\n",
    "    new_shape = prune_conv_out(model=model, conv_node=conv_node, new_ch=new_ch)\n",
    "    # Prune batch norm\n",
    "    bn_node = model.find_direct_successors(conv_node)[0]\n",
    "    prune_bn(model, bn_node, new_shape, non_zero_idx, zero_idx)\n",
    "    \n",
    "    # Find Batch Norm successor\n",
    "    bn_successor_node = model.find_direct_successors(bn_node)[0]\n",
    "    if \"Relu\" in bn_successor_node.name:\n",
    "        # Prune relu output\n",
    "        prune_relu(model=model, relu_node=bn_successor_node, new_shape=new_shape)\n",
    "        # Update successor to relu quant node\n",
    "        bn_successor_node = model.find_direct_successors(bn_successor_node)[0]\n",
    "    if \"Quant\" in bn_successor_node.name:\n",
    "        # Always update the shape of Quant Node: it will be preceded by relu or batch norm\n",
    "        prune_quant_out(model, bn_successor_node, new_shape)   \n",
    "    else:\n",
    "        raise Exception(f'Node following BN is not ReLU or Quant: {bn_successor_node.name}')\n",
    "\n",
    "    # Prune next conv weights, so everything fits\n",
    "    # Check first if it is fork node\n",
    "        # Fork node: \n",
    "            # [0] -> Conv\n",
    "            # [1] -> Add \n",
    "    next_successor_nodes = model.find_direct_successors(bn_successor_node)\n",
    "    next_successor_node = next_successor_nodes[0]\n",
    "    fork_node = False\n",
    "    if len(next_successor_nodes) >= 2:\n",
    "        print(f'This successor node is a fork: {bn_successor_node.name}') \n",
    "        fork_node = True\n",
    "        next_successor_node_fork = next_successor_nodes[1] \n",
    "        print(\"\\n\\t%%%%%%%%%%%%% This is the right branch of the fork\") \n",
    "        if \"Add\" in next_successor_node_fork.name:\n",
    "            add_node = next_successor_node_fork\n",
    "            prune_add_node(model, add_node, new_shape)\n",
    "            quant_add_node = model.find_direct_successors(add_node)[0]\n",
    "            if \"Quant\" in quant_add_node.name:\n",
    "                prune_quant_out(model, quant_add_node, new_shape)  \n",
    "            else:\n",
    "                raise Exception(f'Node following Add is not Quant: {quant_add_node.name}')\n",
    "            conv_after_quant = model.find_direct_successors(quant_add_node)[0]\n",
    "            if \"Conv\" in conv_after_quant.name:\n",
    "                print(f'\\nNext successor node is a convolution: {conv_after_quant.name}')\n",
    "                # Check if next conv is DW. If so, skip, as whole pruning process must be done\n",
    "                conv_group = conv_after_quant.attribute[1].i\n",
    "                if conv_group != 1:\n",
    "                    print(f'---> DW Conv found. Group = {conv_group}. Skip')\n",
    "                else:\n",
    "                    print(f'DW Conv not found. Group = {conv_group}. Prune Conv Weights')\n",
    "                    prune_next_conv_inp(model, conv_after_quant, non_zero_idx, zero_idx)\n",
    "            else:\n",
    "                raise Exception(f'Node following Quant Add is not Conv: {conv_after_quant.name}')\n",
    "        else:\n",
    "            print(f'\\nNext successor node is a fork, but not followed by Add node: {bn_successor_node.name}')     \n",
    "\n",
    "    # Always adjust the input weights of next conv, left side of the Fork if it is the case\n",
    "    if \"Conv\" in next_successor_node.name:\n",
    "        conv_succesor_node = next_successor_node\n",
    "        if fork_node:\n",
    "            print(\"\\n\\t%%%%%%%%%%%%% This is the left branch of the fork\")     \n",
    "        print(f'\\nNext successor node is a convolution: {conv_succesor_node.name}')\n",
    "        # Check if next conv is DW. If so, skip, as whole pruning process must be done\n",
    "        conv_group = conv_succesor_node.attribute[1].i\n",
    "        if conv_group != 1:\n",
    "            print(f'---> DW Conv found. Group = {conv_group}. Skip')\n",
    "        else:\n",
    "            print(f'DW Conv not found. Group = {conv_group}. Prune Conv Weights')\n",
    "            prune_next_conv_inp(model, conv_succesor_node, non_zero_idx, zero_idx)\n",
    "    elif \"Add\" in next_successor_node.name:\n",
    "        add_successor_node = next_successor_node\n",
    "        print(f'\\nNext successor node is add: {add_successor_node.name}. Skip')\n",
    "    # Successor could be Average Pool too, keep in mind\n",
    "    elif \"AveragePool\" in next_successor_node.name:\n",
    "        avgpool_succesor_node = next_successor_node\n",
    "        print(f'\\nNext successor node is average pooling: {avgpool_succesor_node.name}')\n",
    "        gemm_node = prune_avgpool_reshape(model, avgpool_succesor_node, new_shape)\n",
    "        prune_next_gemm_inp(model, gemm_node, non_zero_idx, zero_idx)\n",
    "            \n",
    "    return non_zero_idx, zero_idx, new_ch, new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d840fd0c-88b4-44cf-a481-e018b91a727c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Pruning Weights of Quant_30 node ############\n",
      "Quant 0 shape: (128, 64, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (26 elements):\n",
      "[  4   8  13  14  24  36  41  48  52  59  61  62  71  75  77  78  82  86\n",
      "  91  96 101 105 110 118 120 126]\n",
      "### Non Zero IDX, channels to keep (102 elements):\n",
      "[  0   1   2   3   5   6   7   9  10  11  12  15  16  17  18  19  20  21\n",
      "  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39  40  42\n",
      "  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63  64  65\n",
      "  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87  88  89\n",
      "  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109 111 112\n",
      " 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.00795446]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "2 zero elements must be kept\n",
      "[4 8]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  15  16  17  18  19\n",
      "  20  21  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39\n",
      "  40  42  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63\n",
      "  64  65  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87\n",
      "  88  89  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109\n",
      " 111 112 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (104, 64, 1, 1)\n",
      "New Quant 1 shape: (104, 1, 1, 1)\n",
      "Quant_30 output original shape: (128, 64, 1, 1)\n",
      "Quant_30 output new shape: (104, 64, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_30 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 104, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_30 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.945e-42 -4.913e-42 -4.945e-42 -4.912e-42  4.910e-42  4.921e-42\n",
      " -4.926e-42 -4.907e-42 -4.944e-42 -4.919e-42 -4.912e-42  4.935e-42\n",
      " -4.920e-42 -4.945e-42  4.919e-42 -6.283e-42 -4.934e-42 -4.937e-42\n",
      "  4.919e-42 -4.933e-42  4.910e-42 -4.937e-42 -4.919e-42  4.934e-42\n",
      "  4.941e-42  4.923e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  0   1   2   3   5   6   7   9  10  11  12  15  16  17  18  19  20  21\n",
      "  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39  40  42\n",
      "  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63  64  65\n",
      "  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87  88  89\n",
      "  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109 111 112\n",
      " 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "Real Zero IDX kept:\n",
      "[4 8]\n",
      "-------------------------------------\n",
      "New BatchNormalization_30_param0 shape: (104,)\n",
      "New BatchNormalization_30_param1 shape: (104,)\n",
      "New BatchNormalization_30_param2 shape: (104,)\n",
      "New BatchNormalization_30_param3 shape: (104,)\n",
      "\n",
      "############ Update output shape of Relu_20 node ############\n",
      "New shape: (1, 104, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_69 node ############\n",
      "New shape: (1, 104, 14, 14)\n",
      "\n",
      "Next successor node is average pooling: AveragePool_0\n",
      "\n",
      "############ Update output shape of AveragePool_0 node ############\n",
      "Old Avg Pool output shape: [1, 128, 1, 1]\n",
      "New shape: (1, 104, 1, 1)\n",
      "\n",
      "############ Update output shape of Mul_1 node ############\n",
      "New shape: (1, 104, 1, 1)\n",
      "\n",
      "############ Update output shape of Trunc_0 node ############\n",
      "New shape: (1, 104, 1, 1)\n",
      "\n",
      "############ Update output shape of Reshape_0 node ############\n",
      "New shape: (1, 104)\n",
      "\n",
      "############ Gemm node found: Gemm_0 node ############\n",
      "\n",
      "............ Pruning Weights of Gemm_0 node ............\n",
      "Quant_31_param0 shape: (2, 128)\n",
      "New Quant_31_param0 shape: (2, 104)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  15  16  17  18  19\n",
      "  20  21  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39\n",
      "  40  42  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63\n",
      "  64  65  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87\n",
      "  88  89  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109\n",
      " 111 112 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_31 node: (2, 104)\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "_, _, _, _ = test_prune_any_conv(model, \"Conv_30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3af1316e-34ee-4603-888c-b5c7c184f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prune_any_conv_file = prune_folder + \"10_test_prune_any_conv_file.onnx\"\n",
    "model.save(test_prune_any_conv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "572d5a13-7634-4541-bba4-7bd3e498b1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/pruning/sparse24_mul8/10_test_prune_any_conv_file.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5db6d68670>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(test_prune_any_conv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37aa7d1-992f-4663-bfbe-b79eaca6641f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d6b762d-c698-4ac8-af23-0ef91d7bc342",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test Pruning of first 2 Convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05ae631c-1631-4126-b584-2ab25540d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(qonnx_clean_filename)\n",
    "# # non_zero_idx, zero_idx, new_ch, new_shape = test_prune_conv(model, \"Conv_0\")\n",
    "# # non_zero_idx, zero_idx, new_ch, new_shape = test_prune_conv(model, \"Conv_1\")\n",
    "\n",
    "# _, _, _, _ = test_prune_conv(model, \"Conv_0\")\n",
    "# _, _, _, _ = test_prune_conv(model, \"Conv_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "28345622-19d1-49a2-b7ed-8ad019c5c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_prune_2_conv = prune_folder + \"10_test_prune_2_conv.onnx\"\n",
    "\n",
    "# model = model.transform(InferShapes())\n",
    "# model.save(test_prune_2_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a846942-b86d-4c01-9380-eb6068a3f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(test_prune_2_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751b0cc3-bd79-4ffd-82e6-14febf6efaa3",
   "metadata": {},
   "source": [
    "# Test Pruning the Whole Model - NO MUL 4 or 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "53e332a9-ba4c-43d7-a10c-b327e6e8e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_mul4 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c811656f-40b8-45e4-b6d7-be0473cc91c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_12 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_12 node ############\n",
      "Quant 0 shape: (48, 24, 1, 1)\n",
      "Quant 1 shape: (48, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (1 elements):\n",
      "[28]\n",
      "### Non Zero IDX, channels to keep (47 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: False\n",
      "New Quant 0 shape: (47, 24, 1, 1)\n",
      "New Quant 1 shape: (47, 1, 1, 1)\n",
      "Quant_12 output original shape: (48, 24, 1, 1)\n",
      "Quant_12 output new shape: (47, 24, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_12 node ############\n",
      "Old Conv output shape: (1, 48, 28, 28)\n",
      "New Conv output shape: (1, 47, 28, 28)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_12 node ############\n",
      "BN0 shape: (48,)\n",
      "BN1 shape: (48,)\n",
      "BN2 shape: (48,)\n",
      "BN3 shape: (48,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.909e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_12_param0 shape: (47,)\n",
      "New BatchNormalization_12_param1 shape: (47,)\n",
      "New BatchNormalization_12_param2 shape: (47,)\n",
      "New BatchNormalization_12_param3 shape: (47,)\n",
      "\n",
      "############ Update output shape of Relu_8 node ############\n",
      "New shape: (1, 47, 28, 28)\n",
      "\n",
      "############ Update output shape of Quant_47 node ############\n",
      "New shape: (1, 47, 28, 28)\n",
      "\n",
      "Next successor node is a convolution: Conv_13\n",
      "---> DW Conv found. Group = 48. Skip\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_13 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_13 node ############\n",
      "Quant 0 shape: (48, 1, 3, 3)\n",
      "Quant 1 shape: (48, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (1 elements):\n",
      "[28]\n",
      "### Non Zero IDX, channels to keep (47 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: False\n",
      "New Quant 0 shape: (47, 1, 3, 3)\n",
      "New Quant 1 shape: (47, 1, 1, 1)\n",
      "Quant_13 output original shape: (48, 1, 3, 3)\n",
      "Quant_13 output new shape: (47, 1, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_13 node ############\n",
      "Old Conv output shape: (1, 48, 28, 28)\n",
      "New Conv output shape: (1, 47, 28, 28)\n",
      "---> DW Conv found. Group 48, changed to 47\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_13 node ############\n",
      "BN0 shape: (48,)\n",
      "BN1 shape: (48,)\n",
      "BN2 shape: (48,)\n",
      "BN3 shape: (48,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[4.926e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_13_param0 shape: (47,)\n",
      "New BatchNormalization_13_param1 shape: (47,)\n",
      "New BatchNormalization_13_param2 shape: (47,)\n",
      "New BatchNormalization_13_param3 shape: (47,)\n",
      "\n",
      "############ Update output shape of Relu_9 node ############\n",
      "New shape: (1, 47, 28, 28)\n",
      "\n",
      "############ Update output shape of Quant_48 node ############\n",
      "New shape: (1, 47, 28, 28)\n",
      "\n",
      "Next successor node is a convolution: Conv_14\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_14 node ............\n",
      "Quant_14_param0 shape: (24, 48, 1, 1)\n",
      "New Quant_14_param0 shape: (24, 47, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_14 node: (24, 47, 1, 1)\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_15 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_15 node ############\n",
      "Quant 0 shape: (96, 24, 1, 1)\n",
      "Quant 1 shape: (96, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (4 elements):\n",
      "[ 0 45 54 83]\n",
      "### Non Zero IDX, channels to keep (92 elements):\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 46 47 48 49\n",
      " 50 51 52 53 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: False\n",
      "New Quant 0 shape: (92, 24, 1, 1)\n",
      "New Quant 1 shape: (92, 1, 1, 1)\n",
      "Quant_15 output original shape: (96, 24, 1, 1)\n",
      "Quant_15 output new shape: (92, 24, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_15 node ############\n",
      "Old Conv output shape: (1, 96, 28, 28)\n",
      "New Conv output shape: (1, 92, 28, 28)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_15 node ############\n",
      "BN0 shape: (96,)\n",
      "BN1 shape: (96,)\n",
      "BN2 shape: (96,)\n",
      "BN3 shape: (96,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.931e-42  4.940e-42  4.940e-42 -4.914e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 46 47 48 49\n",
      " 50 51 52 53 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_15_param0 shape: (92,)\n",
      "New BatchNormalization_15_param1 shape: (92,)\n",
      "New BatchNormalization_15_param2 shape: (92,)\n",
      "New BatchNormalization_15_param3 shape: (92,)\n",
      "\n",
      "############ Update output shape of Relu_10 node ############\n",
      "New shape: (1, 92, 28, 28)\n",
      "\n",
      "############ Update output shape of Quant_51 node ############\n",
      "New shape: (1, 92, 28, 28)\n",
      "\n",
      "Next successor node is a convolution: Conv_16\n",
      "---> DW Conv found. Group = 96. Skip\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_16 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_16 node ############\n",
      "Quant 0 shape: (96, 1, 3, 3)\n",
      "Quant 1 shape: (96, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (4 elements):\n",
      "[ 0 45 54 83]\n",
      "### Non Zero IDX, channels to keep (92 elements):\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 46 47 48 49\n",
      " 50 51 52 53 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: False\n",
      "New Quant 0 shape: (92, 1, 3, 3)\n",
      "New Quant 1 shape: (92, 1, 1, 1)\n",
      "Quant_16 output original shape: (96, 1, 3, 3)\n",
      "Quant_16 output new shape: (92, 1, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_16 node ############\n",
      "Old Conv output shape: (1, 96, 14, 14)\n",
      "New Conv output shape: (1, 92, 14, 14)\n",
      "---> DW Conv found. Group 96, changed to 92\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_16 node ############\n",
      "BN0 shape: (96,)\n",
      "BN1 shape: (96,)\n",
      "BN2 shape: (96,)\n",
      "BN3 shape: (96,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.919e-42  4.913e-42 -4.948e-42  4.914e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 46 47 48 49\n",
      " 50 51 52 53 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_16_param0 shape: (92,)\n",
      "New BatchNormalization_16_param1 shape: (92,)\n",
      "New BatchNormalization_16_param2 shape: (92,)\n",
      "New BatchNormalization_16_param3 shape: (92,)\n",
      "\n",
      "############ Update output shape of Relu_11 node ############\n",
      "New shape: (1, 92, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_52 node ############\n",
      "New shape: (1, 92, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_17\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_17 node ............\n",
      "Quant_17_param0 shape: (32, 96, 1, 1)\n",
      "New Quant_17_param0 shape: (32, 92, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 46 47 48 49\n",
      " 50 51 52 53 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_17 node: (32, 92, 1, 1)\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_18 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_18 node ############\n",
      "Quant 0 shape: (128, 32, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (16 elements):\n",
      "[  2   7  12  13  20  33  40  41  51  59  64  89  94  99 102 112]\n",
      "### Non Zero IDX, channels to keep (112 elements):\n",
      "[  0   1   3   4   5   6   8   9  10  11  14  15  16  17  18  19  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  34  35  36  37  38  39  42  43\n",
      "  44  45  46  47  48  49  50  52  53  54  55  56  57  58  60  61  62  63\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  87  88  90  91  92  93  95  96  97  98 100 101 103 104\n",
      " 105 106 107 108 109 110 111 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: False\n",
      "New Quant 0 shape: (112, 32, 1, 1)\n",
      "New Quant 1 shape: (112, 1, 1, 1)\n",
      "Quant_18 output original shape: (128, 32, 1, 1)\n",
      "Quant_18 output new shape: (112, 32, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_18 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 112, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_18 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.938e-42 -4.910e-42  4.921e-42  4.944e-42 -4.924e-42  4.933e-42\n",
      "  4.909e-42  4.941e-42  4.941e-42 -4.928e-42 -4.934e-42  4.931e-42\n",
      " -5.925e-42  4.909e-42  4.952e-42 -4.949e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  0   1   3   4   5   6   8   9  10  11  14  15  16  17  18  19  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  34  35  36  37  38  39  42  43\n",
      "  44  45  46  47  48  49  50  52  53  54  55  56  57  58  60  61  62  63\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  87  88  90  91  92  93  95  96  97  98 100 101 103 104\n",
      " 105 106 107 108 109 110 111 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_18_param0 shape: (112,)\n",
      "New BatchNormalization_18_param1 shape: (112,)\n",
      "New BatchNormalization_18_param2 shape: (112,)\n",
      "New BatchNormalization_18_param3 shape: (112,)\n",
      "\n",
      "############ Update output shape of Relu_12 node ############\n",
      "New shape: (1, 112, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_54 node ############\n",
      "New shape: (1, 112, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_19\n",
      "---> DW Conv found. Group = 128. Skip\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_19 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_19 node ############\n",
      "Quant 0 shape: (128, 1, 3, 3)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (16 elements):\n",
      "[  2   7  12  13  20  33  40  41  51  59  64  89  94  99 102 112]\n",
      "### Non Zero IDX, channels to keep (112 elements):\n",
      "[  0   1   3   4   5   6   8   9  10  11  14  15  16  17  18  19  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  34  35  36  37  38  39  42  43\n",
      "  44  45  46  47  48  49  50  52  53  54  55  56  57  58  60  61  62  63\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  87  88  90  91  92  93  95  96  97  98 100 101 103 104\n",
      " 105 106 107 108 109 110 111 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: False\n",
      "New Quant 0 shape: (112, 1, 3, 3)\n",
      "New Quant 1 shape: (112, 1, 1, 1)\n",
      "Quant_19 output original shape: (128, 1, 3, 3)\n",
      "Quant_19 output new shape: (112, 1, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_19 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 112, 14, 14)\n",
      "---> DW Conv found. Group 128, changed to 112\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_19 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.924e-42 -4.940e-42 -4.917e-42  4.923e-42  4.910e-42  4.923e-42\n",
      "  4.935e-42 -4.913e-42  4.909e-42  4.913e-42 -4.928e-42  4.930e-42\n",
      "  4.919e-42  4.914e-42  4.913e-42  4.919e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  0   1   3   4   5   6   8   9  10  11  14  15  16  17  18  19  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  34  35  36  37  38  39  42  43\n",
      "  44  45  46  47  48  49  50  52  53  54  55  56  57  58  60  61  62  63\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  87  88  90  91  92  93  95  96  97  98 100 101 103 104\n",
      " 105 106 107 108 109 110 111 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_19_param0 shape: (112,)\n",
      "New BatchNormalization_19_param1 shape: (112,)\n",
      "New BatchNormalization_19_param2 shape: (112,)\n",
      "New BatchNormalization_19_param3 shape: (112,)\n",
      "\n",
      "############ Update output shape of Relu_13 node ############\n",
      "New shape: (1, 112, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_55 node ############\n",
      "New shape: (1, 112, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_20\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_20 node ............\n",
      "Quant_20_param0 shape: (32, 128, 1, 1)\n",
      "New Quant_20_param0 shape: (32, 112, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  0   1   3   4   5   6   8   9  10  11  14  15  16  17  18  19  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  34  35  36  37  38  39  42  43\n",
      "  44  45  46  47  48  49  50  52  53  54  55  56  57  58  60  61  62  63\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  87  88  90  91  92  93  95  96  97  98 100 101 103 104\n",
      " 105 106 107 108 109 110 111 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_20 node: (32, 112, 1, 1)\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_21 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_21 node ############\n",
      "Quant 0 shape: (128, 32, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (33 elements):\n",
      "[  3   7   9  12  21  24  27  29  31  32  39  41  43  44  50  57  63  68\n",
      "  71  73  75  80  83  90  94  96  97  99 103 113 117 124 125]\n",
      "### Non Zero IDX, channels to keep (95 elements):\n",
      "[  0   1   2   4   5   6   8  10  11  13  14  15  16  17  18  19  20  22\n",
      "  23  25  26  28  30  33  34  35  36  37  38  40  42  45  46  47  48  49\n",
      "  51  52  53  54  55  56  58  59  60  61  62  64  65  66  67  69  70  72\n",
      "  74  76  77  78  79  81  82  84  85  86  87  88  89  91  92  93  95  98\n",
      " 100 101 102 104 105 106 107 108 109 110 111 112 114 115 116 118 119 120\n",
      " 121 122 123 126 127]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: False\n",
      "New Quant 0 shape: (95, 32, 1, 1)\n",
      "New Quant 1 shape: (95, 1, 1, 1)\n",
      "Quant_21 output original shape: (128, 32, 1, 1)\n",
      "Quant_21 output new shape: (95, 32, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_21 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 95, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_21 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.954e-42  4.914e-42  4.935e-42  4.942e-42  4.949e-42 -4.914e-42\n",
      " -4.905e-42  4.917e-42  4.926e-42  4.924e-42 -4.933e-42  4.916e-42\n",
      "  4.910e-42  4.937e-42  4.909e-42 -4.938e-42 -4.949e-42 -4.949e-42\n",
      " -4.927e-42 -4.951e-42 -4.951e-42  4.933e-42  4.940e-42  4.935e-42\n",
      " -4.930e-42  4.931e-42  4.923e-42 -4.909e-42  4.927e-42  4.906e-42\n",
      "  4.920e-42  4.952e-42  4.905e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  0   1   2   4   5   6   8  10  11  13  14  15  16  17  18  19  20  22\n",
      "  23  25  26  28  30  33  34  35  36  37  38  40  42  45  46  47  48  49\n",
      "  51  52  53  54  55  56  58  59  60  61  62  64  65  66  67  69  70  72\n",
      "  74  76  77  78  79  81  82  84  85  86  87  88  89  91  92  93  95  98\n",
      " 100 101 102 104 105 106 107 108 109 110 111 112 114 115 116 118 119 120\n",
      " 121 122 123 126 127]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_21_param0 shape: (95,)\n",
      "New BatchNormalization_21_param1 shape: (95,)\n",
      "New BatchNormalization_21_param2 shape: (95,)\n",
      "New BatchNormalization_21_param3 shape: (95,)\n",
      "\n",
      "############ Update output shape of Relu_14 node ############\n",
      "New shape: (1, 95, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_58 node ############\n",
      "New shape: (1, 95, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_22\n",
      "---> DW Conv found. Group = 128. Skip\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_22 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_22 node ############\n",
      "Quant 0 shape: (128, 1, 3, 3)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (33 elements):\n",
      "[  3   7   9  12  21  24  27  29  31  32  39  41  43  44  50  57  63  68\n",
      "  71  73  75  80  83  90  94  96  97  99 103 113 117 124 125]\n",
      "### Non Zero IDX, channels to keep (95 elements):\n",
      "[  0   1   2   4   5   6   8  10  11  13  14  15  16  17  18  19  20  22\n",
      "  23  25  26  28  30  33  34  35  36  37  38  40  42  45  46  47  48  49\n",
      "  51  52  53  54  55  56  58  59  60  61  62  64  65  66  67  69  70  72\n",
      "  74  76  77  78  79  81  82  84  85  86  87  88  89  91  92  93  95  98\n",
      " 100 101 102 104 105 106 107 108 109 110 111 112 114 115 116 118 119 120\n",
      " 121 122 123 126 127]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: False\n",
      "New Quant 0 shape: (95, 1, 3, 3)\n",
      "New Quant 1 shape: (95, 1, 1, 1)\n",
      "Quant_22 output original shape: (128, 1, 3, 3)\n",
      "Quant_22 output new shape: (95, 1, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_22 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 95, 14, 14)\n",
      "---> DW Conv found. Group 128, changed to 95\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_22 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.924e-42  4.907e-42 -4.913e-42  4.919e-42  4.921e-42 -4.949e-42\n",
      "  4.905e-42  4.930e-42  4.931e-42  4.905e-42  4.937e-42  4.930e-42\n",
      "  4.912e-42  4.909e-42  4.937e-42 -4.947e-42 -4.914e-42 -4.916e-42\n",
      "  4.948e-42 -6.300e-42  4.907e-42  4.921e-42  4.919e-42  4.909e-42\n",
      "  4.942e-42  4.937e-42  4.940e-42 -4.940e-42  4.913e-42  4.931e-42\n",
      "  4.923e-42  4.923e-42 -4.937e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  0   1   2   4   5   6   8  10  11  13  14  15  16  17  18  19  20  22\n",
      "  23  25  26  28  30  33  34  35  36  37  38  40  42  45  46  47  48  49\n",
      "  51  52  53  54  55  56  58  59  60  61  62  64  65  66  67  69  70  72\n",
      "  74  76  77  78  79  81  82  84  85  86  87  88  89  91  92  93  95  98\n",
      " 100 101 102 104 105 106 107 108 109 110 111 112 114 115 116 118 119 120\n",
      " 121 122 123 126 127]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_22_param0 shape: (95,)\n",
      "New BatchNormalization_22_param1 shape: (95,)\n",
      "New BatchNormalization_22_param2 shape: (95,)\n",
      "New BatchNormalization_22_param3 shape: (95,)\n",
      "\n",
      "############ Update output shape of Relu_15 node ############\n",
      "New shape: (1, 95, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_59 node ############\n",
      "New shape: (1, 95, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_23\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_23 node ............\n",
      "Quant_23_param0 shape: (32, 128, 1, 1)\n",
      "New Quant_23_param0 shape: (32, 95, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  0   1   2   4   5   6   8  10  11  13  14  15  16  17  18  19  20  22\n",
      "  23  25  26  28  30  33  34  35  36  37  38  40  42  45  46  47  48  49\n",
      "  51  52  53  54  55  56  58  59  60  61  62  64  65  66  67  69  70  72\n",
      "  74  76  77  78  79  81  82  84  85  86  87  88  89  91  92  93  95  98\n",
      " 100 101 102 104 105 106 107 108 109 110 111 112 114 115 116 118 119 120\n",
      " 121 122 123 126 127]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_23 node: (32, 95, 1, 1)\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_24 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_24 node ############\n",
      "Quant 0 shape: (64, 32, 1, 1)\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (1 elements):\n",
      "[30]\n",
      "### Non Zero IDX, channels to keep (63 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: False\n",
      "New Quant 0 shape: (63, 32, 1, 1)\n",
      "New Quant 1 shape: (63, 1, 1, 1)\n",
      "Quant_24 output original shape: (64, 32, 1, 1)\n",
      "Quant_24 output new shape: (63, 32, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_24 node ############\n",
      "Old Conv output shape: (1, 64, 14, 14)\n",
      "New Conv output shape: (1, 63, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_24 node ############\n",
      "BN0 shape: (64,)\n",
      "BN1 shape: (64,)\n",
      "BN2 shape: (64,)\n",
      "BN3 shape: (64,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[4.912e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_24_param0 shape: (63,)\n",
      "New BatchNormalization_24_param1 shape: (63,)\n",
      "New BatchNormalization_24_param2 shape: (63,)\n",
      "New BatchNormalization_24_param3 shape: (63,)\n",
      "\n",
      "############ Update output shape of Relu_16 node ############\n",
      "New shape: (1, 63, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_62 node ############\n",
      "New shape: (1, 63, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_25\n",
      "---> DW Conv found. Group = 64. Skip\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_25 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_25 node ############\n",
      "Quant 0 shape: (64, 1, 3, 3)\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (1 elements):\n",
      "[30]\n",
      "### Non Zero IDX, channels to keep (63 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: False\n",
      "New Quant 0 shape: (63, 1, 3, 3)\n",
      "New Quant 1 shape: (63, 1, 1, 1)\n",
      "Quant_25 output original shape: (64, 1, 3, 3)\n",
      "Quant_25 output new shape: (63, 1, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_25 node ############\n",
      "Old Conv output shape: (1, 64, 14, 14)\n",
      "New Conv output shape: (1, 63, 14, 14)\n",
      "---> DW Conv found. Group 64, changed to 63\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_25 node ############\n",
      "BN0 shape: (64,)\n",
      "BN1 shape: (64,)\n",
      "BN2 shape: (64,)\n",
      "BN3 shape: (64,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[4.942e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_25_param0 shape: (63,)\n",
      "New BatchNormalization_25_param1 shape: (63,)\n",
      "New BatchNormalization_25_param2 shape: (63,)\n",
      "New BatchNormalization_25_param3 shape: (63,)\n",
      "\n",
      "############ Update output shape of Relu_17 node ############\n",
      "New shape: (1, 63, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_63 node ############\n",
      "New shape: (1, 63, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_26\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_26 node ............\n",
      "Quant_26_param0 shape: (64, 64, 1, 1)\n",
      "New Quant_26_param0 shape: (64, 63, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_26 node: (64, 63, 1, 1)\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_26 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_26 node ############\n",
      "Quant 0 shape: (64, 63, 1, 1)\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (4 elements):\n",
      "[ 7 10 14 51]\n",
      "### Non Zero IDX, channels to keep (60 elements):\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: False\n",
      "New Quant 0 shape: (60, 63, 1, 1)\n",
      "New Quant 1 shape: (60, 1, 1, 1)\n",
      "Quant_26 output original shape: (64, 63, 1, 1)\n",
      "Quant_26 output new shape: (60, 63, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_26 node ############\n",
      "Old Conv output shape: (1, 64, 14, 14)\n",
      "New Conv output shape: (1, 60, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_26 node ############\n",
      "BN0 shape: (64,)\n",
      "BN1 shape: (64,)\n",
      "BN2 shape: (64,)\n",
      "BN3 shape: (64,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.923e-42  4.942e-42 -4.940e-42 -4.951e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_26_param0 shape: (60,)\n",
      "New BatchNormalization_26_param1 shape: (60,)\n",
      "New BatchNormalization_26_param2 shape: (60,)\n",
      "New BatchNormalization_26_param3 shape: (60,)\n",
      "\n",
      "############ Update output shape of Quant_64 node ############\n",
      "New shape: (1, 60, 14, 14)\n",
      "This successor node is a fork: Quant_64\n",
      "\n",
      "\t%%%%%%%%%%%%% This is the right branch of the fork\n",
      "\n",
      "############ Update output shape of Add_4 node ############\n",
      "New shape: (1, 60, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_68 node ############\n",
      "New shape: (1, 60, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_30\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_30 node ............\n",
      "Quant_30_param0 shape: (128, 64, 1, 1)\n",
      "New Quant_30_param0 shape: (128, 60, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_30 node: (128, 60, 1, 1)\n",
      "\n",
      "\t%%%%%%%%%%%%% This is the left branch of the fork\n",
      "\n",
      "Next successor node is a convolution: Conv_27\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_27 node ............\n",
      "Quant_27_param0 shape: (128, 64, 1, 1)\n",
      "New Quant_27_param0 shape: (128, 60, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_27 node: (128, 60, 1, 1)\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_27 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_27 node ############\n",
      "Quant 0 shape: (128, 60, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (67 elements):\n",
      "[  0   1   5   7  10  11  12  13  14  15  16  18  20  21  22  23  24  25\n",
      "  26  27  28  30  34  35  37  38  45  47  49  51  54  56  57  58  59  66\n",
      "  67  68  70  71  72  73  74  75  76  78  79  82  85  89  92  93  97  98\n",
      " 100 103 104 109 110 111 112 115 117 118 121 126 127]\n",
      "### Non Zero IDX, channels to keep (61 elements):\n",
      "[  2   3   4   6   8   9  17  19  29  31  32  33  36  39  40  41  42  43\n",
      "  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77  80  81  83\n",
      "  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107 108 113 114\n",
      " 116 119 120 122 123 124 125]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: False\n",
      "New Quant 0 shape: (61, 60, 1, 1)\n",
      "New Quant 1 shape: (61, 1, 1, 1)\n",
      "Quant_27 output original shape: (128, 60, 1, 1)\n",
      "Quant_27 output new shape: (61, 60, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_27 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 61, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_27 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 5.420e-42  4.952e-42  4.937e-42  4.944e-42  4.938e-42 -4.923e-42\n",
      " -4.948e-42  4.905e-42  4.909e-42  4.948e-42  4.917e-42  4.914e-42\n",
      "  4.954e-42  4.954e-42  4.928e-42  4.910e-42  4.913e-42  4.937e-42\n",
      " -4.906e-42  4.949e-42  4.954e-42  4.933e-42  4.933e-42  4.940e-42\n",
      " -4.945e-42  4.905e-42  4.910e-42  4.924e-42  4.951e-42  4.938e-42\n",
      "  4.944e-42  4.909e-42  4.912e-42  4.917e-42  4.933e-42  4.947e-42\n",
      " -4.910e-42  4.949e-42  4.920e-42  4.952e-42  4.916e-42 -4.935e-42\n",
      "  4.926e-42  4.931e-42  4.937e-42  4.949e-42  4.938e-42 -4.942e-42\n",
      "  4.928e-42  4.941e-42  4.945e-42  4.928e-42  4.949e-42  4.923e-42\n",
      " -4.930e-42  4.921e-42  5.639e-42  4.948e-42  4.954e-42 -4.913e-42\n",
      "  4.941e-42 -4.909e-42  4.917e-42  4.913e-42  4.951e-42  4.947e-42\n",
      "  4.945e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  2   3   4   6   8   9  17  19  29  31  32  33  36  39  40  41  42  43\n",
      "  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77  80  81  83\n",
      "  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107 108 113 114\n",
      " 116 119 120 122 123 124 125]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_27_param0 shape: (61,)\n",
      "New BatchNormalization_27_param1 shape: (61,)\n",
      "New BatchNormalization_27_param2 shape: (61,)\n",
      "New BatchNormalization_27_param3 shape: (61,)\n",
      "\n",
      "############ Update output shape of Relu_18 node ############\n",
      "New shape: (1, 61, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_65 node ############\n",
      "New shape: (1, 61, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_28\n",
      "---> DW Conv found. Group = 128. Skip\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_28 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_28 node ############\n",
      "Quant 0 shape: (128, 1, 3, 3)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (67 elements):\n",
      "[  0   1   5   7  10  11  12  13  14  15  16  18  20  21  22  23  24  25\n",
      "  26  27  28  30  34  35  37  38  45  47  49  51  54  56  57  58  59  66\n",
      "  67  68  70  71  72  73  74  75  76  78  79  82  85  89  92  93  97  98\n",
      " 100 103 104 109 110 111 112 115 117 118 121 126 127]\n",
      "### Non Zero IDX, channels to keep (61 elements):\n",
      "[  2   3   4   6   8   9  17  19  29  31  32  33  36  39  40  41  42  43\n",
      "  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77  80  81  83\n",
      "  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107 108 113 114\n",
      " 116 119 120 122 123 124 125]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: False\n",
      "New Quant 0 shape: (61, 1, 3, 3)\n",
      "New Quant 1 shape: (61, 1, 1, 1)\n",
      "Quant_28 output original shape: (128, 1, 3, 3)\n",
      "Quant_28 output new shape: (61, 1, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_28 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 61, 14, 14)\n",
      "---> DW Conv found. Group 128, changed to 61\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_28 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.934e-42  4.926e-42 -4.944e-42  4.949e-42  4.934e-42  4.947e-42\n",
      "  4.937e-42  4.951e-42 -4.948e-42  4.916e-42  4.948e-42  4.923e-42\n",
      "  4.927e-42  4.954e-42  4.912e-42 -4.910e-42  4.954e-42  4.910e-42\n",
      "  4.914e-42  4.940e-42  4.912e-42 -4.934e-42 -4.912e-42  4.933e-42\n",
      "  4.912e-42 -4.941e-42  4.941e-42  4.949e-42 -4.916e-42  4.937e-42\n",
      "  4.942e-42  4.947e-42  4.921e-42  4.921e-42  4.927e-42  4.940e-42\n",
      " -4.919e-42  4.954e-42 -4.944e-42  4.934e-42 -4.910e-42 -4.941e-42\n",
      " -4.940e-42  4.951e-42  4.941e-42  4.924e-42  4.947e-42 -4.945e-42\n",
      "  4.952e-42  4.951e-42  4.948e-42  4.928e-42  4.917e-42  4.942e-42\n",
      " -4.947e-42  4.938e-42  4.920e-42  4.930e-42  4.944e-42 -4.916e-42\n",
      " -4.926e-42  4.930e-42  4.947e-42  4.912e-42  4.928e-42  4.928e-42\n",
      " -4.917e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  2   3   4   6   8   9  17  19  29  31  32  33  36  39  40  41  42  43\n",
      "  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77  80  81  83\n",
      "  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107 108 113 114\n",
      " 116 119 120 122 123 124 125]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_28_param0 shape: (61,)\n",
      "New BatchNormalization_28_param1 shape: (61,)\n",
      "New BatchNormalization_28_param2 shape: (61,)\n",
      "New BatchNormalization_28_param3 shape: (61,)\n",
      "\n",
      "############ Update output shape of Relu_19 node ############\n",
      "New shape: (1, 61, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_66 node ############\n",
      "New shape: (1, 61, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_29\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_29 node ............\n",
      "Quant_29_param0 shape: (64, 128, 1, 1)\n",
      "New Quant_29_param0 shape: (64, 61, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  2   3   4   6   8   9  17  19  29  31  32  33  36  39  40  41  42  43\n",
      "  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77  80  81  83\n",
      "  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107 108 113 114\n",
      " 116 119 120 122 123 124 125]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_29 node: (64, 61, 1, 1)\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_29 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_29 node ############\n",
      "Quant 0 shape: (64, 61, 1, 1)\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (4 elements):\n",
      "[ 7 10 14 51]\n",
      "### Non Zero IDX, channels to keep (60 elements):\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: False\n",
      "New Quant 0 shape: (60, 61, 1, 1)\n",
      "New Quant 1 shape: (60, 1, 1, 1)\n",
      "Quant_29 output original shape: (64, 61, 1, 1)\n",
      "Quant_29 output new shape: (60, 61, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_29 node ############\n",
      "Old Conv output shape: (1, 64, 14, 14)\n",
      "New Conv output shape: (1, 60, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_29 node ############\n",
      "BN0 shape: (64,)\n",
      "BN1 shape: (64,)\n",
      "BN2 shape: (64,)\n",
      "BN3 shape: (64,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.906e-42  4.944e-42  4.913e-42 -4.935e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_29_param0 shape: (60,)\n",
      "New BatchNormalization_29_param1 shape: (60,)\n",
      "New BatchNormalization_29_param2 shape: (60,)\n",
      "New BatchNormalization_29_param3 shape: (60,)\n",
      "\n",
      "############ Update output shape of Quant_67 node ############\n",
      "New shape: (1, 60, 14, 14)\n",
      "\n",
      "Next successor node is add: Add_4. Skip\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_30 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_30 node ############\n",
      "Quant 0 shape: (128, 60, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (26 elements):\n",
      "[  4   8  13  14  24  36  41  48  52  59  61  62  71  75  77  78  82  86\n",
      "  91  96 101 105 110 118 120 126]\n",
      "### Non Zero IDX, channels to keep (102 elements):\n",
      "[  0   1   2   3   5   6   7   9  10  11  12  15  16  17  18  19  20  21\n",
      "  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39  40  42\n",
      "  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63  64  65\n",
      "  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87  88  89\n",
      "  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109 111 112\n",
      " 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: False\n",
      "New Quant 0 shape: (102, 60, 1, 1)\n",
      "New Quant 1 shape: (102, 1, 1, 1)\n",
      "Quant_30 output original shape: (128, 60, 1, 1)\n",
      "Quant_30 output new shape: (102, 60, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_30 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 102, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_30 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.945e-42 -4.913e-42 -4.945e-42 -4.912e-42  4.910e-42  4.921e-42\n",
      " -4.926e-42 -4.907e-42 -4.944e-42 -4.919e-42 -4.912e-42  4.935e-42\n",
      " -4.920e-42 -4.945e-42  4.919e-42 -6.283e-42 -4.934e-42 -4.937e-42\n",
      "  4.919e-42 -4.933e-42  4.910e-42 -4.937e-42 -4.919e-42  4.934e-42\n",
      "  4.941e-42  4.923e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  0   1   2   3   5   6   7   9  10  11  12  15  16  17  18  19  20  21\n",
      "  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39  40  42\n",
      "  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63  64  65\n",
      "  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87  88  89\n",
      "  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109 111 112\n",
      " 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_30_param0 shape: (102,)\n",
      "New BatchNormalization_30_param1 shape: (102,)\n",
      "New BatchNormalization_30_param2 shape: (102,)\n",
      "New BatchNormalization_30_param3 shape: (102,)\n",
      "\n",
      "############ Update output shape of Relu_20 node ############\n",
      "New shape: (1, 102, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_69 node ############\n",
      "New shape: (1, 102, 14, 14)\n",
      "\n",
      "Next successor node is average pooling: AveragePool_0\n",
      "\n",
      "############ Update output shape of AveragePool_0 node ############\n",
      "Old Avg Pool output shape: [1, 128, 1, 1]\n",
      "New shape: (1, 102, 1, 1)\n",
      "\n",
      "############ Update output shape of Mul_1 node ############\n",
      "New shape: (1, 102, 1, 1)\n",
      "\n",
      "############ Update output shape of Trunc_0 node ############\n",
      "New shape: (1, 102, 1, 1)\n",
      "\n",
      "############ Update output shape of Reshape_0 node ############\n",
      "New shape: (1, 102)\n",
      "\n",
      "############ Gemm node found: Gemm_0 node ############\n",
      "\n",
      "............ Pruning Weights of Gemm_0 node ............\n",
      "Quant_31_param0 shape: (2, 128)\n",
      "New Quant_31_param0 shape: (2, 102)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  0   1   2   3   5   6   7   9  10  11  12  15  16  17  18  19  20  21\n",
      "  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39  40  42\n",
      "  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63  64  65\n",
      "  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87  88  89\n",
      "  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109 111 112\n",
      " 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_31 node: (2, 102)\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "\n",
    "for conv in convs_to_prune:\n",
    "    print(f'\\n______________________________________________________________________________________________________')\n",
    "    print(f'                                                {conv} ')\n",
    "    print(f'______________________________________________________________________________________________________')\n",
    "\n",
    "    if set_mul4:\n",
    "        _, _, _, _ = test_prune_any_conv(model, conv)\n",
    "    else:\n",
    "        _, _, _, _ = test_prune_any_conv(model, conv, do_mul_val=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "50bbd986-b002-4c16-83d2-7c61f42113c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(InferShapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ebb9c89-3213-4b08-bbde-94dbe36f7c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_mul4:\n",
    "    prune_all_convs_onnx = prune_folder + \"20_prune_all_convs_mul8.onnx\"\n",
    "else:\n",
    "    prune_all_convs_onnx = prune_folder + \"30_prune_all_convs_no_mul8.onnx\"\n",
    "model.save(prune_all_convs_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6cfbf4d9-0fc0-4f54-978b-c7008eecbb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/pruning/sparse24_mul8/30_prune_all_convs_no_mul8.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5db6d9b280>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(prune_all_convs_onnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc7c0c-80ef-46be-8b06-50a3b796190a",
   "metadata": {},
   "source": [
    "### Compare Sparsity NO MUL 4 or 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d721bddd-6774-49ce-9b56-78b488c79442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quant_12_param0: \tbefore: 0.11 - after: 0.09\n",
      "Quant_13_param0: \tbefore: 0.09 - after: 0.07\n",
      "Quant_15_param0: \tbefore: 0.14 - after: 0.1 \n",
      "Quant_16_param0: \tbefore: 0.1  - after: 0.06\n",
      "Quant_18_param0: \tbefore: 0.22 - after: 0.11\n",
      "Quant_19_param0: \tbefore: 0.18 - after: 0.07\n",
      "Quant_21_param0: \tbefore: 0.33 - after: 0.1 \n",
      "Quant_22_param0: \tbefore: 0.31 - after: 0.06\n",
      "Quant_24_param0: \tbefore: 0.11 - after: 0.1 \n",
      "Quant_25_param0: \tbefore: 0.1  - after: 0.08\n",
      "Quant_26_param0: \tbefore: 0.18 - after: 0.11\n",
      "Quant_27_param0: \tbefore: 0.61 - after: 0.13\n",
      "Quant_28_param0: \tbefore: 0.56 - after: 0.07\n",
      "Quant_29_param0: \tbefore: 0.61 - after: 0.13\n",
      "Quant_30_param0: \tbefore: 0.37 - after: 0.16\n"
     ]
    }
   ],
   "source": [
    "sparsity_after_pruning = get_sparsity(model, layers_to_prune)\n",
    "\n",
    "for k1, k2 in zip(sparsity_before_pruning.keys(), sparsity_after_pruning.keys()):\n",
    "    before = sparsity_before_pruning[k1][\"sparsity\"]\n",
    "    after = sparsity_after_pruning[k2][\"sparsity\"]\n",
    "    assert k1 == k2, f'{k1} is not the same as {k2}'\n",
    "    print(f'{k1}: \\tbefore: {before:<4} - after: {after:<4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9c782f-80cd-4188-85e0-ea6a413f284c",
   "metadata": {},
   "source": [
    "# Test Pruning the Whole Model - YES MUL 4 or 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c8f1b976-c437-4ff7-8686-4bddeac2172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_mul4 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "107db4b4-4b3a-4c10-a685-0185c8ed13ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_12 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_12 node ############\n",
      "Quant 0 shape: (48, 24, 1, 1)\n",
      "Quant 1 shape: (48, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (1 elements):\n",
      "[28]\n",
      "### Non Zero IDX, channels to keep (47 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.02151186]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "1 zero elements must be kept\n",
      "[28]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (48, 24, 1, 1)\n",
      "New Quant 1 shape: (48, 1, 1, 1)\n",
      "Quant_12 output original shape: (48, 24, 1, 1)\n",
      "Quant_12 output new shape: (48, 24, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_12 node ############\n",
      "Old Conv output shape: (1, 48, 28, 28)\n",
      "New Conv output shape: (1, 48, 28, 28)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_12 node ############\n",
      "BN0 shape: (48,)\n",
      "BN1 shape: (48,)\n",
      "BN2 shape: (48,)\n",
      "BN3 shape: (48,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.909e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "Real Zero IDX kept:\n",
      "[28]\n",
      "-------------------------------------\n",
      "New BatchNormalization_12_param0 shape: (48,)\n",
      "New BatchNormalization_12_param1 shape: (48,)\n",
      "New BatchNormalization_12_param2 shape: (48,)\n",
      "New BatchNormalization_12_param3 shape: (48,)\n",
      "\n",
      "############ Update output shape of Relu_8 node ############\n",
      "New shape: (1, 48, 28, 28)\n",
      "\n",
      "############ Update output shape of Quant_47 node ############\n",
      "New shape: (1, 48, 28, 28)\n",
      "\n",
      "Next successor node is a convolution: Conv_13\n",
      "---> DW Conv found. Group = 48. Skip\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_13 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_13 node ############\n",
      "Quant 0 shape: (48, 1, 3, 3)\n",
      "Quant 1 shape: (48, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (1 elements):\n",
      "[28]\n",
      "### Non Zero IDX, channels to keep (47 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.02368543]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "1 zero elements must be kept\n",
      "[28]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (48, 1, 3, 3)\n",
      "New Quant 1 shape: (48, 1, 1, 1)\n",
      "Quant_13 output original shape: (48, 1, 3, 3)\n",
      "Quant_13 output new shape: (48, 1, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_13 node ############\n",
      "Old Conv output shape: (1, 48, 28, 28)\n",
      "New Conv output shape: (1, 48, 28, 28)\n",
      "---> DW Conv found. Group 48, changed to 48\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_13 node ############\n",
      "BN0 shape: (48,)\n",
      "BN1 shape: (48,)\n",
      "BN2 shape: (48,)\n",
      "BN3 shape: (48,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[4.926e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "Real Zero IDX kept:\n",
      "[28]\n",
      "-------------------------------------\n",
      "New BatchNormalization_13_param0 shape: (48,)\n",
      "New BatchNormalization_13_param1 shape: (48,)\n",
      "New BatchNormalization_13_param2 shape: (48,)\n",
      "New BatchNormalization_13_param3 shape: (48,)\n",
      "\n",
      "############ Update output shape of Relu_9 node ############\n",
      "New shape: (1, 48, 28, 28)\n",
      "\n",
      "############ Update output shape of Quant_48 node ############\n",
      "New shape: (1, 48, 28, 28)\n",
      "\n",
      "Next successor node is a convolution: Conv_14\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_14 node ............\n",
      "Quant_14_param0 shape: (24, 48, 1, 1)\n",
      "New Quant_14_param0 shape: (24, 48, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_14 node: (24, 48, 1, 1)\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_15 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_15 node ############\n",
      "Quant 0 shape: (96, 24, 1, 1)\n",
      "Quant 1 shape: (96, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (4 elements):\n",
      "[ 0 45 54 83]\n",
      "### Non Zero IDX, channels to keep (92 elements):\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 46 47 48 49\n",
      " 50 51 52 53 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.02079848]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "4 zero elements must be kept\n",
      "[ 0 45 54 83]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (96, 24, 1, 1)\n",
      "New Quant 1 shape: (96, 1, 1, 1)\n",
      "Quant_15 output original shape: (96, 24, 1, 1)\n",
      "Quant_15 output new shape: (96, 24, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_15 node ############\n",
      "Old Conv output shape: (1, 96, 28, 28)\n",
      "New Conv output shape: (1, 96, 28, 28)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_15 node ############\n",
      "BN0 shape: (96,)\n",
      "BN1 shape: (96,)\n",
      "BN2 shape: (96,)\n",
      "BN3 shape: (96,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.931e-42  4.940e-42  4.940e-42 -4.914e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 46 47 48 49\n",
      " 50 51 52 53 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "Real Zero IDX kept:\n",
      "[ 0 45 54 83]\n",
      "-------------------------------------\n",
      "New BatchNormalization_15_param0 shape: (96,)\n",
      "New BatchNormalization_15_param1 shape: (96,)\n",
      "New BatchNormalization_15_param2 shape: (96,)\n",
      "New BatchNormalization_15_param3 shape: (96,)\n",
      "\n",
      "############ Update output shape of Relu_10 node ############\n",
      "New shape: (1, 96, 28, 28)\n",
      "\n",
      "############ Update output shape of Quant_51 node ############\n",
      "New shape: (1, 96, 28, 28)\n",
      "\n",
      "Next successor node is a convolution: Conv_16\n",
      "---> DW Conv found. Group = 96. Skip\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_16 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_16 node ############\n",
      "Quant 0 shape: (96, 1, 3, 3)\n",
      "Quant 1 shape: (96, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (4 elements):\n",
      "[ 0 45 54 83]\n",
      "### Non Zero IDX, channels to keep (92 elements):\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 46 47 48 49\n",
      " 50 51 52 53 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.02857334]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "4 zero elements must be kept\n",
      "[ 0 45 54 83]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (96, 1, 3, 3)\n",
      "New Quant 1 shape: (96, 1, 1, 1)\n",
      "Quant_16 output original shape: (96, 1, 3, 3)\n",
      "Quant_16 output new shape: (96, 1, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_16 node ############\n",
      "Old Conv output shape: (1, 96, 14, 14)\n",
      "New Conv output shape: (1, 96, 14, 14)\n",
      "---> DW Conv found. Group 96, changed to 96\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_16 node ############\n",
      "BN0 shape: (96,)\n",
      "BN1 shape: (96,)\n",
      "BN2 shape: (96,)\n",
      "BN3 shape: (96,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.919e-42  4.913e-42 -4.948e-42  4.914e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 46 47 48 49\n",
      " 50 51 52 53 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "Real Zero IDX kept:\n",
      "[ 0 45 54 83]\n",
      "-------------------------------------\n",
      "New BatchNormalization_16_param0 shape: (96,)\n",
      "New BatchNormalization_16_param1 shape: (96,)\n",
      "New BatchNormalization_16_param2 shape: (96,)\n",
      "New BatchNormalization_16_param3 shape: (96,)\n",
      "\n",
      "############ Update output shape of Relu_11 node ############\n",
      "New shape: (1, 96, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_52 node ############\n",
      "New shape: (1, 96, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_17\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_17 node ............\n",
      "Quant_17_param0 shape: (32, 96, 1, 1)\n",
      "New Quant_17_param0 shape: (32, 96, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_17 node: (32, 96, 1, 1)\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_18 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_18 node ############\n",
      "Quant 0 shape: (128, 32, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (16 elements):\n",
      "[  2   7  12  13  20  33  40  41  51  59  64  89  94  99 102 112]\n",
      "### Non Zero IDX, channels to keep (112 elements):\n",
      "[  0   1   3   4   5   6   8   9  10  11  14  15  16  17  18  19  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  34  35  36  37  38  39  42  43\n",
      "  44  45  46  47  48  49  50  52  53  54  55  56  57  58  60  61  62  63\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  87  88  90  91  92  93  95  96  97  98 100 101 103 104\n",
      " 105 106 107 108 109 110 111 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Elements to keep is multiple of 8\n",
      "New Quant 0 shape: (112, 32, 1, 1)\n",
      "New Quant 1 shape: (112, 1, 1, 1)\n",
      "Quant_18 output original shape: (128, 32, 1, 1)\n",
      "Quant_18 output new shape: (112, 32, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_18 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 112, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_18 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.938e-42 -4.910e-42  4.921e-42  4.944e-42 -4.924e-42  4.933e-42\n",
      "  4.909e-42  4.941e-42  4.941e-42 -4.928e-42 -4.934e-42  4.931e-42\n",
      " -5.925e-42  4.909e-42  4.952e-42 -4.949e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  0   1   3   4   5   6   8   9  10  11  14  15  16  17  18  19  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  34  35  36  37  38  39  42  43\n",
      "  44  45  46  47  48  49  50  52  53  54  55  56  57  58  60  61  62  63\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  87  88  90  91  92  93  95  96  97  98 100 101 103 104\n",
      " 105 106 107 108 109 110 111 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_18_param0 shape: (112,)\n",
      "New BatchNormalization_18_param1 shape: (112,)\n",
      "New BatchNormalization_18_param2 shape: (112,)\n",
      "New BatchNormalization_18_param3 shape: (112,)\n",
      "\n",
      "############ Update output shape of Relu_12 node ############\n",
      "New shape: (1, 112, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_54 node ############\n",
      "New shape: (1, 112, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_19\n",
      "---> DW Conv found. Group = 128. Skip\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_19 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_19 node ############\n",
      "Quant 0 shape: (128, 1, 3, 3)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (16 elements):\n",
      "[  2   7  12  13  20  33  40  41  51  59  64  89  94  99 102 112]\n",
      "### Non Zero IDX, channels to keep (112 elements):\n",
      "[  0   1   3   4   5   6   8   9  10  11  14  15  16  17  18  19  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  34  35  36  37  38  39  42  43\n",
      "  44  45  46  47  48  49  50  52  53  54  55  56  57  58  60  61  62  63\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  87  88  90  91  92  93  95  96  97  98 100 101 103 104\n",
      " 105 106 107 108 109 110 111 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Elements to keep is multiple of 8\n",
      "New Quant 0 shape: (112, 1, 3, 3)\n",
      "New Quant 1 shape: (112, 1, 1, 1)\n",
      "Quant_19 output original shape: (128, 1, 3, 3)\n",
      "Quant_19 output new shape: (112, 1, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_19 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 112, 14, 14)\n",
      "---> DW Conv found. Group 128, changed to 112\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_19 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.924e-42 -4.940e-42 -4.917e-42  4.923e-42  4.910e-42  4.923e-42\n",
      "  4.935e-42 -4.913e-42  4.909e-42  4.913e-42 -4.928e-42  4.930e-42\n",
      "  4.919e-42  4.914e-42  4.913e-42  4.919e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  0   1   3   4   5   6   8   9  10  11  14  15  16  17  18  19  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  34  35  36  37  38  39  42  43\n",
      "  44  45  46  47  48  49  50  52  53  54  55  56  57  58  60  61  62  63\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  87  88  90  91  92  93  95  96  97  98 100 101 103 104\n",
      " 105 106 107 108 109 110 111 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127]\n",
      "Real Zero IDX kept:\n",
      "[]\n",
      "-------------------------------------\n",
      "New BatchNormalization_19_param0 shape: (112,)\n",
      "New BatchNormalization_19_param1 shape: (112,)\n",
      "New BatchNormalization_19_param2 shape: (112,)\n",
      "New BatchNormalization_19_param3 shape: (112,)\n",
      "\n",
      "############ Update output shape of Relu_13 node ############\n",
      "New shape: (1, 112, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_55 node ############\n",
      "New shape: (1, 112, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_20\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_20 node ............\n",
      "Quant_20_param0 shape: (32, 128, 1, 1)\n",
      "New Quant_20_param0 shape: (32, 112, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  0   1   3   4   5   6   8   9  10  11  14  15  16  17  18  19  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  34  35  36  37  38  39  42  43\n",
      "  44  45  46  47  48  49  50  52  53  54  55  56  57  58  60  61  62  63\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  87  88  90  91  92  93  95  96  97  98 100 101 103 104\n",
      " 105 106 107 108 109 110 111 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_20 node: (32, 112, 1, 1)\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_21 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_21 node ############\n",
      "Quant 0 shape: (128, 32, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (33 elements):\n",
      "[  3   7   9  12  21  24  27  29  31  32  39  41  43  44  50  57  63  68\n",
      "  71  73  75  80  83  90  94  96  97  99 103 113 117 124 125]\n",
      "### Non Zero IDX, channels to keep (95 elements):\n",
      "[  0   1   2   4   5   6   8  10  11  13  14  15  16  17  18  19  20  22\n",
      "  23  25  26  28  30  33  34  35  36  37  38  40  42  45  46  47  48  49\n",
      "  51  52  53  54  55  56  58  59  60  61  62  64  65  66  67  69  70  72\n",
      "  74  76  77  78  79  81  82  84  85  86  87  88  89  91  92  93  95  98\n",
      " 100 101 102 104 105 106 107 108 109 110 111 112 114 115 116 118 119 120\n",
      " 121 122 123 126 127]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.02265112]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "1 zero elements must be kept\n",
      "[3]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[  0   1   2   3   4   5   6   8  10  11  13  14  15  16  17  18  19  20\n",
      "  22  23  25  26  28  30  33  34  35  36  37  38  40  42  45  46  47  48\n",
      "  49  51  52  53  54  55  56  58  59  60  61  62  64  65  66  67  69  70\n",
      "  72  74  76  77  78  79  81  82  84  85  86  87  88  89  91  92  93  95\n",
      "  98 100 101 102 104 105 106 107 108 109 110 111 112 114 115 116 118 119\n",
      " 120 121 122 123 126 127]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (96, 32, 1, 1)\n",
      "New Quant 1 shape: (96, 1, 1, 1)\n",
      "Quant_21 output original shape: (128, 32, 1, 1)\n",
      "Quant_21 output new shape: (96, 32, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_21 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 96, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_21 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.954e-42  4.914e-42  4.935e-42  4.942e-42  4.949e-42 -4.914e-42\n",
      " -4.905e-42  4.917e-42  4.926e-42  4.924e-42 -4.933e-42  4.916e-42\n",
      "  4.910e-42  4.937e-42  4.909e-42 -4.938e-42 -4.949e-42 -4.949e-42\n",
      " -4.927e-42 -4.951e-42 -4.951e-42  4.933e-42  4.940e-42  4.935e-42\n",
      " -4.930e-42  4.931e-42  4.923e-42 -4.909e-42  4.927e-42  4.906e-42\n",
      "  4.920e-42  4.952e-42  4.905e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  0   1   2   4   5   6   8  10  11  13  14  15  16  17  18  19  20  22\n",
      "  23  25  26  28  30  33  34  35  36  37  38  40  42  45  46  47  48  49\n",
      "  51  52  53  54  55  56  58  59  60  61  62  64  65  66  67  69  70  72\n",
      "  74  76  77  78  79  81  82  84  85  86  87  88  89  91  92  93  95  98\n",
      " 100 101 102 104 105 106 107 108 109 110 111 112 114 115 116 118 119 120\n",
      " 121 122 123 126 127]\n",
      "Real Zero IDX kept:\n",
      "[3]\n",
      "-------------------------------------\n",
      "New BatchNormalization_21_param0 shape: (96,)\n",
      "New BatchNormalization_21_param1 shape: (96,)\n",
      "New BatchNormalization_21_param2 shape: (96,)\n",
      "New BatchNormalization_21_param3 shape: (96,)\n",
      "\n",
      "############ Update output shape of Relu_14 node ############\n",
      "New shape: (1, 96, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_58 node ############\n",
      "New shape: (1, 96, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_22\n",
      "---> DW Conv found. Group = 128. Skip\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_22 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_22 node ############\n",
      "Quant 0 shape: (128, 1, 3, 3)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (33 elements):\n",
      "[  3   7   9  12  21  24  27  29  31  32  39  41  43  44  50  57  63  68\n",
      "  71  73  75  80  83  90  94  96  97  99 103 113 117 124 125]\n",
      "### Non Zero IDX, channels to keep (95 elements):\n",
      "[  0   1   2   4   5   6   8  10  11  13  14  15  16  17  18  19  20  22\n",
      "  23  25  26  28  30  33  34  35  36  37  38  40  42  45  46  47  48  49\n",
      "  51  52  53  54  55  56  58  59  60  61  62  64  65  66  67  69  70  72\n",
      "  74  76  77  78  79  81  82  84  85  86  87  88  89  91  92  93  95  98\n",
      " 100 101 102 104 105 106 107 108 109 110 111 112 114 115 116 118 119 120\n",
      " 121 122 123 126 127]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.02092198]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "1 zero elements must be kept\n",
      "[3]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[  0   1   2   3   4   5   6   8  10  11  13  14  15  16  17  18  19  20\n",
      "  22  23  25  26  28  30  33  34  35  36  37  38  40  42  45  46  47  48\n",
      "  49  51  52  53  54  55  56  58  59  60  61  62  64  65  66  67  69  70\n",
      "  72  74  76  77  78  79  81  82  84  85  86  87  88  89  91  92  93  95\n",
      "  98 100 101 102 104 105 106 107 108 109 110 111 112 114 115 116 118 119\n",
      " 120 121 122 123 126 127]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (96, 1, 3, 3)\n",
      "New Quant 1 shape: (96, 1, 1, 1)\n",
      "Quant_22 output original shape: (128, 1, 3, 3)\n",
      "Quant_22 output new shape: (96, 1, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_22 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 96, 14, 14)\n",
      "---> DW Conv found. Group 128, changed to 96\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_22 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.924e-42  4.907e-42 -4.913e-42  4.919e-42  4.921e-42 -4.949e-42\n",
      "  4.905e-42  4.930e-42  4.931e-42  4.905e-42  4.937e-42  4.930e-42\n",
      "  4.912e-42  4.909e-42  4.937e-42 -4.947e-42 -4.914e-42 -4.916e-42\n",
      "  4.948e-42 -6.300e-42  4.907e-42  4.921e-42  4.919e-42  4.909e-42\n",
      "  4.942e-42  4.937e-42  4.940e-42 -4.940e-42  4.913e-42  4.931e-42\n",
      "  4.923e-42  4.923e-42 -4.937e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  0   1   2   4   5   6   8  10  11  13  14  15  16  17  18  19  20  22\n",
      "  23  25  26  28  30  33  34  35  36  37  38  40  42  45  46  47  48  49\n",
      "  51  52  53  54  55  56  58  59  60  61  62  64  65  66  67  69  70  72\n",
      "  74  76  77  78  79  81  82  84  85  86  87  88  89  91  92  93  95  98\n",
      " 100 101 102 104 105 106 107 108 109 110 111 112 114 115 116 118 119 120\n",
      " 121 122 123 126 127]\n",
      "Real Zero IDX kept:\n",
      "[3]\n",
      "-------------------------------------\n",
      "New BatchNormalization_22_param0 shape: (96,)\n",
      "New BatchNormalization_22_param1 shape: (96,)\n",
      "New BatchNormalization_22_param2 shape: (96,)\n",
      "New BatchNormalization_22_param3 shape: (96,)\n",
      "\n",
      "############ Update output shape of Relu_15 node ############\n",
      "New shape: (1, 96, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_59 node ############\n",
      "New shape: (1, 96, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_23\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_23 node ............\n",
      "Quant_23_param0 shape: (32, 128, 1, 1)\n",
      "New Quant_23_param0 shape: (32, 96, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  0   1   2   3   4   5   6   8  10  11  13  14  15  16  17  18  19  20\n",
      "  22  23  25  26  28  30  33  34  35  36  37  38  40  42  45  46  47  48\n",
      "  49  51  52  53  54  55  56  58  59  60  61  62  64  65  66  67  69  70\n",
      "  72  74  76  77  78  79  81  82  84  85  86  87  88  89  91  92  93  95\n",
      "  98 100 101 102 104 105 106 107 108 109 110 111 112 114 115 116 118 119\n",
      " 120 121 122 123 126 127]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_23 node: (32, 96, 1, 1)\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_24 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_24 node ############\n",
      "Quant 0 shape: (64, 32, 1, 1)\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (1 elements):\n",
      "[30]\n",
      "### Non Zero IDX, channels to keep (63 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.0395278]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "1 zero elements must be kept\n",
      "[30]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (64, 32, 1, 1)\n",
      "New Quant 1 shape: (64, 1, 1, 1)\n",
      "Quant_24 output original shape: (64, 32, 1, 1)\n",
      "Quant_24 output new shape: (64, 32, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_24 node ############\n",
      "Old Conv output shape: (1, 64, 14, 14)\n",
      "New Conv output shape: (1, 64, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_24 node ############\n",
      "BN0 shape: (64,)\n",
      "BN1 shape: (64,)\n",
      "BN2 shape: (64,)\n",
      "BN3 shape: (64,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[4.912e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "Real Zero IDX kept:\n",
      "[30]\n",
      "-------------------------------------\n",
      "New BatchNormalization_24_param0 shape: (64,)\n",
      "New BatchNormalization_24_param1 shape: (64,)\n",
      "New BatchNormalization_24_param2 shape: (64,)\n",
      "New BatchNormalization_24_param3 shape: (64,)\n",
      "\n",
      "############ Update output shape of Relu_16 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_62 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_25\n",
      "---> DW Conv found. Group = 64. Skip\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_25 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_25 node ############\n",
      "Quant 0 shape: (64, 1, 3, 3)\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (1 elements):\n",
      "[30]\n",
      "### Non Zero IDX, channels to keep (63 elements):\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.02813869]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "1 zero elements must be kept\n",
      "[30]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (64, 1, 3, 3)\n",
      "New Quant 1 shape: (64, 1, 1, 1)\n",
      "Quant_25 output original shape: (64, 1, 3, 3)\n",
      "Quant_25 output new shape: (64, 1, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_25 node ############\n",
      "Old Conv output shape: (1, 64, 14, 14)\n",
      "New Conv output shape: (1, 64, 14, 14)\n",
      "---> DW Conv found. Group 64, changed to 64\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_25 node ############\n",
      "BN0 shape: (64,)\n",
      "BN1 shape: (64,)\n",
      "BN2 shape: (64,)\n",
      "BN3 shape: (64,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[4.942e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "Real Zero IDX kept:\n",
      "[30]\n",
      "-------------------------------------\n",
      "New BatchNormalization_25_param0 shape: (64,)\n",
      "New BatchNormalization_25_param1 shape: (64,)\n",
      "New BatchNormalization_25_param2 shape: (64,)\n",
      "New BatchNormalization_25_param3 shape: (64,)\n",
      "\n",
      "############ Update output shape of Relu_17 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_63 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_26\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_26 node ............\n",
      "Quant_26_param0 shape: (64, 64, 1, 1)\n",
      "New Quant_26_param0 shape: (64, 64, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_26 node: (64, 64, 1, 1)\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_26 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_26 node ############\n",
      "Quant 0 shape: (64, 64, 1, 1)\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (4 elements):\n",
      "[ 7 10 14 51]\n",
      "### Non Zero IDX, channels to keep (60 elements):\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.01414997]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "4 zero elements must be kept\n",
      "[ 7 10 14 51]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (64, 64, 1, 1)\n",
      "New Quant 1 shape: (64, 1, 1, 1)\n",
      "Quant_26 output original shape: (64, 64, 1, 1)\n",
      "Quant_26 output new shape: (64, 64, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_26 node ############\n",
      "Old Conv output shape: (1, 64, 14, 14)\n",
      "New Conv output shape: (1, 64, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_26 node ############\n",
      "BN0 shape: (64,)\n",
      "BN1 shape: (64,)\n",
      "BN2 shape: (64,)\n",
      "BN3 shape: (64,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 4.923e-42  4.942e-42 -4.940e-42 -4.951e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "Real Zero IDX kept:\n",
      "[ 7 10 14 51]\n",
      "-------------------------------------\n",
      "New BatchNormalization_26_param0 shape: (64,)\n",
      "New BatchNormalization_26_param1 shape: (64,)\n",
      "New BatchNormalization_26_param2 shape: (64,)\n",
      "New BatchNormalization_26_param3 shape: (64,)\n",
      "\n",
      "############ Update output shape of Quant_64 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "This successor node is a fork: Quant_64\n",
      "\n",
      "\t%%%%%%%%%%%%% This is the right branch of the fork\n",
      "\n",
      "############ Update output shape of Add_4 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_68 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_30\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_30 node ............\n",
      "Quant_30_param0 shape: (128, 64, 1, 1)\n",
      "New Quant_30_param0 shape: (128, 64, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_30 node: (128, 64, 1, 1)\n",
      "\n",
      "\t%%%%%%%%%%%%% This is the left branch of the fork\n",
      "\n",
      "Next successor node is a convolution: Conv_27\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_27 node ............\n",
      "Quant_27_param0 shape: (128, 64, 1, 1)\n",
      "New Quant_27_param0 shape: (128, 64, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_27 node: (128, 64, 1, 1)\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_27 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_27 node ############\n",
      "Quant 0 shape: (128, 64, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (67 elements):\n",
      "[  0   1   5   7  10  11  12  13  14  15  16  18  20  21  22  23  24  25\n",
      "  26  27  28  30  34  35  37  38  45  47  49  51  54  56  57  58  59  66\n",
      "  67  68  70  71  72  73  74  75  76  78  79  82  85  89  92  93  97  98\n",
      " 100 103 104 109 110 111 112 115 117 118 121 126 127]\n",
      "### Non Zero IDX, channels to keep (61 elements):\n",
      "[  2   3   4   6   8   9  17  19  29  31  32  33  36  39  40  41  42  43\n",
      "  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77  80  81  83\n",
      "  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107 108 113 114\n",
      " 116 119 120 122 123 124 125]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.02123232]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "3 zero elements must be kept\n",
      "[0 1 5]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[  0   1   2   3   4   5   6   8   9  17  19  29  31  32  33  36  39  40\n",
      "  41  42  43  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77\n",
      "  80  81  83  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107\n",
      " 108 113 114 116 119 120 122 123 124 125]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (64, 64, 1, 1)\n",
      "New Quant 1 shape: (64, 1, 1, 1)\n",
      "Quant_27 output original shape: (128, 64, 1, 1)\n",
      "Quant_27 output new shape: (64, 64, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_27 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 64, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_27 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[ 5.420e-42  4.952e-42  4.937e-42  4.944e-42  4.938e-42 -4.923e-42\n",
      " -4.948e-42  4.905e-42  4.909e-42  4.948e-42  4.917e-42  4.914e-42\n",
      "  4.954e-42  4.954e-42  4.928e-42  4.910e-42  4.913e-42  4.937e-42\n",
      " -4.906e-42  4.949e-42  4.954e-42  4.933e-42  4.933e-42  4.940e-42\n",
      " -4.945e-42  4.905e-42  4.910e-42  4.924e-42  4.951e-42  4.938e-42\n",
      "  4.944e-42  4.909e-42  4.912e-42  4.917e-42  4.933e-42  4.947e-42\n",
      " -4.910e-42  4.949e-42  4.920e-42  4.952e-42  4.916e-42 -4.935e-42\n",
      "  4.926e-42  4.931e-42  4.937e-42  4.949e-42  4.938e-42 -4.942e-42\n",
      "  4.928e-42  4.941e-42  4.945e-42  4.928e-42  4.949e-42  4.923e-42\n",
      " -4.930e-42  4.921e-42  5.639e-42  4.948e-42  4.954e-42 -4.913e-42\n",
      "  4.941e-42 -4.909e-42  4.917e-42  4.913e-42  4.951e-42  4.947e-42\n",
      "  4.945e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  2   3   4   6   8   9  17  19  29  31  32  33  36  39  40  41  42  43\n",
      "  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77  80  81  83\n",
      "  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107 108 113 114\n",
      " 116 119 120 122 123 124 125]\n",
      "Real Zero IDX kept:\n",
      "[0 1 5]\n",
      "-------------------------------------\n",
      "New BatchNormalization_27_param0 shape: (64,)\n",
      "New BatchNormalization_27_param1 shape: (64,)\n",
      "New BatchNormalization_27_param2 shape: (64,)\n",
      "New BatchNormalization_27_param3 shape: (64,)\n",
      "\n",
      "############ Update output shape of Relu_18 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_65 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_28\n",
      "---> DW Conv found. Group = 128. Skip\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_28 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_28 node ############\n",
      "Quant 0 shape: (128, 1, 3, 3)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (67 elements):\n",
      "[  0   1   5   7  10  11  12  13  14  15  16  18  20  21  22  23  24  25\n",
      "  26  27  28  30  34  35  37  38  45  47  49  51  54  56  57  58  59  66\n",
      "  67  68  70  71  72  73  74  75  76  78  79  82  85  89  92  93  97  98\n",
      " 100 103 104 109 110 111 112 115 117 118 121 126 127]\n",
      "### Non Zero IDX, channels to keep (61 elements):\n",
      "[  2   3   4   6   8   9  17  19  29  31  32  33  36  39  40  41  42  43\n",
      "  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77  80  81  83\n",
      "  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107 108 113 114\n",
      " 116 119 120 122 123 124 125]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.02739516]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "3 zero elements must be kept\n",
      "[0 1 5]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[  0   1   2   3   4   5   6   8   9  17  19  29  31  32  33  36  39  40\n",
      "  41  42  43  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77\n",
      "  80  81  83  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107\n",
      " 108 113 114 116 119 120 122 123 124 125]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (64, 1, 3, 3)\n",
      "New Quant 1 shape: (64, 1, 1, 1)\n",
      "Quant_28 output original shape: (128, 1, 3, 3)\n",
      "Quant_28 output new shape: (64, 1, 3, 3)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_28 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 64, 14, 14)\n",
      "---> DW Conv found. Group 128, changed to 64\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_28 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.934e-42  4.926e-42 -4.944e-42  4.949e-42  4.934e-42  4.947e-42\n",
      "  4.937e-42  4.951e-42 -4.948e-42  4.916e-42  4.948e-42  4.923e-42\n",
      "  4.927e-42  4.954e-42  4.912e-42 -4.910e-42  4.954e-42  4.910e-42\n",
      "  4.914e-42  4.940e-42  4.912e-42 -4.934e-42 -4.912e-42  4.933e-42\n",
      "  4.912e-42 -4.941e-42  4.941e-42  4.949e-42 -4.916e-42  4.937e-42\n",
      "  4.942e-42  4.947e-42  4.921e-42  4.921e-42  4.927e-42  4.940e-42\n",
      " -4.919e-42  4.954e-42 -4.944e-42  4.934e-42 -4.910e-42 -4.941e-42\n",
      " -4.940e-42  4.951e-42  4.941e-42  4.924e-42  4.947e-42 -4.945e-42\n",
      "  4.952e-42  4.951e-42  4.948e-42  4.928e-42  4.917e-42  4.942e-42\n",
      " -4.947e-42  4.938e-42  4.920e-42  4.930e-42  4.944e-42 -4.916e-42\n",
      " -4.926e-42  4.930e-42  4.947e-42  4.912e-42  4.928e-42  4.928e-42\n",
      " -4.917e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  2   3   4   6   8   9  17  19  29  31  32  33  36  39  40  41  42  43\n",
      "  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77  80  81  83\n",
      "  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107 108 113 114\n",
      " 116 119 120 122 123 124 125]\n",
      "Real Zero IDX kept:\n",
      "[0 1 5]\n",
      "-------------------------------------\n",
      "New BatchNormalization_28_param0 shape: (64,)\n",
      "New BatchNormalization_28_param1 shape: (64,)\n",
      "New BatchNormalization_28_param2 shape: (64,)\n",
      "New BatchNormalization_28_param3 shape: (64,)\n",
      "\n",
      "############ Update output shape of Relu_19 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_66 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "Next successor node is a convolution: Conv_29\n",
      "DW Conv not found. Group = 1. Prune Conv Weights\n",
      "\n",
      "............ Pruning Weights of Conv_29 node ............\n",
      "Quant_29_param0 shape: (64, 128, 1, 1)\n",
      "New Quant_29_param0 shape: (64, 64, 1, 1)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  0   1   2   3   4   5   6   8   9  17  19  29  31  32  33  36  39  40\n",
      "  41  42  43  44  46  48  50  52  53  55  60  61  62  63  64  65  69  77\n",
      "  80  81  83  84  86  87  88  90  91  94  95  96  99 101 102 105 106 107\n",
      " 108 113 114 116 119 120 122 123 124 125]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_29 node: (64, 64, 1, 1)\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_29 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_29 node ############\n",
      "Quant 0 shape: (64, 64, 1, 1)\n",
      "Quant 1 shape: (64, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (4 elements):\n",
      "[ 7 10 14 51]\n",
      "### Non Zero IDX, channels to keep (60 elements):\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[5.016172e-05]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "4 zero elements must be kept\n",
      "[ 7 10 14 51]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (64, 64, 1, 1)\n",
      "New Quant 1 shape: (64, 1, 1, 1)\n",
      "Quant_29 output original shape: (64, 64, 1, 1)\n",
      "Quant_29 output new shape: (64, 64, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_29 node ############\n",
      "Old Conv output shape: (1, 64, 14, 14)\n",
      "New Conv output shape: (1, 64, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_29 node ############\n",
      "BN0 shape: (64,)\n",
      "BN1 shape: (64,)\n",
      "BN2 shape: (64,)\n",
      "BN3 shape: (64,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.906e-42  4.944e-42  4.913e-42 -4.935e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63]\n",
      "Real Zero IDX kept:\n",
      "[ 7 10 14 51]\n",
      "-------------------------------------\n",
      "New BatchNormalization_29_param0 shape: (64,)\n",
      "New BatchNormalization_29_param1 shape: (64,)\n",
      "New BatchNormalization_29_param2 shape: (64,)\n",
      "New BatchNormalization_29_param3 shape: (64,)\n",
      "\n",
      "############ Update output shape of Quant_67 node ############\n",
      "New shape: (1, 64, 14, 14)\n",
      "\n",
      "Next successor node is add: Add_4. Skip\n",
      "\n",
      "______________________________________________________________________________________________________\n",
      "                                                Conv_30 \n",
      "______________________________________________________________________________________________________\n",
      "\n",
      "############ Pruning Weights of Quant_30 node ############\n",
      "Quant 0 shape: (128, 64, 1, 1)\n",
      "Quant 1 shape: (128, 1, 1, 1)\n",
      "-------------------------------------\n",
      "*** Zero IDX, channels to be pruned (26 elements):\n",
      "[  4   8  13  14  24  36  41  48  52  59  61  62  71  75  77  78  82  86\n",
      "  91  96 101 105 110 118 120 126]\n",
      "### Non Zero IDX, channels to keep (102 elements):\n",
      "[  0   1   2   3   5   6   7   9  10  11  12  15  16  17  18  19  20  21\n",
      "  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39  40  42\n",
      "  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63  64  65\n",
      "  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87  88  89\n",
      "  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109 111 112\n",
      " 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "-------------------------------------\n",
      "\n",
      "------ Prune to muliple of 8: True\n",
      "Mean of channels to keep, to use it as default for zero elements: [[[0.00795446]]]\n",
      "Elements to keep is not multiple of 8 -> calculate new Non Zero IDX\n",
      "2 zero elements must be kept\n",
      "[4 8]\n",
      "### Multiple of 8 Non Zero IDX, channels to keep:\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  15  16  17  18  19\n",
      "  20  21  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39\n",
      "  40  42  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63\n",
      "  64  65  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87\n",
      "  88  89  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109\n",
      " 111 112 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "-------------------------------------\n",
      "New Quant 0 shape: (104, 64, 1, 1)\n",
      "New Quant 1 shape: (104, 1, 1, 1)\n",
      "Quant_30 output original shape: (128, 64, 1, 1)\n",
      "Quant_30 output new shape: (104, 64, 1, 1)\n",
      "\n",
      "############ Convert Convolution Output Shape Conv_30 node ############\n",
      "Old Conv output shape: (1, 128, 14, 14)\n",
      "New Conv output shape: (1, 104, 14, 14)\n",
      "DW Conv not found. Group = 1\n",
      "\n",
      "############ Prune Batch Norm BatchNormalization_30 node ############\n",
      "BN0 shape: (128,)\n",
      "BN1 shape: (128,)\n",
      "BN2 shape: (128,)\n",
      "BN3 shape: (128,)\n",
      "-------------------------------------\n",
      "*** Zero IDX, scale value of channels to be pruned:\n",
      "[-4.945e-42 -4.913e-42 -4.945e-42 -4.912e-42  4.910e-42  4.921e-42\n",
      " -4.926e-42 -4.907e-42 -4.944e-42 -4.919e-42 -4.912e-42  4.935e-42\n",
      " -4.920e-42 -4.945e-42  4.919e-42 -6.283e-42 -4.934e-42 -4.937e-42\n",
      "  4.919e-42 -4.933e-42  4.910e-42 -4.937e-42 -4.919e-42  4.934e-42\n",
      "  4.941e-42  4.923e-42]\n",
      "-------------------------------------\n",
      "Real Non Zero IDX, after removing Zero IDX to keep multiple of 4:\n",
      "[  0   1   2   3   5   6   7   9  10  11  12  15  16  17  18  19  20  21\n",
      "  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39  40  42\n",
      "  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63  64  65\n",
      "  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87  88  89\n",
      "  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109 111 112\n",
      " 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "Real Zero IDX kept:\n",
      "[4 8]\n",
      "-------------------------------------\n",
      "New BatchNormalization_30_param0 shape: (104,)\n",
      "New BatchNormalization_30_param1 shape: (104,)\n",
      "New BatchNormalization_30_param2 shape: (104,)\n",
      "New BatchNormalization_30_param3 shape: (104,)\n",
      "\n",
      "############ Update output shape of Relu_20 node ############\n",
      "New shape: (1, 104, 14, 14)\n",
      "\n",
      "############ Update output shape of Quant_69 node ############\n",
      "New shape: (1, 104, 14, 14)\n",
      "\n",
      "Next successor node is average pooling: AveragePool_0\n",
      "\n",
      "############ Update output shape of AveragePool_0 node ############\n",
      "Old Avg Pool output shape: [1, 128, 1, 1]\n",
      "New shape: (1, 104, 1, 1)\n",
      "\n",
      "############ Update output shape of Mul_1 node ############\n",
      "New shape: (1, 104, 1, 1)\n",
      "\n",
      "############ Update output shape of Trunc_0 node ############\n",
      "New shape: (1, 104, 1, 1)\n",
      "\n",
      "############ Update output shape of Reshape_0 node ############\n",
      "New shape: (1, 104)\n",
      "\n",
      "############ Gemm node found: Gemm_0 node ############\n",
      "\n",
      "............ Pruning Weights of Gemm_0 node ............\n",
      "Quant_31_param0 shape: (2, 128)\n",
      "New Quant_31_param0 shape: (2, 104)\n",
      "-------------------------------------\n",
      "*** All weights removed are zero? True\n",
      "### Non Zero IDX, channels to keep:\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  15  16  17  18  19\n",
      "  20  21  22  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39\n",
      "  40  42  43  44  45  46  47  49  50  51  53  54  55  56  57  58  60  63\n",
      "  64  65  66  67  68  69  70  72  73  74  76  79  80  81  83  84  85  87\n",
      "  88  89  90  92  93  94  95  97  98  99 100 102 103 104 106 107 108 109\n",
      " 111 112 113 114 115 116 117 119 121 122 123 124 125 127]\n",
      "-------------------------------------\n",
      "Modify output shape of Quant_31 node: (2, 104)\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "\n",
    "for conv in convs_to_prune:\n",
    "    print(f'\\n______________________________________________________________________________________________________')\n",
    "    print(f'                                                {conv} ')\n",
    "    print(f'______________________________________________________________________________________________________')\n",
    "\n",
    "    if set_mul4:\n",
    "        _, _, _, _ = test_prune_any_conv(model, conv)\n",
    "    else:\n",
    "        _, _, _, _ = test_prune_any_conv(model, conv, do_mul_val=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f28d2fd7-c412-4acf-b520-85829b0790ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(InferShapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "73d8330e-9c18-4064-ae15-c2c5f67484be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_mul4:\n",
    "    prune_all_convs_onnx = prune_folder + \"20_prune_all_convs_mul8.onnx\"\n",
    "else:\n",
    "    prune_all_convs_onnx = prune_folder + \"30_prune_all_convs_no_mul8.onnx\"\n",
    "model.save(prune_all_convs_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d43382a2-fb6a-4c27-8b3c-f86a90434de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './manual_pruning/pruning/sparse24_mul8/20_prune_all_convs_mul8.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f5db6d98880>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(prune_all_convs_onnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3127806e-be76-48c2-9f33-78b893e8fee4",
   "metadata": {},
   "source": [
    "### Compare Sparsity YES MUL 4 or 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bf0f9970-d0f9-4329-9242-61846c8bedef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quant_12_param0: \tbefore: 0.11 - after: 0.11\n",
      "Quant_13_param0: \tbefore: 0.09 - after: 0.09\n",
      "Quant_15_param0: \tbefore: 0.14 - after: 0.14\n",
      "Quant_16_param0: \tbefore: 0.1  - after: 0.1 \n",
      "Quant_18_param0: \tbefore: 0.22 - after: 0.11\n",
      "Quant_19_param0: \tbefore: 0.18 - after: 0.07\n",
      "Quant_21_param0: \tbefore: 0.33 - after: 0.11\n",
      "Quant_22_param0: \tbefore: 0.31 - after: 0.07\n",
      "Quant_24_param0: \tbefore: 0.11 - after: 0.11\n",
      "Quant_25_param0: \tbefore: 0.1  - after: 0.1 \n",
      "Quant_26_param0: \tbefore: 0.18 - after: 0.18\n",
      "Quant_27_param0: \tbefore: 0.61 - after: 0.23\n",
      "Quant_28_param0: \tbefore: 0.56 - after: 0.11\n",
      "Quant_29_param0: \tbefore: 0.61 - after: 0.22\n",
      "Quant_30_param0: \tbefore: 0.37 - after: 0.23\n"
     ]
    }
   ],
   "source": [
    "sparsity_after_pruning = get_sparsity(model, layers_to_prune)\n",
    "\n",
    "for k1, k2 in zip(sparsity_before_pruning.keys(), sparsity_after_pruning.keys()):\n",
    "    before = sparsity_before_pruning[k1][\"sparsity\"]\n",
    "    after = sparsity_after_pruning[k2][\"sparsity\"]\n",
    "    assert k1 == k2, f'{k1} is not the same as {k2}'\n",
    "    print(f'{k1}: \\tbefore: {before:<4} - after: {after:<4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3d2320-3ab5-46aa-9019-82333d73148f",
   "metadata": {},
   "source": [
    "# Prune Conv 22, as it is multiple of 4 or 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "67376d0f-8e14-46bb-bcf8-6c05843453c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(qonnx_clean_filename)\n",
    "# _, _, _, _ = test_prune_any_conv(model, \"Conv_21\")\n",
    "# _, _, _, _ = test_prune_any_conv(model, \"Conv_22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee2d23db-249a-4c31-b5ec-77259c01ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune_only_conv_22 = prune_folder + \"50_prune_only_conv_22.onnx\"\n",
    "# model.save(prune_only_conv_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1f3eb647-8c9f-4337-8dff-5447176c68c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(prune_only_conv_22)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
