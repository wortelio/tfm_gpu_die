{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a01e4ef-8c3c-4ac1-b5a9-7207f732df90",
   "metadata": {},
   "source": [
    "# Folders setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c48cecf-6faf-4092-b12b-50f26c5ee209",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_folder = '.'\n",
    "ori_filename = ori_folder + '/BNN_BED_Resnet_V5_classifier__best_mean_F1__BIPOLAR_Out__QONNX.onnx'\n",
    "\n",
    "models_folder = './step_by_step_v5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62467796-f923-4641-aea9-f27720817207",
   "metadata": {},
   "source": [
    "# Model Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8ce3e63-8792-41a6-8b31-486dca7d843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showSrc, showInNetron\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7286b856-b37b-42ab-a07b-b01ae0f11a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "qonnx_clean_filename = models_folder + '/01_clean.onnx'\n",
    "qonnx_cleanup(ori_filename, out_file=qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d097b8c-37d6-4745-afab-b924eb46f04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './BNN_BED_Resnet_V5_classifier__best_mean_F1__BIPOLAR_Out__QONNX.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3f54251090>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(ori_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32a2061d-8a23-478c-bfe8-57dd0bff238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_v5/01_clean.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3f2c407c10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268926d7-65d1-4c9d-9788-7ec8eb978435",
   "metadata": {},
   "source": [
    "# Dummy Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea79dcc1-8ec3-408f-bb60-f8c3f66c5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "import qonnx.core.onnx_exec as oxe\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30887ba6-8764-469c-9baf-6dbd14026f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ip = np.random.randint(low=0, high=256, size=(1, 3, 224, 224)) / 255.\n",
    "test_ip = test_ip.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f9336f4-ff2a-44af-8dbf-0a241c420d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_model = ModelWrapper(qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b56d5680-a591-47d3-8995-ad60d7f27eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict = {\"global_in\": test_ip}\n",
    "output_dict = oxe.execute_onnx(clean_model, input_dict)\n",
    "produced_clean_qonnx = output_dict[list(output_dict.keys())[0]]\n",
    "produced_clean_qonnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a391c5-af4f-4426-ac7f-345bf0a1310b",
   "metadata": {},
   "source": [
    "# Convert to FINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3392e878-1927-4360-8d58-75402552e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66c7d74d-229d-44e8-a0c4-35bb38951a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(RemoveStaticGraphInputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fea521a-b39a-405d-8181-cf306a167b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_tidy = models_folder + '/02_finn_tidy.onnx'\n",
    "model.save(finn_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f93b85f6-2a27-46ed-92fa-d2fa605fadae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_v5/02_finn_tidy.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3f54253760>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a074441-ef76-4836-bcaa-769972124fe3",
   "metadata": {},
   "source": [
    "# PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fd0bf51-cc0f-47fc-8d2c-6ed3fe805d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from finn.util.pytorch import ToTensor\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.core.datatype import DataType\n",
    "from brevitas.export import export_qonnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "173b59a6-8897-4d57-b25e-d818d4ca65dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/merge_onnx_models.py:70: UserWarning: [MergeONNXModels] opsets for models to merge differ: 14 vs 17, output model will use opset 17\n",
      "  warnings.warn(\n",
      "/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(finn_tidy)\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "# preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "totensor_pyt = ToTensor()\n",
    "chkpt_preproc_name = models_folder + \"/prepro_node.onnx\"\n",
    "export_qonnx(totensor_pyt, torch.randn(ishape), chkpt_preproc_name)\n",
    "qonnx_cleanup(chkpt_preproc_name, out_file=chkpt_preproc_name)\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "pre_model = pre_model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "# join preprocessing and core model\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "# add input quantization annotation: UINT8 for all BNN-PYNQ models\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c9bb0bd-a9b6-42ee-b792-9bbb3b4801b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.infer_datatypes import InferDataTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800e6b66-af2f-4ae8-a1b6-90336c6909f4",
   "metadata": {},
   "source": [
    "### Save prepro after tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eb18cc8-eef6-45ee-a2be-597ef399a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fa559ff-31f3-42ad-8273-ddf6d9a0759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_prepro = models_folder + '/03_finn_prepro.onnx'\n",
    "model.save(finn_prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d380614-f8d7-4b2b-86df-106ba43ab349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_v5/03_finn_prepro.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3f2c42dd50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_prepro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57348031-895c-4f9f-a0d1-22ed7969f60f",
   "metadata": {},
   "source": [
    "# Streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8100a86a-9402-4991-85ab-3b06b9d70da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "from qonnx.transformation.change_datalayout import ChangeDataLayoutQuantAvgPool2d\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "from finn.transformation.streamline import Streamline\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MoveScalarLinearPastInvariants\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC\n",
    "\n",
    "from finn.transformation.streamline.reorder import MoveMulPastFork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87024700-cce4-4e4f-8627-e9e7aefc120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2aeeda85-a2cb-4210-86a8-4bddcc03acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(MoveScalarLinearPastInvariants())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(ChangeDataLayoutQuantAvgPool2d())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "# model = model.transform(absorb.AbsorbAddIntoMultiThreshold())\n",
    "# model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "# model = model.transform(RoundAndClipThresholds())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "############### New for MaxPool\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e193eb3-6b2e-4752-bb21-c9404c65eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_streamline = models_folder + '/04_finn_streamline.onnx'\n",
    "model.save(finn_streamline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ab482f9-a66a-4ba6-8f2f-894f53192f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_v5/04_finn_streamline.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3e181703a0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_streamline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f490d5e8-adff-4f23-a284-4379549909f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a23aab-b962-4363-8b3d-1f20bd9eaf1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26e904f3-272e-466b-9229-b82ba5a6dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.streamline.reorder import MoveTransposePastFork\n",
    "from finn.transformation.streamline.reorder import MoveTransposePastJoinAdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2e179de-0f8f-4c0a-a3db-4597db487ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_streamline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92a0405f-d84d-4932-bd2c-12d3fd3aa4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(MoveTransposePastFork())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "model = model.transform(MoveTransposePastJoinAdd())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5264bf27-5eb2-4b43-9f78-e97a644602b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_transpose = models_folder + '/04_finn_transpose.onnx'\n",
    "model.save(finn_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6ad94ea-a91b-488a-9adc-4cc52cd33df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_v5/04_finn_transpose.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3f2c42c100>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d220b-14b7-4650-8989-e235478d2879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3eb38327-33bd-4506-ac2c-323c8c632f0f",
   "metadata": {},
   "source": [
    "# HW Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca2691fb-64db-456f-8397-5862940d9d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.basic import pynq_part_map\n",
    "# change this if you have a different PYNQ board, see list above\n",
    "pynq_board = \"Pynq-Z1\"\n",
    "fpga_part = pynq_part_map[pynq_board]\n",
    "target_clk_ns = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fa7030e-e5d7-48b1-9573-8744043dcccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ultra96': 'xczu3eg-sbva484-1-e', 'Ultra96-V2': 'xczu3eg-sbva484-1-i', 'Pynq-Z1': 'xc7z020clg400-1', 'Pynq-Z2': 'xc7z020clg400-1', 'ZCU102': 'xczu9eg-ffvb1156-2-e', 'ZCU104': 'xczu7ev-ffvc1156-2-e', 'ZCU111': 'xczu28dr-ffvg1517-2-e', 'RFSoC2x2': 'xczu28dr-ffvg1517-2-e', 'RFSoC4x2': 'xczu48dr-ffvg1517-2-e', 'KV260_SOM': 'xck26-sfvc784-2LV-c'}\n",
      "xc7z020clg400-1\n"
     ]
    }
   ],
   "source": [
    "print(pynq_part_map)\n",
    "print(fpga_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "024e8167-ceaa-4a34-b120-460e903a89e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "\n",
    "from qonnx.custom_op.registry import getCustomOp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f186e83-05e0-4b12-8b22-c7c0a60dbc08",
   "metadata": {},
   "source": [
    "### Change last Bipolar Node to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c870c7b-a916-4f2d-a96e-62ef2b42f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c8d1859-ce8d-495a-8d92-63924a696f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multithreshold_node = model.get_nodes_by_op_type(\"MultiThreshold\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad93dfa6-8f04-4d93-9745-236dd49ebddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiThreshold_2 converted from Bipolar to Binary\n",
      "MultiThreshold_6 converted from Bipolar to Binary\n",
      "MultiThreshold_8 converted from Bipolar to Binary\n",
      "MultiThreshold_14 converted from Bipolar to Binary\n",
      "MultiThreshold_16 converted from Bipolar to Binary\n",
      "MultiThreshold_22 converted from Bipolar to Binary\n",
      "MultiThreshold_24 converted from Bipolar to Binary\n",
      "MultiThreshold_29 converted from Bipolar to Binary\n"
     ]
    }
   ],
   "source": [
    "for node in Multithreshold_node:\n",
    "    node_inst = getCustomOp(node)\n",
    "    # if node.name == \"MultiThreshold_24\" or node.name == \"MultiThreshold_27\":\n",
    "        # if node_inst.get_nodeattr(\"out_dtype\") == \"BIPOLAR\":\n",
    "        #     node_inst.set_nodeattr(\"out_dtype\", \"BINARY\")\n",
    "        #     node_inst.set_nodeattr(\"out_scale\", 1.0)\n",
    "        #     node_inst.set_nodeattr(\"out_bias\", 0.0)\n",
    "        #     print(f'{node.name} converted from Bipolar to Binary\\n{node}')\n",
    "    if node_inst.get_nodeattr(\"out_dtype\") == \"BIPOLAR\":\n",
    "        node_inst.set_nodeattr(\"out_dtype\", \"BINARY\")\n",
    "        node_inst.set_nodeattr(\"out_scale\", 1.0)\n",
    "        node_inst.set_nodeattr(\"out_bias\", 0.0)\n",
    "        #print(f'{node.name} converted from Bipolar to Binary\\n{node}')\n",
    "        print(f'{node.name} converted from Bipolar to Binary')\n",
    "        \n",
    "        # node_name = node.output[0].name\n",
    "        # model.set_tensor_datatype(node_name, DataType[\"BINARY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd450e0d-8166-4eb4-8056-c445dae4aecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'global_out'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_out_name = model.graph.output[0].name\n",
    "global_out_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "305bff06-b6f9-43a1-8c74-11a7fb5f67b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_tensor_datatype(global_out_name, DataType[\"BINARY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d18e3aa2-dec3-4790-ba90-5e2f0a61a438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiThreshold_3: node with Float32 annotation\n",
      "MultiThreshold_3: changed to datatype INT32\n",
      "MultiThreshold_7: node with Float32 annotation\n",
      "MultiThreshold_7: changed to datatype INT32\n",
      "MultiThreshold_9: node with Float32 annotation\n",
      "MultiThreshold_9: changed to datatype INT32\n",
      "MultiThreshold_10: node with Float32 annotation\n",
      "MultiThreshold_10: changed to datatype INT32\n",
      "MultiThreshold_11: node with Float32 annotation\n",
      "MultiThreshold_11: changed to datatype INT32\n",
      "MultiThreshold_12: node with Float32 annotation\n",
      "MultiThreshold_12: changed to datatype INT32\n",
      "MultiThreshold_15: node with Float32 annotation\n",
      "MultiThreshold_15: changed to datatype INT32\n",
      "MultiThreshold_17: node with Float32 annotation\n",
      "MultiThreshold_17: changed to datatype INT32\n",
      "MultiThreshold_18: node with Float32 annotation\n",
      "MultiThreshold_18: changed to datatype INT32\n",
      "MultiThreshold_19: node with Float32 annotation\n",
      "MultiThreshold_19: changed to datatype INT32\n",
      "MultiThreshold_20: node with Float32 annotation\n",
      "MultiThreshold_20: changed to datatype INT32\n",
      "MultiThreshold_23: node with Float32 annotation\n",
      "MultiThreshold_23: changed to datatype INT32\n"
     ]
    }
   ],
   "source": [
    "Multithreshold_node = model.get_nodes_by_op_type(\"MultiThreshold\")    \n",
    "\n",
    "for node in Multithreshold_node:\n",
    "    if model.get_tensor_datatype(node.input[1]) == \"FLOAT32\":\n",
    "        print(f'{node.name}: node with Float32 annotation')\n",
    "        model.set_tensor_datatype(node.input[1], DataType[\"INT32\"])\n",
    "        print(f'{node.name}: changed to datatype {model.get_tensor_datatype(node.input[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2b6d58-aa34-47ba-a8e1-e95de2a5e6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3a243-77f4-4f83-a110-5701861cfc39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c28f0c4e-88d5-4337-ac0a-9d79c634fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b99431f-c95a-4bd1-8e9b-31fa5c5ae6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e3c75-87a5-48f5-a1c8-290c9b4f0c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "402c8184-8e14-4294-b32d-645f433bd8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_bipolar_to_binary = models_folder + '/05_finn_bipolar_to_binary.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9838e02a-25bb-4196-828c-0d6a351542d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(finn_bipolar_to_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e66c3a2-50e8-49a6-80a2-016a166450cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_v5/05_finn_bipolar_to_binary.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3e1821c280>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_bipolar_to_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f930e3-a725-474c-9b50-0573df8f2a22",
   "metadata": {},
   "source": [
    "### Standlone Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e411e32-f8dd-4295-9b00-eb05759c5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_bipolar_to_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f966c235-3824-4b36-b2a9-837796f3772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.transform(to_hw.InferThresholdingLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47ec7581-0897-4a90-8720-501ad32bc84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_7: UINT32 -> UINT2 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_15: UINT32 -> UINT2 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_23: UINT32 -> UINT2 \n",
      "  warnings.warn(warn_str)\n"
     ]
    }
   ],
   "source": [
    "# Changed for Multithresholds\n",
    "model = model.transform(to_hw.InferThresholdingLayer())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "model = model.transform(to_hw.InferAddStreamsLayer())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "\n",
    "# model = model.transform(to_hw.InferThresholdingLayer())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df0946a5-0673-476b-bfcf-2de3f16879df",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_std_alone_thres = models_folder + '/06_finn_std_alone_thres.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "801cbcd7-21de-4e58-bc48-be3626c9a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(finn_std_alone_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40976fc2-1593-49e3-9c8c-e2a92a27e62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_v5/06_finn_std_alone_thres.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3f54250fa0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_std_alone_thres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e500c22a-13ea-45c6-822d-f4b24ad0da6d",
   "metadata": {},
   "source": [
    "## Rest of the Streamline Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f315d0e8-fcfd-462b-8e24-bd10712af988",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_std_alone_thres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d1444b-2757-4f9f-9f8b-71386acee793",
   "metadata": {},
   "source": [
    "### Convert Multithreshold to INT32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9558d07e-9c38-474a-a58a-6de8cbbd612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multithreshold_node = model.get_nodes_by_op_type(\"MultiThreshold\")    \n",
    "\n",
    "# for node in Multithreshold_node:\n",
    "#     if model.get_tensor_datatype(node.input[1]) == \"FLOAT32\":\n",
    "#         print(f'{node.name}: node with Float32 annotation')\n",
    "#         model.set_tensor_datatype(node.input[1], DataType[\"INT32\"])\n",
    "#         print(f'{node.name}: changed to datatype {model.get_tensor_datatype(node.input[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e0a4d861-4f25-4fd1-bc1d-5257f5e5d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.transform(to_hw.InferAddStreamsLayer())\n",
    "# model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "\n",
    "model = model.transform(to_hw.InferBinaryMatrixVectorActivation())\n",
    "# Maybe for the first Conv, which receives UINT8 from the input\n",
    "model = model.transform(to_hw.InferQuantizedMatrixVectorActivation())\n",
    "\n",
    "# input quantization (if any) to standalone thresholding\n",
    "model = model.transform(to_hw.InferThresholdingLayer())\n",
    "model = model.transform(to_hw.InferPool())\n",
    "model = model.transform(to_hw.InferStreamingMaxPool())\n",
    "model = model.transform(to_hw.InferConvInpGen())\n",
    "\n",
    "# get rid of Reshape(-1, 1) operation between hw nodes \n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "\n",
    "# get rid of Tranpose -> Tranpose identity seq\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "# infer tensor data layouts\n",
    "model = model.transform(InferDataLayouts())\n",
    "\n",
    "model = model.transform(Streamline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f6581c2-b961-4544-97bf-d67acc6c0040",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_hw_layers = models_folder + '/05_fin_hw_layers.onnx'\n",
    "model.save(finn_hw_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b23bd3ad-9e1c-44b9-8107-f867688694f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_v5/05_fin_hw_layers.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3e181f1210>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_hw_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0a3f8-4f8a-475c-b24c-a58f7ba6adfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec4e01a0-4f5d-4805-81d0-3c2191bebc47",
   "metadata": {},
   "source": [
    "# Duplicate Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4773c44e-2f80-4e5a-89a8-467643f2bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.general import SortGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f3d8ab3e-cd89-4809-842b-60df1ee3f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_hw_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0b9976ad-0b08-46aa-8513-fe11d88f87ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(to_hw.InferDuplicateStreamsLayer())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "model = model.transform(SortGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1eda06eb-a7b1-4e6d-a0da-4c4b68d65167",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_duplicate_layers = models_folder + '/07_finn_duplicate_layers.onnx'\n",
    "model.save(finn_duplicate_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04e62201-e49a-4481-9ce6-3d845b98fd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_v5/07_finn_duplicate_layers.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3f2c42e380>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_duplicate_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf835dea-ccb5-422e-943d-8eb238279a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61773670-1d1d-4faf-b67e-43fbacc98066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c05f983-59b8-4e86-bb05-6abfac036a86",
   "metadata": {},
   "source": [
    "# Dataflow Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bef29c49-b692-4833-bdce-86b7c661e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_duplicate_layers)\n",
    "parent_model = model.transform(CreateDataflowPartition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b12ea7e0-99c8-47dd-ae6d-2d78617c0c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_parent_filename = models_folder + '/00_finn_dataflow_parent.onnx'\n",
    "parent_model.save(finn_parent_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b8dcd845-4380-4573-b822-d081ddd1c6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_v5/00_finn_dataflow_parent.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3e178e70d0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_parent_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "72d9ac0b-66e7-4369-9845-4e40e395d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_filename = sdp_node.get_nodeattr(\"model\")\n",
    "dataflow_model = ModelWrapper(dataflow_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b9153-30ca-4c0a-a352-ea557fb9452a",
   "metadata": {},
   "source": [
    "# Specialize Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "51f62b04-9c4e-42f2-aebc-8c10a81f4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce2cc8-6845-4753-9717-99258b5e4a6c",
   "metadata": {},
   "source": [
    "### Change Padding Nodes to HLS, so Auto Folding can be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc8c05ff-aec6-4dff-846a-671bfaf68286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node FMPadding_0 forced to HLS\n",
      "Node FMPadding_1 forced to HLS\n",
      "Node FMPadding_2 forced to HLS\n",
      "Node FMPadding_3 forced to HLS\n",
      "Node FMPadding_4 forced to HLS\n",
      "Node FMPadding_5 forced to HLS\n",
      "Node FMPadding_6 forced to HLS\n",
      "Node FMPadding_7 forced to HLS\n",
      "Node FMPadding_8 forced to HLS\n",
      "Node FMPadding_9 forced to HLS\n",
      "Node FMPadding_10 forced to HLS\n",
      "Node FMPadding_11 forced to HLS\n",
      "Node FMPadding_12 forced to HLS\n"
     ]
    }
   ],
   "source": [
    "FMPadding_node = dataflow_model.get_nodes_by_op_type(\"FMPadding\")\n",
    "\n",
    "for node in FMPadding_node:\n",
    "    node_inst = getCustomOp(node)\n",
    "    node_inst.set_nodeattr(\"preferred_impl_style\", \"hls\")\n",
    "    print(f'Node {node.name} forced to HLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dcaf1258-b22c-4b9f-bfd4-47a21bbc6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataflow partition with a different name for easier access\n",
    "# and specialize the layers to HLS variants\n",
    "dataflow_model = dataflow_model.transform(SpecializeLayers(fpga_part))\n",
    "\n",
    "dataflow_model = dataflow_model.transform(GiveUniqueNodeNames())\n",
    "dataflow_model = dataflow_model.transform(GiveReadableTensorNames())\n",
    "\n",
    "finn_dataflow_filename = models_folder + '/10_finn_dataflow_model.onnx'\n",
    "dataflow_model.save(finn_dataflow_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "733f7c1f-a632-4531-a1a9-651ab6386dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_v5/10_finn_dataflow_model.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3e18235960>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_dataflow_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c124c8b-e399-4e42-b3aa-bfc526c568f0",
   "metadata": {},
   "source": [
    "### Check execution???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ed28cd42-2fdf-4482-8732-b103519945ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_dataflow_model = ModelWrapper(finn_parent_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f5db2df8-b5ce-4136-bd07-6db6586839f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dict = {\"global_in\": test_ip*255}\n",
    "# output_dict = oxe.execute_onnx(parent_dataflow_model, input_dict)\n",
    "# produced_clean_qonnx = output_dict[list(output_dict.keys())[0]]\n",
    "# produced_clean_qonnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519407a4-c9cb-4a41-9ad2-9e539e5af923",
   "metadata": {},
   "source": [
    "# Folding Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c17f2a8d-2186-47f0-beae-258b50133bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.set_folding import SetFolding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff9d2ae-2345-46c8-b90e-258c12eb23de",
   "metadata": {},
   "source": [
    "**Taregt Cycles Per Frame**\n",
    "\n",
    "If target is 25 FPS, inference time is $\\frac{1}{25}=40ms$\n",
    "\n",
    "If $clk = 10 ns$:\n",
    "$$\n",
    "Target~Cycles~Per~Frame = \\frac{40\\times 10^{-3}}{10\\times 10^{-9}}= 4\\times 10^{6}\n",
    "$$\n",
    "\n",
    "No se tiene en cuenta el tiempo de preprocesado, que en realidad debería ser inexistente, ya que está embebido en el preprocess del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96b60113-5133-488d-93ea-fb09df218e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_dataflow_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1358a51-11ac-46ea-896f-96893d395b69",
   "metadata": {},
   "source": [
    "apply method of SetFolding returns (model, False), so model is [0]\n",
    "\n",
    "maybe it is easier to do: model, _ = folder.apply(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fdd92cef-a6b5-4174-aaad-8e3bdd12ad57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/src/finn/transformation/fpgadataflow/set_folding.py:233: UserWarning: Node ConvolutionInputGenerator_rtl_0 is bottleneck with 51078 cycles, running second pass\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = model.transform(SetFolding(\n",
    "    target_cycles_per_frame=1000,\n",
    "    mvau_wwidth_max=10000,\n",
    "    two_pass_relaxation=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "96500d41-ef99-47f1-b306-cb129ecc5611",
   "metadata": {},
   "outputs": [],
   "source": [
    "folding_filename = models_folder + '/20_finn_folding.onnx'\n",
    "#model[0].save(folding_filename)\n",
    "model.save(folding_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a7d32ab3-c906-4918-9690-18c0267fe4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_v5/20_finn_folding.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3e181f1180>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(folding_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3597a82-86be-44b0-8524-bc6bcc600c31",
   "metadata": {},
   "source": [
    "### Check Total Estimated Cycles, looping over each node attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "56fd5ac7-d477-4977-936a-0dadb41669c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = model.get_finn_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "60bbdff5-c927-43b6-b3e2-5621d4191c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 estimated cycles: 50176\n",
      "Node 1 estimated cycles: 51076\n",
      "Node 2 estimated cycles: 51078\n",
      "Node 3 estimated cycles: 50176\n",
      "Node 4 estimated cycles: 50176\n",
      "Node 5 estimated cycles: 50626\n",
      "Node 6 estimated cycles: 50176\n",
      "Node 7 estimated cycles: 25992\n",
      "Node 8 estimated cycles: 12998\n",
      "Node 9 estimated cycles: 50176\n",
      "Node 10 estimated cycles: 50176\n",
      "Node 11 estimated cycles: 60488\n",
      "Node 12 estimated cycles: 50176\n",
      "Node 13 estimated cycles: 50176\n",
      "Node 14 estimated cycles: 50176\n",
      "Node 15 estimated cycles: 50176\n",
      "Node 16 estimated cycles: 50176\n",
      "Node 17 estimated cycles: 26912\n",
      "Node 18 estimated cycles: 28343\n",
      "Node 19 estimated cycles: 50176\n",
      "Node 20 estimated cycles: 50176\n",
      "Node 21 estimated cycles: 50176\n",
      "Node 22 estimated cycles: 50176\n",
      "Node 23 estimated cycles: 50176\n",
      "Node 24 estimated cycles: 50176\n",
      "Node 25 estimated cycles: 26912\n",
      "Node 26 estimated cycles: 28343\n",
      "Node 27 estimated cycles: 50176\n",
      "Node 28 estimated cycles: 50176\n",
      "Node 29 estimated cycles: 63760\n",
      "Node 30 estimated cycles: 50176\n",
      "Node 31 estimated cycles: 50176\n",
      "Node 32 estimated cycles: 50176\n",
      "Node 33 estimated cycles: 50176\n",
      "Node 34 estimated cycles: 25088\n",
      "Node 35 estimated cycles: 28800\n",
      "Node 36 estimated cycles: 28476\n",
      "Node 37 estimated cycles: 50176\n",
      "Node 38 estimated cycles: 50176\n",
      "Node 39 estimated cycles: 50176\n",
      "Node 40 estimated cycles: 25088\n",
      "Node 41 estimated cycles: 28800\n",
      "Node 42 estimated cycles: 28476\n",
      "Node 43 estimated cycles: 50176\n",
      "Node 44 estimated cycles: 50176\n",
      "Node 45 estimated cycles: 50176\n",
      "Node 46 estimated cycles: 50176\n",
      "Node 47 estimated cycles: 50176\n",
      "Node 48 estimated cycles: 50176\n",
      "Node 49 estimated cycles: 28800\n",
      "Node 50 estimated cycles: 28476\n",
      "Node 51 estimated cycles: 37632\n",
      "Node 52 estimated cycles: 37632\n",
      "Node 53 estimated cycles: 49628\n",
      "Node 54 estimated cycles: 37632\n",
      "Node 55 estimated cycles: 18816\n",
      "Node 56 estimated cycles: 18816\n",
      "Node 57 estimated cycles: 37632\n",
      "Node 58 estimated cycles: 9408\n",
      "Node 59 estimated cycles: 12288\n",
      "Node 60 estimated cycles: 43176\n",
      "Node 61 estimated cycles: 37632\n",
      "Node 62 estimated cycles: 18816\n",
      "Node 63 estimated cycles: 37632\n",
      "Node 64 estimated cycles: 9408\n",
      "Node 65 estimated cycles: 12288\n",
      "Node 66 estimated cycles: 43176\n",
      "Node 67 estimated cycles: 37632\n",
      "Node 68 estimated cycles: 18816\n",
      "Node 69 estimated cycles: 24576\n",
      "Node 70 estimated cycles: 43176\n",
      "Node 71 estimated cycles: 37632\n",
      "Node 72 estimated cycles: 18816\n",
      "Node 73 estimated cycles: 18816\n",
      "Node 74 estimated cycles: 18816\n",
      "Node 75 estimated cycles: 24576\n",
      "Node 76 estimated cycles: 43176\n",
      "Node 77 estimated cycles: 50176\n",
      "Node 78 estimated cycles: 25088\n",
      "Node 79 estimated cycles: 35151\n",
      "Node 80 estimated cycles: 25088\n",
      "Node 81 estimated cycles: 10368\n",
      "Node 82 estimated cycles: 29568\n",
      "Node 83 estimated cycles: 50176\n",
      "Node 84 estimated cycles: 6272\n",
      "Node 85 estimated cycles: 10368\n",
      "Node 86 estimated cycles: 29568\n",
      "Node 87 estimated cycles: 50176\n",
      "Node 88 estimated cycles: 6272\n",
      "Node 89 estimated cycles: 18682\n",
      "Node 90 estimated cycles: 6272\n",
      "Node 91 estimated cycles: 8192\n",
      "Node 92 estimated cycles: 64\n",
      "Node 93 estimated cycles: 2048\n",
      "Node 94 estimated cycles: 32\n",
      "Node 95 estimated cycles: 64\n",
      "Node 96 estimated cycles: 2\n",
      "\n",
      "Total estimated cycles: 3365435\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "total_cycles = []\n",
    "for node in all_nodes:\n",
    "    my_node = getCustomOp(node)\n",
    "    node_cycles = my_node.get_nodeattr(\"cycles_estimate\")\n",
    "    total_cycles.append(node_cycles)\n",
    "    print(f'Node {i} estimated cycles: {node_cycles}')\n",
    "    i += 1\n",
    "print(f'\\nTotal estimated cycles: {np.array(total_cycles).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346b1a9-d48e-409c-a316-828f3350f502",
   "metadata": {},
   "source": [
    "# Minimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b5528e3a-c5fe-46b7-91d2-cb9a4ce5b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.minimize_accumulator_width import (\n",
    "    MinimizeAccumulatorWidth,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.minimize_weight_bit_width import (\n",
    "    MinimizeWeightBitWidth,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6cb4d663-2497-4e2e-a375-9cc6b0060434",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(folding_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0a6bffa3-db61-4bf9-ba52-b9fa1c47b23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_1: INT32 -> INT16 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_2: INT32 -> INT15 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_4: UINT32 -> INT6 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_5: UINT32 -> INT8 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_6: UINT32 -> INT6 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_8: UINT32 -> INT9 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_10: UINT32 -> INT7 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_11: UINT32 -> INT9 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_12: UINT32 -> INT7 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_13: UINT32 -> INT9 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_14: UINT32 -> INT7 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_16: UINT32 -> INT10 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_18: UINT32 -> INT8 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_19: UINT32 -> INT10 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_20: UINT32 -> INT7 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_21: UINT32 -> INT10 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_22: UINT32 -> INT10 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_24: UINT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_25: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_26: INT32 -> INT16 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_27: INT32 -> INT18 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_28: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_29: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n"
     ]
    }
   ],
   "source": [
    "model = model.transform(MinimizeAccumulatorWidth())\n",
    "model = model.transform(MinimizeWeightBitWidth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6653c288-15f1-4972-bbfa-101cdffed607",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize_filename = models_folder + '/21_finn_minimize.onnx'\n",
    "model.save(minimize_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c1a85c57-19c4-4b87-a918-345b58160385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_v5/21_finn_minimize.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3e178e6fb0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(minimize_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6d687b-0494-4cd1-80ac-070d14553677",
   "metadata": {},
   "source": [
    "# HW IP Generation: PrepareIP and HLSSynthIP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b8ccc6-0fe0-4bde-824f-e6f0bd51ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from finn.transformation.fpgadataflow.prepare_ip import PrepareIP\n",
    "# from finn.transformation.fpgadataflow.hlssynth_ip import HLSSynthIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0be8cf-bb21-41f0-9f6a-cc55edadd683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(minimize_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76818f0f-02d5-43aa-b65d-9d052db23336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.transform(PrepareIP(fpga_part, target_clk_ns))\n",
    "# model = model.transform(HLSSynthIP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c37ba9-8d8b-4083-80c5-6b1967980bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hw_filename = models_folder + '32_finn_hw_ipgen.onnx'\n",
    "# model.save(hw_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f9a23-1a14-44f7-94b9-52f3f60f5eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(hw_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b224fe1f-5886-4439-b572-223bceb0ba16",
   "metadata": {},
   "source": [
    "# FIFO depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e559b-d622-40ed-8132-fad3107b02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.set_fifo_depths import InsertAndSetFIFODepths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f029018-824e-4303-965e-3428cabd53a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ModelWrapper(hw_filename)\n",
    "\n",
    "# model = ModelWrapper(minimize_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad09844f-392b-4abc-b2ae-895862cb5448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.transform(InsertAndSetFIFODepths(\n",
    "#     fpgapart=fpga_part,\n",
    "#     clk_ns=10.0,\n",
    "#     max_qsrl_depth=256,\n",
    "#     max_depth=None,\n",
    "#     swg_exception=False,#True, # Used to optimize convolution FIFOs, splitting in several with Power of Two\n",
    "#     vivado_ram_style=\"auto\",\n",
    "#     force_python_sim=False)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c427a1-5ff2-4083-9695-ab7742683ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifo_filename = models_folder + '31_finn_fifo.onnx'\n",
    "# #model[0].save(fifo_filename)\n",
    "# model.save(fifo_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b843e2-0bc4-4929-817d-eca89b65a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(fifo_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3322c539-37d1-4fa1-ae08-dcd8d916f7e3",
   "metadata": {},
   "source": [
    "### Streamline FIFOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a18232-1569-4130-9b7a-15026bc8583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from finn.transformation.fpgadataflow.set_fifo_depths import SplitLargeFIFOs\n",
    "# from finn.transformation.fpgadataflow.set_fifo_depths import RemoveShallowFIFOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7381a6-5cdd-4875-9e1e-8395c8549d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model[0].transform(SplitLargeFIFOs())\n",
    "\n",
    "# model = model.transform(SplitLargeFIFOs())\n",
    "# model = model.transform(RemoveShallowFIFOs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe072021-5b59-49e0-85dc-ca0d1e2fd84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after FIFOs are ready to go, call PrepareIP and HLSSynthIP again\n",
    "# this will only run for the new nodes (e.g. FIFOs and DWCs) -> DWCs for Mobilenet\n",
    "# model = model.transform(PrepareIP(fpga_part, target_clk_ns))\n",
    "# model = model.transform(HLSSynthIP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb88151-c03d-4b1c-8c01-bd1dae5fae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifo_streamline_filename = models_folder + '33_finn_fifo_streamline.onnx'\n",
    "# model.save(fifo_streamline_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec70cde2-09ba-4fdd-b6f8-454121ff6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(fifo_streamline_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e049589-e6f3-4ba2-9a89-dd8a7a947b50",
   "metadata": {},
   "source": [
    "# PYNQ Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee6904-e30e-4a68-978b-59571c1edc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db01d436-01ed-4a5e-aca6-d992ad5edea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(fifo_streamline_filename)\n",
    "# model = model.transform(ZynqBuild(platform = pynq_board, period_ns = target_clk_ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4726f80-8fbb-4991-b7cb-937b38e8f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e466a10-dc61-499c-aacc-d56e0a34a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.transform(MakePYNQDriver(\"zynq-iodma\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399688a0-b838-4752-9b41-d989c28123d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pynq_driver_filename = '/40_pynq_driver.onnx'\n",
    "# model.save(pynq_driver_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
