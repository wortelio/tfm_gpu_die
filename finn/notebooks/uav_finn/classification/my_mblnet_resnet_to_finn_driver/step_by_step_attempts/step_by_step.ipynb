{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463c1477-b429-4abe-b16e-f51487ed935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "import model_mobilenetv2_mini_Resnet_Brevitas as brevitas_model\n",
    "from brevitas.export import export_qonnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990fce3e-24f8-4e2b-9a92-3ba716faea5f",
   "metadata": {},
   "source": [
    "# Mobilenet Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4f861ce-1362-4bec-b658-818c517a24c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/deps/brevitas/src/brevitas/nn/mixin/base.py:77: UserWarning: Keyword arguments are being passed but they not being used.\n",
      "  warn('Keyword arguments are being passed but they not being used.')\n"
     ]
    }
   ],
   "source": [
    "model_qnn = brevitas_model.MobileNetV2_MINI_RESNET().to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c34946d-14b2-4802-9dec-a6fd402f3210",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 3, 224, 224)\n",
    "# print(summary(model_qnn, input_size=input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afa1f10b-4eba-4fd1-978b-6448998826ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = './step_by_step'\n",
    "model_qnn_filename = models_folder + '/MobilenetV2_Resnet__QONNX.onnx' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63a098b0-f1db-45dc-89c9-57ceb9f84648",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qnn.eval();\n",
    "export_qonnx(model_qnn, torch.randn(input_shape), model_qnn_filename);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fed44b-915d-4f13-bf47-f09b669a065d",
   "metadata": {},
   "source": [
    "# FINN Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda68f6-24c1-4eb3-8796-62c91f570e47",
   "metadata": {},
   "source": [
    "## Load Model and View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf723b71-f555-490c-b185-776f73396c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showSrc, showInNetron\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dff265e-bed5-4efd-92a6-1ee06471f86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './step_by_step/MobilenetV2_Resnet__QONNX.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe0e8aeb970>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(model_qnn_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52bb090-4801-4cd6-91f4-e86048dfcb11",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2150e426-3ba5-4aab-b680-78cd716e2ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qonnx_clean_filename = models_folder + '/01_clean.onnx'\n",
    "qonnx_cleanup(model_qnn_filename, out_file=qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42d9a172-78a4-404f-be19-334b6747409d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step/01_clean.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe0e2194910>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e71cacf-447e-4a5e-a628-1e4b5188b6a8",
   "metadata": {},
   "source": [
    "## Convert to FINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c2d3af5-b4df-47ba-af6b-2391ba0950c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89512ff2-3de9-435d-9ac0-459a5b4f30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "622516fa-c609-4dc0-86a4-19aafedaaa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/gemm_to_matmul.py:57: UserWarning: The GemmToMatMul transformation only offers explicit support for version 9 of the Gemm node, but the ONNX version of the supplied model is 14. Thus the transformation may fail or return incomplete results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(RemoveStaticGraphInputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b36e1b0a-eec1-476d-ac12-6919a911d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_tidy = models_folder + '/02_finn_tidy.onnx'\n",
    "model.save(finn_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb2c21cb-492c-4cee-8e1b-ec8784405cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step/02_finn_tidy.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe0e2197d90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f9fec5-a30c-4d6f-8e50-4bfb3a674a3f",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b39deb7-0653-4b54-bb09-ac774320547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.pytorch import ToTensor\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f39b02d-f548-4fb8-baa2-9bd0add11fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(finn_tidy)\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "# preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "totensor_pyt = ToTensor()\n",
    "chkpt_preproc_name = models_folder + \"/prepro_node.onnx\"\n",
    "export_qonnx(totensor_pyt, torch.randn(ishape), chkpt_preproc_name)\n",
    "qonnx_cleanup(chkpt_preproc_name, out_file=chkpt_preproc_name)\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "pre_model = pre_model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "# join preprocessing and core model\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "# add input quantization annotation: UINT8 for all BNN-PYNQ models\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e994573e-3b15-4f90-9e4e-4d82b9288ad0",
   "metadata": {},
   "source": [
    "### Tidy again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87c667fd-97b6-4bf5-bd82-ae0f97353bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c8d211b-0a24-4381-b2fe-cc9e92eac928",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_prepro = models_folder + '/03_finn_prepro.onnx'\n",
    "model.save(finn_prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11e7ee6e-aa4b-4e6b-9b32-4ad8d1a45911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step/03_finn_prepro.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe0e2212470>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_prepro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426532b9-8327-4539-a3da-83dbb47a5899",
   "metadata": {},
   "source": [
    "## Streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "deabcd45-ecb5-4e18-b104-862f4c6a8d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "\n",
    "from qonnx.transformation.change_datalayout import ChangeDataLayoutQuantAvgPool2d\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "from finn.transformation.streamline import Streamline\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MoveScalarLinearPastInvariants\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC\n",
    "from finn.transformation.streamline.reorder import MoveLinearPastEltwiseAdd\n",
    "\n",
    "from finn.transformation.streamline.reorder import MoveMulPastFork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "defe695a-fb96-4440-94f3-f2d3bff6620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_prepro)\n",
    "# model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "# model = model.transform(absorb.AbsorbAddIntoMultiThreshold())\n",
    "\n",
    "model = model.transform(MoveMulPastFork())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0442ce55-9fe5-4a44-9723-f7ef26ef5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_mul_past_fork = models_folder + '/040_finn_mul_past_fork.onnx'\n",
    "model.save(finn_mul_past_fork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8de7f1ba-147e-4c78-a29d-e08adf95e29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step/040_finn_mul_past_fork.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe0e2194640>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_mul_past_fork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29ca04a-c83a-4f4a-8587-c1b25ade03fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec27c9d8-02d9-4e9b-8e94-0e4fda8aba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_mul_past_fork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff96a0f7-f81c-4acd-b570-b553b4260d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/src/finn/transformation/streamline/absorb.py:66: UserWarning: Threshold or add bias not constant, skipping\n",
      "  warnings.warn(\"Threshold or add bias not constant, skipping\")\n"
     ]
    }
   ],
   "source": [
    "model = model.transform(MoveLinearPastEltwiseAdd())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3fc3c08-f909-4bbc-a776-cd49cd4de373",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_move_mul_past_add = models_folder + '/041_finn_move_mul_past_add.onnx'\n",
    "model.save(finn_move_mul_past_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef008020-7cd5-4b1e-b4c4-e3da9d22a24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step/041_finn_move_mul_past_add.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe0e01e9c00>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_move_mul_past_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4af8f13e-9b51-42ee-b79a-083534209322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from finn.transformation.streamline.reorder import MoveTransposePastFork "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c8e134b-ecdd-4572-87af-24c7a328a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_move_mul_past_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eff18e43-f3e8-47b5-bc3a-6567ee4f3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(to_hw.InferAddStreamsLayer())\n",
    "# model = model.transform(MoveTransposePastFork())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83bab094-fcaf-4961-95c9-a1db0c0102bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_add_to_hw = models_folder + '/042_finn_add_to_hw.onnx'\n",
    "model.save(finn_add_to_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "120eb1d7-afc1-432e-b648-f513b8d8aa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step/042_finn_add_to_hw.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe0e022db10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_add_to_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601f942-f731-4860-865e-6edbe61d8c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1041e015-8ad0-49bb-8bbd-eb1b489ff359",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_add_to_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "504dcc1f-bc9c-4e31-a132-d33ac5d9950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(ChangeDataLayoutQuantAvgPool2d())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51c9f1b7-2bab-40a2-9ec8-a84999f29338",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_avgpool = models_folder + '/043_finn_avgpool.onnx'\n",
    "model.save(finn_avgpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7eca122f-b85e-4e1e-959d-8883fa14e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step/043_finn_avgpool.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe0e2197ee0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_avgpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a6ac34-7fed-4233-8b0d-24d7fbea4f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a41ea4-cf49-4000-9dd5-5066548fc8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40e917aa-ebb9-4770-80ee-460cad359a91",
   "metadata": {},
   "source": [
    "# Old Streamline plus some test: it does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d96d965e-7920-4183-b3ac-7e6375911892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(finn_prepro)\n",
    "# # model = model.transform(MoveLinearPastEltwiseAdd())\n",
    "# model = model.transform(absorb.AbsorbAddIntoMultiThreshold())\n",
    "# model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "\n",
    "# model = model.transform(MoveScalarLinearPastInvariants())\n",
    "# model = model.transform(Streamline())\n",
    "# model = model.transform(LowerConvsToMatMul())\n",
    "# model = model.transform(MakeMaxPoolNHWC())\n",
    "# model = model.transform(ChangeDataLayoutQuantAvgPool2d())\n",
    "# model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "\n",
    "# model = model.transform(Streamline())\n",
    "# model = model.transform(InferDataLayouts())\n",
    "# model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "864f1a68-a3be-4aa7-8d18-ae6da439c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finn_streamline = models_folder + '/04_finn_streamline.onnx'\n",
    "# model.save(finn_streamline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb88790d-6012-42bc-93e3-7ec9a5aa4c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(finn_streamline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98f73da-659c-4885-8f3a-05c45d38d15c",
   "metadata": {},
   "source": [
    "# To HW Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a8179a6-5bce-4bcc-8ea7-5bdfdbe73b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "\n",
    "from qonnx.custom_op.registry import getCustomOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e32052d3-830e-4090-9ac0-877f8ced6e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_avgpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5eebb4d-da1a-4d75-b726-e532ed20df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(to_hw.InferQuantizedMatrixVectorActivation())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fece644c-de0b-4bd0-9b67-56ebbdaaa560",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_hw_mvau = models_folder + '/044_finn_hw_mvau.onnx'\n",
    "model.save(finn_hw_mvau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "438e1ddb-d185-4171-b8d2-a524b5040aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step/044_finn_hw_mvau.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe0e2194730>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_hw_mvau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f31b9-3e8a-43ea-ba4c-e4c71c72ba26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f937d692-7f4d-49af-b79c-3bdd8cfaaae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_hw_mvau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90c0e32a-bf9b-449f-a71e-d726e94579dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(to_hw.InferConvInpGen())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b91408ab-fcb4-4659-9905-7594d663a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_hw_convs = models_folder + '/045_finn_hw_convs.onnx'\n",
    "model.save(finn_hw_convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb75da93-d4a9-44e5-bf92-a034d955e494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step/045_finn_hw_convs.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe0e016a5c0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_hw_convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb56bdc-7393-4ed1-a986-c637e2f1eae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed661dd0-c3ac-4753-a00c-d0a08344d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_hw_convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bea65c16-2cf1-4e88-88bc-7b5002791cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(to_hw.InferPool())\n",
    "model = model.transform(to_hw.InferConvInpGen())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b7ec11c-8a9d-40a0-af5e-73755e5e0e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_hw_pool = models_folder + '/046_finn_hw_pool.onnx'\n",
    "model.save(finn_hw_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e3e6e53-ae7d-4bc5-bfeb-f1cb32fb0f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step/046_finn_hw_pool.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe0e016a4d0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_hw_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efecb11-f594-49d1-a0d8-44e74e74ab2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6495df43-b7ba-4088-9be0-78676bf8c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_hw_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d08482a4-0205-444d-88f6-23f824a9b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(to_hw.InferThresholdingLayer())\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6cd34c43-5e9e-41db-8281-2cbf7b2acaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_hw_multithres_flaten = models_folder + '/047_finn_hw_multithres_flaten.onnx'\n",
    "model.save(finn_hw_multithres_flaten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a8a5a5c-65ec-4737-8f9e-4c816bbf7060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step/047_finn_hw_multithres_flaten.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe0e01541f0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_hw_multithres_flaten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca1cf6-0fb5-457d-b4ad-4a8ccbcba58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "61dd0bab-d225-44b9-8669-11a6472eed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_hw_multithres_flaten)\n",
    "model = model.transform(to_hw.InferVectorVectorActivation())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0fa8e19-c37b-44ea-a0b8-6844587f3363",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_hw_dw_convs = models_folder + '/047_finn_hw_dw_convs.onnx'\n",
    "model.save(finn_hw_dw_convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b8e8e437-f29f-4e17-a0d3-3995de38e7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step/047_finn_hw_dw_convs.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe0e0157f70>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_hw_dw_convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9898f-02ca-4e2f-bdfd-3dd7cc268022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764b1d6-9c2d-4679-bc32-be98742408e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4014cddb-719f-445b-8ed9-eb2112a3b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_hw_dw_convs)\n",
    "parent_model = model.transform(CreateDataflowPartition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fb110eb3-7038-4f7e-a1d1-170884f9460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_parent_filename = models_folder + '/00_finn_dataflow_parent.onnx'\n",
    "parent_model.save(finn_parent_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce570573-8efc-4e94-bbbe-319c822210e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step/00_finn_dataflow_parent.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe0e016a170>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_parent_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59ef0394-b25e-4cad-98d4-f75d27fb6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_filename = sdp_node.get_nodeattr(\"model\")\n",
    "dataflow_model = ModelWrapper(dataflow_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad4339d-c00a-4c9c-ac1a-953757d5465b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b925d6ce-2a8a-46ae-8c7c-910ca12f7ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd9cd70c-db50-478b-9022-73f3999ccd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a8c7493-5d7b-40c1-8620-53bbe68a5eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.basic import pynq_part_map\n",
    "# change this if you have a different PYNQ board, see list above\n",
    "pynq_board = \"Pynq-Z1\"\n",
    "fpga_part = pynq_part_map[pynq_board]\n",
    "target_clk_ns = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "90f463dc-3f78-4a41-9864-801ee55ecca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataflow partition with a different name for easier access\n",
    "# and specialize the layers to HLS variants\n",
    "dataflow_model = dataflow_model.transform(SpecializeLayers(fpga_part))\n",
    "\n",
    "dataflow_model = dataflow_model.transform(GiveUniqueNodeNames())\n",
    "dataflow_model = dataflow_model.transform(GiveReadableTensorNames())\n",
    "\n",
    "finn_dataflow_filename = models_folder + '/20_finn_dataflow_model.onnx'\n",
    "dataflow_model.save(finn_dataflow_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e319d52f-9592-4d4f-8b03-00248c8ef6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step/20_finn_dataflow_model.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe0e0244fd0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_dataflow_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145b9b0f-542e-4054-bc29-ed3af9699863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
