{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "663fc823-cba4-4c64-b961-f01e20984a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run folder created in: experiments_pynq-z1/09_pynq-z1__16FPS__workspace__AIMET_Balanced__BIPOLAR__w4W2a4__estimates/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import config\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "from brevitas.export import export_qonnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd308cca-d93b-4cec-a9ae-27b493426f34",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b31d40-aefc-45d5-8203-cadee298fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = config.RUN_FOLDER\n",
    "\n",
    "logger = logging.getLogger(\"GonLogger\")\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.INFO)\n",
    "file_handler = logging.FileHandler(log_path + 'logfile.log')\n",
    "# formatter = logging.Formatter('%(message)s')\n",
    "# file_handler.setFormatter(formatter)\n",
    "\n",
    "# add file handler to logger\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a01e4ef-8c3c-4ac1-b5a9-7207f732df90",
   "metadata": {},
   "source": [
    "# FINN Folders setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c48cecf-6faf-4092-b12b-50f26c5ee209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finn_root_dir = os.environ[\"FINN_ROOT\"]\n",
    "# nb_dir = finn_root_dir + \"/notebooks/uav_finn/classification/qonnx_to_finn_driver/\"\n",
    "# # Leave all build files inside experiments folder\n",
    "# os.environ[\"FINN_BUILD_DIR\"] = nb_dir + config.BUILD_FOLDER\n",
    "# os.environ[\"FINN_HOST_BUILD_DIR\"] = nb_dir + config.TMP_FOLDER\n",
    "\n",
    "# models_folder = config.MODELS_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bd679e-11a8-4008-8642-0fb6599793ee",
   "metadata": {},
   "source": [
    "# Original QONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56884858-a0bf-4bd7-b9c9-d9ca54f747c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#brevitas_cpu = './models/BED_classifier__best_mean_F1__BIPOLAR_Out__QONNX.onnx'\n",
    "#brevitas_cpu = './models/Best_F1_AIMET__Bipolar.onnx'\n",
    "# brevitas_cpu = './aimet_onnx/BED_classifier__best_mean_F1__BIPOLAR_Out__QONNX.onnx'\n",
    "# brevitas_cpu = './models/aimet_onnx/BED_classifier__best_mean_F1__AIMET_NoPadding__BIPOLAR_Out__QONNX.onnx'\n",
    "# brevitas_cpu = './models/aimet_onnx/BED_classifier__best_mean_F1__AIMET_NoPading_QIdy__BIPOLAR_Out__QONNX.onnx'\n",
    "#brevitas_cpu = './models/aimet_onnx/BED_classifier__best_mean_F1__AIMET_NoPad_QIdy__Balanced__NoTrain__QONNX.onnx'\n",
    "brevitas_cpu = './models/aimet_onnx/BED_classifier__best_mean_F1__AIMET_Balanced__BIPOLAR_Out__QONNX.onnx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44addd53-bf50-4e04-b1d0-109d48297fa0",
   "metadata": {},
   "source": [
    "# FINN IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d379ebf2-eb47-4035-be7a-308ebe6dd546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showSrc, showInNetron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f20cb421-8368-4d3d-b15a-09ca512a6160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(brevitas_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbecf7c-f2bb-4e01-a3ce-21f021028ce9",
   "metadata": {},
   "source": [
    "# FINN Build IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72e3ef7e-98b6-443a-bd3f-c36e2370e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62467796-f923-4641-aea9-f27720817207",
   "metadata": {},
   "source": [
    "# Custom step: Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7730ede7-ad4f-4c0e-9914-81eec22e5697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.pytorch import ToTensor\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.core.datatype import DataType\n",
    "\n",
    "def custom_step_add_pre_proc(model: ModelWrapper, cfg: build.DataflowBuildConfig):\n",
    "    global_inp_name = model.graph.input[0].name\n",
    "    ishape = model.get_tensor_shape(global_inp_name)\n",
    "    preproc = ToTensor()\n",
    "    export_qonnx(preproc, torch.randn(ishape), \"preproc.onnx\", opset_version=11)\n",
    "    preproc_model = ModelWrapper(\"preproc.onnx\")\n",
    "    # set input finn datatype to UINT8\n",
    "    preproc_model.set_tensor_datatype(preproc_model.graph.input[0].name, DataType[\"UINT8\"])\n",
    "    # merge pre-processing onnx model with cnv model (passed as input argument)\n",
    "    model = model.transform(MergeONNXModels(preproc_model))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac7b37-c94b-46a5-aea1-f976b124ad02",
   "metadata": {},
   "source": [
    "# Custom step: Streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa25352c-0be7-483e-ae72-a9789535bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.datatype import DataType\n",
    "\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.change_datalayout import ChangeDataLayoutQuantAvgPool2d\n",
    "#from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "from finn.transformation.streamline import Streamline\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants\n",
    "from finn.transformation.streamline.reorder import MoveTransposePastScalarMul\n",
    "\n",
    "def custom_step_streamline(model: ModelWrapper, cfg: build.DataflowBuildConfig):\n",
    "\n",
    "    # Find MultiThreshold that FINN could not annotate datatype properly and set them to INT32\n",
    "    Multithreshold_node = model.get_nodes_by_op_type(\"MultiThreshold\")    \n",
    "    for node in Multithreshold_node:\n",
    "        if model.get_tensor_datatype(node.input[1]) == \"FLOAT32\":\n",
    "            print(f'{node.name}: node with Float32 annotation')\n",
    "            model.set_tensor_datatype(node.input[1], DataType[\"INT32\"])\n",
    "            print(f'{node.name}: changed to datatype {model.get_tensor_datatype(node.input[1])}')\n",
    "    \n",
    "    model = model.transform(MoveScalarLinearPastInvariants())\n",
    "    model = model.transform(Streamline())\n",
    "    model = model.transform(LowerConvsToMatMul())\n",
    "    model = model.transform(MakeMaxPoolNHWC())\n",
    "    model = model.transform(ChangeDataLayoutQuantAvgPool2d())\n",
    "    model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "    #model = model.transform(RoundAndClipThresholds())\n",
    "    model = model.transform(Streamline())\n",
    "    model = model.transform(InferDataLayouts())\n",
    "    model = model.transform(RemoveUnusedTensors())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ca5813-c5ea-4f6a-8726-60a028c049e2",
   "metadata": {},
   "source": [
    "# Custom step: Convert to HW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ab20f6-3e9a-46f8-b01a-ade675f5f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from qonnx.transformation.general import GiveUniqueNodeNames\n",
    "\n",
    "def custom_step_convert_to_hw(model: ModelWrapper, cfg: build.DataflowBuildConfig):\n",
    "   \n",
    "    if cfg.standalone_thresholds:\n",
    "        # doing this first causes all threshold layers to be standalone\n",
    "        model = model.transform(to_hw.InferThresholdingLayer())\n",
    "    model = model.transform(to_hw.InferQuantizedMatrixVectorActivation())   \n",
    "    # input quantization (if any) to standalone thresholding. \n",
    "    model = model.transform(to_hw.InferThresholdingLayer())\n",
    "    model = model.transform(to_hw.InferPool())\n",
    "    model = model.transform(to_hw.InferStreamingMaxPool())\n",
    "    model = model.transform(to_hw.InferConvInpGen())\n",
    "    # get rid of Reshape(-1, 1) operation between hw nodes \n",
    "    model = model.transform(RemoveCNVtoFCFlatten())\n",
    "    # get rid of Tranpose -> Tranpose identity seq\n",
    "    model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "    # # Move transpose\n",
    "    # model = model.transform(Streamline())\n",
    "    # model = model.transform(MoveTransposePastScalarMul()) # Only AIMET model\n",
    "    # model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "    \n",
    "    # infer tensor data layouts\n",
    "    model = model.transform(InferDataLayouts())\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    #model = model.transform(Streamline()) -> MAYBE NOT NEEDED ????\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270295cd-a9f9-4f32-9a0b-fed3ab4812d9",
   "metadata": {},
   "source": [
    "# Custom step: Specialize Layers -> redefine FMPadding as HLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13763a14-479e-4672-9e87-85d0eb4d62ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.general import GiveReadableTensorNames\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "\n",
    "def custom_step_specialize_layers(model: ModelWrapper, cfg: build.DataflowBuildConfig):\n",
    "    # Change all FMPadding to HLS, as Folding does not support this layer as RTL\n",
    "    # It does not hurt if Padding is not present, as it will do nothing\n",
    "    FMPadding_node = model.get_nodes_by_op_type(\"FMPadding\")\n",
    "    i = 0\n",
    "    for node in FMPadding_node:\n",
    "        node_inst = getCustomOp(node)\n",
    "        node_inst.set_nodeattr(\"preferred_impl_style\", \"hls\")\n",
    "        print(f'Node {i}: {node}')\n",
    "        i += 1  \n",
    "    \n",
    "    # Change all MVAU to RTL, which is more optimized\n",
    "    # It does not work:\n",
    "        # Warning\n",
    "    # /home/gmoreno/uav/finn/src/finn/transformation/fpgadataflow/specialize_layers.py:143: \n",
    "    # UserWarning: There is no RTL variant for MVAU_17. The node will automatically be\n",
    "    # set to HLS variant. Please check the bit-widths to be <= 8 and ensure the\n",
    "    # thresholds are implemented as standalone layer\n",
    "    #\n",
    "    MVAU_node = model.get_nodes_by_op_type(\"MVAU\")\n",
    "    j = 0\n",
    "    for node in MVAU_node:\n",
    "        node_inst = getCustomOp(node)\n",
    "        node_inst.set_nodeattr(\"preferred_impl_style\", \"rtl\")\n",
    "        print(f'Node {j}: {node}')\n",
    "        j += 1\n",
    "    \n",
    "    # Specialize\n",
    "    model = model.transform(SpecializeLayers(cfg._resolve_fpga_part()))\n",
    "    model = model.transform(InferShapes())\n",
    "    model = model.transform(InferDataTypes())   \n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    model = model.transform(GiveReadableTensorNames())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e0f8e-0679-4c51-ae94-52d6922d8461",
   "metadata": {},
   "source": [
    "# FPGA Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e0f8bb0-51c8-48c9-aedf-037a2a0f3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.basic import pynq_part_map\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c207e43-1605-4e93-9005-e6183f107552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Board</th>\n",
       "      <th>FPGA Part</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ultra96</td>\n",
       "      <td>xczu3eg-sbva484-1-e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ultra96-V2</td>\n",
       "      <td>xczu3eg-sbva484-1-i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pynq-Z1</td>\n",
       "      <td>xc7z020clg400-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pynq-Z2</td>\n",
       "      <td>xc7z020clg400-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZCU102</td>\n",
       "      <td>xczu9eg-ffvb1156-2-e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ZCU104</td>\n",
       "      <td>xczu7ev-ffvc1156-2-e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ZCU111</td>\n",
       "      <td>xczu28dr-ffvg1517-2-e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RFSoC2x2</td>\n",
       "      <td>xczu28dr-ffvg1517-2-e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RFSoC4x2</td>\n",
       "      <td>xczu48dr-ffvg1517-2-e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KV260_SOM</td>\n",
       "      <td>xck26-sfvc784-2LV-c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Board              FPGA Part\n",
       "0     Ultra96    xczu3eg-sbva484-1-e\n",
       "1  Ultra96-V2    xczu3eg-sbva484-1-i\n",
       "2     Pynq-Z1        xc7z020clg400-1\n",
       "3     Pynq-Z2        xc7z020clg400-1\n",
       "4      ZCU102   xczu9eg-ffvb1156-2-e\n",
       "5      ZCU104   xczu7ev-ffvc1156-2-e\n",
       "6      ZCU111  xczu28dr-ffvg1517-2-e\n",
       "7    RFSoC2x2  xczu28dr-ffvg1517-2-e\n",
       "8    RFSoC4x2  xczu48dr-ffvg1517-2-e\n",
       "9   KV260_SOM    xck26-sfvc784-2LV-c"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpga_df = pd.DataFrame(pynq_part_map.items(), columns=['Board', 'FPGA Part'])\n",
    "fpga_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b64e5853-8786-4504-b41a-458f5da34c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this if you have a different PYNQ board, see list above\n",
    "pynq_board = \"Pynq-Z1\"\n",
    "fpga_part = pynq_part_map[pynq_board]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4069398-ce9f-4ea4-a067-7260ba425585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xc7z020clg400-1\n"
     ]
    }
   ],
   "source": [
    "print(fpga_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b6e7598-c2e8-45e3-b141-75b076c53ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/aimet_onnx/BED_classifier__best_mean_F1__AIMET_Balanced__BIPOLAR_Out__QONNX.onnx\n"
     ]
    }
   ],
   "source": [
    "model_file = brevitas_cpu\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320cb88-e841-4abc-a690-5fff85a0dc04",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e10a8c99-c5a3-49fc-a692-4c53beb01de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_target_fps = 16\n",
    "my_mvau_wwidth_max = 80\n",
    "my_default_swg_exception = True\n",
    "my_standalone_thresholds = True\n",
    "my_auto_fifo_depths = True\n",
    "my_auto_fifo_strategy = \"largefifo_rtlsim\"\n",
    "my_split_large_fifos = True\n",
    "my_folding_config_file = \"./experiments_pynq-z1\" + \"/final_hw_config_edited_16FPS_balanced_v0.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a391c5-af4f-4426-ac7f-345bf0a1310b",
   "metadata": {},
   "source": [
    "# Build estimate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3392e878-1927-4360-8d58-75402552e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66c7d74d-229d-44e8-a0c4-35bb38951a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder does not exist and it will be created\n"
     ]
    }
   ],
   "source": [
    "estimates_output_dir = config.RUN_FOLDER + \"output_estimates_only\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "else:\n",
    "    print(\"Folder does not exist and it will be created\")\n",
    "\n",
    "my_estimate_steps = [\n",
    "    custom_step_add_pre_proc,\n",
    "    \"step_qonnx_to_finn\",\n",
    "    \"step_tidy_up\",\n",
    "    custom_step_streamline,\n",
    "    custom_step_convert_to_hw,\n",
    "    \"step_create_dataflow_partition\",\n",
    "    custom_step_specialize_layers,\n",
    "    \"step_target_fps_parallelization\",\n",
    "    \"step_apply_folding_config\",\n",
    "    \"step_minimize_bit_width\",\n",
    "    \"step_generate_estimate_reports\",\n",
    "]\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir                    = estimates_output_dir,\n",
    "    mvau_wwidth_max               = my_mvau_wwidth_max,#36,\n",
    "    target_fps                    = my_target_fps,\n",
    "    synth_clk_period_ns           = 10.0,\n",
    "    board                         = pynq_board,\n",
    "    fpga_part                     = fpga_part,\n",
    "    shell_flow_type               = build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "    standalone_thresholds         = my_standalone_thresholds,\n",
    "    default_swg_exception         = my_default_swg_exception, # Change to True to optimize ConvGenerators, removing FIFOs\n",
    "    auto_fifo_depths              = my_auto_fifo_depths,\n",
    "    auto_fifo_strategy            = my_auto_fifo_strategy, #\"characterize\", -> the other option, takes toooo long\n",
    "    split_large_fifos             = my_split_large_fifos, # Change to True to save resources\n",
    "\n",
    "    steps                         = my_estimate_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b22af7-20ef-4ec0-b1d0-69bc2459cbf7",
   "metadata": {},
   "source": [
    "# Build FULL Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22a981b1-30b2-4d29-962e-3f218d4d2385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder does not exist and it will be created\n"
     ]
    }
   ],
   "source": [
    "full_build_output_dir = config.RUN_FOLDER + \"output_full_build\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(full_build_output_dir):\n",
    "    shutil.rmtree(full_build_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "else:\n",
    "    print(\"Folder does not exist and it will be created\")\n",
    "\n",
    "my_build_steps = [\n",
    "    custom_step_add_pre_proc,\n",
    "    \"step_qonnx_to_finn\",\n",
    "    \"step_tidy_up\",\n",
    "    custom_step_streamline,\n",
    "    custom_step_convert_to_hw,\n",
    "    \"step_create_dataflow_partition\",\n",
    "    custom_step_specialize_layers,\n",
    "    \"step_target_fps_parallelization\",\n",
    "    \"step_apply_folding_config\",\n",
    "    \"step_minimize_bit_width\",\n",
    "    \"step_generate_estimate_reports\",\n",
    "    \"step_hw_codegen\",\n",
    "    \"step_hw_ipgen\",\n",
    "    \"step_set_fifo_depths\",\n",
    "    \"step_create_stitched_ip\",\n",
    "    #\"step_measure_rtlsim_performance\",\n",
    "    \"step_out_of_context_synthesis\",\n",
    "    \"step_synthesize_bitfile\",\n",
    "    \"step_make_pynq_driver\",\n",
    "    \"step_deployment_package\",\n",
    "]\n",
    "\n",
    "cfg_full_build = build.DataflowBuildConfig(\n",
    "    output_dir                    = full_build_output_dir,\n",
    "    mvau_wwidth_max               = my_mvau_wwidth_max, #36,\n",
    "    target_fps                    = my_target_fps,\n",
    "    synth_clk_period_ns           = 10.0,\n",
    "    board                         = pynq_board,\n",
    "    fpga_part                     = fpga_part,\n",
    "    shell_flow_type               = build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "    standalone_thresholds         = my_standalone_thresholds,\n",
    "    default_swg_exception         = my_default_swg_exception, # Change to True to optimize ConvGenerators, removing FIFOs\n",
    "    auto_fifo_depths              = my_auto_fifo_depths,\n",
    "    auto_fifo_strategy            = my_auto_fifo_strategy, #\"characterize\", -> the other option, takes toooo long\n",
    "    split_large_fifos             = my_split_large_fifos, # Change to True to save resources\n",
    "\n",
    "    steps                         = my_build_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "        build_cfg.DataflowOutputType.BITFILE,\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abc46cb-5da7-4d67-9adb-78d4b0156065",
   "metadata": {},
   "source": [
    "# Build using JSON file for Folding or FIFO sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b3df90f-5990-4067-972f-45b2cd306eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder does not exist and it will be created\n"
     ]
    }
   ],
   "source": [
    "full_build_output_dir = config.RUN_FOLDER + \"output_full_build\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(full_build_output_dir):\n",
    "    shutil.rmtree(full_build_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "else:\n",
    "    print(\"Folder does not exist and it will be created\")\n",
    "\n",
    "my_build_json_steps = [\n",
    "    custom_step_add_pre_proc,\n",
    "    \"step_qonnx_to_finn\",\n",
    "    \"step_tidy_up\",\n",
    "    custom_step_streamline,\n",
    "    custom_step_convert_to_hw,\n",
    "    \"step_create_dataflow_partition\",\n",
    "    custom_step_specialize_layers,\n",
    "    \"step_target_fps_parallelization\",\n",
    "    \"step_apply_folding_config\",\n",
    "    \"step_minimize_bit_width\",\n",
    "    \"step_generate_estimate_reports\",\n",
    "    \"step_hw_codegen\",\n",
    "    \"step_hw_ipgen\",\n",
    "    \"step_set_fifo_depths\",\n",
    "    \"step_create_stitched_ip\",\n",
    "    \"step_measure_rtlsim_performance\",\n",
    "    \"step_out_of_context_synthesis\",\n",
    "    \"step_synthesize_bitfile\",\n",
    "    \"step_make_pynq_driver\",\n",
    "    \"step_deployment_package\",\n",
    "]\n",
    "\n",
    "cfg_full_build_json_folding = build.DataflowBuildConfig(\n",
    "    output_dir                    = full_build_output_dir,\n",
    "    #mvau_wwidth_max               = my_mvau_wwidth_max, #36,\n",
    "    #target_fps                    = my_target_fps,\n",
    "    synth_clk_period_ns           = 10.0,\n",
    "    board                         = pynq_board,\n",
    "    fpga_part                     = fpga_part,\n",
    "    shell_flow_type               = build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "    standalone_thresholds         = my_standalone_thresholds,\n",
    "    default_swg_exception         = my_default_swg_exception, # Change to True to optimize ConvGenerators, removing FIFOs\n",
    "    auto_fifo_depths              = my_auto_fifo_depths,\n",
    "    auto_fifo_strategy            = my_auto_fifo_strategy, #\"characterize\", -> the other option, takes toooo long\n",
    "    split_large_fifos             = my_split_large_fifos, # Change to True to save resources\n",
    "\n",
    "    steps                         = my_build_json_steps,\n",
    "    folding_config_file           = my_folding_config_file,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "        build_cfg.DataflowOutputType.BITFILE,\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c0309-a6e3-47b4-a850-50551fada8c6",
   "metadata": {},
   "source": [
    "# Choose type of build: estimate, full build or build with json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e829246-2713-4d35-aa94-c0feb1980202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform: estimates\n"
     ]
    }
   ],
   "source": [
    "flow_config = \"estimates\"\n",
    "# flow_config = \"full_build\"\n",
    "# flow_config = \"full_build_json_folding\"\n",
    "\n",
    "if flow_config == \"estimates\":\n",
    "    current_build_config = cfg_estimates\n",
    "elif flow_config == \"full_build\":\n",
    "    current_build_config = cfg_full_build\n",
    "elif flow_config == \"full_build_json_folding\":\n",
    "    current_build_config = cfg_full_build_json_folding\n",
    "else:\n",
    "    raise ValueError(\"Wrong config\")\n",
    "\n",
    "print(f'Perform: {flow_config}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25af4f59-1711-47b2-8275-b8d953766c58",
   "metadata": {},
   "source": [
    "# Logging before build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b61950e-3fcd-4651-a303-677253306201",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f'PYNQ board: {pynq_board}\\n' +  \n",
    "            f'\\tModel used: {model_file}\\n' +\n",
    "            f'\\tTarget fps: my_target_fps: {my_target_fps}.\\n' +\n",
    "            f'\\tmvau_wwidth_max: {my_mvau_wwidth_max}.\\n'+ \n",
    "            f'\\tDefault sliding window exception: {my_default_swg_exception}.\\n'+ \n",
    "            f'\\tAuto FIFO depth: {my_auto_fifo_depths}.\\n'+ \n",
    "            f'\\tAuto FIFO strategy: {my_auto_fifo_strategy}.\\n'+ \n",
    "            f'\\tSplit large FIFOs: {my_split_large_fifos}.\\n'+ \n",
    "            f'\\tFolding JSON file: {my_folding_config_file}.\\n'+ \n",
    "            f'\\tFlow config: {flow_config}.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50be7c34-7b1c-45ed-b959-3b5e2dc08776",
   "metadata": {},
   "source": [
    "# Build command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "400add5d-a3a9-4dd6-9c1f-ccd173d2e71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from ./models/aimet_onnx/BED_classifier__best_mean_F1__AIMET_Balanced__BIPOLAR_Out__QONNX.onnx\n",
      "Intermediate outputs will be generated in /home/gmoreno/workspace\n",
      "Final outputs will be generated in experiments_pynq-z1/09_pynq-z1__16FPS__workspace__AIMET_Balanced__BIPOLAR__w4W2a4__estimates/output_estimates_only\n",
      "Build log is at experiments_pynq-z1/09_pynq-z1__16FPS__workspace__AIMET_Balanced__BIPOLAR__w4W2a4__estimates/output_estimates_only/build_dataflow.log\n",
      "Running step: custom_step_add_pre_proc [1/11]\n",
      "Running step: step_qonnx_to_finn [2/11]\n",
      "Running step: step_tidy_up [3/11]\n",
      "Running step: custom_step_streamline [4/11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/gmoreno/uav/finn/src/finn/builder/build_dataflow.py\", line 158, in build_dataflow_cfg\n",
      "    model = transform_step(model, cfg)\n",
      "  File \"/tmp/ipykernel_28677/498140205.py\", line 12, in custom_step_convert_to_hw\n",
      "    model = model.transform(to_hw.InferThresholdingLayer())\n",
      "  File \"/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/core/modelwrapper.py\", line 140, in transform\n",
      "    (transformed_model, model_was_changed) = transformation.apply(transformed_model)\n",
      "  File \"/home/gmoreno/uav/finn/src/finn/transformation/fpgadataflow/convert_to_hw_layers.py\", line 236, in apply\n",
      "    assert scale == 1.0, (\n",
      "AssertionError: MultiThreshold_19: MultiThreshold out_scale must be 1 for HLS conversion.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step: custom_step_convert_to_hw [5/11]\n",
      "> \u001b[0;32m/home/gmoreno/uav/finn/src/finn/transformation/fpgadataflow/convert_to_hw_layers.py\u001b[0m(236)\u001b[0;36mapply\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    234 \u001b[0;31m                \u001b[0modt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_datatype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthl_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    235 \u001b[0;31m                \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetCustomOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nodeattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"out_scale\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 236 \u001b[0;31m                assert scale == 1.0, (\n",
      "\u001b[0m\u001b[0;32m    237 \u001b[0;31m                    \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\": MultiThreshold out_scale must be 1 for HLS conversion.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    238 \u001b[0;31m                )\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build failed\n",
      "CPU times: user 13.2 s, sys: 510 ms, total: 13.7 s\n",
      "Wall time: 2min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, current_build_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be292d-b169-4016-bf86-0e33a9859f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
