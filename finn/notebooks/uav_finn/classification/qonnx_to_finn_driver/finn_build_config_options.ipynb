{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a391c5-af4f-4426-ac7f-345bf0a1310b",
   "metadata": {},
   "source": [
    "# Build estimate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3392e878-1927-4360-8d58-75402552e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showSrc, showInNetron\n",
    "\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import finn.builder.build_dataflow_steps as build_dataflow_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "388f5701-6565-4c73-9cce-e0227baffa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_qonnx_to_finn\n",
      "step_tidy_up\n",
      "step_streamline\n",
      "step_convert_to_hw\n",
      "step_create_dataflow_partition\n",
      "step_specialize_layers\n",
      "step_target_fps_parallelization\n",
      "step_apply_folding_config\n",
      "step_minimize_bit_width\n",
      "step_generate_estimate_reports\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(build_cfg.estimate_only_dataflow_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2a0d183-7b16-4f5b-ad57-6f7d1bf26bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def step_qonnx_to_finn(model: ModelWrapper, cfg: DataflowBuildConfig):\n",
      "    \"\"\"\n",
      "    This step will only execute if QONNX nodes are found.\n",
      "    These include the following op_types: \"Quant\" , \"Trunc\" and \"BinaryQuant\".\n",
      "    If such nodes are found the step will run the tidy-up step from QONNX\n",
      "    and then convert the QONNX model to the FINN-ONNX dialect.\n",
      "    \"\"\"\n",
      "    # Check if any QONNX nodes exist, i.e. BinaryQuant, Quant or Trunc\n",
      "    q_count = 0\n",
      "    for op_type in [\"BinaryQuant\", \"Quant\", \"Trunc\"]:\n",
      "        q_count += len(model.get_nodes_by_op_type(op_type))\n",
      "    if q_count == 0:\n",
      "        return model\n",
      "\n",
      "    # QONNX cleanup\n",
      "    model = cleanup_model(model)\n",
      "    # QONNX to FINN-ONNX\n",
      "    model = model.transform(\n",
      "        ConvertQONNXtoFINN(\n",
      "            filter_function=default_filter_function_generator(\n",
      "                max_multithreshold_bit_width=cfg.max_multithreshold_bit_width\n",
      "            )\n",
      "        )\n",
      "    )\n",
      "\n",
      "    if VerificationStepType.QONNX_TO_FINN_PYTHON in cfg._resolve_verification_steps():\n",
      "        verify_step(model, cfg, \"qonnx_to_finn_python\", need_parent=False)\n",
      "\n",
      "    return model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "showSrc(build_dataflow_steps.step_qonnx_to_finn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e920bd84-9603-4e68-95e3-e330d7e7861d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def step_tidy_up(model: ModelWrapper, cfg: DataflowBuildConfig):\n",
      "    \"\"\"Run the tidy-up step on given model. This includes shape and datatype\n",
      "    inference, constant folding, and giving nodes and tensors better names.\n",
      "    \"\"\"\n",
      "\n",
      "    model = model.transform(InferShapes())\n",
      "    model = model.transform(FoldConstants())\n",
      "    model = model.transform(GiveUniqueNodeNames())\n",
      "    model = model.transform(GiveReadableTensorNames())\n",
      "    model = model.transform(InferDataTypes())\n",
      "    model = model.transform(RemoveStaticGraphInputs())\n",
      "\n",
      "    if VerificationStepType.TIDY_UP_PYTHON in cfg._resolve_verification_steps():\n",
      "        verify_step(model, cfg, \"initial_python\", need_parent=False)\n",
      "\n",
      "    return model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "showSrc(build_dataflow_steps.step_tidy_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "662cf34d-f879-43ea-9fb3-58c9758c7fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class VerificationStepType(str, Enum):\n",
      "    \"Steps at which FINN ONNX execution can be launched for verification.\"\n",
      "\n",
      "    #: verify after step_qonnx_to_finn, using Python execution\n",
      "    QONNX_TO_FINN_PYTHON = \"finn_onnx_python\"\n",
      "    #: verify after step_tidy_up, using Python execution\n",
      "    TIDY_UP_PYTHON = \"initial_python\"\n",
      "    #: verify after step_streamline , using Python execution\n",
      "    STREAMLINED_PYTHON = \"streamlined_python\"\n",
      "    #: verify after step_apply_folding_config, using C++ for each HLS node\n",
      "    FOLDED_HLS_CPPSIM = \"folded_hls_cppsim\"\n",
      "    #: verify after step_create_stitched_ip, using stitched-ip Verilog\n",
      "    STITCHED_IP_RTLSIM = \"stitched_ip_rtlsim\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "showSrc(build_cfg.VerificationStepType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5de82f7d-b36f-4dc6-ada3-3b02b64000dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def step_streamline(model: ModelWrapper, cfg: DataflowBuildConfig):\n",
      "    \"\"\"Run streamlining on given model. Streamlining involves moving floating point\n",
      "    scale/shift parameters around, collapsing adjacent ones into a single parameter,\n",
      "    then absorbing the scale/shift into the following `MultiThreshold` node.\n",
      "    Streamlining requires careful topology design and cannot be applied to all\n",
      "    topologies.\n",
      "    \"\"\"\n",
      "\n",
      "    model = model.transform(absorb.AbsorbSignBiasIntoMultiThreshold())\n",
      "    model = model.transform(Streamline())\n",
      "    need_lowering = len(model.get_nodes_by_op_type(\"Conv\")) > 0\n",
      "    if need_lowering:\n",
      "        model = model.transform(LowerConvsToMatMul())\n",
      "        model = model.transform(MakeMaxPoolNHWC())\n",
      "        model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
      "        model = model.transform(MakeMaxPoolNHWC())\n",
      "        model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
      "    model = model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
      "    model = model.transform(Streamline())\n",
      "    # absorb final add-mul nodes into TopK\n",
      "    model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
      "    model = model.transform(InferDataLayouts())\n",
      "    model = model.transform(RemoveUnusedTensors())\n",
      "\n",
      "    if VerificationStepType.STREAMLINED_PYTHON in cfg._resolve_verification_steps():\n",
      "        verify_step(model, cfg, \"streamlined_python\", need_parent=False)\n",
      "\n",
      "    return model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "showSrc(build_dataflow_steps.step_streamline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b88da744-476e-4dcb-b6f3-5c6d7cf94299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def step_create_dataflow_partition(model: ModelWrapper, cfg: DataflowBuildConfig):\n",
      "    \"\"\"Separate consecutive groups of HWCustomOp nodes into StreamingDataflowPartition\n",
      "    nodes, which point to a separate ONNX file. Dataflow accelerator synthesis\n",
      "    can only be performed on those HWCustomOp sub-graphs.\"\"\"\n",
      "\n",
      "    parent_model = model.transform(\n",
      "        CreateDataflowPartition(\n",
      "            partition_model_dir=cfg.output_dir + \"/intermediate_models/supported_op_partitions\"\n",
      "        )\n",
      "    )\n",
      "    sdp_nodes = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")\n",
      "    assert len(sdp_nodes) == 1, \"Only a single StreamingDataflowPartition supported.\"\n",
      "    sdp_node = sdp_nodes[0]\n",
      "    sdp_node = getCustomOp(sdp_node)\n",
      "    dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
      "    if cfg.save_intermediate_models:\n",
      "        parent_model.save(cfg.output_dir + \"/intermediate_models/dataflow_parent.onnx\")\n",
      "    model = ModelWrapper(dataflow_model_filename)\n",
      "\n",
      "    # create a configuration json file that can be used to set the specialize layer config\n",
      "    attrs = [\n",
      "        \"preferred_impl_style\",\n",
      "    ]\n",
      "    extract_model_config_to_json(\n",
      "        model, cfg.output_dir + \"/template_specialize_layers_config.json\", attrs\n",
      "    )\n",
      "\n",
      "    return model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "showSrc(build_dataflow_steps.step_create_dataflow_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a36223d-479f-430d-9904-d18c69c9db69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def step_convert_to_hw(model: ModelWrapper, cfg: DataflowBuildConfig):\n",
      "    \"\"\"Convert eligible nodes to `HWCustomOp` subclasses that represent HW\n",
      "    layers. Which nodes and particular configurations can be converted to HW\n",
      "    is limited, see the source code of the `convert_to_hw` module for more.\n",
      "    In the end am empty json file is created which can be used to set user specific\n",
      "    preferred implementation styles for each node.\"\"\"\n",
      "\n",
      "    if cfg.standalone_thresholds:\n",
      "        # doing this first causes all threshold layers to be standalone\n",
      "        model = model.transform(to_hw.InferThresholdingLayer())\n",
      "    # needed for bipolar MatMul layers\n",
      "    model = model.transform(to_hw.InferBinaryMatrixVectorActivation())\n",
      "    # needed for non-bipolar MatMul layers\n",
      "    model = model.transform(to_hw.InferQuantizedMatrixVectorActivation())\n",
      "    # TopK to LabelSelect\n",
      "    model = model.transform(to_hw.InferLabelSelectLayer())\n",
      "    # input quantization (if any) as standalone threshold\n",
      "    model = model.transform(to_hw.InferThresholdingLayer())\n",
      "    # needed for convolutions -- TODO always exec?\n",
      "    need_conv = len(model.get_nodes_by_op_type(\"Im2Col\")) > 0\n",
      "    if need_conv:\n",
      "        model = model.transform(to_hw.InferConvInpGen())\n",
      "        model = model.transform(to_hw.InferStreamingMaxPool())\n",
      "        model = model.transform(RemoveCNVtoFCFlatten())\n",
      "    # get rid of Tranpose -> Tranpose identity seq\n",
      "    model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
      "    model = model.transform(GiveUniqueNodeNames())\n",
      "    model = model.transform(InferDataLayouts())\n",
      "\n",
      "    return model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "showSrc(build_dataflow_steps.step_convert_to_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61708156-5862-49d5-9565-04c24bdf6dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_qonnx_to_finn\n",
      "step_tidy_up\n",
      "step_streamline\n",
      "step_convert_to_hw\n",
      "step_create_dataflow_partition\n",
      "step_specialize_layers\n",
      "step_target_fps_parallelization\n",
      "step_apply_folding_config\n",
      "step_minimize_bit_width\n",
      "step_generate_estimate_reports\n",
      "step_hw_codegen\n",
      "step_hw_ipgen\n",
      "step_set_fifo_depths\n",
      "step_create_stitched_ip\n",
      "step_measure_rtlsim_performance\n",
      "step_out_of_context_synthesis\n",
      "step_synthesize_bitfile\n",
      "step_make_pynq_driver\n",
      "step_deployment_package\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(build_cfg.default_build_dataflow_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e3fd979-2ff1-4cbe-a084-949b94fc2538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def step_specialize_layers(model: ModelWrapper, cfg: DataflowBuildConfig):\n",
      "    \"\"\"Convert HW nodes to either an HLS or RTL variant of the node. HW nodes\n",
      "    get converted either based on pre-determined rules (details can be found\n",
      "    in `specialize_layers` source code) or the user provides a configuration file\n",
      "    which contains the desired setting. If the user preference cannot be fulfilled,\n",
      "    a warning will be printed and the implementation style will be set to a default.\"\"\"\n",
      "\n",
      "    if cfg.specialize_layers_config_file is not None:\n",
      "        model = model.transform(GiveUniqueNodeNames())\n",
      "        model = model.transform(ApplyConfig(cfg.specialize_layers_config_file))\n",
      "    model = model.transform(SpecializeLayers(cfg._resolve_fpga_part()))\n",
      "    model = model.transform(InferShapes())\n",
      "    model = model.transform(InferDataTypes())\n",
      "    return model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "showSrc(build_dataflow_steps.step_specialize_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e3bd50f-febf-4b22-b7ec-7dc9e283420c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def step_minimize_bit_width(model: ModelWrapper, cfg: DataflowBuildConfig):\n",
      "    \"\"\"Tighten the weight and accumulator bit widths for each layer.\"\"\"\n",
      "    if cfg.minimize_bit_width:\n",
      "        model = model.transform(MinimizeWeightBitWidth())\n",
      "        model = model.transform(MinimizeAccumulatorWidth())\n",
      "        # make sure the changed datatypes are propagated through the network\n",
      "        model = model.transform(InferDataTypes())\n",
      "    return model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "showSrc(build_dataflow_steps.step_minimize_bit_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed9374b7-5c69-4858-8a79-f3e8124b03b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def step_hw_codegen(model: ModelWrapper, cfg: DataflowBuildConfig):\n",
      "    \"\"\"Generate Vitis HLS code to prepare HLSBackend nodes for IP generation.\n",
      "    And fills RTL templates for RTLBackend nodes.\"\"\"\n",
      "\n",
      "    model = model.transform(PrepareIP(cfg._resolve_fpga_part(), cfg._resolve_hls_clk_period()))\n",
      "    return model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "showSrc(build_dataflow_steps.step_hw_codegen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63ab008e-6800-4cbb-8b80-0ccef3c7adf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def step_hw_ipgen(model: ModelWrapper, cfg: DataflowBuildConfig):\n",
      "    \"\"\"Run Vitis HLS synthesis on generated code for HLSBackend nodes,\n",
      "    in order to generate IP blocks. For RTL nodes this step does not do anything.\"\"\"\n",
      "\n",
      "    model = model.transform(HLSSynthIP())\n",
      "    model = model.transform(ReplaceVerilogRelPaths())\n",
      "    report_dir = cfg.output_dir + \"/report\"\n",
      "    os.makedirs(report_dir, exist_ok=True)\n",
      "    estimate_layer_resources_hls = model.analysis(hls_synth_res_estimation)\n",
      "    with open(report_dir + \"/estimate_layer_resources_hls.json\", \"w\") as f:\n",
      "        json.dump(estimate_layer_resources_hls, f, indent=2)\n",
      "    return model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "showSrc(build_dataflow_steps.step_hw_ipgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "674f65ce-999e-454f-927b-a32954b3e147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def step_set_fifo_depths(model: ModelWrapper, cfg: DataflowBuildConfig):\n",
      "    \"\"\"\n",
      "    Depending on the auto_fifo_depths setting, do one of the following:\n",
      "    * if auto_fifo_depths=True:  Run the appropriate auto-sizing transformation\n",
      "    to attempt to determine the FIFO sizes that provide full throughput.\n",
      "    May take a long time.\n",
      "    * if auto_fifo_depths=False:  Assume the folding config file contains FIFO\n",
      "    sizes as well. Runs the `InsertFIFO` transformation, then\n",
      "    `ApplyConfig(cfg.folding_config_file)`, and finally `RemoveShallowFIFOs`.\n",
      "    Coherency with config file node naming is ensured by calling\n",
      "    `GiveUniqueNodeNames`.\n",
      "    \"\"\"\n",
      "\n",
      "    if cfg.auto_fifo_depths:\n",
      "        if cfg.auto_fifo_strategy == \"characterize\":\n",
      "            model = model.transform(InsertDWC())\n",
      "            model = model.transform(SpecializeLayers(cfg._resolve_fpga_part()))\n",
      "            model = model.transform(GiveUniqueNodeNames())\n",
      "            model = model.transform(\n",
      "                PrepareIP(cfg._resolve_fpga_part(), cfg._resolve_hls_clk_period())\n",
      "            )\n",
      "            model = model.transform(HLSSynthIP())\n",
      "            model = model.transform(PrepareRTLSim())\n",
      "            model = model.transform(AnnotateCycles())\n",
      "            period = model.analysis(dataflow_performance)[\"max_cycles\"] + 10\n",
      "            model = model.transform(DeriveCharacteristic(period))\n",
      "            model = model.transform(DeriveFIFOSizes())\n",
      "            model = model.transform(\n",
      "                InsertFIFO(\n",
      "                    vivado_ram_style=cfg.large_fifo_mem_style,\n",
      "                    max_qsrl_depth=256,\n",
      "                    create_shallow_fifos=True,\n",
      "                )\n",
      "            )\n",
      "            model = model.transform(SpecializeLayers(cfg._resolve_fpga_part()))\n",
      "            model = model.transform(GiveUniqueNodeNames())\n",
      "            model = model.transform(GiveReadableTensorNames())\n",
      "        elif cfg.auto_fifo_strategy == \"largefifo_rtlsim\":\n",
      "            # multi-in/out streams currently not supported in our C++ verilator driver\n",
      "            model_multi_io = len(model.graph.input) > 1 or len(model.graph.output) > 1\n",
      "            force_python_sim = model_multi_io or cfg.force_python_rtlsim\n",
      "            if model_multi_io:\n",
      "                warnings.warn(\n",
      "                    \"Multi-in/out streams currently not supported \"\n",
      "                    + \"in FINN C++ verilator driver, falling back to Python\"\n",
      "                )\n",
      "            model = model.transform(\n",
      "                InsertAndSetFIFODepths(\n",
      "                    cfg._resolve_fpga_part(),\n",
      "                    cfg._resolve_hls_clk_period(),\n",
      "                    swg_exception=cfg.default_swg_exception,\n",
      "                    vivado_ram_style=cfg.large_fifo_mem_style,\n",
      "                    force_python_sim=force_python_sim,\n",
      "                )\n",
      "            )\n",
      "            # InsertAndSetFIFODepths internally removes any shallow FIFOs\n",
      "            # so no need to call RemoveShallowFIFOs here\n",
      "        else:\n",
      "            assert \"Unsupported auto_fifo_strategy: \" + cfg.auto_fifo_strategy\n",
      "    else:\n",
      "        # assume folding cfg json contains FIFO sizes too\n",
      "        # insert DWCs, FIFOs and run ApplyConfig once more\n",
      "        model = model.transform(InsertDWC())\n",
      "        # need to make sure all FIFOs are created so that their depth can be\n",
      "        # set by ApplyConfig, so create_shallow_fifos=True\n",
      "        model = model.transform(InsertFIFO(create_shallow_fifos=True))\n",
      "        model = model.transform(SpecializeLayers(cfg._resolve_fpga_part()))\n",
      "        model = model.transform(GiveUniqueNodeNames())\n",
      "        model = model.transform(GiveReadableTensorNames())\n",
      "        if cfg.folding_config_file is not None:\n",
      "            model = model.transform(ApplyConfig(cfg.folding_config_file))\n",
      "\n",
      "    # extract the final configuration and save it as json\n",
      "    hw_attrs = [\n",
      "        \"PE\",\n",
      "        \"SIMD\",\n",
      "        \"parallel_window\",\n",
      "        \"ram_style\",\n",
      "        \"depth\",\n",
      "        \"impl_style\",\n",
      "        \"resType\",\n",
      "        \"mem_mode\",\n",
      "        \"runtime_writeable_weights\",\n",
      "        \"inFIFODepths\",\n",
      "        \"outFIFODepths\",\n",
      "        \"depth_trigger_uram\",\n",
      "        \"depth_trigger_bram\",\n",
      "    ]\n",
      "    extract_model_config_to_json(model, cfg.output_dir + \"/final_hw_config.json\", hw_attrs)\n",
      "\n",
      "    # perform FIFO splitting and shallow FIFO removal only after the final config\n",
      "    # json file has been written. otherwise, since these transforms may add/remove\n",
      "    # FIFOs, we get name mismatch problems when trying to reuse the final config.\n",
      "    if cfg.split_large_fifos:\n",
      "        model = model.transform(SplitLargeFIFOs())\n",
      "    model = model.transform(RemoveShallowFIFOs())\n",
      "\n",
      "    # after FIFOs are ready to go, call PrepareIP and HLSSynthIP again\n",
      "    # this will only run for the new nodes (e.g. FIFOs and DWCs)\n",
      "    model = model.transform(PrepareIP(cfg._resolve_fpga_part(), cfg._resolve_hls_clk_period()))\n",
      "    model = model.transform(HLSSynthIP())\n",
      "    return model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "showSrc(build_dataflow_steps.step_set_fifo_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67d9d7a-a89e-4f06-a278-1e69a264c63a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
