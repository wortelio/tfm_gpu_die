{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "788cab8d-76f6-48f2-bbc1-295390464d01",
   "metadata": {},
   "source": [
    "# No Funciona\n",
    "\n",
    "Parece que no funciona porque el Bias tiene escala interna y la conversión no lo tiene en cuenta\n",
    "\n",
    "Mejor entrenar con BatchNorm, eliminar el Bias y luego quitárselo con el streamline de FINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5be61a68-a646-43a4-8783-9ac253accad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "from finn.util.test import get_test_model_trained\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "\n",
    "import numpy as np\n",
    "import qonnx.core.onnx_exec as oxe\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d0d6405-1192-475c-8bdf-39f630b7b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.qcdq_to_qonnx import QCDQToQuant\n",
    "from qonnx.transformation.extract_conv_bias import ExtractBiasFromConv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b015b6a-ebc1-40e2-ab9f-cd25fb75621f",
   "metadata": {},
   "source": [
    "# Clean QCDQ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f87f12f-3d3b-4984-9ef6-528aa6847bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_onnx = 'BED__no_comp__best_mean_f1__cpu.onnx'\n",
    "clean_onnx = 'BED_classifier__best_mean_F1__QCDQ__clean.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e525cfc-f5f9-494a-b404-675637bdff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "qonnx_cleanup(ori_onnx, out_file=clean_onnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c40298-a066-423c-befd-abd4ba26bfef",
   "metadata": {},
   "source": [
    "# Convert QCDQ to QONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d08e21b-5765-4b0b-9dff-d51ad720d31c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (32,3,3,3) (32,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m ModelWrapper(clean_onnx)\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(ExtractBiasFromConv())\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQCDQToQuant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/core/modelwrapper.py:140\u001b[0m, in \u001b[0;36mModelWrapper.transform\u001b[0;34m(self, transformation, make_deepcopy, cleanup)\u001b[0m\n\u001b[1;32m    138\u001b[0m model_was_changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m model_was_changed:\n\u001b[0;32m--> 140\u001b[0m     (transformed_model, model_was_changed) \u001b[38;5;241m=\u001b[39m \u001b[43mtransformation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m    142\u001b[0m     transformed_model\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/qcdq_to_qonnx.py:127\u001b[0m, in \u001b[0;36mQCDQToQuant.apply\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    125\u001b[0m (bitwidth, signed, narrow) \u001b[38;5;241m=\u001b[39m extract_elem_type(q_vi\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mtensor_type\u001b[38;5;241m.\u001b[39melem_type)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# overwrite DQ initializer with scaled version\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m scaled_qnt_t \u001b[38;5;241m=\u001b[39m (\u001b[43mdq_init\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdq_zeropt_v\u001b[49m) \u001b[38;5;241m*\u001b[39m dq_scale_v\n\u001b[1;32m    128\u001b[0m scaled_qnt_t \u001b[38;5;241m=\u001b[39m scaled_qnt_t\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    129\u001b[0m model\u001b[38;5;241m.\u001b[39mset_initializer(dq_inp, scaled_qnt_t)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (32,3,3,3) (32,) "
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(clean_onnx)\n",
    "model = model.transform(ExtractBiasFromConv())\n",
    "model = model.transform(QCDQToQuant())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92d5b0-1166-4468-b4fe-4eec3f819ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
