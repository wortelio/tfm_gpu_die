{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "719af929-1f81-4c5a-bfa4-1d45ba1d942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "from brevitas.export import export_qonnx\n",
    "\n",
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "from finn.util.test import get_test_model_trained\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "\n",
    "import numpy as np\n",
    "import qonnx.core.onnx_exec as oxe\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f37ec5e-5577-49c5-bbae-00afe5f236bc",
   "metadata": {},
   "source": [
    "### Export to QONNX during training and test with DFire MINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7be0a8a1-6e61-4704-ba78-a4ecb080410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_onnx = 'BED_classifier__best_mean_F1__perChannel_fxPoint__QONNX.onnx'\n",
    "clean_onnx = 'BED_classifier__best_mean_F1_clean__perChannel_fxPoint__QONNX.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95089f8d-4875-4863-8d1b-9606f6191690",
   "metadata": {},
   "outputs": [],
   "source": [
    "qonnx_cleanup(ori_onnx, out_file=clean_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e34bbd8-9300-4ca3-9fca-5a5656946785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving 'BED_classifier__best_mean_F1__perChannel_fxPoint__QONNX.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb042bedab0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(ori_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1035b16-9a56-413c-b3f0-3ff9646c5303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving 'BED_classifier__best_mean_F1_clean__perChannel_fxPoint__QONNX.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb042bef7c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(clean_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db8cfc3e-f0b1-4609-b410-9336bb4d73eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_tidy_onnx =  'BED_classifier__best_mean_F1_finn_tidy__perChannel_fxPoint__QONNX.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5997dd4-0a00-4cde-9311-47ae0441c08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(clean_onnx)\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model.save(finn_tidy_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7f698f2-2ba8-4ad1-9c50-07c71ed6bd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving 'BED_classifier__best_mean_F1_finn_tidy__perChannel_fxPoint__QONNX.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb042bedfc0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_tidy_onnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9486879b-97df-430d-bd7c-e8082339675a",
   "metadata": {},
   "source": [
    "# Compare Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c06a1cc8-12f6-482e-a83e-ab133305b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_in = np.random.randint(low = 0, high = 255+1, size = (1, 3, 224, 224)) \n",
    "dummy_in = (dummy_in / 256.).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eae2359d-3b1a-482d-abc0-b928543d1ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ori_model = ModelWrapper(ori_onnx)\n",
    "clean_model = ModelWrapper(clean_onnx)\n",
    "finn_model = ModelWrapper(finn_tidy_onnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596967b-69c4-4466-b7c5-ad938fb9cd20",
   "metadata": {},
   "source": [
    "### Cleaned QONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f22786da-5144-4596-85ea-014d61ad8f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3982027, -2.1908169]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict = {\"global_in\": dummy_in}\n",
    "output_dict = oxe.execute_onnx(clean_model, input_dict)\n",
    "produced_clean_qonnx = output_dict[list(output_dict.keys())[0]]\n",
    "produced_clean_qonnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f795ad-972f-4e27-8ca4-1965b3a4d998",
   "metadata": {},
   "source": [
    "### FINN QONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78b7c553-1f25-4c64-b5fd-a5a1d30c5c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3982027, -2.1908169]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict = {\"global_in\": dummy_in}\n",
    "output_dict = oxe.execute_onnx(finn_model, input_dict)\n",
    "produced_finn_qonnx = output_dict[list(output_dict.keys())[0]]\n",
    "produced_finn_qonnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31643563-b279-4aff-841f-1a8a8922dcb3",
   "metadata": {},
   "source": [
    "# Compare with Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "678df304-6e6f-48aa-b5f1-a6eb4f47aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = './WEB10495.jpg' # Smoke and Fire\n",
    "#img_file = './WEB10980.jpg' # Only Smoke\n",
    "#img_file = './WEB10031.jpg' # Empty\n",
    "img = cv2.imread(img_file)\n",
    "img = cv2.imread(img_file)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
    "img = cv2.resize(img, (224,224), interpolation = cv2.INTER_LINEAR) \n",
    "img = img / 256.\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = np.transpose(img, (0, 3, 1, 2))\n",
    "img = img.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b266fad5-762a-4a13-a5a9-4267a61b1eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (1, 3, 224, 224)\n",
      "Data type: float32\n"
     ]
    }
   ],
   "source": [
    "print(f'Image shape: {img.shape}')\n",
    "print(f'Data type: {img.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e918859-309c-44b6-84de-80c7c30776ab",
   "metadata": {},
   "source": [
    "### Cleaned QONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb367365-3176-40bb-ad8a-08caa3c39dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6415325 , 0.50019217]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict = {\"global_in\": img}\n",
    "output_dict = oxe.execute_onnx(clean_model, input_dict)\n",
    "produced_clean_qonnx = output_dict[list(output_dict.keys())[0]]\n",
    "produced_clean_qonnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db5dc1-5c7e-4855-8b7b-dcebdc524ee0",
   "metadata": {},
   "source": [
    "### FINN QONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e47a245-b34d-453a-8c32-6ab4c0ca1ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6415325 , 0.50019217]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict = {\"global_in\": img}\n",
    "output_dict = oxe.execute_onnx(finn_model, input_dict)\n",
    "produced_finn_qonnx = output_dict[list(output_dict.keys())[0]]\n",
    "produced_finn_qonnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0f27e7-52c9-44a7-a146-cc5726e99423",
   "metadata": {},
   "source": [
    "# Add Preprocessing Node: /255. -> ToTensor, FINN function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ce28615-6348-4ec8-b922-c4197c5d4903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.pytorch import ToTensor\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.core.datatype import DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b708dc32-164c-40be-a6cd-eeb76b7abc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/merge_onnx_models.py:70: UserWarning: [MergeONNXModels] opsets for models to merge differ: 14 vs 17, output model will use opset 17\n",
      "  warnings.warn(\n",
      "/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(finn_tidy_onnx)\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "# preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "totensor_pyt = ToTensor()\n",
    "chkpt_preproc_name = \"./preproc_BED_input.onnx\"\n",
    "export_qonnx(totensor_pyt, torch.randn(ishape), chkpt_preproc_name)\n",
    "qonnx_cleanup(chkpt_preproc_name, out_file=chkpt_preproc_name)\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "pre_model = pre_model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "# join preprocessing and core model\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "# add input quantization annotation: UINT8 for all BNN-PYNQ models\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45e12c3-db8f-4480-99e2-babf7ff9a809",
   "metadata": {},
   "source": [
    "### Tidy up again and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79d96171-d742-4917-9988-c2f7123e0efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "\n",
    "finn_tidy_preprocess = 'BED_classifier__best_mean_F1_finn_prepro__perChannel_fxPoint__QONNX.onnx'\n",
    "model.save(finn_tidy_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3147cda-6032-401d-b1f9-9e33074c1000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
