{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "990fce3e-24f8-4e2b-9a92-3ba716faea5f",
   "metadata": {},
   "source": [
    "# Mobilenet Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa1f10b-4eba-4fd1-978b-6448998826ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = './mvau_wwidth_max'\n",
    "model_qnn_filename = models_folder + '/MY_MBLNET_V2_RESNET_classifier__best_mean_F1__BIPOLAR_Out__QONNX.onnx' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fed44b-915d-4f13-bf47-f09b669a065d",
   "metadata": {},
   "source": [
    "# FINN Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda68f6-24c1-4eb3-8796-62c91f570e47",
   "metadata": {},
   "source": [
    "## Load Model and View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf723b71-f555-490c-b185-776f73396c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showSrc, showInNetron\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dff265e-bed5-4efd-92a6-1ee06471f86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './mvau_wwidth_max/MY_MBLNET_V2_RESNET_classifier__best_mean_F1__BIPOLAR_Out__QONNX.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fadc82bafe0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(model_qnn_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52bb090-4801-4cd6-91f4-e86048dfcb11",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2150e426-3ba5-4aab-b680-78cd716e2ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qonnx_clean_filename = models_folder + '/01_clean.onnx'\n",
    "qonnx_cleanup(model_qnn_filename, out_file=qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d9a172-78a4-404f-be19-334b6747409d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './mvau_wwidth_max/01_clean.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fadc82badd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e71cacf-447e-4a5e-a628-1e4b5188b6a8",
   "metadata": {},
   "source": [
    "## Convert to FINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c2d3af5-b4df-47ba-af6b-2391ba0950c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89512ff2-3de9-435d-9ac0-459a5b4f30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "622516fa-c609-4dc0-86a4-19aafedaaa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/gemm_to_matmul.py:57: UserWarning: The GemmToMatMul transformation only offers explicit support for version 9 of the Gemm node, but the ONNX version of the supplied model is 17. Thus the transformation may fail or return incomplete results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(qonnx_clean_filename)\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(RemoveStaticGraphInputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b36e1b0a-eec1-476d-ac12-6919a911d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_tidy = models_folder + '/02_finn_tidy.onnx'\n",
    "model.save(finn_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb2c21cb-492c-4cee-8e1b-ec8784405cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './mvau_wwidth_max/02_finn_tidy.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fade8103c70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f9fec5-a30c-4d6f-8e50-4bfb3a674a3f",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b39deb7-0653-4b54-bb09-ac774320547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from brevitas.export import export_qonnx\n",
    "from finn.util.pytorch import ToTensor\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f39b02d-f548-4fb8-baa2-9bd0add11fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/merge_onnx_models.py:70: UserWarning: [MergeONNXModels] opsets for models to merge differ: 14 vs 17, output model will use opset 17\n",
      "  warnings.warn(\n",
      "/home/gmoreno/uav/finn/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(finn_tidy)\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "# preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "totensor_pyt = ToTensor()\n",
    "chkpt_preproc_name = models_folder + \"/prepro_node.onnx\"\n",
    "export_qonnx(totensor_pyt, torch.randn(ishape), chkpt_preproc_name)\n",
    "qonnx_cleanup(chkpt_preproc_name, out_file=chkpt_preproc_name)\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "pre_model = pre_model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "# join preprocessing and core model\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "# add input quantization annotation: UINT8 for all BNN-PYNQ models\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e994573e-3b15-4f90-9e4e-4d82b9288ad0",
   "metadata": {},
   "source": [
    "### Tidy again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87c667fd-97b6-4bf5-bd82-ae0f97353bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c8d211b-0a24-4381-b2fe-cc9e92eac928",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_prepro = models_folder + '/03_finn_prepro.onnx'\n",
    "model.save(finn_prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11e7ee6e-aa4b-4e6b-9b32-4ad8d1a45911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './mvau_wwidth_max/03_finn_prepro.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7facc0f35c60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_prepro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426532b9-8327-4539-a3da-83dbb47a5899",
   "metadata": {},
   "source": [
    "## Streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deabcd45-ecb5-4e18-b104-862f4c6a8d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "\n",
    "from qonnx.transformation.change_datalayout import ChangeDataLayoutQuantAvgPool2d\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "from finn.transformation.streamline import Streamline\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MoveScalarLinearPastInvariants\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC\n",
    "from finn.transformation.streamline.reorder import MoveLinearPastEltwiseAdd\n",
    "\n",
    "from finn.transformation.streamline.reorder import MoveMulPastFork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e0772f-fc63-49bf-8bf1-9479bca7d515",
   "metadata": {},
   "source": [
    "### Move Mul Past Fork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdd7fe36-1fcd-4d53-92a0-4c329876783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "defe695a-fb96-4440-94f3-f2d3bff6620f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/src/finn/transformation/streamline/absorb.py:166: RuntimeWarning: divide by zero encountered in divide\n",
      "  Tnew = T / A.reshape(-1, 1)\n"
     ]
    }
   ],
   "source": [
    "model = model.transform(MoveMulPastFork())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0442ce55-9fe5-4a44-9723-f7ef26ef5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_mul_past_fork = models_folder + '/040_finn_mul_past_fork.onnx'\n",
    "model.save(finn_mul_past_fork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8de7f1ba-147e-4c78-a29d-e08adf95e29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './mvau_wwidth_max/040_finn_mul_past_fork.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7facf3487eb0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_mul_past_fork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f35ce4-6e7a-4cd3-9be9-cde0455d2486",
   "metadata": {},
   "source": [
    "### Move Mul Past Residual Adds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec27c9d8-02d9-4e9b-8e94-0e4fda8aba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_mul_past_fork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff96a0f7-f81c-4acd-b570-b553b4260d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/src/finn/transformation/streamline/absorb.py:66: UserWarning: Threshold or add bias not constant, skipping\n",
      "  warnings.warn(\"Threshold or add bias not constant, skipping\")\n"
     ]
    }
   ],
   "source": [
    "model = model.transform(MoveLinearPastEltwiseAdd())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3fc3c08-f909-4bbc-a776-cd49cd4de373",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_move_mul_past_add = models_folder + '/041_finn_move_mul_past_add.onnx'\n",
    "model.save(finn_move_mul_past_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef008020-7cd5-4b1e-b4c4-e3da9d22a24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './mvau_wwidth_max/041_finn_move_mul_past_add.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7facf3487c70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_move_mul_past_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4af8f13e-9b51-42ee-b79a-083534209322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c8e134b-ecdd-4572-87af-24c7a328a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_move_mul_past_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "023e1ad2-5d91-4459-876d-91ff2e781ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(ChangeDataLayoutQuantAvgPool2d())\n",
    "\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92fc9f1e-f8af-470e-b3db-a23566ffa3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_lowerconvs_avgpool = models_folder + '/042_finn_lowerconvs_avgpool.onnx'\n",
    "model.save(finn_lowerconvs_avgpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e9359b5-334e-4d33-8edb-a2edd3c64e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './mvau_wwidth_max/042_finn_lowerconvs_avgpool.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7facf3487e80>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_lowerconvs_avgpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eff18e43-f3e8-47b5-bc3a-6567ee4f3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.transform(to_hw.InferAddStreamsLayer())\n",
    "# model = model.transform(LowerConvsToMatMul())\n",
    "\n",
    "# model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "# model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "# model = model.transform(Streamline())\n",
    "# model = model.transform(InferDataLayouts())\n",
    "# model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83bab094-fcaf-4961-95c9-a1db0c0102bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finn_add_to_hw_lower_convs = models_folder + '/042_finn_add_to_hw_lower_convs.onnx'\n",
    "# model.save(finn_add_to_hw_lower_convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "120eb1d7-afc1-432e-b648-f513b8d8aa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_onnx_trained_standalone/042_finn_add_to_hw_lower_convs.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f95dc4f2e90>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showInNetron(finn_add_to_hw_lower_convs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da1618-4f48-4785-ba40-c5e67540ecd6",
   "metadata": {},
   "source": [
    "### Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1041e015-8ad0-49bb-8bbd-eb1b489ff359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(finn_add_to_hw_lower_convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "504dcc1f-bc9c-4e31-a132-d33ac5d9950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.transform(ChangeDataLayoutQuantAvgPool2d())\n",
    "# model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "# model = model.transform(Streamline())\n",
    "# model = model.transform(InferDataTypes())\n",
    "# model = model.transform(InferDataLayouts())\n",
    "# model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51c9f1b7-2bab-40a2-9ec8-a84999f29338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finn_avgpool = models_folder + '/043_finn_avgpool.onnx'\n",
    "# model.save(finn_avgpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7eca122f-b85e-4e1e-959d-8883fa14e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_onnx_trained_standalone/043_finn_avgpool.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f95dc3803a0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showInNetron(finn_avgpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98f73da-659c-4885-8f3a-05c45d38d15c",
   "metadata": {},
   "source": [
    "# To HW Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a8179a6-5bce-4bcc-8ea7-5bdfdbe73b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "\n",
    "from qonnx.custom_op.registry import getCustomOp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5ed703-99de-4d12-95eb-7e41b133d360",
   "metadata": {},
   "source": [
    "# Convert Last Bipolar Node to Binary and Nodes.Input[1] Float to INT32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2afd44e-1b36-460a-8044-ecda4530920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ModelWrapper(finn_avgpool)\n",
    "\n",
    "model = ModelWrapper(finn_lowerconvs_avgpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b209a24b-ea82-44e3-9b52-0fb9fbdba906",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multithreshold_node = model.get_nodes_by_op_type(\"MultiThreshold\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16e958bf-d29c-4968-a701-da37d22bc775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiThreshold_37 converted from Bipolar to Binary\n",
      "input: \"MatMul_31_out0\"\n",
      "input: \"MultiThreshold_37_param0\"\n",
      "output: \"global_out\"\n",
      "name: \"MultiThreshold_37\"\n",
      "op_type: \"MultiThreshold\"\n",
      "attribute {\n",
      "  name: \"out_dtype\"\n",
      "  s: \"BINARY\"\n",
      "  type: STRING\n",
      "}\n",
      "attribute {\n",
      "  name: \"out_scale\"\n",
      "  f: 1.0\n",
      "  type: FLOAT\n",
      "}\n",
      "attribute {\n",
      "  name: \"out_bias\"\n",
      "  f: 0.0\n",
      "  type: FLOAT\n",
      "}\n",
      "domain: \"qonnx.custom_op.general\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in Multithreshold_node:\n",
    "    node_inst = getCustomOp(node)\n",
    "    if node_inst.get_nodeattr(\"out_dtype\") == \"BIPOLAR\":\n",
    "        node_inst.set_nodeattr(\"out_dtype\", \"BINARY\")\n",
    "        node_inst.set_nodeattr(\"out_scale\", 1.0)\n",
    "        node_inst.set_nodeattr(\"out_bias\", 0.0)\n",
    "        print(f'{node.name} converted from Bipolar to Binary\\n{node}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54c53315-5739-4dc0-adef-1fe083254eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiThreshold_37: node with Float32 annotation\n",
      "MultiThreshold_37: changed to datatype INT32\n"
     ]
    }
   ],
   "source": [
    "for node in Multithreshold_node:\n",
    "    if model.get_tensor_datatype(node.input[1]) == \"FLOAT32\":\n",
    "        print(f'{node.name}: node with Float32 annotation')\n",
    "        model.set_tensor_datatype(node.input[1], DataType[\"INT32\"])\n",
    "        print(f'{node.name}: changed to datatype {model.get_tensor_datatype(node.input[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe988f13-5b29-400e-ae53-33e3e76ffbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'global_out'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_out_name = model.graph.output[0].name\n",
    "global_out_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72e61fcf-5a3e-4d55-abe3-76addd6f50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_tensor_datatype(global_out_name, DataType[\"BINARY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8deb0e80-63ea-41d4-baae-7740d24adaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_bipolar_to_binary = models_folder + '/044_finn_bipolar_to_binary.onnx'\n",
    "model.save(finn_bipolar_to_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca1fbb85-c086-4950-af7b-cd96050c050d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './mvau_wwidth_max/044_finn_bipolar_to_binary.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7facc0f36c50>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_bipolar_to_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b16a85-2b43-42f2-abf7-998e27f89ddf",
   "metadata": {},
   "source": [
    "### Standalone before MVAU/VVAU conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59b0a9fd-c7ef-46ab-8385-702060a1f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_bipolar_to_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "435157be-1bdb-4a29-922c-4c37e6ccb60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(to_hw.InferAddStreamsLayer())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "\n",
    "\n",
    "model = model.transform(to_hw.InferThresholdingLayer())\n",
    "model = model.transform(to_hw.InferQuantizedMatrixVectorActivation())\n",
    "model = model.transform(to_hw.InferVectorVectorActivation())\n",
    "model = model.transform(to_hw.InferPool())\n",
    "model = model.transform(to_hw.InferConvInpGen())\n",
    "\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2286282-4b65-451b-ba02-165c410e1cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_hw_standalone = models_folder + '/045_finn_hw_standalone.onnx'\n",
    "model.save(finn_hw_standalone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e64c8701-4894-4c48-b21a-c46b7092b6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './mvau_wwidth_max/045_finn_hw_standalone.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fadc82bbb20>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_hw_standalone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efe14d0-8762-44db-8ec0-132a6fd1fdac",
   "metadata": {},
   "source": [
    "# Infer Duplicate Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc6d6c69-32fb-4c79-935b-ee9818502b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.general import SortGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea749a9f-2354-4fca-8acc-0008adc171af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_hw_standalone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6401de4c-5c52-4d02-b9a6-db90c1dbd483",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(to_hw.InferDuplicateStreamsLayer())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "model = model.transform(SortGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b65cfb52-b568-4999-a848-8c3790b6c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_hw_duplicate = models_folder + '/46_finn_hw_duplicate.onnx'\n",
    "model.save(finn_hw_duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9513706-724d-4832-8794-2e8778d45e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './mvau_wwidth_max/46_finn_hw_duplicate.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7facc0f35690>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_hw_duplicate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5ea5c1-3953-4af7-b0fc-df4207b2d5af",
   "metadata": {},
   "source": [
    "# Dataflow Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4014cddb-719f-445b-8ed9-eb2112a3b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_hw_duplicate)\n",
    "parent_model = model.transform(CreateDataflowPartition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb110eb3-7038-4f7e-a1d1-170884f9460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_parent_filename = models_folder + '/50_finn_dataflow_parent.onnx'\n",
    "parent_model.save(finn_parent_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce570573-8efc-4e94-bbbe-319c822210e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './step_by_step_onnx_trained_standalone_duplicateLayer/50_finn_dataflow_parent.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff2ddeb5ff0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_parent_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59ef0394-b25e-4cad-98d4-f75d27fb6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_filename = sdp_node.get_nodeattr(\"model\")\n",
    "dataflow_model = ModelWrapper(dataflow_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd9cd70c-db50-478b-9022-73f3999ccd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a8c7493-5d7b-40c1-8620-53bbe68a5eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.basic import pynq_part_map\n",
    "# change this if you have a different PYNQ board, see list above\n",
    "pynq_board = \"Pynq-Z1\"\n",
    "fpga_part = pynq_part_map[pynq_board]\n",
    "target_clk_ns = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918d2544-a2e4-4b97-b3ba-f3e5dcfeef55",
   "metadata": {},
   "source": [
    "# Specialize Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58dbd138-3594-4b86-bbdf-96d3e898bd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node FMPadding_0 forced to HLS\n",
      "Node FMPadding_1 forced to HLS\n",
      "Node FMPadding_2 forced to HLS\n",
      "Node FMPadding_3 forced to HLS\n",
      "Node FMPadding_4 forced to HLS\n",
      "Node FMPadding_5 forced to HLS\n",
      "Node FMPadding_6 forced to HLS\n",
      "Node FMPadding_7 forced to HLS\n",
      "Node FMPadding_8 forced to HLS\n",
      "Node FMPadding_9 forced to HLS\n",
      "Node FMPadding_10 forced to HLS\n"
     ]
    }
   ],
   "source": [
    "FMPadding_node = dataflow_model.get_nodes_by_op_type(\"FMPadding\")\n",
    "\n",
    "for node in FMPadding_node:\n",
    "    node_inst = getCustomOp(node)\n",
    "    node_inst.set_nodeattr(\"preferred_impl_style\", \"hls\")\n",
    "    print(f'Node {node.name} forced to HLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90f463dc-3f78-4a41-9864-801ee55ecca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataflow partition with a different name for easier access\n",
    "# and specialize the layers to HLS variants\n",
    "dataflow_model = dataflow_model.transform(SpecializeLayers(fpga_part))\n",
    "\n",
    "dataflow_model = dataflow_model.transform(GiveUniqueNodeNames())\n",
    "dataflow_model = dataflow_model.transform(GiveReadableTensorNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "405f8708-ac6f-406a-9e2c-2a1fa4b559f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "finn_dataflow_filename = models_folder + '/60_finn_dataflow_model.onnx'\n",
    "dataflow_model.save(finn_dataflow_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e319d52f-9592-4d4f-8b03-00248c8ef6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './mvau_wwidth_max/60_finn_dataflow_model.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7facc0de3c70>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_dataflow_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1578449b-b126-4d0c-bccf-fdb07823e6c4",
   "metadata": {},
   "source": [
    "# Analyze MVAU_WWIDTH_MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6a935bf4-4b8d-4459-bc1f-d8d95325b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_dataflow_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5497ab06-9cde-4648-b3fa-b0378df195a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVAU_rtl_0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for node in model.graph.node:\n",
    "    op_type = node.op_type\n",
    "    node_inst = getCustomOp(node)\n",
    "    if op_type in [\"MVAU_rtl\"]:\n",
    "        print(node.name)\n",
    "        print(node_inst.get_weight_datatype().bitwidth())\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5a7ba9-7876-4674-bbc3-de4d87b5f1a0",
   "metadata": {},
   "source": [
    "# Folding Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ac0f96-dbf5-49f6-8db8-67e28dbafffa",
   "metadata": {},
   "source": [
    "### Calculate cycles per frame first, for a FPS target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3a6a23b7-3f7e-4120-ac2a-92d93a71c2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame latency = 0.0013333333333333333\n",
      "Cycles per frame = 133333\n"
     ]
    }
   ],
   "source": [
    "FPS_target = 750\n",
    "frame_latency = 1 / FPS_target\n",
    "my_target_cycles_per_frame = int(frame_latency / (target_clk_ns*1e-9))\n",
    "\n",
    "print(f'Frame latency = {frame_latency}')\n",
    "print(f'Cycles per frame = {my_target_cycles_per_frame}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b4b6ab10-ca2b-401a-be6d-70372401a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.set_folding import SetFolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "97358474-b5de-4894-8c54-782920fd3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(finn_dataflow_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7697b8a-05b4-407b-9bc6-39287fa05ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(SetFolding(\n",
    "    target_cycles_per_frame=my_target_cycles_per_frame,\n",
    "    mvau_wwidth_max=36,\n",
    "    two_pass_relaxation=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e01cfb32-0c1b-49ed-acb2-ef0bb80c6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "folding_filename = models_folder + '/70_finn_folding.onnx'\n",
    "model.save(folding_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bbef00e3-557c-470b-ae6e-fb9ff5e4da72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './mvau_wwidth_max/70_finn_folding.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7facc14baad0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(folding_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54806a98-d612-436c-a14a-5bb0ad20e639",
   "metadata": {},
   "source": [
    "### Check estimated cycles per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "06010602-d7c5-4cb8-a08a-99b3eed17ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a42491ab-044d-467d-a020-e2cdb90ba4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = model.get_finn_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5e6fb55d-d1c8-423c-808f-753393f33723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 estimated cycles: 50176\n",
      "Node 1 estimated cycles: 51076\n",
      "Node 2 estimated cycles: 113351\n",
      "Node 3 estimated cycles: 75264\n",
      "Node 4 estimated cycles: 100352\n",
      "Node 5 estimated cycles: 103968\n",
      "Node 6 estimated cycles: 113127\n",
      "Node 7 estimated cycles: 112896\n",
      "Node 8 estimated cycles: 100352\n",
      "Node 9 estimated cycles: 100352\n",
      "Node 10 estimated cycles: 100352\n",
      "Node 11 estimated cycles: 100352\n",
      "Node 12 estimated cycles: 100352\n",
      "Node 13 estimated cycles: 103968\n",
      "Node 14 estimated cycles: 123684\n",
      "Node 15 estimated cycles: 112896\n",
      "Node 16 estimated cycles: 50176\n",
      "Node 17 estimated cycles: 100352\n",
      "Node 18 estimated cycles: 50176\n",
      "Node 19 estimated cycles: 50176\n",
      "Node 20 estimated cycles: 100352\n",
      "Node 21 estimated cycles: 100352\n",
      "Node 22 estimated cycles: 107648\n",
      "Node 23 estimated cycles: 113372\n",
      "Node 24 estimated cycles: 112896\n",
      "Node 25 estimated cycles: 100352\n",
      "Node 26 estimated cycles: 100352\n",
      "Node 27 estimated cycles: 50176\n",
      "Node 28 estimated cycles: 50176\n",
      "Node 29 estimated cycles: 50176\n",
      "Node 30 estimated cycles: 100352\n",
      "Node 31 estimated cycles: 100352\n",
      "Node 32 estimated cycles: 107648\n",
      "Node 33 estimated cycles: 127488\n",
      "Node 34 estimated cycles: 112896\n",
      "Node 35 estimated cycles: 25088\n",
      "Node 36 estimated cycles: 75264\n",
      "Node 37 estimated cycles: 18816\n",
      "Node 38 estimated cycles: 18816\n",
      "Node 39 estimated cycles: 112896\n",
      "Node 40 estimated cycles: 37632\n",
      "Node 41 estimated cycles: 43200\n",
      "Node 42 estimated cycles: 113904\n",
      "Node 43 estimated cycles: 112896\n",
      "Node 44 estimated cycles: 37632\n",
      "Node 45 estimated cycles: 112896\n",
      "Node 46 estimated cycles: 18816\n",
      "Node 47 estimated cycles: 18816\n",
      "Node 48 estimated cycles: 18816\n",
      "Node 49 estimated cycles: 112896\n",
      "Node 50 estimated cycles: 75264\n",
      "Node 51 estimated cycles: 86400\n",
      "Node 52 estimated cycles: 98348\n",
      "Node 53 estimated cycles: 84672\n",
      "Node 54 estimated cycles: 18816\n",
      "Node 55 estimated cycles: 100352\n",
      "Node 56 estimated cycles: 6272\n",
      "Node 57 estimated cycles: 6272\n",
      "Node 58 estimated cycles: 100352\n",
      "Node 59 estimated cycles: 25088\n",
      "Node 60 estimated cycles: 32768\n",
      "Node 61 estimated cycles: 115136\n",
      "Node 62 estimated cycles: 112896\n",
      "Node 63 estimated cycles: 25088\n",
      "Node 64 estimated cycles: 100352\n",
      "Node 65 estimated cycles: 6272\n",
      "Node 66 estimated cycles: 6272\n",
      "Node 67 estimated cycles: 6272\n",
      "Node 68 estimated cycles: 6272\n",
      "Node 69 estimated cycles: 100352\n",
      "Node 70 estimated cycles: 25088\n",
      "Node 71 estimated cycles: 32768\n",
      "Node 72 estimated cycles: 115136\n",
      "Node 73 estimated cycles: 112896\n",
      "Node 74 estimated cycles: 25088\n",
      "Node 75 estimated cycles: 100352\n",
      "Node 76 estimated cycles: 6272\n",
      "Node 77 estimated cycles: 6272\n",
      "Node 78 estimated cycles: 6272\n",
      "Node 79 estimated cycles: 100352\n",
      "Node 80 estimated cycles: 12544\n",
      "Node 81 estimated cycles: 16384\n",
      "Node 82 estimated cycles: 115136\n",
      "Node 83 estimated cycles: 112896\n",
      "Node 84 estimated cycles: 12544\n",
      "Node 85 estimated cycles: 100352\n",
      "Node 86 estimated cycles: 12544\n",
      "Node 87 estimated cycles: 12544\n",
      "Node 88 estimated cycles: 100352\n",
      "Node 89 estimated cycles: 25088\n",
      "Node 90 estimated cycles: 32768\n",
      "Node 91 estimated cycles: 115136\n",
      "Node 92 estimated cycles: 112896\n",
      "Node 93 estimated cycles: 25088\n",
      "Node 94 estimated cycles: 100352\n",
      "Node 95 estimated cycles: 12544\n",
      "Node 96 estimated cycles: 12544\n",
      "Node 97 estimated cycles: 12544\n",
      "Node 98 estimated cycles: 100352\n",
      "Node 99 estimated cycles: 25088\n",
      "Node 100 estimated cycles: 75123\n",
      "Node 101 estimated cycles: 25088\n",
      "Node 102 estimated cycles: 256\n",
      "Node 103 estimated cycles: 2\n",
      "\n",
      "Total estimated cycles: 6940547\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "total_cycles = []\n",
    "for node in all_nodes:\n",
    "    my_node = getCustomOp(node)\n",
    "    node_cycles = my_node.get_nodeattr(\"cycles_estimate\")\n",
    "    total_cycles.append(node_cycles)\n",
    "    print(f'Node {i} estimated cycles: {node_cycles}')\n",
    "    i += 1\n",
    "print(f'\\nTotal estimated cycles: {np.array(total_cycles).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad554e47-0869-408c-a378-d60897635722",
   "metadata": {},
   "source": [
    "# Minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3a6dc4d6-9e7a-42ec-b4b2-4e8aaea8cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.minimize_accumulator_width import (\n",
    "    MinimizeAccumulatorWidth,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.minimize_weight_bit_width import (\n",
    "    MinimizeWeightBitWidth,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a99104d3-ef7f-4f32-9c57-cb95ecaefb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(folding_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b1f28dd0-3190-4ec4-92e2-2ae9b6f6231b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_1: INT32 -> INT15 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_2: INT32 -> INT10 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_3: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_4: INT32 -> INT10 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_5: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_6: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_7: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_8: INT32 -> INT10 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_9: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_11: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_12: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_13: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_14: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_15: INT32 -> INT10 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_16: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_18: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_19: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_20: INT32 -> INT13 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_21: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_22: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_23: INT32 -> INT13 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_25: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_26: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_27: INT32 -> INT13 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_29: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_30: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_31: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_32: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_33: INT32 -> INT11 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_34: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_36: INT32 -> INT12 \n",
      "  warnings.warn(warn_str)\n",
      "/home/gmoreno/uav/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_rtl_37: INT32 -> INT21 \n",
      "  warnings.warn(warn_str)\n"
     ]
    }
   ],
   "source": [
    "model = model.transform(MinimizeAccumulatorWidth())\n",
    "model = model.transform(MinimizeWeightBitWidth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2352b565-e13a-41a8-858d-8315dedbe7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize_filename = models_folder + '/71_finn_minimize.onnx'\n",
    "model.save(minimize_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fe41b1e0-58d3-4cf7-91c6-ab1b4bee958a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8083\n",
      "Serving './mvau_wwidth_max/71_finn_minimize.onnx' at http://0.0.0.0:8083\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8083/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7facc116e8f0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(minimize_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9898ff-7a29-4f9a-8a1d-e3ba82d13696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
