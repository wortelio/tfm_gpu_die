{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "663fc823-cba4-4c64-b961-f01e20984a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run folder created in: experiments/A_2500_FPS/112/15_full_build_json_mvau_rtl_mvau_wwidth_max_24_manual_folding/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import config\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "from brevitas.export import export_qonnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd308cca-d93b-4cec-a9ae-27b493426f34",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b31d40-aefc-45d5-8203-cadee298fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = config.RUN_FOLDER\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "file_handler = logging.FileHandler(log_path + 'logfile.log', mode=\"a\", encoding=\"utf-8\")\n",
    "formatter = logging.Formatter(\n",
    "    \"{asctime} - {message}\",\n",
    "    style=\"{\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M\",\n",
    ")\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# add file handler to logger\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bd679e-11a8-4008-8642-0fb6599793ee",
   "metadata": {},
   "source": [
    "# Original QONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56884858-a0bf-4bd7-b9c9-d9ca54f747c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brevitas_cpu = './onnx_models/Mobilenetv2_Mini_Resnet_4bitINP__best_F1__Bipolar.onnx'\n",
    "\n",
    "brevitas_cpu = './onnx_models/Mobilenetv2_Mini_Resnet_112__best_F1__Bipolar.onnx'\n",
    "\n",
    "# brevitas_cpu = './onnx_models/Mobilenetv2_Mini_Resnet_Sparse24__best_F1__Bipolar.onnx'\n",
    "\n",
    "# brevitas_cpu = './onnx_models/Sparse24__only_thres.onnx'\n",
    "\n",
    "# brevitas_cpu = './onnx_models/Sparse24_mul8.onnx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44addd53-bf50-4e04-b1d0-109d48297fa0",
   "metadata": {},
   "source": [
    "# FINN IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d379ebf2-eb47-4035-be7a-308ebe6dd546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showSrc, showInNetron\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20cb421-8368-4d3d-b15a-09ca512a6160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showInNetron(brevitas_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7a53f4-02df-41db-89ac-8d8b6e0b5a4e",
   "metadata": {},
   "source": [
    "# Clean QONNX Model trained with Brevitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dc6bf08-c03f-41f0-b91e-fd8c3a487b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "qonnx_clean_filename = config.RUN_FOLDER + 'clean_model.onnx'\n",
    "qonnx_cleanup(brevitas_cpu, out_file=qonnx_clean_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbecf7c-f2bb-4e01-a3ce-21f021028ce9",
   "metadata": {},
   "source": [
    "# FINN Build IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72e3ef7e-98b6-443a-bd3f-c36e2370e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db6102b-10ad-41a7-8b6c-c8231f6e73e4",
   "metadata": {},
   "source": [
    "# Custom step: Tidy Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96e37153-07d1-4c2c-8078-a706b2d46f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1ac10d1-727f-4ecb-92b2-80d9d6343b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_step_tidy_up(model: ModelWrapper, cfg: build.DataflowBuildConfig):\n",
    "    \n",
    "    model = model.transform(ConvertQONNXtoFINN())\n",
    "    model = model.transform(InferShapes())\n",
    "    model = model.transform(FoldConstants())\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    model = model.transform(GiveReadableTensorNames())\n",
    "    model = model.transform(RemoveStaticGraphInputs())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62467796-f923-4641-aea9-f27720817207",
   "metadata": {},
   "source": [
    "# Custom step: Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1634e251-23cd-4622-b9b4-c275806c1865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.pytorch import ToTensor\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.core.datatype import DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7730ede7-ad4f-4c0e-9914-81eec22e5697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_step_add_pre_proc(model: ModelWrapper, cfg: build.DataflowBuildConfig):\n",
    "    \n",
    "    global_inp_name = model.graph.input[0].name\n",
    "    ishape = model.get_tensor_shape(global_inp_name)\n",
    "    # preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "    totensor_pyt = ToTensor()\n",
    "    chkpt_preproc_name = config.RUN_FOLDER +  \"/prepro_node.onnx\"\n",
    "    export_qonnx(totensor_pyt, torch.randn(ishape), chkpt_preproc_name)\n",
    "    qonnx_cleanup(chkpt_preproc_name, out_file=chkpt_preproc_name)\n",
    "    pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "    pre_model = pre_model.transform(ConvertQONNXtoFINN())\n",
    "    \n",
    "    # join preprocessing and core model\n",
    "    model = model.transform(MergeONNXModels(pre_model))\n",
    "    # add input quantization annotation: UINT8 for all BNN-PYNQ models\n",
    "    global_inp_name = model.graph.input[0].name\n",
    "    model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])\n",
    "\n",
    "    model = model.transform(InferShapes())\n",
    "    model = model.transform(FoldConstants())\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    model = model.transform(GiveReadableTensorNames())\n",
    "    model = model.transform(InferDataTypes())\n",
    "    model = model.transform(RemoveStaticGraphInputs())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac7b37-c94b-46a5-aea1-f976b124ad02",
   "metadata": {},
   "source": [
    "# Custom step: Streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "104ce881-e11d-4548-933a-477d2aff4b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.streamline.reorder import MoveMulPastFork\n",
    "from finn.transformation.streamline.reorder import MoveLinearPastEltwiseAdd\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.change_datalayout import ChangeDataLayoutQuantAvgPool2d\n",
    "\n",
    "from finn.transformation.streamline import Streamline\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c4b2b21-9187-46a9-9483-ffeaed97a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_step_streamline(model: ModelWrapper, cfg: build.DataflowBuildConfig):\n",
    "    \n",
    "    trans_list = [\n",
    "        MoveMulPastFork,\n",
    "        MoveLinearPastEltwiseAdd,\n",
    "        LowerConvsToMatMul,\n",
    "        ChangeDataLayoutQuantAvgPool2d,\n",
    "    ]\n",
    "    for trans in trans_list:\n",
    "        model = model.transform(trans())\n",
    "        model = model.transform(Streamline())\n",
    "        model = model.transform(InferDataLayouts())\n",
    "        model = model.transform(RemoveUnusedTensors())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ca5813-c5ea-4f6a-8726-60a028c049e2",
   "metadata": {},
   "source": [
    "# Custom step: Convert to HW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54b11a09-cf09-441a-9237-1c5c5a3d57b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from qonnx.transformation.general import GiveUniqueNodeNames\n",
    "from qonnx.transformation.general import SortGraph\n",
    "\n",
    "from qonnx.custom_op.registry import getCustomOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76ab20f6-3e9a-46f8-b01a-ade675f5f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_step_convert_to_hw(model: ModelWrapper, cfg: build.DataflowBuildConfig):\n",
    "\n",
    "    # Change BIPOLAR end node to BINARY\n",
    "    Multithreshold_node = model.get_nodes_by_op_type(\"MultiThreshold\") \n",
    "    for node in Multithreshold_node:\n",
    "        node_inst = getCustomOp(node)\n",
    "        if node_inst.get_nodeattr(\"out_dtype\") == \"BIPOLAR\":\n",
    "            node_inst.set_nodeattr(\"out_dtype\", \"BINARY\")\n",
    "            node_inst.set_nodeattr(\"out_scale\", 1.0)\n",
    "            node_inst.set_nodeattr(\"out_bias\", 0.0)\n",
    "            print(f'Node changed from BIPOLAR to BINARY, to fulfill standalone MultiThreshold requirement\\n{node}')\n",
    "            print(\"Set Output to BINARY Datatype\")\n",
    "            global_out_name = model.graph.output[0].name\n",
    "            model.set_tensor_datatype(global_out_name, DataType[\"BINARY\"])\n",
    "\n",
    "    # Fix Float32 input to Int32\n",
    "    for node in Multithreshold_node: # Línea añadida al hacer los experimentos de BED Resnet\n",
    "                                     # Quizá no fuese necesario aquí, porque todos los threshold ya fuesen INT32\n",
    "                                     # Añadido el indent en el if de abajo también\n",
    "        if model.get_tensor_datatype(node.input[1]) == \"FLOAT32\":\n",
    "            print(f'{node.name}: node with Float32 annotation')\n",
    "            model.set_tensor_datatype(node.input[1], DataType[\"INT32\"])\n",
    "            print(f'{node.name}: changed to datatype {model.get_tensor_datatype(node.input[1])}')\n",
    "\n",
    "    model = model.transform(to_hw.InferAddStreamsLayer())\n",
    "    model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "    \n",
    "    if cfg.standalone_thresholds:\n",
    "        # doing this first causes all threshold layers to be standalone\n",
    "        # It allows MVAU_rtl and optimization with DSP\n",
    "        model = model.transform(to_hw.InferThresholdingLayer())  \n",
    "    \n",
    "    model = model.transform(to_hw.InferQuantizedMatrixVectorActivation())\n",
    "    model = model.transform(to_hw.InferVectorVectorActivation())\n",
    "    model = model.transform(to_hw.InferThresholdingLayer()) # Convert in Multithres if Standalone is not applied\n",
    "    model = model.transform(to_hw.InferPool())\n",
    "    model = model.transform(to_hw.InferConvInpGen())\n",
    "    \n",
    "    model = model.transform(RemoveCNVtoFCFlatten())\n",
    "    model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "    # Very importante to stich Resnets. Fifo fails if not, as it cannot insert DWC.    \n",
    "    model = model.transform(to_hw.InferDuplicateStreamsLayer())\n",
    "    \n",
    "    model = model.transform(Streamline())\n",
    "    model = model.transform(InferDataLayouts())\n",
    "    model = model.transform(GiveReadableTensorNames())\n",
    "    model = model.transform(RemoveUnusedTensors())\n",
    "    model = model.transform(SortGraph())\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0abeb42-4e5b-485d-8768-d5504341f6e3",
   "metadata": {},
   "source": [
    "# Settings for Specialize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9658abe4-6733-4915-a677-2a21c945adcd",
   "metadata": {},
   "source": [
    "# Define Number of MVAU to keep in RTL. The others will be converted to HLS\n",
    "\n",
    "https://github.com/Xilinx/finn/discussions/1021\n",
    "\n",
    "Useful to control the number of DSP and LUT used.\n",
    "\n",
    "RTL MVAU will consume DSP very efficiently. On the other hand, HLS variants will be forced to use LUTs\n",
    "\n",
    "**Strategy**:\n",
    "1. Check LUTs with all MVAU as HLS \n",
    "2. Check DSPs with all MVAU as RTL\n",
    "3. Decide the best combination to fill the FPGA resources and fit in\n",
    "\n",
    "<font color='red'>VVAU are still not supported for RTL DSP48, the one included in PYNQ-Z1</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ac02ac0-ce73-4aa8-8353-298b8180b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_HLS = False\n",
    "ALL_RTL = True\n",
    "\n",
    "if ALL_HLS:\n",
    "    MVAU_list = [] # Empty, so no nodes are kept in RTL. 22 MVAU in MobilenetV2 Resnet\n",
    "else:\n",
    "    # MVAU_list = [i for i in range(16)] # Nodes to keep in RTL\n",
    "    MVAU_list = [i for i in range(16)] + [17] # Nodes to keep in RTL\n",
    "\n",
    "    # For MobilenetV2 Original\n",
    "    # MVAU_list = [i for i in range(20)] # Nodes to keep in RTL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d523f-cb1b-4193-9111-2e8eceb654e3",
   "metadata": {},
   "source": [
    "## VVAU to DSP or LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b731569e-b535-4b00-8078-d950e4ed6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "VVAU_DSP_list = [] # If empty, no VVAUs to DSP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84543195-0567-4f34-9ee9-0b1be1db5420",
   "metadata": {},
   "source": [
    "## Conv Input Generator to BRAM or LutRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3270e8e-0e9d-4061-8584-be60cab07aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_CONV_INP_GEN_bram = True\n",
    "CONV_INP_GEN_list = [1, 6, 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3338208-7d8b-4c05-b098-75b39e49ebeb",
   "metadata": {},
   "source": [
    "## Padding RTL or HLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7a74c9e-bc69-4f0f-acbb-ab8d055718e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_rtl = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270295cd-a9f9-4f32-9a0b-fed3ab4812d9",
   "metadata": {},
   "source": [
    "# Custom step: Specialize Layers -> redefine FMPadding as HLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dea630ea-7a8b-4e7f-9949-ccad43f8cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13763a14-479e-4672-9e87-85d0eb4d62ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_step_specialize_layers(model: ModelWrapper, cfg: build.DataflowBuildConfig):\n",
    "    \n",
    "    # Change all FMPadding to HLS, as Folding does not support this layer as RTL\n",
    "    # It does not hurt if Padding is not present, as it will do nothing\n",
    "    print(f'Padding to rtl: {padding_rtl}')\n",
    "    if not padding_rtl:\n",
    "        FMPadding_node = model.get_nodes_by_op_type(\"FMPadding\")\n",
    "        for node in FMPadding_node:\n",
    "            node_inst = getCustomOp(node)\n",
    "            node_inst.set_nodeattr(\"preferred_impl_style\", \"hls\")\n",
    "            print(f'Node {node.name} forced to HLS')\n",
    "\n",
    "    # MVAUs in the list are kept like RTL. All other layers are converted to HLS\n",
    "    if ALL_RTL == False:\n",
    "        MVAU_nodes = model.get_nodes_by_op_type(\"MVAU\")\n",
    "        for idx in range(len(MVAU_nodes)):\n",
    "            if idx in MVAU_list:\n",
    "                print(f'MVAU {idx} left unchanged')\n",
    "                continue\n",
    "            else:\n",
    "                MVAU_node = MVAU_nodes[idx]\n",
    "                node_inst = getCustomOp(MVAU_node)\n",
    "                node_inst.set_nodeattr(\"preferred_impl_style\", \"hls\")\n",
    "                node_inst.set_nodeattr(\"ram_style\", \"block\")\n",
    "                node_inst.set_nodeattr(\"resType\", \"lut\")\n",
    "                print(f'Node MVAU {idx} changed to hls, block, lut: \\n{MVAU_node}')\n",
    "    else:\n",
    "        print(\"All MVAU configured to RTL\")\n",
    "\n",
    "    # All VVAU nodes inside VVAU_DSP_list to DSP\n",
    "    VVAU_nodes = model.get_nodes_by_op_type(\"VVAU\")\n",
    "    for idx in range(len(VVAU_nodes)):\n",
    "        VVAU_node = VVAU_nodes[idx]\n",
    "        node_inst = getCustomOp(VVAU_node)\n",
    "        if idx in VVAU_DSP_list:\n",
    "            node_inst.set_nodeattr(\"preferred_impl_style\", \"hls\")\n",
    "            node_inst.set_nodeattr(\"ram_style\", \"block\")\n",
    "            node_inst.set_nodeattr(\"resType\", \"dsp\")\n",
    "            print(f'Node VVAU {idx} changed to hls, block, dsp: \\n{VVAU_node}')  \n",
    "        else:\n",
    "            node_inst.set_nodeattr(\"preferred_impl_style\", \"hls\")\n",
    "            node_inst.set_nodeattr(\"ram_style\", \"block\")\n",
    "            node_inst.set_nodeattr(\"resType\", \"lut\")\n",
    "            print(f'Node VVAU {idx} changed to rtl, block, lut: \\n{VVAU_node}')              \n",
    "\n",
    "    # # Last ConvInputGen to BRAM\n",
    "    # last_conv_inp_gen_node = model.get_nodes_by_op_type(\"ConvolutionInputGenerator\")[-1]\n",
    "    # conv_node_inst = getCustomOp(last_conv_inp_gen_node)\n",
    "    # conv_node_inst.set_nodeattr(\"ram_style\", \"block\")\n",
    "    # print(f'Last node ConvInGen {last_conv_inp_gen_node.name} changed to BRAM: \\n{last_conv_inp_gen_node}')\n",
    "\n",
    "    # # All ConvInputGen to BRAM to save LUTs\n",
    "    ConvInGen_nodes = model.get_nodes_by_op_type(\"ConvolutionInputGenerator\")\n",
    "    for conv_node in ConvInGen_nodes:\n",
    "        node_inst = getCustomOp(conv_node)\n",
    "        node_inst.set_nodeattr(\"ram_style\", \"block\")\n",
    "        print(f'Node ConvInGen {conv_node.name} changed to BRAM: \\n{conv_node}')\n",
    "    \n",
    "    # # Only ConvInputGen in list to BRAM to save LUTs\n",
    "    # ConvInpGen_nodes = model.get_nodes_by_op_type(\"ConvolutionInputGenerator\")\n",
    "    # for idx in range(len(ConvInpGen_nodes)):\n",
    "    #     if idx in CONV_INP_GEN_list:\n",
    "    #         conv_node = ConvInpGen_nodes[idx]\n",
    "    #         node_inst = getCustomOp(conv_node)\n",
    "    #         node_inst.set_nodeattr(\"ram_style\", \"block\")\n",
    "    #         print(f'Node ConvInGen {conv_node.name} changed to BRAM: \\n{conv_node}')\n",
    "    #     else:\n",
    "    #         print(f'ConvInpGen {idx} left unchanged')\n",
    "    \n",
    "    \n",
    "    # Specialize\n",
    "    model = model.transform(SpecializeLayers(cfg._resolve_fpga_part()))\n",
    "    model = model.transform(InferShapes())\n",
    "    model = model.transform(InferDataTypes())   \n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    model = model.transform(GiveReadableTensorNames())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e0f8e-0679-4c51-ae94-52d6922d8461",
   "metadata": {},
   "source": [
    "# FPGA Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e0f8bb0-51c8-48c9-aedf-037a2a0f3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.basic import pynq_part_map\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c207e43-1605-4e93-9005-e6183f107552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Board</th>\n",
       "      <th>FPGA Part</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ultra96</td>\n",
       "      <td>xczu3eg-sbva484-1-e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ultra96-V2</td>\n",
       "      <td>xczu3eg-sbva484-1-i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pynq-Z1</td>\n",
       "      <td>xc7z020clg400-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pynq-Z2</td>\n",
       "      <td>xc7z020clg400-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZCU102</td>\n",
       "      <td>xczu9eg-ffvb1156-2-e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ZCU104</td>\n",
       "      <td>xczu7ev-ffvc1156-2-e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ZCU111</td>\n",
       "      <td>xczu28dr-ffvg1517-2-e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RFSoC2x2</td>\n",
       "      <td>xczu28dr-ffvg1517-2-e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RFSoC4x2</td>\n",
       "      <td>xczu48dr-ffvg1517-2-e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KV260_SOM</td>\n",
       "      <td>xck26-sfvc784-2LV-c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Board              FPGA Part\n",
       "0     Ultra96    xczu3eg-sbva484-1-e\n",
       "1  Ultra96-V2    xczu3eg-sbva484-1-i\n",
       "2     Pynq-Z1        xc7z020clg400-1\n",
       "3     Pynq-Z2        xc7z020clg400-1\n",
       "4      ZCU102   xczu9eg-ffvb1156-2-e\n",
       "5      ZCU104   xczu7ev-ffvc1156-2-e\n",
       "6      ZCU111  xczu28dr-ffvg1517-2-e\n",
       "7    RFSoC2x2  xczu28dr-ffvg1517-2-e\n",
       "8    RFSoC4x2  xczu48dr-ffvg1517-2-e\n",
       "9   KV260_SOM    xck26-sfvc784-2LV-c"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpga_df = pd.DataFrame(pynq_part_map.items(), columns=['Board', 'FPGA Part'])\n",
    "fpga_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b64e5853-8786-4504-b41a-458f5da34c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this if you have a different PYNQ board, see list above\n",
    "pynq_board = \"Pynq-Z1\"\n",
    "fpga_part = pynq_part_map[pynq_board]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4069398-ce9f-4ea4-a067-7260ba425585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xc7z020clg400-1\n"
     ]
    }
   ],
   "source": [
    "print(fpga_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b6e7598-c2e8-45e3-b141-75b076c53ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments/A_2500_FPS/112/15_full_build_json_mvau_rtl_mvau_wwidth_max_24_manual_folding/clean_model.onnx\n"
     ]
    }
   ],
   "source": [
    "model_file = qonnx_clean_filename\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320cb88-e841-4abc-a690-5fff85a0dc04",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "\n",
    "Perform following operations to calculate synth_clk_period, based in other experiments:\n",
    "\n",
    "$$\n",
    "clk = \\frac{1}{FPS \\times Max_{Cycles}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e10a8c99-c5a3-49fc-a692-4c53beb01de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_synth_clk_period_ns = 10\n",
    "my_target_fps = 2500\n",
    "my_mvau_wwidth_max = 24 # \n",
    "my_default_swg_exception = True\n",
    "my_standalone_thresholds = True\n",
    "my_auto_fifo_depths = True\n",
    "my_auto_fifo_strategy = \"largefifo_rtlsim\" # \"characterize\"\n",
    "my_split_large_fifos = True\n",
    "my_folding_config_file =  './experiments/A_2500_FPS/112/manual_folding.json'\n",
    "my_specialize_layers_config_file = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb90284e-346a-4f98-881d-75aea0b3a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    (my_auto_fifo_depths and my_folding_config_file is None)\n",
    "    or\n",
    "    (not my_auto_fifo_depths and my_folding_config_file is not None)\n",
    "    or\n",
    "    (my_auto_fifo_depths and my_folding_config_file is not None)\n",
    ")       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a391c5-af4f-4426-ac7f-345bf0a1310b",
   "metadata": {},
   "source": [
    "# Build estimate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3392e878-1927-4360-8d58-75402552e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66c7d74d-229d-44e8-a0c4-35bb38951a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder does not exist and it will be created\n",
      "Using folding config file -> NO step_target_fps_parallelization\n"
     ]
    }
   ],
   "source": [
    "estimates_output_dir = config.RUN_FOLDER + \"output_estimates_only\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "else:\n",
    "    print(\"Folder does not exist and it will be created\")\n",
    "\n",
    "if my_folding_config_file is None:\n",
    "    print(\"Not using folding config file -> step_target_fps_parallelization\")\n",
    "    my_estimate_steps = [\n",
    "        custom_step_tidy_up,\n",
    "        custom_step_add_pre_proc,\n",
    "        custom_step_streamline,\n",
    "        custom_step_convert_to_hw,\n",
    "        \"step_create_dataflow_partition\",\n",
    "        custom_step_specialize_layers,\n",
    "        \"step_target_fps_parallelization\",\n",
    "        \"step_apply_folding_config\",\n",
    "        \"step_minimize_bit_width\",\n",
    "        \"step_generate_estimate_reports\",\n",
    "    ]\n",
    "else:\n",
    "    print(\"Using folding config file -> NO step_target_fps_parallelization\")\n",
    "    my_estimate_steps = [\n",
    "        custom_step_tidy_up,\n",
    "        custom_step_add_pre_proc,\n",
    "        custom_step_streamline,\n",
    "        custom_step_convert_to_hw,\n",
    "        \"step_create_dataflow_partition\",\n",
    "        custom_step_specialize_layers,\n",
    "        \"step_apply_folding_config\",\n",
    "        \"step_minimize_bit_width\",\n",
    "        \"step_generate_estimate_reports\",\n",
    "    ]\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir                    = estimates_output_dir,\n",
    "    mvau_wwidth_max               = my_mvau_wwidth_max,\n",
    "    target_fps                    = my_target_fps,\n",
    "    synth_clk_period_ns           = my_synth_clk_period_ns, #10.0,\n",
    "    board                         = pynq_board,\n",
    "    fpga_part                     = fpga_part,\n",
    "    shell_flow_type               = build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "    standalone_thresholds         = my_standalone_thresholds,\n",
    "    default_swg_exception         = my_default_swg_exception, # Change to True to optimize ConvGenerators, removing FIFOs\n",
    "    auto_fifo_depths              = my_auto_fifo_depths,\n",
    "    auto_fifo_strategy            = my_auto_fifo_strategy, #\"characterize\", -> the other option, takes toooo long\n",
    "    split_large_fifos             = my_split_large_fifos, # Change to True to save resources\n",
    "\n",
    "    steps                         = my_estimate_steps,\n",
    "    #specialize_layers_config_file = my_specialize_layers_config_file,\n",
    "    folding_config_file           = my_folding_config_file,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b22af7-20ef-4ec0-b1d0-69bc2459cbf7",
   "metadata": {},
   "source": [
    "# Build FULL Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22a981b1-30b2-4d29-962e-3f218d4d2385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder does not exist and it will be created\n"
     ]
    }
   ],
   "source": [
    "full_build_output_dir = config.RUN_FOLDER + \"output_full_build\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(full_build_output_dir):\n",
    "    shutil.rmtree(full_build_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "else:\n",
    "    print(\"Folder does not exist and it will be created\")\n",
    "\n",
    "my_build_steps = [\n",
    "    custom_step_tidy_up,\n",
    "    custom_step_add_pre_proc,\n",
    "    custom_step_streamline,\n",
    "    custom_step_convert_to_hw,\n",
    "    \"step_create_dataflow_partition\",\n",
    "    custom_step_specialize_layers,\n",
    "    \"step_target_fps_parallelization\",\n",
    "    \"step_apply_folding_config\",\n",
    "    \"step_minimize_bit_width\",\n",
    "    \"step_generate_estimate_reports\",\n",
    "    \"step_hw_codegen\",\n",
    "    \"step_hw_ipgen\",\n",
    "    \"step_set_fifo_depths\",\n",
    "    \"step_create_stitched_ip\",\n",
    "    \"step_measure_rtlsim_performance\",\n",
    "    \"step_out_of_context_synthesis\",\n",
    "    \"step_synthesize_bitfile\",\n",
    "    \"step_make_pynq_driver\",\n",
    "    \"step_deployment_package\",\n",
    "]\n",
    "\n",
    "cfg_full_build = build.DataflowBuildConfig(\n",
    "    output_dir                    = full_build_output_dir,\n",
    "    mvau_wwidth_max               = my_mvau_wwidth_max, \n",
    "    target_fps                    = my_target_fps,\n",
    "    synth_clk_period_ns           = my_synth_clk_period_ns, #10.0,\n",
    "    board                         = pynq_board,\n",
    "    fpga_part                     = fpga_part,\n",
    "    shell_flow_type               = build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "    standalone_thresholds         = my_standalone_thresholds,\n",
    "    default_swg_exception         = my_default_swg_exception, # Change to True to optimize ConvGenerators, removing FIFOs\n",
    "    auto_fifo_depths              = my_auto_fifo_depths,\n",
    "    auto_fifo_strategy            = my_auto_fifo_strategy, #\"characterize\", -> the other option, takes toooo long\n",
    "    split_large_fifos             = my_split_large_fifos, # Change to True to save resources\n",
    "\n",
    "    steps                         = my_build_steps,\n",
    "    #specialize_layers_config_file = my_specialize_layers_config_file,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "        build_cfg.DataflowOutputType.BITFILE,\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abc46cb-5da7-4d67-9adb-78d4b0156065",
   "metadata": {},
   "source": [
    "# Build using JSON file for Folding or FIFO sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b3df90f-5990-4067-972f-45b2cd306eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder does not exist and it will be created\n"
     ]
    }
   ],
   "source": [
    "full_build_output_dir = config.RUN_FOLDER + \"output_full_build\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(full_build_output_dir):\n",
    "    shutil.rmtree(full_build_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "else:\n",
    "    print(\"Folder does not exist and it will be created\")\n",
    "\n",
    "my_build_json_steps = [\n",
    "    custom_step_tidy_up,\n",
    "    custom_step_add_pre_proc,\n",
    "    custom_step_streamline,\n",
    "    custom_step_convert_to_hw,\n",
    "    \"step_create_dataflow_partition\",\n",
    "    custom_step_specialize_layers,\n",
    "    #\"step_target_fps_parallelization\", # REMOVE this STEP, as folding file will be used\n",
    "    \"step_apply_folding_config\",\n",
    "    \"step_minimize_bit_width\",\n",
    "    \"step_generate_estimate_reports\",\n",
    "    \"step_hw_codegen\",\n",
    "    \"step_hw_ipgen\",\n",
    "    \"step_set_fifo_depths\",\n",
    "    \"step_create_stitched_ip\",\n",
    "    \"step_measure_rtlsim_performance\",\n",
    "    \"step_out_of_context_synthesis\",\n",
    "    \"step_synthesize_bitfile\",\n",
    "    \"step_make_pynq_driver\",\n",
    "    \"step_deployment_package\",\n",
    "]\n",
    "\n",
    "cfg_full_build_json_folding = build.DataflowBuildConfig(\n",
    "    output_dir                    = full_build_output_dir,\n",
    "    mvau_wwidth_max               = my_mvau_wwidth_max, \n",
    "    target_fps                    = my_target_fps,\n",
    "    synth_clk_period_ns           = my_synth_clk_period_ns, #10.0,\n",
    "    board                         = pynq_board,\n",
    "    fpga_part                     = fpga_part,\n",
    "    shell_flow_type               = build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "    standalone_thresholds         = my_standalone_thresholds,\n",
    "    default_swg_exception         = my_default_swg_exception, # Change to True to optimize ConvGenerators, removing FIFOs\n",
    "    auto_fifo_depths              = my_auto_fifo_depths,\n",
    "    auto_fifo_strategy            = my_auto_fifo_strategy, #\"characterize\", -> the other option, takes toooo long\n",
    "    split_large_fifos             = my_split_large_fifos, # Change to True to save resources\n",
    "\n",
    "    steps                         = my_build_json_steps,\n",
    "    folding_config_file           = my_folding_config_file,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "        build_cfg.DataflowOutputType.BITFILE,\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c0309-a6e3-47b4-a850-50551fada8c6",
   "metadata": {},
   "source": [
    "# Choose type of build: estimate, full build or build with json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e829246-2713-4d35-aa94-c0feb1980202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform: full_build_json_folding\n"
     ]
    }
   ],
   "source": [
    "# flow_config = \"estimates\"\n",
    "# flow_config = \"full_build\"\n",
    "flow_config = \"full_build_json_folding\"\n",
    "\n",
    "if flow_config == \"estimates\":\n",
    "    current_build_config = cfg_estimates\n",
    "elif flow_config == \"full_build\":\n",
    "    current_build_config = cfg_full_build\n",
    "elif flow_config == \"full_build_json_folding\":\n",
    "    current_build_config = cfg_full_build_json_folding\n",
    "else:\n",
    "    raise ValueError(\"Wrong config\")\n",
    "\n",
    "print(f'Perform: {flow_config}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25af4f59-1711-47b2-8275-b8d953766c58",
   "metadata": {},
   "source": [
    "# Logging before build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b61950e-3fcd-4651-a303-677253306201",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f'PYNQ board: {pynq_board}\\n' +  \n",
    "            f'\\tModel used: {brevitas_cpu}\\n' +\n",
    "            f'\\tTarget clock period: {my_synth_clk_period_ns} ns.\\n' +\n",
    "            f'\\tTarget fps: my_target_fps: {my_target_fps}.\\n' +\n",
    "            f'\\tmvau_wwidth_max: {my_mvau_wwidth_max}.\\n'+\n",
    "            f'\\tMVAU ALL HLS: {ALL_HLS}.\\n'+ \n",
    "            f'\\tMVAU ALL RTL: {ALL_RTL}.\\n'+ \n",
    "            f'\\tMVAU list: {MVAU_list}.\\n'+\n",
    "            f'\\tVVAU list to DSP: {VVAU_DSP_list}.\\n'+\n",
    "            f'\\tAll ConvInputGen to BRAM: {all_CONV_INP_GEN_bram}.\\n'+\n",
    "            f'\\tConvInputGen list: {CONV_INP_GEN_list}.\\n'+\n",
    "            f'\\tDefault sliding window exception: {my_default_swg_exception}.\\n'+ \n",
    "            f'\\tAuto FIFO depth: {my_auto_fifo_depths}.\\n'+ \n",
    "            f'\\tAuto FIFO strategy: {my_auto_fifo_strategy}.\\n'+ \n",
    "            f'\\tSplit large FIFOs: {my_split_large_fifos}.\\n'+ \n",
    "            f'\\tFolding JSON file: {my_folding_config_file}.\\n'+\n",
    "            f'\\tSpecialize JSON file: {my_specialize_layers_config_file}.\\n'+\n",
    "            f'\\tFlow config: {flow_config}.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50be7c34-7b1c-45ed-b959-3b5e2dc08776",
   "metadata": {},
   "source": [
    "# Build command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "400add5d-a3a9-4dd6-9c1f-ccd173d2e71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from experiments/A_2500_FPS/112/15_full_build_json_mvau_rtl_mvau_wwidth_max_24_manual_folding/clean_model.onnx\n",
      "Intermediate outputs will be generated in /home/gmoreno/workspace\n",
      "Final outputs will be generated in experiments/A_2500_FPS/112/15_full_build_json_mvau_rtl_mvau_wwidth_max_24_manual_folding/output_full_build\n",
      "Build log is at experiments/A_2500_FPS/112/15_full_build_json_mvau_rtl_mvau_wwidth_max_24_manual_folding/output_full_build/build_dataflow.log\n",
      "Running step: custom_step_tidy_up [1/18]\n",
      "Running step: custom_step_add_pre_proc [2/18]\n",
      "Running step: custom_step_streamline [3/18]\n",
      "Running step: custom_step_convert_to_hw [4/18]\n",
      "Running step: step_create_dataflow_partition [5/18]\n",
      "Running step: custom_step_specialize_layers [6/18]\n",
      "Running step: step_apply_folding_config [7/18]\n",
      "Running step: step_minimize_bit_width [8/18]\n",
      "Running step: step_generate_estimate_reports [9/18]\n",
      "Running step: step_hw_codegen [10/18]\n",
      "Running step: step_hw_ipgen [11/18]\n",
      "Running step: step_set_fifo_depths [12/18]\n",
      "Running step: step_create_stitched_ip [13/18]\n",
      "Running step: step_measure_rtlsim_performance [14/18]\n",
      "Running step: step_out_of_context_synthesis [15/18]\n",
      "Running step: step_synthesize_bitfile [16/18]\n",
      "Running step: step_make_pynq_driver [17/18]\n",
      "Running step: step_deployment_package [18/18]\n",
      "Completed successfully\n",
      "CPU times: user 1min 14s, sys: 1.44 s, total: 1min 15s\n",
      "Wall time: 7h 53min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, current_build_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be292d-b169-4016-bf86-0e33a9859f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
