SHUFFLENET Classifier.
	One Head.
	Weighted for Precision.
	Dataset images divided by 255.


Datasets Length
	Train and Val: 128

Device: cuda
Optimizer:
	Learning Rate Freeze: 0.001
	Weight Decay Freeze: 0.001
	Learning Rate Fine Tuning: 1e-05
	Weight Decay Fine Tuning: 0.0001
Scheduler:
	Scheduler factor: 0.8
	Scheduler patience: 2
	Scheduler threshold: 0.001
	Scheduler min learning rate: 1e-06

Batch Size: 64
Num Workers: 6
Pin Memory: True
Epochs Freeze: 2
Epochs Fine Tuning: 3

IMG DIMS:
	Width: 224
	Height: 224

Trainable parameters = 32866
Total parameters = 374658


Torch Summary
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
PRETRAINED_MODEL                              [1, 2]                    --
├─Sequential: 1-1                             [1, 1024, 7, 7]           --
│    └─Sequential: 2-1                        [1, 24, 112, 112]         --
│    │    └─Conv2d: 3-1                       [1, 24, 112, 112]         (648)
│    │    └─BatchNorm2d: 3-2                  [1, 24, 112, 112]         (48)
│    │    └─ReLU: 3-3                         [1, 24, 112, 112]         --
│    └─MaxPool2d: 2-2                         [1, 24, 56, 56]           --
│    └─Sequential: 2-3                        [1, 48, 28, 28]           --
│    │    └─InvertedResidual: 3-4             [1, 48, 28, 28]           (2,400)
│    │    └─InvertedResidual: 3-5             [1, 48, 28, 28]           (1,512)
│    │    └─InvertedResidual: 3-6             [1, 48, 28, 28]           (1,512)
│    │    └─InvertedResidual: 3-7             [1, 48, 28, 28]           (1,512)
│    └─Sequential: 2-4                        [1, 96, 14, 14]           --
│    │    └─InvertedResidual: 3-8             [1, 96, 14, 14]           (8,256)
│    │    └─InvertedResidual: 3-9             [1, 96, 14, 14]           (5,328)
│    │    └─InvertedResidual: 3-10            [1, 96, 14, 14]           (5,328)
│    │    └─InvertedResidual: 3-11            [1, 96, 14, 14]           (5,328)
│    │    └─InvertedResidual: 3-12            [1, 96, 14, 14]           (5,328)
│    │    └─InvertedResidual: 3-13            [1, 96, 14, 14]           (5,328)
│    │    └─InvertedResidual: 3-14            [1, 96, 14, 14]           (5,328)
│    │    └─InvertedResidual: 3-15            [1, 96, 14, 14]           (5,328)
│    └─Sequential: 2-5                        [1, 192, 7, 7]            --
│    │    └─InvertedResidual: 3-16            [1, 192, 7, 7]            (30,336)
│    │    └─InvertedResidual: 3-17            [1, 192, 7, 7]            (19,872)
│    │    └─InvertedResidual: 3-18            [1, 192, 7, 7]            (19,872)
│    │    └─InvertedResidual: 3-19            [1, 192, 7, 7]            (19,872)
│    └─Sequential: 2-6                        [1, 1024, 7, 7]           --
│    │    └─Conv2d: 3-20                      [1, 1024, 7, 7]           (196,608)
│    │    └─BatchNorm2d: 3-21                 [1, 1024, 7, 7]           (2,048)
│    │    └─ReLU: 3-22                        [1, 1024, 7, 7]           --
├─AdaptiveAvgPool2d: 1-2                      [1, 1024, 1, 1]           --
├─Sequential: 1-3                             [1, 2]                    --
│    └─Dropout: 2-7                           [1, 1024]                 --
│    └─Linear: 2-8                            [1, 32]                   32,800
│    └─ReLU: 2-9                              [1, 32]                   --
│    └─Dropout: 2-10                          [1, 32]                   --
│    └─Linear: 2-11                           [1, 2]                    66
===============================================================================================
Total params: 374,658
Trainable params: 32,866
Non-trainable params: 341,792
Total mult-adds (M): 39.49
===============================================================================================
Input size (MB): 0.60
Forward/backward pass size (MB): 16.38
Params size (MB): 1.50
Estimated Total Size (MB): 18.48
===============================================================================================

Torch Model
PRETRAINED_MODEL(
  (base_model): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (2): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (3): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (4): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (5): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (6): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (7): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (4): Sequential(
      (0): InvertedResidual(
        (branch1): Sequential(
          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU(inplace=True)
        )
        (branch2): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (1): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (2): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
      (3): InvertedResidual(
        (branch1): Sequential()
        (branch2): Sequential(
          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (7): ReLU(inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): Conv2d(192, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  (linear): Sequential(
    (0): Dropout(p=0.2, inplace=False)
    (1): Linear(in_features=1024, out_features=32, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.2, inplace=False)
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)

Loss Function: BCE
Smoke Precision Weight: 0.8
Starting script


***Start Training: 23:42:13


=== EPOCH 0/1 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.4875   |0.4883   |0.9968   |0.6555   |
85.08      |40.55     |44.54     |    Fire   |0.4719   |0.3712   |0.8673   |0.5199   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.4870   |0.4883   |0.9947   |0.6550   |
84.06      |40.19     |43.87     |    Fire   |0.6510   |0.3333   |0.1552   |0.2118   |

Saving model with new best validation loss: 84.0579
Saving model with best Mean F1: 0.4334

=== EPOCH 1/1 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.6016   |0.5824   |0.6550   |0.6165   |
81.80      |39.71     |42.09     |    Fire   |0.6906   |0.7826   |0.0853   |0.1538   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.6094   |0.7500   |0.3032   |0.4318   |
80.69      |39.50     |41.18     |    Fire   |0.6979   |0.0000   |0.0000   |0.0000   |

Saving model with new best validation loss: 80.6854
Saving last model

***Script finished: 23:42:23

Time elapsed: 0:00:09.657609

Trainable parameters = 374658
Total parameters = 374658

Fine Tuning


***Start Training: 23:42:23


=== EPOCH 2/4 ===
Learning Rate = 1e-05

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5984   |0.7154   |0.2971   |0.4199   |
80.07      |39.34     |40.73     |    Fire   |0.6859   |1.0000   |0.0474   |0.0905   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.6094   |0.8167   |0.2606   |0.3952   |
80.04      |39.41     |40.62     |    Fire   |0.6979   |0.0000   |0.0000   |0.0000   |

Saving model with new best validation loss: 80.0354
Saving model with best Mean F1: 0.1976

=== EPOCH 3/4 ===
Learning Rate = 1e-05

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5859   |0.6905   |0.2780   |0.3964   |
80.05      |39.35     |40.70     |    Fire   |0.6766   |1.0000   |0.0190   |0.0372   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.6094   |0.8519   |0.2447   |0.3802   |
79.76      |39.37     |40.39     |    Fire   |0.7005   |1.0000   |0.0086   |0.0171   |

Saving model with new best validation loss: 79.7571
Saving model with best Mean F1: 0.1986

=== EPOCH 4/4 ===
Learning Rate = 1e-05

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.6078   |0.7067   |0.3387   |0.4579   |
79.86      |39.23     |40.64     |    Fire   |0.6781   |0.8571   |0.0284   |0.0550   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.6120   |0.8421   |0.2553   |0.3918   |
79.56      |39.33     |40.23     |    Fire   |0.7005   |1.0000   |0.0086   |0.0171   |

Saving model with new best validation loss: 79.5568
Saving model with best Mean F1: 0.2045
Saving last model

***Script finished: 23:42:38

Time elapsed: 0:00:15.391647
