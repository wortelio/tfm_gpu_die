{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba6f86b-976b-4011-9ce7-7624ef404d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import config\n",
    "import modules.classification_dataloaders as classification_data_loader\n",
    "import modules.dataloaders as detection_data_loader\n",
    "import modules.metrics as metrics\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f19697c9-984a-471a-b8a0-6bde511a2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b168b-544e-46ee-841a-ac7fd4db5b37",
   "metadata": {},
   "source": [
    "# Check Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271ebeb-50c8-47e7-99e0-f3f04a2eae9b",
   "metadata": {},
   "source": [
    "## Classifier Medium Compression: 25,59 KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab06eb5-becf-454d-a639-b3f45f2c9079",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = onnx.load('./onnx_models/medium_fassd__conv341_big__epoch=93.onnx')\n",
    "onnx.checker.check_model(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55312cde-319a-4789-b0ae-47e7c08e80e9",
   "metadata": {},
   "source": [
    "## Detector with Compression and w8a8b8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c59929c-4825-4f6e-a2a6-a86e2ac30370",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = onnx.load('./onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx')\n",
    "onnx.checker.check_model(detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd2f4f-24b4-49c2-a0ea-3b58ddef593d",
   "metadata": {},
   "source": [
    "# Classification Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07f07076-7bac-4bc8-aa29-34d12bf9c66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST DFire dataset\n",
      "DFire Removed wrong images: 0\n",
      "DFire empty images: 2005\n",
      "DFire only smoke images: 1186\n",
      "DFire only fire images: 220\n",
      "DFire smoke and fire images: 895\n",
      "\n",
      "Test dataset len: 4306\n",
      "\n",
      "TEST FASDD UAV dataset\n",
      "DFire Removed wrong images: 0\n",
      "DFire empty images: 1997\n",
      "DFire only smoke images: 846\n",
      "DFire only fire images: 35\n",
      "DFire smoke and fire images: 1303\n",
      "\n",
      "Test FASDD UAV dataset len: 4181\n",
      "\n",
      "TEST FASDD CV dataset\n",
      "DFire Removed wrong images: 0\n",
      "DFire empty images: 6533\n",
      "DFire only smoke images: 3902\n",
      "DFire only fire images: 2091\n",
      "DFire smoke and fire images: 3358\n",
      "\n",
      "Test FASDD CV dataset len: 15884\n",
      "\n",
      "Concatenate Test DFire and FASDD UAV datasets\n",
      "Test dataset len: 8487\n",
      "Concatenate with FASDD CV dataset\n",
      "Test dataset len: 24371\n"
     ]
    }
   ],
   "source": [
    "#classification_loader = classification_data_loader.get_val_loader(shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a026033e-c8b5-4da0-a087-ace6e428caa5",
   "metadata": {},
   "source": [
    "# Helper function to convert pytorch tensors to numpy. Useful to handle datatset output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71913b22-0a62-49f5-9027-3b07ec2648ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7108e0-2bbd-4106-b597-cfec81cca0f6",
   "metadata": {},
   "source": [
    "# Evaluate ONNX with F1 Mean, Smoke and Fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d667e34-8352-45f1-ada8-51feefbdf4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_metric = torchmetrics.classification.MultilabelPrecision(num_labels = config.N_CLASSES, \n",
    "#                                                                    threshold = 0.5, \n",
    "#                                                                    average = None).to('cpu')\n",
    "# recall_metric = torchmetrics.classification.MultilabelRecall(num_labels = config.N_CLASSES, \n",
    "#                                                              threshold = 0.5, \n",
    "#                                                              average = None).to('cpu')\n",
    "# accuracy_metric = torchmetrics.classification.MultilabelAccuracy(num_labels = config.N_CLASSES, \n",
    "#                                                                  threshold = 0.5, \n",
    "#                                                                  average = None).to('cpu')\n",
    "# f1_metric = torchmetrics.classification.MultilabelF1Score(num_labels = config.N_CLASSES, \n",
    "#                                                           threshold = 0.5, \n",
    "#                                                           average = None).to('cpu')\n",
    "\n",
    "# f1_metric_mean = torchmetrics.classification.MultilabelF1Score(num_labels = config.N_CLASSES, \n",
    "#                                                                threshold = 0.5, \n",
    "#                                                                average = 'macro').to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcee3f5-22d2-457f-bd2e-c8c1154cb674",
   "metadata": {},
   "source": [
    "### Classifier evaluation funtion\n",
    "\n",
    "Out of ONNX Model:\n",
    "- list with 1 np.array\n",
    "- [ np.array(batch, shape of 1 inference) ]\n",
    "- to access 1 inference: out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea734538-d03d-4fcf-a812-4642894c1778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_classifier_onnx(loader, model_name):\n",
    "\n",
    "#     ort_session = onnxruntime.InferenceSession(model_name, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "#     precision_metric.reset()\n",
    "#     recall_metric.reset()\n",
    "#     accuracy_metric.reset()\n",
    "#     f1_metric.reset()\n",
    "#     f1_metric_mean.reset()\n",
    "    \n",
    "#     loop = tqdm(loader, desc='Validating', leave=True)\n",
    "\n",
    "#     for batch_idx, (img, label) in enumerate(loop):\n",
    "\n",
    "#         for idx in range(config.BATCH_SIZE):\n",
    "            \n",
    "#             ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img[idx].unsqueeze(dim=0))}\n",
    "#             yhat = ort_session.run(None, ort_inputs)\n",
    "#             yhat = np.array(yhat)\n",
    "#             #yhat = torch.tensor(yhat).squeeze(dim=0)\n",
    "#             yhat = torch.sigmoid(torch.tensor(yhat).squeeze(dim=0))\n",
    "#             target = label[idx].unsqueeze(dim=0)\n",
    "\n",
    "#             precision_metric.update(yhat, target)\n",
    "#             recall_metric.update(yhat, target)\n",
    "#             accuracy_metric.update(yhat, target)\n",
    "#             f1_metric.update(yhat, target)\n",
    "#             f1_metric_mean.update(yhat, target)\n",
    "    \n",
    "#     precision = precision_metric.compute()\n",
    "#     recall = recall_metric.compute()\n",
    "#     accuracy = accuracy_metric.compute()\n",
    "#     f1 = f1_metric.compute()\n",
    "#     f1_mean = f1_metric_mean.compute()\n",
    "\n",
    "#     precision_metric.reset()\n",
    "#     recall_metric.reset()\n",
    "#     accuracy_metric.reset()\n",
    "#     f1_metric.reset()\n",
    "#     f1_metric_mean.reset()\n",
    "\n",
    "#     print(f'SMOKE -> Precision: {precision[0]:.4f} - Recall: {recall[0]:.4f} - Accuracy: {accuracy[0]:.4f} - F1: {f1[0]:.4f}')\n",
    "#     print(f'FIRE -> Precision: {precision[1]:.4f} - Recall: {recall[1]:.4f} - Accuracy: {accuracy[1]:.4f} - F1: {f1[1]:.4f}')\n",
    "#     print(f'Mean F1 Score: {f1_mean.item():.4f}')\n",
    "    \n",
    "#     return (\n",
    "#         {\n",
    "#         'Accuracy': [accuracy[0].item(), accuracy[1].item()],\n",
    "#         'Precision': [precision[0].item(), precision[1].item()],\n",
    "#         'Recall': [recall[0].item(), recall[1].item()],\n",
    "#         'F1': [f1[0].item(), f1[1].item()],\n",
    "#         'F1 mean': f1_mean.item(),\n",
    "#         }\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5511c960-7f6a-4161-a902-9530f9c7a249",
   "metadata": {},
   "source": [
    "# Evaluate Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d23b7a7-750e-431d-a37d-2a58b02280b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "________________________________ Classifier MEDIUM COMPRESSION _______________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 380/380 [01:12<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOKE -> Precision: 0.9099 - Recall: 0.8943 - Accuracy: 0.9084 - F1: 0.9020\n",
      "FIRE -> Precision: 0.9032 - Recall: 0.9697 - Accuracy: 0.9565 - F1: 0.9353\n",
      "Mean F1 Score: 0.9187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# print(\"\\n________________________________ Classifier MEDIUM COMPRESSION _______________________________\")\n",
    "# _ = eval_classifier_onnx(classification_loader, './onnx_models/medium_fassd__conv341_big__epoch=93.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c00db97-79d2-4d7a-b30a-6ceed359a8e1",
   "metadata": {},
   "source": [
    "### Results with Full Dataset\n",
    "\n",
    "- SMOKE -> Precision: 0.9099 - Recall: 0.8943 - Accuracy: 0.9084 - F1: 0.9020\n",
    "- FIRE -> Precision: 0.9032 - Recall: 0.9697 - Accuracy: 0.9565 - F1: 0.9353\n",
    "- Mean F1 Score: 0.9187"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7588acf-53c8-4a42-81f0-91104f972d2a",
   "metadata": {},
   "source": [
    "# Detection Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "496a4ef3-6a8b-48ca-9a30-16ebaffafc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST DFire dataset\n",
      "DFire Removed wrong images: 0\n",
      "DFire Removed due to overlapping: 310\n",
      "DFire Removed due to more than 10: 13\n",
      "\n",
      "Test DFire dataset len: 3983\n",
      "\n",
      "TEST FASDD UAV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD Removed due to overlapping: 377\n",
      "FASDD Removed due to more than 10: 156\n",
      "\n",
      "Test FASDD UAV dataset len: 3648\n",
      "\n",
      "TEST FASDD CV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD Removed due to overlapping: 317\n",
      "FASDD Removed due to more than 10: 44\n",
      "\n",
      "Test FASDD CV dataset len: 15523\n",
      "\n",
      "Concatenate Test DFire and FASDD UAV datasets\n",
      "Test dataset len: 7631\n",
      "Concatenate with FASDD CV dataset\n",
      "Test dataset len: 23154\n"
     ]
    }
   ],
   "source": [
    "detection_loader = detection_data_loader.get_val_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ec9f0e-6cba-483b-91a9-3f0480dace32",
   "metadata": {},
   "source": [
    "# Evaluate Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c520ebc0-3558-4b8a-b1c1-dd72ed63d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_metric = MeanAveragePrecision(\n",
    "    box_format='xyxy',\n",
    "    iou_thresholds=[config.IOU_THRESHOLD],\n",
    "    class_metrics=True, # Enables separated metrics for each class\n",
    "    #average='micro',\n",
    "    extended_summary=False).to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fdb067-87f5-4f3d-9a8e-005b560ee4bb",
   "metadata": {},
   "source": [
    "### Score Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e65b80-b9c7-4e4c-b043-f747a870cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE_THRES = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f15194-af3f-4006-a267-1ecef05cab30",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69dbabd9-aee8-4701-b978-82d2fa3b2c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_detector_onnx(loader, model_name, score_thres):\n",
    "\n",
    "    ort_session = onnxruntime.InferenceSession(model_name, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "    map_metric.reset()\n",
    "    \n",
    "    loop = tqdm(loader, desc='Validating', leave=True)\n",
    "\n",
    "    for batch_idx, (img, label) in enumerate(loop):\n",
    "\n",
    "        for idx in range(config.BATCH_SIZE):\n",
    "            \n",
    "            ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img[idx].unsqueeze(dim=0))}\n",
    "            out = ort_session.run(None, ort_inputs)\n",
    "            \n",
    "            # out of onnx session is a list: [out_tensor with batch dim] -> [ (1,12,7,7) ] \n",
    "            # -> out[0] = (1,12,7,7)\n",
    "            # -> out[0][0] = (12,7,7)\n",
    "            #print(f'Out type: {type(out[0])} - Output shape: {out[0].shape}')\n",
    "            out = torch.tensor(np.array(out[0]))\n",
    "            out = out.permute(0, 2, 3, 1)\n",
    "            #print(f'Out shape after permute: {out.shape}')\n",
    "            #print(f'Out shape after indexing: {out[0].shape}')\n",
    "            \n",
    "            # Label should be [xc, yc, w, h, score=1, smoke, fire] in 7x7 square\n",
    "            #print(f'Label indexed shape: {label[idx].shape}')\n",
    "            \n",
    "        # Mean Average Precision\n",
    "            target_boxes = metrics.get_true_boxes(label[idx].detach().to('cpu'))\n",
    "            pred_boxes = metrics.get_pred_boxes(\n",
    "                model_out = out[0].detach().to('cpu'),\n",
    "                score_threshold=score_thres)\n",
    "            map_metric.update(preds = pred_boxes, target = target_boxes)\n",
    "    \n",
    "    meanAP = map_metric.compute()\n",
    "    map_metric.reset()\n",
    "\n",
    "    print(f'Smoke -> AP: {meanAP[\"map_per_class\"][0].item():.4f} - AR: {meanAP[\"mar_100_per_class\"][0].item():.4f}')\n",
    "    print(f'Fire -> AP: {meanAP[\"map_per_class\"][1].item():.4f} - AR: {meanAP[\"mar_100_per_class\"][1].item():.4f}')\n",
    "    print(f'mAP: {meanAP[\"map_50\"].item():.4f}')\n",
    "    \n",
    "    return (\n",
    "        {'mAP': meanAP['map_50'].item(),\n",
    "         'AP': [meanAP['map_per_class'][0].item(), meanAP['map_per_class'][1].item()],\n",
    "         'AR': [meanAP['mar_100_per_class'][0].item(), meanAP['mar_100_per_class'][1].item()]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4ecac66-d2a6-4449-96c6-7176d61d3519",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "________________________________ Detector MEDIUM COMPRESSION _______________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [01:18<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6470 - AR: 0.7070\n",
      "Fire -> AP: 0.6108 - AR: 0.6680\n",
      "mAP: 0.6289\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n________________________________ Detector MEDIUM COMPRESSION _______________________________\")\n",
    "_ = eval_detector_onnx(\n",
    "    detection_loader, \n",
    "    './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    SCORE_THRES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d4e69a-5eba-47e1-8b24-37647ae6e495",
   "metadata": {},
   "source": [
    "# Classify 1st + Detection 2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4618786-17b7-4af2-a473-b226582852e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_classifier_plus_detector_onnx(\n",
    "    loader, \n",
    "    classifier_model_name,\n",
    "    detector_model_name,\n",
    "    classification_thres=0,\n",
    "    score_thres=0.2\n",
    "):\n",
    "\n",
    "    classify_session = onnxruntime.InferenceSession(classifier_model_name, providers=[\"CPUExecutionProvider\"])\n",
    "    detect_session = onnxruntime.InferenceSession(detector_model_name, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "    map_metric.reset()\n",
    "    \n",
    "    loop = tqdm(loader, desc='Validating', leave=True)\n",
    "\n",
    "    for batch_idx, (img, label) in enumerate(loop):\n",
    "\n",
    "        for idx in range(config.BATCH_SIZE):\n",
    "            \n",
    "            classify_inputs = {classify_session.get_inputs()[0].name: to_numpy(img[idx].unsqueeze(dim=0))}\n",
    "            classification_out = classify_session.run(None, classify_inputs)\n",
    "            # print(f'Smoke pred: {classification_out[0][0][0]}')\n",
    "            # print(f'Fire pred: {classification_out[0][0][1]}')\n",
    "            \n",
    "            # Use Detector if Classifier predicts fire or smoke\n",
    "            if ( classification_out[0][0][0] >= classification_thres \n",
    "                or \n",
    "                classification_out[0][0][1] >= classification_thres ):\n",
    "                detect_inputs = {detect_session.get_inputs()[0].name: to_numpy(img[idx].unsqueeze(dim=0))}\n",
    "                out = detect_session.run(None, detect_inputs)\n",
    "                out = torch.tensor(np.array(out[0]))\n",
    "                out = out.permute(0, 2, 3, 1)\n",
    "            else:\n",
    "                out = torch.zeros(1,7,7,12)           \n",
    "            \n",
    "            \n",
    "        # Mean Average Precision\n",
    "            target_boxes = metrics.get_true_boxes(label[idx].detach().to('cpu'))\n",
    "            pred_boxes = metrics.get_pred_boxes(\n",
    "                model_out = out[0].detach().to('cpu'),\n",
    "                score_threshold=score_thres)\n",
    "            map_metric.update(preds = pred_boxes, target = target_boxes)\n",
    "    \n",
    "    meanAP = map_metric.compute()\n",
    "    map_metric.reset()\n",
    "\n",
    "    print(f'Smoke -> AP: {meanAP[\"map_per_class\"][0].item():.4f} - AR: {meanAP[\"mar_100_per_class\"][0].item():.4f}')\n",
    "    print(f'Fire -> AP: {meanAP[\"map_per_class\"][1].item():.4f} - AR: {meanAP[\"mar_100_per_class\"][1].item():.4f}')\n",
    "    print(f'mAP: {meanAP[\"map_50\"]:.4f}')\n",
    "    \n",
    "    return (\n",
    "        {'mAP': meanAP['map_50'].item(),\n",
    "         'AP': [meanAP['map_per_class'][0].item(), meanAP['map_per_class'][1].item()],\n",
    "         'AR': [meanAP['mar_100_per_class'][0].item(), meanAP['mar_100_per_class'][1].item()]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3912ee72-4603-417f-913c-867f267f22c9",
   "metadata": {},
   "source": [
    "### Classification Threshold = 0, Score Threshold = 0.2\n",
    "\n",
    "Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cae94db2-24f4-4eb6-a0f2-e7bf160e4c84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [02:56<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6322 - AR: 0.6851\n",
      "Fire -> AP: 0.6139 - AR: 0.6639\n",
      "mAP: 0.6231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': 0.6230778694152832,\n",
       " 'AP': [0.6322451233863831, 0.6139106154441833],\n",
       " 'AR': [0.6851410865783691, 0.6639198660850525]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classifier_plus_detector_onnx(\n",
    "    loader = detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    classification_thres = 0,\n",
    "    score_thres = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49129fd-f216-4b7f-b5ee-371bc9f779d8",
   "metadata": {},
   "source": [
    "## Classification Threshold\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sigma(z) = \\frac{1}{1-e^{-z}} \\; & \\Longrightarrow \\; z=\\ln(\\sigma(z)) - \\ln(1-\\sigma(z)) \\\\\n",
    "\\\\\n",
    "\\sigma(z) = 0.45 \\; & \\longrightarrow \\; z=-0.20067 \\\\\n",
    "\\sigma(z) = 0.40 \\; & \\longrightarrow \\; z=-0.4054651081 \\\\\n",
    "\\sigma(z) = 0.35 \\; & \\longrightarrow \\; z=-0.6190392084 \\\\\n",
    "\\sigma(z) = 0.30 \\; & \\longrightarrow \\; z=-0.8472978604 \\\\\n",
    "\\sigma(z) = 0.25 \\; & \\longrightarrow \\; z=-1.098612289\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3232b10-f260-4081-8c68-dde2f5fcb9ce",
   "metadata": {},
   "source": [
    "### Classification Threshold (45 %)= -0.20067, Score Threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85269113-5e0e-4fdc-a5ec-8957c733324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [03:03<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6332 - AR: 0.6899\n",
      "Fire -> AP: 0.6139 - AR: 0.6644\n",
      "mAP: 0.6235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': 0.6235257387161255,\n",
       " 'AP': [0.633199155330658, 0.613852322101593],\n",
       " 'AR': [0.6899014115333557, 0.6643880605697632]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classifier_plus_detector_onnx(\n",
    "    loader = detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    classification_thres = -0.20067,\n",
    "    score_thres = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fa8e72-eaf8-43d2-836f-26c9020780ff",
   "metadata": {},
   "source": [
    "### Classification Threshold (40 %) = -0.4054651081, Score Threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a538b00-815a-49a7-abcd-a68944b71193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [03:01<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6414 - AR: 0.6947\n",
      "Fire -> AP: 0.6138 - AR: 0.6648\n",
      "mAP: 0.6276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': 0.627581775188446,\n",
       " 'AP': [0.6413736343383789, 0.613789975643158],\n",
       " 'AR': [0.6947466731071472, 0.6647626161575317]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classifier_plus_detector_onnx(\n",
    "    loader = detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    classification_thres = -0.4054651081,\n",
    "    score_thres = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99820d5-3cbc-4df1-a3fd-d45bcf800bbe",
   "metadata": {},
   "source": [
    "### Classification Threshold (35 %) = -0.6190392084, Score Threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35a69230-a00e-4c8d-ada3-9e0a10cd5ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [02:59<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6421 - AR: 0.6991\n",
      "Fire -> AP: 0.6136 - AR: 0.6649\n",
      "mAP: 0.6279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': 0.6278664469718933,\n",
       " 'AP': [0.6421014666557312, 0.6136313676834106],\n",
       " 'AR': [0.6990819573402405, 0.6648562550544739]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classifier_plus_detector_onnx(\n",
    "    loader = detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    classification_thres = -0.6190392084,\n",
    "    score_thres = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688646cb-7cbe-4aab-bb6d-aafeec2bfd7a",
   "metadata": {},
   "source": [
    "### Classification Threshold (30 %) = -0.8472978604, Score Threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea2e2e30-7db0-48e1-b28f-53bc8f5a9fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [03:02<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6495 - AR: 0.7014\n",
      "Fire -> AP: 0.6134 - AR: 0.6649\n",
      "mAP: 0.6315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': 0.6314582228660583,\n",
       " 'AP': [0.6495007872581482, 0.6134156584739685],\n",
       " 'AR': [0.7013770937919617, 0.664949893951416]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classifier_plus_detector_onnx(\n",
    "    loader = detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    classification_thres = -0.8472978604,\n",
    "    score_thres = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652d5065-c8c4-404c-89db-beefbc229ace",
   "metadata": {},
   "source": [
    "### Classification Threshold (25 %) = -1.098612289, Score Threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d82558d-3a4a-4598-95cf-927f9fedaef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [03:05<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6497 - AR: 0.7031\n",
      "Fire -> AP: 0.6133 - AR: 0.6655\n",
      "mAP: 0.6315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': 0.6315064430236816,\n",
       " 'AP': [0.6496885418891907, 0.6133243441581726],\n",
       " 'AR': [0.7030771970748901, 0.6655117273330688]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classifier_plus_detector_onnx(\n",
    "    loader = detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    classification_thres = -1.098612289,\n",
    "    score_thres = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2d9440-81ec-4eb5-a295-e41c0a25a93c",
   "metadata": {},
   "source": [
    "### Classification Threshold = 0, Score Threshold = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f09c002a-8b44-4e34-ac3a-16c8f90936e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [03:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6393 - AR: 0.6993\n",
      "Fire -> AP: 0.6139 - AR: 0.6699\n",
      "mAP: 0.6266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': 0.6266161799430847,\n",
       " 'AP': [0.6393217444419861, 0.6139106154441833],\n",
       " 'AR': [0.6993369460105896, 0.6699129343032837]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classifier_plus_detector_onnx(\n",
    "    loader = detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    score_thres = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9460834-14f7-40fa-80df-8ed3cd0f0578",
   "metadata": {},
   "source": [
    "### Classification Threshold = 0, Score Threshold = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50ba1227-b943-4946-a705-790947fa49d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [03:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6523 - AR: 0.7153\n",
      "Fire -> AP: 0.6201 - AR: 0.6758\n",
      "mAP: 0.6362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': 0.6361923813819885,\n",
       " 'AP': [0.6522578001022339, 0.6201269626617432],\n",
       " 'AR': [0.7153179049491882, 0.6758123636245728]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classifier_plus_detector_onnx(\n",
    "    loader = detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    score_thres = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e96f1-b188-4c94-ad47-dddf5dd35dd3",
   "metadata": {},
   "source": [
    "### Classification Threshold = 0, Score Threshold = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0edb512-7e61-438d-b109-3e0b6f3f0fca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [03:38<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6740 - AR: 0.7727\n",
      "Fire -> AP: 0.6251 - AR: 0.6896\n",
      "mAP: 0.6496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': 0.649551510810852,\n",
       " 'AP': [0.6739742755889893, 0.6251287460327148],\n",
       " 'AR': [0.7726963758468628, 0.6895776987075806]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classifier_plus_detector_onnx(\n",
    "    loader = detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    score_thres = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed1654c-8c43-4fa8-926d-9bd2c607f715",
   "metadata": {},
   "source": [
    "### Score Threshold = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "736d9df5-a37e-46be-9b66-d669f70dcfed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [10:26<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6746 - AR: 0.7843\n",
      "Fire -> AP: 0.6269 - AR: 0.6904\n",
      "mAP: 0.6508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': 0.6507548093795776,\n",
       " 'AP': [0.6746267676353455, 0.626882791519165],\n",
       " 'AR': [0.7843420505523682, 0.6904204487800598]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classifier_plus_detector_onnx(\n",
    "    loader = detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    score_thres = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eb3f6d-f5f1-49aa-98ce-0e138eeb053f",
   "metadata": {},
   "source": [
    "# Aladdin Metrics to Get Precision and Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db5e8805-abfb-4d81-aec3-12f6b6e58baf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import modules.metrics_mAP_aladdin as aladdin_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1f59270-db99-4155-871b-de41e4086a14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' ============================\n",
    "    Cell to Box Mask\n",
    "============================ '''\n",
    "cell2box_mask = torch.zeros((config.S, config.S, 2))\n",
    "for i in range(config.S):\n",
    "    for j in range(config.S):\n",
    "        cell2box_mask[i,j,0] = j\n",
    "        cell2box_mask[i,j,1] = i  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2590ba94-5e1e-4a5f-b145-87d0ec068548",
   "metadata": {},
   "source": [
    "### Aladdin mAP modified for ONNX, classify + detect, with classification and detection thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b31282c8-1c12-49e8-bff9-6559b22ee7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aladdin_get_bboxes(\n",
    "    loader,\n",
    "    classifier_model_name,\n",
    "    detector_model_name,\n",
    "    S=config.S,\n",
    "    B=config.B,\n",
    "    C=config.C,\n",
    "    mask=cell2box_mask,\n",
    "    device='cpu',\n",
    "    iou_threshold=0.5,\n",
    "    classification_thres = 0,\n",
    "    score_thres=0.2,\n",
    "    box_format=\"midpoint\"):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Return:\n",
    "        - all_pred_boxes\n",
    "        - all_true_boxes\n",
    "        Format: [train_idx, class_prediction, prob_score, x1, y1, x2, y2]\n",
    "    '''\n",
    "    \n",
    "    classify_session = onnxruntime.InferenceSession(classifier_model_name, providers=[\"CPUExecutionProvider\"])\n",
    "    detect_session = onnxruntime.InferenceSession(detector_model_name, providers=[\"CPUExecutionProvider\"])\n",
    "    \n",
    "    \n",
    "    all_pred_boxes = []\n",
    "    all_true_boxes = []\n",
    "\n",
    "    # Original Code\n",
    "    # make sure model is in eval before get bboxes\n",
    "    #model.eval()\n",
    "    train_idx = 0\n",
    "\n",
    "    loop = tqdm(loader, desc='Get Boxes', leave=True)\n",
    "    for batch_idx, (imgs, labels) in enumerate(loop):\n",
    "        # Original Code\n",
    "        # Inference in GPU. Move tensor to CPU in outcell_2_outboxes\n",
    "        # imgs = imgs.to(device)\n",
    "        # labels = labels.to(device)\n",
    "\n",
    "\n",
    "        for idx in range(config.BATCH_SIZE):\n",
    "            \n",
    "            classify_inputs = {classify_session.get_inputs()[0].name: to_numpy(imgs[idx].unsqueeze(dim=0))}\n",
    "            classification_out = classify_session.run(None, classify_inputs)\n",
    "            # print(f'Smoke pred: {classification_out[0][0][0]}')\n",
    "            # print(f'Fire pred: {classification_out[0][0][1]}')\n",
    "            \n",
    "            # Use Detector if Classifier predicts fire or smoke\n",
    "            if ( classification_out[0][0][0] >= classification_thres \n",
    "                or \n",
    "                classification_out[0][0][1] >= classification_thres ):\n",
    "                detect_inputs = {detect_session.get_inputs()[0].name: to_numpy(imgs[idx].unsqueeze(dim=0))}\n",
    "                out = detect_session.run(None, detect_inputs)\n",
    "                out = torch.tensor(np.array(out[0]))\n",
    "                out = out.permute(0, 2, 3, 1)\n",
    "            else:\n",
    "                out = torch.zeros(1,7,7,12)           \n",
    "            \n",
    "            # Original Code\n",
    "            # with torch.no_grad():\n",
    "            #     predictions = model(imgs)\n",
    "\n",
    "            # Original Code\n",
    "            # Remove Permute from the model\n",
    "            #predictions = predictions.permute(0, 2, 3, 1) # Original Code\n",
    "\n",
    "            #batch_size = imgs.shape[0] # Original Code\n",
    "\n",
    "            true_bboxes = aladdin_metrics.outcell_2_outboxes(\n",
    "                out_cells=labels[idx].unsqueeze(dim=0), \n",
    "                S=S, B=B, C=C, \n",
    "                mask=mask, \n",
    "                device='cpu', # Changed to cpu\n",
    "                is_pred=False)\n",
    "            bboxes = aladdin_metrics.outcell_2_outboxes(\n",
    "                out_cells=out, \n",
    "                S=S, B=B, C=C, \n",
    "                mask=mask, \n",
    "                device='cpu', # Changed to cpu\n",
    "                is_pred=True)\n",
    "\n",
    "            for idx in range(1): # Only 1 image every time, due to ONNX prediction in CPU\n",
    "                nms_boxes = aladdin_metrics.nms_yv1_getBBoxes(\n",
    "                    bboxes[idx],\n",
    "                    iou_threshold=iou_threshold,\n",
    "                    threshold=score_thres,\n",
    "                    box_format=box_format, # Midpoint, to use iou_tensor inside\n",
    "                )\n",
    "\n",
    "\n",
    "                # Plot some examples\n",
    "                #if batch_idx == 0 and idx == 0:\n",
    "                #    plot_image(x[idx].permute(1,2,0).to(\"cpu\"), nms_boxes)\n",
    "                #    print(nms_boxes)\n",
    "\n",
    "                for nms_box in nms_boxes:\n",
    "                    all_pred_boxes.append([train_idx] + nms_box)\n",
    "\n",
    "                for box in true_bboxes[idx]:\n",
    "                    # many will get converted to 0 pred, as bboxes have Conf = 1 and the rest are 0\n",
    "                    if box[1] > score_thres:\n",
    "                        all_true_boxes.append([train_idx] + box)\n",
    "\n",
    "                train_idx += 1\n",
    "\n",
    "    #model.train()\n",
    "    return all_pred_boxes, all_true_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69d3002-4bbf-48e6-8d0a-0fc04d2689c3",
   "metadata": {},
   "source": [
    "# Function to Print mAP metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3106e8f4-b50f-44b0-977d-9b0790f38846",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_metrics(mAP_metrics):\n",
    "    mAP, avg_prec, cls_prec, cls_rec = mAP_metrics\n",
    "    \n",
    "    mAP_str = \"mAP @0.50\"\n",
    "    smoke = \"Smoke\"\n",
    "    fire = \"Fire\"\n",
    "    \n",
    "    print(f'{mAP_str:<12}' + f'{mAP:.4f}')\n",
    "    print('Average Precision')\n",
    "    print(f'- {smoke:<10}' + f'{avg_prec[0]:.4f}')\n",
    "    print(f'- {fire:<10}' + f'{avg_prec[1]:.4f}')\n",
    "    print('Class Precision')\n",
    "    print(f'- {smoke:<10}' + f'{cls_prec[0]:.4f}')\n",
    "    print(f'- {fire:<10}' + f'{cls_prec[1]:.4f}')  \n",
    "    print('Class Recall')\n",
    "    print(f'- {smoke:<10}' + f'{cls_rec[0]:.4f}')\n",
    "    print(f'- {fire:<10}' + f'{cls_rec[1]:.4f}')\n",
    "    print('Class F1-Score')\n",
    "    smoke_f1 = 2 * (cls_prec[0] * cls_rec[0]) / (cls_prec[0] + cls_rec[0])\n",
    "    fire_f1 = 2 * (cls_prec[1] * cls_rec[1]) / (cls_prec[1] + cls_rec[1])\n",
    "    print(f'- {smoke:<10}' + f'{smoke_f1:.4f}')\n",
    "    print(f'- {fire:<10}' + f'{fire_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723eab35-675b-4b31-bf5f-8b31baa29493",
   "metadata": {},
   "source": [
    "### Log Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c793261-c7c8-4c5f-858f-f68a93a0fc9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_path = './mAP_&_pr_curves/classify_&_detect/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24ce81-8b18-4f4a-8fbf-07e328effa35",
   "metadata": {},
   "source": [
    "## Score Thres = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bec29fcc-8b71-4b44-8abc-de74f9156e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Boxes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [03:15<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_boxes_1, true_boxes_1 = aladdin_get_bboxes(\n",
    "    detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c88d61-6893-4af1-9aaf-909354d02c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_02_metrics = aladdin_metrics.mAP(\n",
    "    log_path=log_path + 'score_thres_2e-1/',\n",
    "    pred_boxes=pred_boxes_1,\n",
    "    true_boxes=true_boxes_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4c193cc-f7df-4798-8328-7dabf4a7ce55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP @0.50   0.6239\n",
      "Average Precision\n",
      "- Smoke     0.6343\n",
      "- Fire      0.6134\n",
      "Class Precision\n",
      "- Smoke     0.7291\n",
      "- Fire      0.6776\n",
      "Class Recall\n",
      "- Smoke     0.6855\n",
      "- Fire      0.6640\n",
      "Class F1-Score\n",
      "- Smoke     0.7066\n",
      "- Fire      0.6707\n"
     ]
    }
   ],
   "source": [
    "print_metrics(score_02_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8916ead-e02a-4b78-8bfe-611c4511b569",
   "metadata": {},
   "source": [
    "## Score Thres = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "489b2977-9cdb-4f76-89c1-df8d0f3fa2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Boxes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [10:42<00:00,  1.78s/it]\n"
     ]
    }
   ],
   "source": [
    "pred_boxes_2, true_boxes_2 = aladdin_get_bboxes(\n",
    "    detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    score_thres = 0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6a3568-bc17-48b8-80fc-753cf3759cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_0001_metrics = aladdin_metrics.mAP(\n",
    "    log_path=log_path + 'score_thres_1e-3/',\n",
    "    pred_boxes=pred_boxes_2,\n",
    "    true_boxes=true_boxes_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bc2924a-a3d9-4bf8-a072-995452fd24d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP @0.50   0.6519\n",
      "Average Precision\n",
      "- Smoke     0.6769\n",
      "- Fire      0.6270\n",
      "Class Precision\n",
      "- Smoke     0.0254\n",
      "- Fire      0.1187\n",
      "Class Recall\n",
      "- Smoke     0.7846\n",
      "- Fire      0.6905\n",
      "Class F1-Score\n",
      "- Smoke     0.0492\n",
      "- Fire      0.2026\n"
     ]
    }
   ],
   "source": [
    "print_metrics(score_0001_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd159a2f-0855-4051-b42c-bcc257b40bf0",
   "metadata": {},
   "source": [
    "## Classification Threshold (30 %) =  Score Thres = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0b2ec43-a950-4ac9-abca-ef63f6721393",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Boxes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [04:32<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_boxes_3, true_boxes_3 = aladdin_get_bboxes(\n",
    "    detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    classification_thres = -0.8472978604,\n",
    "    score_thres = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b88d68-4813-4c48-a95e-d31a60637125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_030_score_02_metrics = aladdin_metrics.mAP(\n",
    "    log_path=log_path + 'classify_030_score_thres_2e-1/',\n",
    "    pred_boxes=pred_boxes_3,\n",
    "    true_boxes=true_boxes_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d73f65a5-02d0-4699-a742-1ea8ce23130f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP @0.50   0.6314\n",
      "Average Precision\n",
      "- Smoke     0.6491\n",
      "- Fire      0.6136\n",
      "Class Precision\n",
      "- Smoke     0.7234\n",
      "- Fire      0.6665\n",
      "Class Recall\n",
      "- Smoke     0.7017\n",
      "- Fire      0.6650\n",
      "Class F1-Score\n",
      "- Smoke     0.7124\n",
      "- Fire      0.6658\n"
     ]
    }
   ],
   "source": [
    "print_metrics(class_030_score_02_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193da3d7-37e2-499d-8169-653f8f972708",
   "metadata": {},
   "source": [
    "## Classification Threshold (30 %) =  Score Thres = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e888d93-9afb-474f-8e2e-7b0b69deec31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Boxes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [04:31<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_boxes_4, true_boxes_4 = aladdin_get_bboxes(\n",
    "    detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    classification_thres = -0.8472978604,\n",
    "    score_thres = 0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48708312-dbba-4cdc-be7c-08b4536c7b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mAP:@.5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:10<00:00,  5.25s/it]\n"
     ]
    }
   ],
   "source": [
    "class_030_score_025_metrics = aladdin_metrics.mAP(\n",
    "    log_path=log_path + 'classify_030_score_thres_25e-2/',\n",
    "    pred_boxes=pred_boxes_4,\n",
    "    true_boxes=true_boxes_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4800f91d-1ad2-48d0-b047-8543ab11127c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP @0.50   0.6251\n",
      "Average Precision\n",
      "- Smoke     0.6402\n",
      "- Fire      0.6100\n",
      "Class Precision\n",
      "- Smoke     0.7592\n",
      "- Fire      0.7067\n",
      "Class Recall\n",
      "- Smoke     0.6897\n",
      "- Fire      0.6597\n",
      "Class F1-Score\n",
      "- Smoke     0.7228\n",
      "- Fire      0.6824\n"
     ]
    }
   ],
   "source": [
    "print_metrics(class_030_score_025_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6496099d-a267-4d74-9f74-1e5569f781bd",
   "metadata": {},
   "source": [
    "## Classification Threshold (30 %) =  Score Thres = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "152a8a1a-54d3-4bec-ac11-682a99aa3d35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Boxes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [04:29<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_boxes_5, true_boxes_5 = aladdin_get_bboxes(\n",
    "    detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    classification_thres = -0.8472978604,\n",
    "    score_thres = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f5c3380-7a06-4872-a92b-e86f165f66f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mAP:@.5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:10<00:00,  5.02s/it]\n"
     ]
    }
   ],
   "source": [
    "class_030_score_03_metrics = aladdin_metrics.mAP(\n",
    "    log_path=log_path + 'classify_030_score_thres_3e-1/',\n",
    "    pred_boxes=pred_boxes_5,\n",
    "    true_boxes=true_boxes_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2d393c9-6ee3-474a-b2bd-aeb706556f74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP @0.50   0.6181\n",
      "Average Precision\n",
      "- Smoke     0.6304\n",
      "- Fire      0.6058\n",
      "Class Precision\n",
      "- Smoke     0.7891\n",
      "- Fire      0.7457\n",
      "Class Recall\n",
      "- Smoke     0.6772\n",
      "- Fire      0.6540\n",
      "Class F1-Score\n",
      "- Smoke     0.7289\n",
      "- Fire      0.6968\n"
     ]
    }
   ],
   "source": [
    "print_metrics(class_030_score_03_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98528cd4-c385-47f0-a3a0-4f02b3bd0036",
   "metadata": {},
   "source": [
    "## Classification Threshold (30 %) =  Score Thres = 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9865d98-0bc9-409a-a89e-8bc10a87ff65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Boxes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [04:28<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_boxes_6, true_boxes_6 = aladdin_get_bboxes(\n",
    "    detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    classification_thres = -0.8472978604,\n",
    "    score_thres = 0.35\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "155070f5-2e05-4748-a976-28ba0227ea16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mAP:@.5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.65s/it]\n"
     ]
    }
   ],
   "source": [
    "class_030_score_035_metrics = aladdin_metrics.mAP(\n",
    "    log_path=log_path + 'classify_030_score_thres_35e-2/',\n",
    "    pred_boxes=pred_boxes_6,\n",
    "    true_boxes=true_boxes_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6f834f9-aa2c-48d6-9f4e-e0f4db572e00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP @0.50   0.6090\n",
      "Average Precision\n",
      "- Smoke     0.6187\n",
      "- Fire      0.5993\n",
      "Class Precision\n",
      "- Smoke     0.8132\n",
      "- Fire      0.7763\n",
      "Class Recall\n",
      "- Smoke     0.6626\n",
      "- Fire      0.6454\n",
      "Class F1-Score\n",
      "- Smoke     0.7302\n",
      "- Fire      0.7048\n"
     ]
    }
   ],
   "source": [
    "print_metrics(class_030_score_035_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b71ad8-518d-4036-b782-a2567399e3f5",
   "metadata": {},
   "source": [
    "## Classification Threshold (30 %) =  Score Thres = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "664e241c-5365-47e5-a96d-c7be7955fbe3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Boxes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [04:24<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_boxes_7, true_boxes_7 = aladdin_get_bboxes(\n",
    "    detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    classification_thres = -0.8472978604,\n",
    "    score_thres = 0.4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1406f81c-b7c5-49ac-bcec-5a29a5d6b8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mAP:@.5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:08<00:00,  4.35s/it]\n"
     ]
    }
   ],
   "source": [
    "class_030_score_04_metrics = aladdin_metrics.mAP(\n",
    "    log_path=log_path + 'classify_030_score_thres_4e-1/',\n",
    "    pred_boxes=pred_boxes_7,\n",
    "    true_boxes=true_boxes_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8006416a-160e-4bd9-ba96-0435de2ab4e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP @0.50   0.5977\n",
      "Average Precision\n",
      "- Smoke     0.6027\n",
      "- Fire      0.5927\n",
      "Class Precision\n",
      "- Smoke     0.8366\n",
      "- Fire      0.8045\n",
      "Class Recall\n",
      "- Smoke     0.6432\n",
      "- Fire      0.6370\n",
      "Class F1-Score\n",
      "- Smoke     0.7273\n",
      "- Fire      0.7111\n"
     ]
    }
   ],
   "source": [
    "print_metrics(class_030_score_04_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3e26d9-8586-4f4c-9216-6e772b68196f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
