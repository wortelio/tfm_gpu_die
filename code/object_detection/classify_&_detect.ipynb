{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba6f86b-976b-4011-9ce7-7624ef404d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import config\n",
    "import modules.classification_dataloaders as classification_data_loader\n",
    "import modules.dataloaders as detection_data_loader\n",
    "import modules.metrics as metrics\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f19697c9-984a-471a-b8a0-6bde511a2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b168b-544e-46ee-841a-ac7fd4db5b37",
   "metadata": {},
   "source": [
    "# Check Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271ebeb-50c8-47e7-99e0-f3f04a2eae9b",
   "metadata": {},
   "source": [
    "## Classifier Medium Compression: 25,59 KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab06eb5-becf-454d-a639-b3f45f2c9079",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = onnx.load('./onnx_models/medium_fassd__conv341_big__epoch=93.onnx')\n",
    "onnx.checker.check_model(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55312cde-319a-4789-b0ae-47e7c08e80e9",
   "metadata": {},
   "source": [
    "## Detector with Compression and w8a8b8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c59929c-4825-4f6e-a2a6-a86e2ac30370",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = onnx.load('./onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx')\n",
    "onnx.checker.check_model(detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd2f4f-24b4-49c2-a0ea-3b58ddef593d",
   "metadata": {},
   "source": [
    "# Classification Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07f07076-7bac-4bc8-aa29-34d12bf9c66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST DFire dataset\n",
      "DFire Removed wrong images: 0\n",
      "DFire empty images: 2005\n",
      "DFire only smoke images: 1186\n",
      "DFire only fire images: 220\n",
      "DFire smoke and fire images: 895\n",
      "\n",
      "Test dataset len: 4306\n",
      "\n",
      "TEST FASDD UAV dataset\n",
      "DFire Removed wrong images: 0\n",
      "DFire empty images: 1997\n",
      "DFire only smoke images: 846\n",
      "DFire only fire images: 35\n",
      "DFire smoke and fire images: 1303\n",
      "\n",
      "Test FASDD UAV dataset len: 4181\n",
      "\n",
      "TEST FASDD CV dataset\n",
      "DFire Removed wrong images: 0\n",
      "DFire empty images: 6533\n",
      "DFire only smoke images: 3902\n",
      "DFire only fire images: 2091\n",
      "DFire smoke and fire images: 3358\n",
      "\n",
      "Test FASDD CV dataset len: 15884\n",
      "\n",
      "Concatenate Test DFire and FASDD UAV datasets\n",
      "Test dataset len: 8487\n",
      "Concatenate with FASDD CV dataset\n",
      "Test dataset len: 24371\n"
     ]
    }
   ],
   "source": [
    "#classification_loader = classification_data_loader.get_val_loader(shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a026033e-c8b5-4da0-a087-ace6e428caa5",
   "metadata": {},
   "source": [
    "# Helper function to convert pytorch tensors to numpy. Useful to handle datatset output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71913b22-0a62-49f5-9027-3b07ec2648ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7108e0-2bbd-4106-b597-cfec81cca0f6",
   "metadata": {},
   "source": [
    "# Evaluate ONNX with F1 Mean, Smoke and Fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d667e34-8352-45f1-ada8-51feefbdf4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_metric = torchmetrics.classification.MultilabelPrecision(num_labels = config.N_CLASSES, \n",
    "#                                                                    threshold = 0.5, \n",
    "#                                                                    average = None).to('cpu')\n",
    "# recall_metric = torchmetrics.classification.MultilabelRecall(num_labels = config.N_CLASSES, \n",
    "#                                                              threshold = 0.5, \n",
    "#                                                              average = None).to('cpu')\n",
    "# accuracy_metric = torchmetrics.classification.MultilabelAccuracy(num_labels = config.N_CLASSES, \n",
    "#                                                                  threshold = 0.5, \n",
    "#                                                                  average = None).to('cpu')\n",
    "# f1_metric = torchmetrics.classification.MultilabelF1Score(num_labels = config.N_CLASSES, \n",
    "#                                                           threshold = 0.5, \n",
    "#                                                           average = None).to('cpu')\n",
    "\n",
    "# f1_metric_mean = torchmetrics.classification.MultilabelF1Score(num_labels = config.N_CLASSES, \n",
    "#                                                                threshold = 0.5, \n",
    "#                                                                average = 'macro').to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcee3f5-22d2-457f-bd2e-c8c1154cb674",
   "metadata": {},
   "source": [
    "### Classifier evaluation funtion\n",
    "\n",
    "Out of ONNX Model:\n",
    "- list with 1 np.array\n",
    "- [ np.array(batch, shape of 1 inference) ]\n",
    "- to access 1 inference: out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea734538-d03d-4fcf-a812-4642894c1778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_classifier_onnx(loader, model_name):\n",
    "\n",
    "#     ort_session = onnxruntime.InferenceSession(model_name, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "#     precision_metric.reset()\n",
    "#     recall_metric.reset()\n",
    "#     accuracy_metric.reset()\n",
    "#     f1_metric.reset()\n",
    "#     f1_metric_mean.reset()\n",
    "    \n",
    "#     loop = tqdm(loader, desc='Validating', leave=True)\n",
    "\n",
    "#     for batch_idx, (img, label) in enumerate(loop):\n",
    "\n",
    "#         for idx in range(config.BATCH_SIZE):\n",
    "            \n",
    "#             ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img[idx].unsqueeze(dim=0))}\n",
    "#             yhat = ort_session.run(None, ort_inputs)\n",
    "#             yhat = np.array(yhat)\n",
    "#             #yhat = torch.tensor(yhat).squeeze(dim=0)\n",
    "#             yhat = torch.sigmoid(torch.tensor(yhat).squeeze(dim=0))\n",
    "#             target = label[idx].unsqueeze(dim=0)\n",
    "\n",
    "#             precision_metric.update(yhat, target)\n",
    "#             recall_metric.update(yhat, target)\n",
    "#             accuracy_metric.update(yhat, target)\n",
    "#             f1_metric.update(yhat, target)\n",
    "#             f1_metric_mean.update(yhat, target)\n",
    "    \n",
    "#     precision = precision_metric.compute()\n",
    "#     recall = recall_metric.compute()\n",
    "#     accuracy = accuracy_metric.compute()\n",
    "#     f1 = f1_metric.compute()\n",
    "#     f1_mean = f1_metric_mean.compute()\n",
    "\n",
    "#     precision_metric.reset()\n",
    "#     recall_metric.reset()\n",
    "#     accuracy_metric.reset()\n",
    "#     f1_metric.reset()\n",
    "#     f1_metric_mean.reset()\n",
    "\n",
    "#     print(f'SMOKE -> Precision: {precision[0]:.4f} - Recall: {recall[0]:.4f} - Accuracy: {accuracy[0]:.4f} - F1: {f1[0]:.4f}')\n",
    "#     print(f'FIRE -> Precision: {precision[1]:.4f} - Recall: {recall[1]:.4f} - Accuracy: {accuracy[1]:.4f} - F1: {f1[1]:.4f}')\n",
    "#     print(f'Mean F1 Score: {f1_mean.item():.4f}')\n",
    "    \n",
    "#     return (\n",
    "#         {\n",
    "#         'Accuracy': [accuracy[0].item(), accuracy[1].item()],\n",
    "#         'Precision': [precision[0].item(), precision[1].item()],\n",
    "#         'Recall': [recall[0].item(), recall[1].item()],\n",
    "#         'F1': [f1[0].item(), f1[1].item()],\n",
    "#         'F1 mean': f1_mean.item(),\n",
    "#         }\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5511c960-7f6a-4161-a902-9530f9c7a249",
   "metadata": {},
   "source": [
    "# Evaluate Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d23b7a7-750e-431d-a37d-2a58b02280b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "________________________________ Classifier MEDIUM COMPRESSION _______________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 380/380 [01:12<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOKE -> Precision: 0.9099 - Recall: 0.8943 - Accuracy: 0.9084 - F1: 0.9020\n",
      "FIRE -> Precision: 0.9032 - Recall: 0.9697 - Accuracy: 0.9565 - F1: 0.9353\n",
      "Mean F1 Score: 0.9187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# print(\"\\n________________________________ Classifier MEDIUM COMPRESSION _______________________________\")\n",
    "# _ = eval_classifier_onnx(classification_loader, './onnx_models/medium_fassd__conv341_big__epoch=93.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c00db97-79d2-4d7a-b30a-6ceed359a8e1",
   "metadata": {},
   "source": [
    "### Results with Full Dataset\n",
    "\n",
    "- SMOKE -> Precision: 0.9099 - Recall: 0.8943 - Accuracy: 0.9084 - F1: 0.9020\n",
    "- FIRE -> Precision: 0.9032 - Recall: 0.9697 - Accuracy: 0.9565 - F1: 0.9353\n",
    "- Mean F1 Score: 0.9187"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7588acf-53c8-4a42-81f0-91104f972d2a",
   "metadata": {},
   "source": [
    "# Detection Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "496a4ef3-6a8b-48ca-9a30-16ebaffafc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST DFire dataset\n",
      "DFire Removed wrong images: 0\n",
      "DFire Removed due to overlapping: 310\n",
      "DFire Removed due to more than 10: 13\n",
      "\n",
      "Test DFire dataset len: 3983\n",
      "\n",
      "TEST FASDD UAV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD Removed due to overlapping: 377\n",
      "FASDD Removed due to more than 10: 156\n",
      "\n",
      "Test FASDD UAV dataset len: 3648\n",
      "\n",
      "TEST FASDD CV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD Removed due to overlapping: 317\n",
      "FASDD Removed due to more than 10: 44\n",
      "\n",
      "Test FASDD CV dataset len: 15523\n",
      "\n",
      "Concatenate Test DFire and FASDD UAV datasets\n",
      "Test dataset len: 7631\n",
      "Concatenate with FASDD CV dataset\n",
      "Test dataset len: 23154\n"
     ]
    }
   ],
   "source": [
    "detection_loader = detection_data_loader.get_val_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ec9f0e-6cba-483b-91a9-3f0480dace32",
   "metadata": {},
   "source": [
    "# Evaluate Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c520ebc0-3558-4b8a-b1c1-dd72ed63d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_metric = MeanAveragePrecision(\n",
    "    box_format='xyxy',\n",
    "    iou_thresholds=[config.IOU_THRESHOLD],\n",
    "    class_metrics=True, # Enables separated metrics for each class\n",
    "    #average='micro',\n",
    "    extended_summary=False).to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fdb067-87f5-4f3d-9a8e-005b560ee4bb",
   "metadata": {},
   "source": [
    "### Score Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2e65b80-b9c7-4e4c-b043-f747a870cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE_THRES = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f15194-af3f-4006-a267-1ecef05cab30",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69dbabd9-aee8-4701-b978-82d2fa3b2c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_detector_onnx(loader, model_name, score_thres):\n",
    "\n",
    "    ort_session = onnxruntime.InferenceSession(model_name, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "    map_metric.reset()\n",
    "    \n",
    "    loop = tqdm(loader, desc='Validating', leave=True)\n",
    "\n",
    "    for batch_idx, (img, label) in enumerate(loop):\n",
    "\n",
    "        for idx in range(config.BATCH_SIZE):\n",
    "            \n",
    "            ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img[idx].unsqueeze(dim=0))}\n",
    "            out = ort_session.run(None, ort_inputs)\n",
    "            \n",
    "            # out of onnx session is a list: [out_tensor with batch dim] -> [ (1,12,7,7) ] \n",
    "            # -> out[0] = (1,12,7,7)\n",
    "            # -> out[0][0] = (12,7,7)\n",
    "            #print(f'Out type: {type(out[0])} - Output shape: {out[0].shape}')\n",
    "            out = torch.tensor(np.array(out[0]))\n",
    "            out = out.permute(0, 2, 3, 1)\n",
    "            #print(f'Out shape after permute: {out.shape}')\n",
    "            #print(f'Out shape after indexing: {out[0].shape}')\n",
    "            \n",
    "            # Label should be [xc, yc, w, h, score=1, smoke, fire] in 7x7 square\n",
    "            #print(f'Label indexed shape: {label[idx].shape}')\n",
    "            \n",
    "        # Mean Average Precision\n",
    "            target_boxes = metrics.get_true_boxes(label[idx].detach().to('cpu'))\n",
    "            pred_boxes = metrics.get_pred_boxes(\n",
    "                model_out = out[0].detach().to('cpu'),\n",
    "                score_threshold=score_thres)\n",
    "            map_metric.update(preds = pred_boxes, target = target_boxes)\n",
    "    \n",
    "    meanAP = map_metric.compute()\n",
    "    map_metric.reset()\n",
    "\n",
    "    print(f'Smoke -> AP: {meanAP[\"map_per_class\"][0].item():.4f} - AR: {meanAP[\"mar_100_per_class\"][0].item():.4f}')\n",
    "    print(f'Fire -> AP: {meanAP[\"map_per_class\"][1].item():.4f} - AR: {meanAP[\"mar_100_per_class\"][1].item():.4f}')\n",
    "    print(f'mAP: {meanAP[\"map_50\"].item():.4f}')\n",
    "    \n",
    "    return (\n",
    "        {'mAP': meanAP['map_50'].item(),\n",
    "         'AP': [meanAP['map_per_class'][0].item(), meanAP['map_per_class'][1].item()],\n",
    "         'AR': [meanAP['mar_100_per_class'][0].item(), meanAP['mar_100_per_class'][1].item()]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4ecac66-d2a6-4449-96c6-7176d61d3519",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "________________________________ Detector MEDIUM COMPRESSION _______________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [01:19<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6470 - AR: 0.7070\n",
      "Fire -> AP: 0.6108 - AR: 0.6680\n",
      "mAP: 0.6289\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n________________________________ Detector MEDIUM COMPRESSION _______________________________\")\n",
    "_ = eval_detector_onnx(\n",
    "    detection_loader, \n",
    "    './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    SCORE_THRES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d4e69a-5eba-47e1-8b24-37647ae6e495",
   "metadata": {},
   "source": [
    "# Classify 1st + Detection 2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4618786-17b7-4af2-a473-b226582852e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_classifier_plus_detector_onnx(\n",
    "    loader, \n",
    "    classifier_model_name,\n",
    "    detector_model_name,\n",
    "    score_thres\n",
    "):\n",
    "\n",
    "    classify_session = onnxruntime.InferenceSession(classifier_model_name, providers=[\"CPUExecutionProvider\"])\n",
    "    detect_session = onnxruntime.InferenceSession(detector_model_name, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "    map_metric.reset()\n",
    "    \n",
    "    loop = tqdm(loader, desc='Validating', leave=True)\n",
    "\n",
    "    for batch_idx, (img, label) in enumerate(loop):\n",
    "\n",
    "        for idx in range(config.BATCH_SIZE):\n",
    "            \n",
    "            classify_inputs = {classify_session.get_inputs()[0].name: to_numpy(img[idx].unsqueeze(dim=0))}\n",
    "            classification_out = classify_session.run(None, classify_inputs)\n",
    "            # print(f'Smoke pred: {classification_out[0][0][0]}')\n",
    "            # print(f'Fire pred: {classification_out[0][0][1]}')\n",
    "            \n",
    "            # Use Detector if Classifier predicts fire or smoke\n",
    "            if classification_out[0][0][0] >= 0 or classification_out[0][0][1] >= 0:\n",
    "                detect_inputs = {detect_session.get_inputs()[0].name: to_numpy(img[idx].unsqueeze(dim=0))}\n",
    "                out = detect_session.run(None, detect_inputs)\n",
    "                out = torch.tensor(np.array(out[0]))\n",
    "                out = out.permute(0, 2, 3, 1)\n",
    "            else:\n",
    "                out = torch.zeros(1,7,7,12)           \n",
    "            \n",
    "            \n",
    "        # Mean Average Precision\n",
    "            target_boxes = metrics.get_true_boxes(label[idx].detach().to('cpu'))\n",
    "            pred_boxes = metrics.get_pred_boxes(\n",
    "                model_out = out[0].detach().to('cpu'),\n",
    "                score_threshold=score_thres)\n",
    "            map_metric.update(preds = pred_boxes, target = target_boxes)\n",
    "    \n",
    "    meanAP = map_metric.compute()\n",
    "    map_metric.reset()\n",
    "\n",
    "    print(f'Smoke -> AP: {meanAP[\"map_per_class\"][0].item():.4f} - AR: {meanAP[\"mar_100_per_class\"][0].item():.4f}')\n",
    "    print(f'Fire -> AP: {meanAP[\"map_per_class\"][1].item():.4f} - AR: {meanAP[\"mar_100_per_class\"][1].item():.4f}')\n",
    "    print(f'mAP: {meanAP[\"map_50\"]:.4f}')\n",
    "    \n",
    "    return (\n",
    "        {'mAP': meanAP['map_50'].item(),\n",
    "         'AP': [meanAP['map_per_class'][0].item(), meanAP['map_per_class'][1].item()],\n",
    "         'AR': [meanAP['mar_100_per_class'][0].item(), meanAP['mar_100_per_class'][1].item()]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3912ee72-4603-417f-913c-867f267f22c9",
   "metadata": {},
   "source": [
    "### Score Threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cae94db2-24f4-4eb6-a0f2-e7bf160e4c84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [02:58<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6322 - AR: 0.6851\n",
      "Fire -> AP: 0.6139 - AR: 0.6639\n",
      "mAP: 0.6231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': 0.6230778694152832,\n",
       " 'AP': [0.6322451233863831, 0.6139106154441833],\n",
       " 'AR': [0.6851410865783691, 0.6639198660850525]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classifier_plus_detector_onnx(\n",
    "    loader = detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    score_thres = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2d9440-81ec-4eb5-a295-e41c0a25a93c",
   "metadata": {},
   "source": [
    "### Score Threshold = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f09c002a-8b44-4e34-ac3a-16c8f90936e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [02:57<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6523 - AR: 0.7153\n",
      "Fire -> AP: 0.6201 - AR: 0.6758\n",
      "mAP: 0.6362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': 0.6361923813819885,\n",
       " 'AP': [0.6522578001022339, 0.6201269626617432],\n",
       " 'AR': [0.7153179049491882, 0.6758123636245728]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classifier_plus_detector_onnx(\n",
    "    loader = detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    score_thres = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9460834-14f7-40fa-80df-8ed3cd0f0578",
   "metadata": {},
   "source": [
    "### Score Threshold = 0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50ba1227-b943-4946-a705-790947fa49d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [03:32<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6740 - AR: 0.7727\n",
      "Fire -> AP: 0.6251 - AR: 0.6896\n",
      "mAP: 0.6496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': 0.649551510810852,\n",
       " 'AP': [0.6739742755889893, 0.6251287460327148],\n",
       " 'AR': [0.7726963758468628, 0.6895776987075806]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classifier_plus_detector_onnx(\n",
    "    loader = detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    score_thres = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e96f1-b188-4c94-ad47-dddf5dd35dd3",
   "metadata": {},
   "source": [
    "### Score Threshold = 0.001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0edb512-7e61-438d-b109-3e0b6f3f0fca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [10:35<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6746 - AR: 0.7843\n",
      "Fire -> AP: 0.6269 - AR: 0.6904\n",
      "mAP: 0.6508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': 0.6507548093795776,\n",
       " 'AP': [0.6746267676353455, 0.626882791519165],\n",
       " 'AR': [0.7843420505523682, 0.6904204487800598]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classifier_plus_detector_onnx(\n",
    "    loader = detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    score_thres = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed1654c-8c43-4fa8-926d-9bd2c607f715",
   "metadata": {},
   "source": [
    "### Score Threshold = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "736d9df5-a37e-46be-9b66-d669f70dcfed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 361/361 [13:52<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.6746 - AR: 0.7849\n",
      "Fire -> AP: 0.6269 - AR: 0.6904\n",
      "mAP: 0.6508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': 0.6507548093795776,\n",
       " 'AP': [0.6746267676353455, 0.626882791519165],\n",
       " 'AR': [0.7848520874977112, 0.6904204487800598]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_classifier_plus_detector_onnx(\n",
    "    loader = detection_loader,\n",
    "    classifier_model_name = './onnx_models/medium_fassd__conv341_big__epoch=93.onnx',\n",
    "    detector_model_name = './onnx_models/w8a8b8__bed_detector___aimet__fixed_point__qcdq__CPU.onnx',\n",
    "    score_thres = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282e2f60-4385-4e78-be73-d4d71b2ee7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
