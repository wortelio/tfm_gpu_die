{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba6f86b-976b-4011-9ce7-7624ef404d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.14 (you have 1.4.10). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import config\n",
    "import modules.dataloaders as detection_data_loader\n",
    "import modules.metrics as metrics\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f19697c9-984a-471a-b8a0-6bde511a2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b168b-544e-46ee-841a-ac7fd4db5b37",
   "metadata": {},
   "source": [
    "# Check Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c59929c-4825-4f6e-a2a6-a86e2ac30370",
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_manual_optim_name = './onnx_models/bed_manual_optim_detection_epoch=144_cpu.onnx'\n",
    "bed_manual_optim_model = onnx.load(bed_manual_optim_name)\n",
    "onnx.checker.check_model(bed_manual_optim_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a026033e-c8b5-4da0-a087-ace6e428caa5",
   "metadata": {},
   "source": [
    "# Helper function to convert pytorch tensors to numpy. Useful to handle datatset output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71913b22-0a62-49f5-9027-3b07ec2648ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7588acf-53c8-4a42-81f0-91104f972d2a",
   "metadata": {},
   "source": [
    "# Detection Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "496a4ef3-6a8b-48ca-9a30-16ebaffafc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST DFire dataset\n",
      "DFire Removed wrong images: 0\n",
      "DFire Removed due to overlapping: 310\n",
      "DFire Removed due to more than 10: 13\n",
      "\n",
      "Test dataset len: 3983\n"
     ]
    }
   ],
   "source": [
    "detection_loader = detection_data_loader.get_dfire_val_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ec9f0e-6cba-483b-91a9-3f0480dace32",
   "metadata": {},
   "source": [
    "# Evaluate Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c520ebc0-3558-4b8a-b1c1-dd72ed63d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_metric = MeanAveragePrecision(\n",
    "    box_format='xyxy',\n",
    "    iou_thresholds=[config.IOU_THRESHOLD],\n",
    "    class_metrics=True, # Enables separated metrics for each class\n",
    "    #average='micro',\n",
    "    extended_summary=False).to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f15194-af3f-4006-a267-1ecef05cab30",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69dbabd9-aee8-4701-b978-82d2fa3b2c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_detector_onnx(loader, model_name, score_thres):\n",
    "\n",
    "    ort_session = onnxruntime.InferenceSession(model_name, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "    map_metric.reset()\n",
    "    \n",
    "    loop = tqdm(loader, desc='Validating', leave=True)\n",
    "\n",
    "    for batch_idx, (img, label) in enumerate(loop):\n",
    "\n",
    "        for idx in range(config.BATCH_SIZE):\n",
    "            \n",
    "            ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img[idx].unsqueeze(dim=0))}\n",
    "            out = ort_session.run(None, ort_inputs)\n",
    "            \n",
    "            # out of onnx session is a list: [out_tensor with batch dim] -> [ (1,12,7,7) ] \n",
    "            # -> out[0] = (1,12,7,7)\n",
    "            # -> out[0][0] = (12,7,7)\n",
    "            #print(f'Out type: {type(out[0])} - Output shape: {out[0].shape}')\n",
    "            out = torch.tensor(np.array(out[0]))\n",
    "            out = out.permute(0, 2, 3, 1)\n",
    "            #print(f'Out shape after permute: {out.shape}')\n",
    "            #print(f'Out shape after indexing: {out[0].shape}')\n",
    "            \n",
    "            # Label should be [xc, yc, w, h, score=1, smoke, fire] in 7x7 square\n",
    "            #print(f'Label indexed shape: {label[idx].shape}')\n",
    "            \n",
    "        # Mean Average Precision\n",
    "            target_boxes = metrics.get_true_boxes(label[idx].detach().to('cpu'))\n",
    "            pred_boxes = metrics.get_pred_boxes(\n",
    "                model_out = out[0].detach().to('cpu'),\n",
    "                score_threshold=score_thres)\n",
    "            map_metric.update(preds = pred_boxes, target = target_boxes)\n",
    "    \n",
    "    meanAP = map_metric.compute()\n",
    "    map_metric.reset()\n",
    "\n",
    "    print(f'Smoke -> AP: {meanAP[\"map_per_class\"][0].item():.4f} - AR: {meanAP[\"mar_100_per_class\"][0].item():.4f}')\n",
    "    print(f'Fire -> AP: {meanAP[\"map_per_class\"][1].item():.4f} - AR: {meanAP[\"mar_100_per_class\"][1].item():.4f}')\n",
    "    print(f'mAP: {meanAP[\"map_50\"].item():.4f}')\n",
    "    \n",
    "    return (\n",
    "        {'mAP': meanAP['map_50'].item(),\n",
    "         'AP': [meanAP['map_per_class'][0].item(), meanAP['map_per_class'][1].item()],\n",
    "         'AR': [meanAP['mar_100_per_class'][0].item(), meanAP['mar_100_per_class'][1].item()]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4ecac66-d2a6-4449-96c6-7176d61d3519",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "________________________________ BED manual optim _______________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [02:26<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke -> AP: 0.4611 - AR: 0.5522\n",
      "Fire -> AP: 0.2658 - AR: 0.3712\n",
      "mAP: 0.3635\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n________________________________ BED manual optim _______________________________\")\n",
    "_ = eval_detector_onnx(\n",
    "    detection_loader, \n",
    "    bed_manual_optim_name,\n",
    "    0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eb3f6d-f5f1-49aa-98ce-0e138eeb053f",
   "metadata": {},
   "source": [
    "# Aladdin Metrics to Get Precision and Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db5e8805-abfb-4d81-aec3-12f6b6e58baf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import modules.metrics_mAP_aladdin as aladdin_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1f59270-db99-4155-871b-de41e4086a14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' ============================\n",
    "    Cell to Box Mask\n",
    "============================ '''\n",
    "cell2box_mask = torch.zeros((config.S, config.S, 2))\n",
    "for i in range(config.S):\n",
    "    for j in range(config.S):\n",
    "        cell2box_mask[i,j,0] = j\n",
    "        cell2box_mask[i,j,1] = i  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2590ba94-5e1e-4a5f-b145-87d0ec068548",
   "metadata": {},
   "source": [
    "### Aladdin mAP modified for ONNX detection with thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b31282c8-1c12-49e8-bff9-6559b22ee7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aladdin_get_bboxes(\n",
    "    loader,\n",
    "    detector_model_name,\n",
    "    S=config.S,\n",
    "    B=config.B,\n",
    "    C=config.C,\n",
    "    mask=cell2box_mask,\n",
    "    device='cpu',\n",
    "    iou_threshold=0.5,\n",
    "    score_thres=0.2,\n",
    "    box_format=\"midpoint\"):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Return:\n",
    "        - all_pred_boxes\n",
    "        - all_true_boxes\n",
    "        Format: [train_idx, class_prediction, prob_score, x1, y1, x2, y2]\n",
    "    '''\n",
    "    \n",
    "    detect_session = onnxruntime.InferenceSession(detector_model_name, providers=[\"CPUExecutionProvider\"])\n",
    "    \n",
    "    \n",
    "    all_pred_boxes = []\n",
    "    all_true_boxes = []\n",
    "\n",
    "    # Original Code\n",
    "    # make sure model is in eval before get bboxes\n",
    "    #model.eval()\n",
    "    train_idx = 0\n",
    "\n",
    "    loop = tqdm(loader, desc='Get Boxes', leave=True)\n",
    "    for batch_idx, (imgs, labels) in enumerate(loop):\n",
    "        # Original Code\n",
    "        # Inference in GPU. Move tensor to CPU in outcell_2_outboxes\n",
    "        # imgs = imgs.to(device)\n",
    "        # labels = labels.to(device)\n",
    "\n",
    "\n",
    "        for idx in range(config.BATCH_SIZE):\n",
    "            \n",
    "            detect_inputs = {detect_session.get_inputs()[0].name: to_numpy(imgs[idx].unsqueeze(dim=0))}\n",
    "            out = detect_session.run(None, detect_inputs)\n",
    "            out = torch.tensor(np.array(out[0]))\n",
    "            out = out.permute(0, 2, 3, 1)         \n",
    "            \n",
    "            # Original Code\n",
    "            # with torch.no_grad():\n",
    "            #     predictions = model(imgs)\n",
    "\n",
    "            # Original Code\n",
    "            # Remove Permute from the model\n",
    "            #predictions = predictions.permute(0, 2, 3, 1) # Original Code\n",
    "\n",
    "            #batch_size = imgs.shape[0] # Original Code\n",
    "\n",
    "            true_bboxes = aladdin_metrics.outcell_2_outboxes(\n",
    "                out_cells=labels[idx].unsqueeze(dim=0), \n",
    "                S=S, B=B, C=C, \n",
    "                mask=mask, \n",
    "                device='cpu', # Changed to cpu\n",
    "                is_pred=False)\n",
    "            bboxes = aladdin_metrics.outcell_2_outboxes(\n",
    "                out_cells=out, \n",
    "                S=S, B=B, C=C, \n",
    "                mask=mask, \n",
    "                device='cpu', # Changed to cpu\n",
    "                is_pred=True)\n",
    "\n",
    "            for idx in range(1): # Only 1 image every time, due to ONNX prediction in CPU\n",
    "                nms_boxes = aladdin_metrics.nms_yv1_getBBoxes(\n",
    "                    bboxes[idx],\n",
    "                    iou_threshold=iou_threshold,\n",
    "                    threshold=score_thres,\n",
    "                    box_format=box_format, # Midpoint, to use iou_tensor inside\n",
    "                )\n",
    "\n",
    "\n",
    "                # Plot some examples\n",
    "                #if batch_idx == 0 and idx == 0:\n",
    "                #    plot_image(x[idx].permute(1,2,0).to(\"cpu\"), nms_boxes)\n",
    "                #    print(nms_boxes)\n",
    "\n",
    "                for nms_box in nms_boxes:\n",
    "                    all_pred_boxes.append([train_idx] + nms_box)\n",
    "\n",
    "                for box in true_bboxes[idx]:\n",
    "                    # many will get converted to 0 pred, as bboxes have Conf = 1 and the rest are 0\n",
    "                    if box[1] > score_thres:\n",
    "                        all_true_boxes.append([train_idx] + box)\n",
    "\n",
    "                train_idx += 1\n",
    "\n",
    "    #model.train()\n",
    "    return all_pred_boxes, all_true_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69d3002-4bbf-48e6-8d0a-0fc04d2689c3",
   "metadata": {},
   "source": [
    "# Function to Print mAP metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3106e8f4-b50f-44b0-977d-9b0790f38846",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_metrics(mAP_metrics):\n",
    "    mAP, avg_prec, cls_prec, cls_rec = mAP_metrics\n",
    "    \n",
    "    mAP_str = \"mAP @0.50\"\n",
    "    smoke = \"Smoke\"\n",
    "    fire = \"Fire\"\n",
    "    \n",
    "    print(f'{mAP_str:<12}' + f'{mAP:.4f}')\n",
    "    print('Average Precision')\n",
    "    print(f'- {smoke:<10}' + f'{avg_prec[0]:.4f}')\n",
    "    print(f'- {fire:<10}' + f'{avg_prec[1]:.4f}')\n",
    "    print('Class Precision')\n",
    "    print(f'- {smoke:<10}' + f'{cls_prec[0]:.4f}')\n",
    "    print(f'- {fire:<10}' + f'{cls_prec[1]:.4f}')  \n",
    "    print('Class Recall')\n",
    "    print(f'- {smoke:<10}' + f'{cls_rec[0]:.4f}')\n",
    "    print(f'- {fire:<10}' + f'{cls_rec[1]:.4f}')\n",
    "    print('Class F1-Score')\n",
    "    smoke_f1 = 2 * (cls_prec[0] * cls_rec[0]) / (cls_prec[0] + cls_rec[0])\n",
    "    fire_f1 = 2 * (cls_prec[1] * cls_rec[1]) / (cls_prec[1] + cls_rec[1])\n",
    "    print(f'- {smoke:<10}' + f'{smoke_f1:.4f}')\n",
    "    print(f'- {fire:<10}' + f'{fire_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723eab35-675b-4b31-bf5f-8b31baa29493",
   "metadata": {},
   "source": [
    "### Log Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c793261-c7c8-4c5f-858f-f68a93a0fc9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_path = './mAP_&_pr_curves/classify_&_detect/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7183fba5-0300-4451-9d41-3f13633e6691",
   "metadata": {},
   "source": [
    "# BED manual optim DFire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24ce81-8b18-4f4a-8fbf-07e328effa35",
   "metadata": {},
   "source": [
    "## Score Thres = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bec29fcc-8b71-4b44-8abc-de74f9156e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Boxes: 100%|███████████████████████████████████████████████████████████████████████████████████| 62/62 [02:01<00:00,  1.96s/it]\n"
     ]
    }
   ],
   "source": [
    "pred_boxes, true_boxes = aladdin_get_bboxes(\n",
    "    detection_loader,\n",
    "    detector_model_name = bed_manual_optim_name,\n",
    "    score_thres = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02c88d61-6893-4af1-9aaf-909354d02c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mAP:@.5: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.73it/s]\n"
     ]
    }
   ],
   "source": [
    "score_02_metrics = aladdin_metrics.mAP(\n",
    "    log_path=log_path + 'score_thres_2e-1/',\n",
    "    pred_boxes=pred_boxes,\n",
    "    true_boxes=true_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4c193cc-f7df-4798-8328-7dabf4a7ce55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP @0.50   0.3542\n",
      "Average Precision\n",
      "- Smoke     0.4485\n",
      "- Fire      0.2600\n",
      "Class Precision\n",
      "- Smoke     0.6325\n",
      "- Fire      0.4775\n",
      "Class Recall\n",
      "- Smoke     0.5511\n",
      "- Fire      0.3725\n",
      "Class F1-Score\n",
      "- Smoke     0.5890\n",
      "- Fire      0.4185\n"
     ]
    }
   ],
   "source": [
    "print_metrics(score_02_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8916ead-e02a-4b78-8bfe-611c4511b569",
   "metadata": {},
   "source": [
    "## Score Thres = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a65d3bf-54c3-49d1-b908-269d13e49dde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Boxes: 100%|███████████████████████████████████████████████████████████████████████████████████| 62/62 [04:42<00:00,  4.55s/it]\n"
     ]
    }
   ],
   "source": [
    "pred_boxes, true_boxes = aladdin_get_bboxes(\n",
    "    detection_loader,\n",
    "    detector_model_name = bed_manual_optim_name,\n",
    "    score_thres = 0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "306d55b4-126a-47df-ac27-19a698c124fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mAP:@.5: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:14<00:00,  7.47s/it]\n"
     ]
    }
   ],
   "source": [
    "score_0001_metrics = aladdin_metrics.mAP(\n",
    "    log_path=log_path + 'score_thres_2e-1/',\n",
    "    pred_boxes=pred_boxes,\n",
    "    true_boxes=true_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe6e370d-9902-4002-89c3-c25ceeac4976",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP @0.50   0.3912\n",
      "Average Precision\n",
      "- Smoke     0.5033\n",
      "- Fire      0.2792\n",
      "Class Precision\n",
      "- Smoke     0.0140\n",
      "- Fire      0.0777\n",
      "Class Recall\n",
      "- Smoke     0.7200\n",
      "- Fire      0.4333\n",
      "Class F1-Score\n",
      "- Smoke     0.0275\n",
      "- Fire      0.1318\n"
     ]
    }
   ],
   "source": [
    "print_metrics(score_0001_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
