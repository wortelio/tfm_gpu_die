{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8a513a-1549-4be7-af63-4f9542994187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import collections\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "import config\n",
    "import modules.dataloaders as data_loaders\n",
    "import modules.utils as utils\n",
    "import modules.models as models\n",
    "import modules.loss as loss_module\n",
    "import modules.metrics as metrics\n",
    "import modules.train_epoch as train_epoch\n",
    "import modules.val_epoch as val_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f7873-fc40-4e71-b3ad-7e3aadf45081",
   "metadata": {},
   "source": [
    "# AIMET imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b1b731b-4520-4b6c-8cc2-5d601081a059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-20 02:19:29,621 - root - INFO - AIMET\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.1.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"jspanel\"], function(jsPanel) {\n",
       "\twindow.jsPanel = jsPanel\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-modal\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-tooltip\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-hint\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-layout\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-contextmenu\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-dock\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 9;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      Bokeh = root.Bokeh;\n",
       "      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      if (!reloading && (!bokeh_loaded || is_dev)) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.1.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from decimal import Decimal\n",
    "\n",
    "from aimet_torch.compress import ModelCompressor\n",
    "from aimet_torch.defs import ChannelPruningParameters\n",
    "from aimet_torch.onnx_utils import OnnxSaver\n",
    "from aimet_common.defs import CostMetric, CompressionScheme, GreedySelectionParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077e3863-baa1-481f-bec2-bde8c1a0c03c",
   "metadata": {},
   "source": [
    "# Supress Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423ca7c6-5d21-460f-9d55-073aceab5616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d8132b-9f5b-403d-aa2b-bfa50ecf25d5",
   "metadata": {},
   "source": [
    "# Define Matplot Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3728c53e-0c8c-4a8c-92fa-8f676e65b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpl.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfc923c-eb11-4077-88d4-82c09c17e1a1",
   "metadata": {},
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b4e5f0e-110e-4319-aeb1-ea3fcc692ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = config.LOGS_FOLDER\n",
    "\n",
    "logger = logging.getLogger(\"GonLogger\")\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.INFO)\n",
    "file_handler = logging.FileHandler(log_path + 'logfile.log')\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# add file handler to logger\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.info('BED Detector.\\n' +  \n",
    "            '\\tDFire and FASDD UAV and CV.\\n' +\n",
    "            '\\tFASDD: train and val datasets to train, and test dataset to validate.\\n' +\n",
    "            '\\tFASDD RS not included, as it only has smoke and it is too different to current pictures\\n' + \n",
    "            f'\\tPruning Compression Ratio  = {config.PRUNING_COMPRESSION_RATIO}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf3ef1-7de2-4eb9-bda1-64eb9019fad8",
   "metadata": {},
   "source": [
    "# Hyperparameters Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fcb8a16-c7aa-4ed0-9b34-92b3400073df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datasets Length\n",
      "\tTrain: Full\n",
      "\tVal: Full\n",
      "\n",
      "Load Model: True\n",
      "\tModel: ./experiments/test_31_svd_080_simple_model/weights/BED_detector__best_mAP=0.6204__epoch=4.pt\n",
      "Device: cuda\n",
      "Optimizer:\n",
      "\tLearning Rate: 0.0005\n",
      "\tGradients Clip Norm: 500\n",
      "\tWeight Decay: 0.0005\n",
      "Scheduler:\n",
      "\tScheduler factor: 0.8\n",
      "\tScheduler patience: 1\n",
      "\tScheduler threshold: 0.01\n",
      "\tScheduler min learning rate: 1e-06\n",
      "Batch Size: 64\n",
      "Num Workers: 8\n",
      "Pin Memory: True\n",
      "Epochs: 40\n",
      "IMG DIMS:\n",
      "\tWidth: 224\n",
      "\tHeight: 224\n",
      "\n",
      "Grid, Bounding Boxes, Classes, Max Obj and Thresholds:\n",
      "\tGrid: 7\n",
      "\tNumber of Bounding Boxes per Cell: 2\n",
      "\tNumber of Classes: 2\n",
      "\tMaximum Number of Objects per Image: 10\n",
      "\tIOU Threshold: 0.5\n",
      "\tScore Threshold: 0.2\n",
      "\n",
      "AIMET Configuration\n",
      "\tUse Previous Dic: True\n",
      "\tSpatial SVD Compression: 0.8\n",
      "\tPrunning Compression: 0.9\n"
     ]
    }
   ],
   "source": [
    "''' ============================\n",
    "    Print Config Values\n",
    "============================ '''\n",
    "print('\\nDatasets Length')\n",
    "print(f'\\tTrain: {\"Full\" if config.DS_LEN == None else config.DS_LEN}')\n",
    "print(f'\\tVal: {\"Full\" if config.VAL_DS_LEN == None else config.VAL_DS_LEN}')\n",
    "print(f'\\nLoad Model: {config.LOAD_MODEL}')\n",
    "print(f'\\tModel: {config.LOAD_MODEL_FILE}')\n",
    "print(f'Device: {config.DEVICE}')\n",
    "print('Optimizer:')\n",
    "print(f'\\tLearning Rate: {config.LEARNING_RATE}')\n",
    "print(f'\\tGradients Clip Norm: {config.GRADIENTS_CLIP_NORM}')\n",
    "print(f'\\tWeight Decay: {config.WEIGHT_DECAY}')\n",
    "print('Scheduler:')\n",
    "print(f'\\tScheduler factor: {config.FACTOR}')\n",
    "print(f'\\tScheduler patience: {config.PATIENCE}')\n",
    "print(f'\\tScheduler threshold: {config.THRES}')\n",
    "print(f'\\tScheduler min learning rate: {config.MIN_LR}')\n",
    "print(f'Batch Size: {config.BATCH_SIZE}')\n",
    "print(f'Num Workers: {config.NUM_WORKERS}')\n",
    "print(f'Pin Memory: {config.PIN_MEMORY}')\n",
    "print(f'Epochs: {config.EPOCHS}')\n",
    "print('IMG DIMS:')\n",
    "print(f'\\tWidth: {config.IMG_W}\\n\\tHeight: {config.IMG_H}')\n",
    "print('\\nGrid, Bounding Boxes, Classes, Max Obj and Thresholds:')\n",
    "print(f'\\tGrid: {config.S}')\n",
    "print(f'\\tNumber of Bounding Boxes per Cell: {config.B}')\n",
    "print(f'\\tNumber of Classes: {config.C}')\n",
    "print(f'\\tMaximum Number of Objects per Image: {config.MAX_OBJ}')\n",
    "print(f'\\tIOU Threshold: {config.IOU_THRESHOLD}')\n",
    "print(f'\\tScore Threshold: {config.SCORE_THRESHOLD}')\n",
    "print('\\nAIMET Configuration')\n",
    "print(f'\\tUse Previous Dic: {config.USE_PREVIOUS_DIC}')\n",
    "print(f'\\tSpatial SVD Compression: {config.SVD_COMPRESSION_RATIO}')\n",
    "print(f'\\tPrunning Compression: {config.PRUNING_COMPRESSION_RATIO}')\n",
    "\n",
    "logger.info('\\nDatasets Length')\n",
    "logger.info(f'\\tTrain: {\"Full\" if config.DS_LEN == None else config.DS_LEN}')\n",
    "logger.info(f'\\tVal: {\"Full\" if config.VAL_DS_LEN == None else config.VAL_DS_LEN}')\n",
    "logger.info(f'\\nLoad Model: {config.LOAD_MODEL}')\n",
    "logger.info(f'\\tModel: {config.LOAD_MODEL_FILE}')\n",
    "logger.info(f'\\nDevice: {config.DEVICE}')\n",
    "logger.info('Optimizer:')\n",
    "logger.info(f'\\tLearning Rate: {config.LEARNING_RATE}')\n",
    "logger.info(f'\\tGradients Clip Norm: {config.GRADIENTS_CLIP_NORM}')\n",
    "logger.info(f'\\tWeight Decay: {config.WEIGHT_DECAY}')\n",
    "logger.info('Scheduler:')\n",
    "logger.info(f'\\tScheduler factor: {config.FACTOR}')\n",
    "logger.info(f'\\tScheduler patience: {config.PATIENCE}')\n",
    "logger.info(f'\\tScheduler threshold: {config.THRES}')\n",
    "logger.info(f'\\tScheduler min learning rate: {config.MIN_LR}')\n",
    "logger.info(f'\\nBatch Size: {config.BATCH_SIZE}')\n",
    "logger.info(f'Num Workers: {config.NUM_WORKERS}')\n",
    "logger.info(f'Pin Memory: {config.PIN_MEMORY}')\n",
    "logger.info(f'Epochs: {config.EPOCHS}')\n",
    "logger.info('IMG DIMS:')\n",
    "logger.info(f'\\tWidth: {config.IMG_W}\\n\\tHeight: {config.IMG_H}')\n",
    "logger.info('\\nGrid, Bounding Boxes, Classes and Thresholds:')\n",
    "logger.info(f'\\tGrid: {config.S}')\n",
    "logger.info(f'\\tNumber of Bounding Boxes per Cell: {config.B}')\n",
    "logger.info(f'\\tNumber of Classes: {config.C}')\n",
    "logger.info(f'\\tMaximum Number of Objects per Image: {config.MAX_OBJ}')\n",
    "logger.info(f'\\tIOU Threshold: {config.IOU_THRESHOLD}')\n",
    "logger.info(f'\\tScore Threshold: {config.SCORE_THRESHOLD}\\n')\n",
    "logger.info('\\nAIMET Configuration')\n",
    "logger.info(f'\\tUse Previous Dic: {config.USE_PREVIOUS_DIC}')\n",
    "logger.info(f'\\tSpatial SVD Compression: {config.SVD_COMPRESSION_RATIO}')\n",
    "logger.info(f'\\tPrunning Compression: {config.PRUNING_COMPRESSION_RATIO}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9374d99a-7746-4bd2-b6b5-548f2b6f95bd",
   "metadata": {},
   "source": [
    "# Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50319596-f4bd-499c-a063-7612aa2c641b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN DFIRE dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFire Removed wrong images: 0\n",
      "DFire Removed due to overlapping: 1292\n",
      "DFire Removed due to more than 10: 59\n",
      "\n",
      "Train DFire dataset len: 15870\n",
      "\n",
      "TRAIN FASDD UAV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD Removed due to overlapping: 1233\n",
      "FASDD Removed due to more than 10: 449\n",
      "\n",
      "Train FASDD UAV dataset len: 10869\n",
      "\n",
      "VAL FASDD UAV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD Removed due to overlapping: 841\n",
      "FASDD Removed due to more than 10: 300\n",
      "\n",
      "Val FASDD UAV dataset len: 7224\n",
      "\n",
      "TRAIN FASDD CV dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 32.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASDD Removed wrong images: 0\n",
      "FASDD Removed due to overlapping: 2141\n",
      "FASDD Removed due to more than 10: 342\n",
      "\n",
      "Train FASDD CV dataset len: 45177\n",
      "\n",
      "VAL FASDD CV dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASDD Removed wrong images: 0\n",
      "FASDD Removed due to overlapping: 1238\n",
      "FASDD Removed due to more than 10: 221\n",
      "\n",
      "Val FASDD CV dataset len: 30311\n",
      "\n",
      "Concatenate Train DFire and Train FASDD UAV datasets\n",
      "Train dataset len: 26739\n",
      "Concatenate with Val FASDD UAV dataset\n",
      "Train dataset len: 33963\n",
      "Concatenate with Train FASDD CV dataset\n",
      "Train dataset len: 79140\n",
      "Concatenate with Val FASDD CV dataset\n",
      "Train dataset len: 109451\n",
      "\n",
      "TEST DFire dataset\n",
      "DFire Removed wrong images: 0\n",
      "DFire Removed due to overlapping: 310\n",
      "DFire Removed due to more than 10: 13\n",
      "\n",
      "Test dataset len: 3983\n",
      "\n",
      "TEST FASDD UAV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD Removed due to overlapping: 377\n",
      "FASDD Removed due to more than 10: 156\n",
      "\n",
      "Val FASDD UAV dataset len: 3648\n",
      "\n",
      "TEST FASDD CV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD Removed due to overlapping: 317\n",
      "FASDD Removed due to more than 10: 44\n",
      "\n",
      "Test FASDD CV dataset len: 15523\n",
      "\n",
      "Concatenate Test DFire and FASDD UAV datasets\n",
      "Test dataset len: 7631\n",
      "Concatenate with FASDD CV dataset\n",
      "Test dataset len: 23154\n"
     ]
    }
   ],
   "source": [
    "train_loader = data_loaders.get_train_loader()\n",
    "\n",
    "# val_loader = data_loaders.get_val_loader(\n",
    "#     dfire_len = 900,\n",
    "#     fasdd_uav_len = 900,\n",
    "#     fasdd_cv_len = 3400)\n",
    "val_loader = data_loaders.get_val_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39f5e00-cc05-4784-ac22-30c3a05b8905",
   "metadata": {},
   "source": [
    "# Plot Some Train Pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d560d114-e070-4e90-bc93-c97566f9752e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size equal to img.shape[0] = 64\n",
      "Batch images shape = torch.Size([64, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (img, label) in enumerate(train_loader):\n",
    "       \n",
    "    if batch_idx == 0:\n",
    "        print(f'Batch size equal to img.shape[0] = {img.shape[0]}')\n",
    "        print(f'Batch images shape = {img.shape}')\n",
    "        plt.subplots(4, 5, figsize=(10,8))\n",
    "        for i in range(20):\n",
    "            pic = utils.plot_dataset_img(img[i], label[i], grid=True)\n",
    "            plt.subplot(4, 5, i+1)\n",
    "            plt.imshow(pic)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.RUN_FOLDER + 'train_pictures.png')\n",
    "        plt.close()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d3a917-92e6-400f-9bb4-87c61c7e2d92",
   "metadata": {},
   "source": [
    "# Plot Some Val Pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9f62109-ea58-4a61-8094-9725ce8782ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size equal to img.shape[0] = 64\n",
      "Batch images shape = torch.Size([64, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (img, label) in enumerate(val_loader):\n",
    "       \n",
    "    if batch_idx == 27:\n",
    "        print(f'Batch size equal to img.shape[0] = {img.shape[0]}')\n",
    "        print(f'Batch images shape = {img.shape}')\n",
    "        plt.subplots(4, 5, figsize=(10,8))\n",
    "        for i in range(20):\n",
    "            pic = utils.plot_dataset_img(img[i], label[i], grid=True)\n",
    "            plt.subplot(4, 5, i+1)\n",
    "            plt.imshow(pic)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(config.RUN_FOLDER + 'val_pictures.png')\n",
    "        plt.close()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c7d2c7-76b3-458a-a0a5-80a1c78b53a8",
   "metadata": {},
   "source": [
    "# Loss Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afe56373-36bf-4131-8dbf-34c100fe06d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function: YOLOV1_LOSS\n",
      "Lambda for L1 regularization: 0\n"
     ]
    }
   ],
   "source": [
    "if config.LOSS_FN == \"YOLOV1_LOSS\":\n",
    "    print(f'Loss Function: YOLOV1_LOSS')\n",
    "    logger.info(f'\\nLoss Function: YOLOV1_LOSS')\n",
    "    loss_fn = loss_module.YoloLoss_2BBox()\n",
    "    print(f'Lambda for L1 regularization: {config.LAMBDA_L1_LOSS}')\n",
    "    logger.info(f'Lambda for L1 regularization: {config.LAMBDA_L1_LOSS}')\n",
    "else:\n",
    "    print(\"Wrong loss function\")\n",
    "    logger.info(\"Wrong loss function\")\n",
    "    raise SystemExit(\"Wrong loss function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15183310-3690-45fe-a282-d67b55e9cc4c",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac4fcfec-6bfb-42dd-b4b3-227a40ae8469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using BED Detector\n",
      "\n",
      "Trainable parameters = 229209\n",
      "Total parameters = 229209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if config.MODEL == \"BED\":\n",
    "    \n",
    "    print(\"Using BED Detector\")\n",
    "    logger.info(\"\\nUsing BED Detector\")\n",
    "    model = models.SVD_BED_DETECTOR().to(config.DEVICE)  \n",
    "\n",
    "else:\n",
    "    print(\"Wrong Model\")\n",
    "    logger.info(\"Wrong Model\")\n",
    "    raise SystemExit(\"Wrong Model\")\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), \n",
    "#                        lr=config.LEARNING_RATE, \n",
    "#                        weight_decay=config.WEIGHT_DECAY)\n",
    "\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "#                                                  mode='min',\n",
    "#                                                  factor=config.FACTOR, \n",
    "#                                                  patience=config.PATIENCE, \n",
    "#                                                  threshold=config.THRES, \n",
    "#                                                  threshold_mode='abs',\n",
    "#                                                  min_lr=config.MIN_LR)\n",
    "\n",
    "# MODEL PARAMETERS\n",
    "n_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'\\nTrainable parameters = {n_trainable}')\n",
    "logger.info(f'\\nTrainable parameters = {n_trainable}')\n",
    "\n",
    "n_params = parameters_to_vector(model.parameters()).numel()\n",
    "print(f'Total parameters = {n_params}\\n')\n",
    "logger.info(f'Total parameters = {n_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ca70e-262b-4c78-88d1-ec9e81176f4d",
   "metadata": {},
   "source": [
    "### Check Model Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce04b628-4a5b-4aa7-8668-0ad7b5a834c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is torch.Size([4, 3, 224, 224])\n",
      "Model shape is torch.Size([4, 12, 7, 7])\n",
      "BED Model Arquitecture\n",
      "SVD_BED_DETECTOR(\n",
      "  (model): Sequential(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(3, 5, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(5, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout2d(p=0.3, inplace=False)\n",
      "    (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(32, 6, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(6, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout2d(p=0.3, inplace=False)\n",
      "    (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv31): Sequential(\n",
      "      (0): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu31): ReLU()\n",
      "    (conv32): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(16, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn32): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu32): ReLU()\n",
      "    (conv33): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu33): ReLU()\n",
      "    (conv34): Sequential(\n",
      "      (0): Conv2d(32, 51, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(51, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn34): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu34): ReLU()\n",
      "    (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv41): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu41): ReLU()\n",
      "    (conv42): Sequential(\n",
      "      (0): Conv2d(32, 38, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(38, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn42): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu42): ReLU()\n",
      "    (conv43): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu43): ReLU()\n",
      "    (conv44): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(32, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn44): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu44): ReLU()\n",
      "    (conv45): Sequential(\n",
      "      (0): Conv2d(64, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): Conv2d(17, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn45): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu45): ReLU()\n",
      "    (conv46): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(32, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn46): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu46): ReLU()\n",
      "    (maxpool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv51): Sequential(\n",
      "      (0): Conv2d(64, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): Conv2d(14, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn51): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu51): ReLU()\n",
      "    (conv52): Sequential(\n",
      "      (0): Conv2d(32, 51, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(51, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn52): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu52): ReLU()\n",
      "    (conv53): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn53): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu53): ReLU()\n",
      "    (conv54): Sequential(\n",
      "      (0): Conv2d(32, 57, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(57, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn54): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu54): ReLU()\n",
      "    (conv55): Sequential(\n",
      "      (0): Conv2d(64, 67, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(67, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu55): ReLU()\n",
      "    (conv56): Sequential(\n",
      "      (0): Conv2d(64, 86, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(86, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn56): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu56): ReLU()\n",
      "    (maxpool6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv61): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu61): ReLU()\n",
      "    (conv62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn62): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu62): ReLU()\n",
      "    (conv71): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn71): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu71): ReLU()\n",
      "    (conv72): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn72): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu72): ReLU()\n",
      "    (conv73): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu73): ReLU()\n",
      "    (conv74): Conv2d(16, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "in_rand_np = np.random.rand(4, 3, config.IMG_H, config.IMG_W)\n",
    "in_rand = torch.tensor(in_rand_np, dtype=torch.float32, device=config.DEVICE)\n",
    "out_test = model(in_rand)\n",
    "\n",
    "print(f'Input shape is {in_rand.shape}')\n",
    "print(f'Model shape is {out_test.shape}')\n",
    "print(f'BED Model Arquitecture\\n{model}')\n",
    "logger.info(f'\\nInput shape is {in_rand.shape}')\n",
    "logger.info(f'Model shape is {out_test.shape}\\n')\n",
    "logger.info(f'BED Model Arquitecture\\n{model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14357ea-8b99-42e1-8cbf-c83083b22f1d",
   "metadata": {},
   "source": [
    "### Torch Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78ae5811-b351-4f57-a55e-2cc3b60c2947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "SVD_BED_DETECTOR                         [1, 12, 7, 7]             --\n",
      "Sequential: 1-1                        [1, 12, 7, 7]             --\n",
      "    Sequential: 2-1                   [1, 32, 224, 224]         --\n",
      "        Conv2d: 3-1                  [1, 5, 224, 224]          45\n",
      "        Conv2d: 3-2                  [1, 32, 224, 224]         480\n",
      "    BatchNorm2d: 2-2                  [1, 32, 224, 224]         64\n",
      "    ReLU: 2-3                         [1, 32, 224, 224]         --\n",
      "    Dropout2d: 2-4                    [1, 32, 224, 224]         --\n",
      "    MaxPool2d: 2-5                    [1, 32, 112, 112]         --\n",
      "    Sequential: 2-6                   [1, 16, 112, 112]         --\n",
      "        Conv2d: 3-3                  [1, 6, 112, 112]          576\n",
      "        Conv2d: 3-4                  [1, 16, 112, 112]         288\n",
      "    BatchNorm2d: 2-7                  [1, 16, 112, 112]         32\n",
      "    ReLU: 2-8                         [1, 16, 112, 112]         --\n",
      "    Dropout2d: 2-9                    [1, 16, 112, 112]         --\n",
      "    MaxPool2d: 2-10                   [1, 16, 56, 56]           --\n",
      "    Sequential: 2-11                  [1, 16, 56, 56]           --\n",
      "        Conv2d: 3-5                  [1, 3, 56, 56]            48\n",
      "        Conv2d: 3-6                  [1, 16, 56, 56]           48\n",
      "    BatchNorm2d: 2-12                 [1, 16, 56, 56]           32\n",
      "    ReLU: 2-13                        [1, 16, 56, 56]           --\n",
      "    Sequential: 2-14                  [1, 32, 56, 56]           --\n",
      "        Conv2d: 3-7                  [1, 16, 56, 56]           768\n",
      "        Conv2d: 3-8                  [1, 32, 56, 56]           1,536\n",
      "    BatchNorm2d: 2-15                 [1, 32, 56, 56]           64\n",
      "    ReLU: 2-16                        [1, 32, 56, 56]           --\n",
      "    Conv2d: 2-17                      [1, 32, 56, 56]           1,024\n",
      "    BatchNorm2d: 2-18                 [1, 32, 56, 56]           64\n",
      "    ReLU: 2-19                        [1, 32, 56, 56]           --\n",
      "    Sequential: 2-20                  [1, 64, 56, 56]           --\n",
      "        Conv2d: 3-9                  [1, 51, 56, 56]           4,896\n",
      "        Conv2d: 3-10                 [1, 64, 56, 56]           9,792\n",
      "    BatchNorm2d: 2-21                 [1, 64, 56, 56]           128\n",
      "    ReLU: 2-22                        [1, 64, 56, 56]           --\n",
      "    MaxPool2d: 2-23                   [1, 64, 28, 28]           --\n",
      "    Conv2d: 2-24                      [1, 32, 28, 28]           2,048\n",
      "    BatchNorm2d: 2-25                 [1, 32, 28, 28]           64\n",
      "    ReLU: 2-26                        [1, 32, 28, 28]           --\n",
      "    Sequential: 2-27                  [1, 64, 28, 28]           --\n",
      "        Conv2d: 3-11                 [1, 38, 28, 28]           3,648\n",
      "        Conv2d: 3-12                 [1, 64, 28, 28]           7,296\n",
      "    BatchNorm2d: 2-28                 [1, 64, 28, 28]           128\n",
      "    ReLU: 2-29                        [1, 64, 28, 28]           --\n",
      "    Conv2d: 2-30                      [1, 32, 28, 28]           2,048\n",
      "    BatchNorm2d: 2-31                 [1, 32, 28, 28]           64\n",
      "    ReLU: 2-32                        [1, 32, 28, 28]           --\n",
      "    Sequential: 2-33                  [1, 64, 28, 28]           --\n",
      "        Conv2d: 3-13                 [1, 32, 28, 28]           3,072\n",
      "        Conv2d: 3-14                 [1, 64, 28, 28]           6,144\n",
      "    BatchNorm2d: 2-34                 [1, 64, 28, 28]           128\n",
      "    ReLU: 2-35                        [1, 64, 28, 28]           --\n",
      "    Sequential: 2-36                  [1, 32, 28, 28]           --\n",
      "        Conv2d: 3-15                 [1, 17, 28, 28]           1,088\n",
      "        Conv2d: 3-16                 [1, 32, 28, 28]           544\n",
      "    BatchNorm2d: 2-37                 [1, 32, 28, 28]           64\n",
      "    ReLU: 2-38                        [1, 32, 28, 28]           --\n",
      "    Sequential: 2-39                  [1, 64, 28, 28]           --\n",
      "        Conv2d: 3-17                 [1, 32, 28, 28]           3,072\n",
      "        Conv2d: 3-18                 [1, 64, 28, 28]           6,144\n",
      "    BatchNorm2d: 2-40                 [1, 64, 28, 28]           128\n",
      "    ReLU: 2-41                        [1, 64, 28, 28]           --\n",
      "    MaxPool2d: 2-42                   [1, 64, 14, 14]           --\n",
      "    Sequential: 2-43                  [1, 32, 14, 14]           --\n",
      "        Conv2d: 3-19                 [1, 14, 14, 14]           896\n",
      "        Conv2d: 3-20                 [1, 32, 14, 14]           448\n",
      "    BatchNorm2d: 2-44                 [1, 32, 14, 14]           64\n",
      "    ReLU: 2-45                        [1, 32, 14, 14]           --\n",
      "    Sequential: 2-46                  [1, 64, 14, 14]           --\n",
      "        Conv2d: 3-21                 [1, 51, 14, 14]           4,896\n",
      "        Conv2d: 3-22                 [1, 64, 14, 14]           9,792\n",
      "    BatchNorm2d: 2-47                 [1, 64, 14, 14]           128\n",
      "    ReLU: 2-48                        [1, 64, 14, 14]           --\n",
      "    Conv2d: 2-49                      [1, 32, 14, 14]           2,048\n",
      "    BatchNorm2d: 2-50                 [1, 32, 14, 14]           64\n",
      "    ReLU: 2-51                        [1, 32, 14, 14]           --\n",
      "    Sequential: 2-52                  [1, 64, 14, 14]           --\n",
      "        Conv2d: 3-23                 [1, 57, 14, 14]           5,472\n",
      "        Conv2d: 3-24                 [1, 64, 14, 14]           10,944\n",
      "    BatchNorm2d: 2-53                 [1, 64, 14, 14]           128\n",
      "    ReLU: 2-54                        [1, 64, 14, 14]           --\n",
      "    Sequential: 2-55                  [1, 64, 14, 14]           --\n",
      "        Conv2d: 3-25                 [1, 67, 14, 14]           12,864\n",
      "        Conv2d: 3-26                 [1, 64, 14, 14]           12,864\n",
      "    BatchNorm2d: 2-56                 [1, 64, 14, 14]           128\n",
      "    ReLU: 2-57                        [1, 64, 14, 14]           --\n",
      "    Sequential: 2-58                  [1, 64, 14, 14]           --\n",
      "        Conv2d: 3-27                 [1, 86, 14, 14]           16,512\n",
      "        Conv2d: 3-28                 [1, 64, 14, 14]           16,512\n",
      "    BatchNorm2d: 2-59                 [1, 64, 14, 14]           128\n",
      "    ReLU: 2-60                        [1, 64, 14, 14]           --\n",
      "    MaxPool2d: 2-61                   [1, 64, 7, 7]             --\n",
      "    Conv2d: 2-62                      [1, 64, 7, 7]             36,864\n",
      "    BatchNorm2d: 2-63                 [1, 64, 7, 7]             128\n",
      "    ReLU: 2-64                        [1, 64, 7, 7]             --\n",
      "    Conv2d: 2-65                      [1, 64, 7, 7]             36,864\n",
      "    BatchNorm2d: 2-66                 [1, 64, 7, 7]             128\n",
      "    ReLU: 2-67                        [1, 64, 7, 7]             --\n",
      "    Conv2d: 2-68                      [1, 64, 7, 7]             4,096\n",
      "    BatchNorm2d: 2-69                 [1, 64, 7, 7]             128\n",
      "    ReLU: 2-70                        [1, 64, 7, 7]             --\n",
      "    Conv2d: 2-71                      [1, 16, 7, 7]             1,024\n",
      "    BatchNorm2d: 2-72                 [1, 16, 7, 7]             32\n",
      "    ReLU: 2-73                        [1, 16, 7, 7]             --\n",
      "    Conv2d: 2-74                      [1, 16, 7, 7]             256\n",
      "    BatchNorm2d: 2-75                 [1, 16, 7, 7]             32\n",
      "    ReLU: 2-76                        [1, 16, 7, 7]             --\n",
      "    Conv2d: 2-77                      [1, 12, 7, 7]             204\n",
      "==========================================================================================\n",
      "Total params: 229,209\n",
      "Trainable params: 229,209\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 143.67\n",
      "==========================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 46.47\n",
      "Params size (MB): 0.92\n",
      "Estimated Total Size (MB): 47.99\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, input_size=(1, 3, config.IMG_H, config.IMG_W)))\n",
    "logger.info(\"\\nModel Summary\")\n",
    "logger.info(summary(model, input_size=(1, 3, config.IMG_H, config.IMG_W)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0f708-5b0a-40a8-a587-89fd3ac364f8",
   "metadata": {},
   "source": [
    "# Load Pretrained or Initialize Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39cf7f82-ad2c-4e60-b4cc-e71f0c676a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model. Trained during 4 epochs\n"
     ]
    }
   ],
   "source": [
    "epochs_trained = utils.load_checkpoint(config.LOAD_MODEL_FILE, \n",
    "                                       model, \n",
    "                                       optimizer=None, \n",
    "                                       scheduler=None, \n",
    "                                       device=config.DEVICE)\n",
    "\n",
    "logger.info(f\"Loading Model. Trained during {epochs_trained} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a7b3d-ba26-4d62-a0c0-9132bb9fb35f",
   "metadata": {},
   "source": [
    "# AIMET Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f564b84-b70c-4e68-b8d5-6ae540ed069d",
   "metadata": {},
   "source": [
    "### Configure Pruning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43798232-a5fb-4ef5-b89c-2f5d87db0dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_to_ignore = [model.model.conv1[0], model.model.conv72, model.model.conv73, model.model.conv74]\n",
    "greedy_params = GreedySelectionParameters(target_comp_ratio=Decimal(config.PRUNING_COMPRESSION_RATIO),\n",
    "                                          saved_eval_scores_dict=config.PRUNING_DIC_FILE)\n",
    "auto_params = ChannelPruningParameters.AutoModeParams(greedy_params,\n",
    "                                                  modules_to_ignore=modules_to_ignore)\n",
    "cp_params = ChannelPruningParameters(mode=ChannelPruningParameters.Mode.auto,\n",
    "                                     params=auto_params,\n",
    "                                     data_loader=val_loader,\n",
    "                                     num_reconstruction_samples=500,\n",
    "                                     allow_custom_downsample_ops=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136cbbb0-74c8-4ed1-bb30-6af7db2ea077",
   "metadata": {},
   "source": [
    "### Evaluate Model Callback\n",
    "\n",
    "Signature: (model, iterations, use_cuda)\n",
    "Return an accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d261f98-8a70-4930-88b3-cc2912e7ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, iterations, use_cuda):\n",
    "   \n",
    "    model.eval()\n",
    "    \n",
    "    for batch_idx, (x, y) in enumerate(val_loader):\n",
    "        if use_cuda == True:\n",
    "            x, y = x.to('cuda'), y.to('cuda')\n",
    "        else:\n",
    "            model.to('cpu')\n",
    "        out = model(x)\n",
    "\n",
    "        # Remove Permute from the model\n",
    "        out = out.permute(0, 2, 3, 1)\n",
    "        \n",
    "        if iterations is not None:\n",
    "            if batch_idx == iterations:\n",
    "                break\n",
    "\n",
    "        # Mean Average Precision\n",
    "        for idx in range(x.shape[0]):\n",
    "            target_boxes = metrics.get_true_boxes(y[idx].detach().to('cpu'))\n",
    "            pred_boxes = metrics.get_pred_boxes(out[idx].detach().to('cpu'))\n",
    "            metrics.map_metric.update(preds = pred_boxes, target = target_boxes) \n",
    "\n",
    "    meanAP = metrics.map_metric.compute()\n",
    "    metrics.map_metric.reset()\n",
    "    print(f'Val mAP = {meanAP[\"map_50\"]:.4f}')\n",
    "    \n",
    "    return meanAP['map_50'].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953badff-069f-4e95-8a9e-4f96a54ab344",
   "metadata": {},
   "source": [
    "### Baseline mAP Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1827951-a0f9-4ebf-8c7d-3be08fa1bf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val mAP = 0.6186\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "baseline_mAP = evaluate_model(model, None, True)\n",
    "print(type(baseline_mAP))\n",
    "\n",
    "logger.info(f'Baseline mAP: {baseline_mAP}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8f96c-3726-4f04-a2f1-f7d0d06d2699",
   "metadata": {},
   "source": [
    "### Input Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f21b1fa-a78d-4b35-8fdf-def1657a45ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 3, config.IMG_H, config.IMG_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64e4c418-6d55-4445-985e-3b652b0bc9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-20 02:37:47,529 - CompRatioSelect - INFO - Greedy selection: Read eval dict from ./data/greedy_selection_eval_scores_dict.pkl\n",
      "2024-07-20 02:37:47,530 - CompRatioSelect - INFO - Greedy selection: overall_min_score=0.000000, overall_max_score=0.624938\n",
      "2024-07-20 02:37:47,531 - CompRatioSelect - INFO - Greedy selection: Original model cost=(Cost: memory=227149, mac=143663296)\n",
      "2024-07-20 02:38:28,824 - CompRatioSelect - INFO - Greedy selection: final choice - comp_ratio=0.890482, score=0.618339\n",
      "2024-07-20 02:38:30,475 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:32,095 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:33,731 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:35,397 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:37,095 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:38,765 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:40,401 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:42,047 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:43,725 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:45,378 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:47,024 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:48,653 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:50,293 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:51,946 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:53,562 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:55,413 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:57,083 - ChannelPruning - INFO - finished linear regression fit \n",
      "2024-07-20 02:38:58,740 - ChannelPruning - INFO - finished linear regression fit \n",
      "Val mAP = 0.6186\n",
      "Val mAP = 0.2888\n"
     ]
    }
   ],
   "source": [
    "comp_model, stats = ModelCompressor.compress_model(model,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   eval_callback=evaluate_model,\n",
    "                                                   eval_iterations=None,\n",
    "                                                   compress_scheme=CompressionScheme.channel_pruning,\n",
    "                                                   cost_metric=CostMetric.memory,\n",
    "                                                   parameters=cp_params,\n",
    "                                                   visualization_url=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a2a90fb-8ba0-4965-a897-9eda4cfa7c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD_BED_DETECTOR(\n",
      "  (model): Sequential(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(3, 5, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(5, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout2d(p=0.3, inplace=False)\n",
      "    (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(32, 4, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(4, 11, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout2d(p=0.3, inplace=False)\n",
      "    (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv31): Sequential(\n",
      "      (0): Conv2d(11, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): Conv2d(3, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn31): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu31): ReLU()\n",
      "    (conv32): Sequential(\n",
      "      (0): Conv2d(14, 14, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(14, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn32): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu32): ReLU()\n",
      "    (conv33): Conv2d(25, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn33): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu33): ReLU()\n",
      "    (conv34): Sequential(\n",
      "      (0): Conv2d(22, 30, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(30, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn34): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu34): ReLU()\n",
      "    (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv41): Conv2d(64, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn41): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu41): ReLU()\n",
      "    (conv42): Sequential(\n",
      "      (0): Conv2d(28, 38, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(38, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn42): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu42): ReLU()\n",
      "    (conv43): Conv2d(64, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn43): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu43): ReLU()\n",
      "    (conv44): Sequential(\n",
      "      (0): Conv2d(28, 25, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(25, 57, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn44): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu44): ReLU()\n",
      "    (conv45): Sequential(\n",
      "      (0): Conv2d(57, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): Conv2d(15, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn45): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu45): ReLU()\n",
      "    (conv46): Sequential(\n",
      "      (0): Conv2d(28, 28, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(28, 57, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn46): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu46): ReLU()\n",
      "    (maxpool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv51): Sequential(\n",
      "      (0): Conv2d(57, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): Conv2d(14, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn51): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu51): ReLU()\n",
      "    (conv52): Sequential(\n",
      "      (0): Conv2d(32, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(40, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn52): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu52): ReLU()\n",
      "    (conv53): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn53): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu53): ReLU()\n",
      "    (conv54): Sequential(\n",
      "      (0): Conv2d(32, 45, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(45, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn54): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu54): ReLU()\n",
      "    (conv55): Sequential(\n",
      "      (0): Conv2d(64, 67, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(67, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu55): ReLU()\n",
      "    (conv56): Sequential(\n",
      "      (0): Conv2d(64, 77, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(77, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn56): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu56): ReLU()\n",
      "    (maxpool6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv61): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu61): ReLU()\n",
      "    (conv62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn62): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu62): ReLU()\n",
      "    (conv71): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn71): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu71): ReLU()\n",
      "    (conv72): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn72): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu72): ReLU()\n",
      "    (conv73): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu73): ReLU()\n",
      "    (conv74): Conv2d(16, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(comp_model)\n",
    "logger.info(comp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c76311-21bf-4f16-9d03-bae8220f5f6f",
   "metadata": {},
   "source": [
    "### Print Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "667d2c30-8733-4b30-aa77-0432f95135d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************************************\n",
      "Compressed Model Statistics\n",
      "Baseline model accuracy: 0.618582, Compressed model accuracy: 0.288772\n",
      "Compression ratio for memory=0.890482, mac=0.744655\n",
      "\n",
      "**********************************************************************************************\n",
      "\n",
      "Per-layer Stats\n",
      "    Name:model.conv1.1, compression-ratio: None\n",
      "    Name:model.conv2.0, compression-ratio: None\n",
      "    Name:model.conv2.1, compression-ratio: 0.7\n",
      "    Name:model.conv31.0, compression-ratio: 0.7\n",
      "    Name:model.conv31.1, compression-ratio: None\n",
      "    Name:model.conv32.0, compression-ratio: 0.9\n",
      "    Name:model.conv32.1, compression-ratio: 0.9\n",
      "    Name:model.conv33, compression-ratio: 0.8\n",
      "    Name:model.conv34.0, compression-ratio: 0.7\n",
      "    Name:model.conv34.1, compression-ratio: 0.6\n",
      "    Name:model.conv41, compression-ratio: None\n",
      "    Name:model.conv42.0, compression-ratio: 0.9\n",
      "    Name:model.conv42.1, compression-ratio: None\n",
      "    Name:model.conv43, compression-ratio: None\n",
      "    Name:model.conv44.0, compression-ratio: 0.9\n",
      "    Name:model.conv44.1, compression-ratio: 0.8\n",
      "    Name:model.conv45.0, compression-ratio: 0.9\n",
      "    Name:model.conv45.1, compression-ratio: 0.9\n",
      "    Name:model.conv46.0, compression-ratio: 0.9\n",
      "    Name:model.conv46.1, compression-ratio: 0.9\n",
      "    Name:model.conv51.0, compression-ratio: 0.9\n",
      "    Name:model.conv51.1, compression-ratio: None\n",
      "    Name:model.conv52.0, compression-ratio: None\n",
      "    Name:model.conv52.1, compression-ratio: 0.8\n",
      "    Name:model.conv53, compression-ratio: None\n",
      "    Name:model.conv54.0, compression-ratio: None\n",
      "    Name:model.conv54.1, compression-ratio: 0.8\n",
      "    Name:model.conv55.0, compression-ratio: None\n",
      "    Name:model.conv55.1, compression-ratio: None\n",
      "    Name:model.conv56.0, compression-ratio: None\n",
      "    Name:model.conv56.1, compression-ratio: 0.9\n",
      "    Name:model.conv61, compression-ratio: None\n",
      "    Name:model.conv62, compression-ratio: None\n",
      "    Name:model.conv71, compression-ratio: None\n",
      "\n",
      "**********************************************************************************************\n",
      "\n",
      "Greedy Eval Dict\n",
      "    Layer: model.conv1.1\n",
      "        Ratio=0.1, Eval score=0.25772690773010254\n",
      "        Ratio=0.2, Eval score=0.25999364256858826\n",
      "        Ratio=0.3, Eval score=0.260303258895874\n",
      "        Ratio=0.4, Eval score=0.6084394454956055\n",
      "        Ratio=0.5, Eval score=0.6010971069335938\n",
      "        Ratio=0.6, Eval score=0.6179224848747253\n",
      "        Ratio=0.7, Eval score=0.6187876462936401\n",
      "        Ratio=0.8, Eval score=0.6178123950958252\n",
      "        Ratio=0.9, Eval score=0.617100715637207\n",
      "    Layer: model.conv2.0\n",
      "        Ratio=0.1, Eval score=0.2622887194156647\n",
      "        Ratio=0.2, Eval score=0.4361843466758728\n",
      "        Ratio=0.3, Eval score=0.5609697103500366\n",
      "        Ratio=0.4, Eval score=0.6087331771850586\n",
      "        Ratio=0.5, Eval score=0.6067729592323303\n",
      "        Ratio=0.6, Eval score=0.6137507557868958\n",
      "        Ratio=0.7, Eval score=0.6156763434410095\n",
      "        Ratio=0.8, Eval score=0.6155288219451904\n",
      "        Ratio=0.9, Eval score=0.6166341304779053\n",
      "    Layer: model.conv2.1\n",
      "        Ratio=0.1, Eval score=0.26625970005989075\n",
      "        Ratio=0.2, Eval score=0.268608957529068\n",
      "        Ratio=0.3, Eval score=0.26624324917793274\n",
      "        Ratio=0.4, Eval score=0.5957219004631042\n",
      "        Ratio=0.5, Eval score=0.6151818633079529\n",
      "        Ratio=0.6, Eval score=0.6113100051879883\n",
      "        Ratio=0.7, Eval score=0.6208763122558594\n",
      "        Ratio=0.8, Eval score=0.6203456521034241\n",
      "        Ratio=0.9, Eval score=0.6229894161224365\n",
      "    Layer: model.conv31.0\n",
      "        Ratio=0.1, Eval score=0.012130523100495338\n",
      "        Ratio=0.2, Eval score=0.3426642417907715\n",
      "        Ratio=0.3, Eval score=0.34068775177001953\n",
      "        Ratio=0.4, Eval score=0.6142542958259583\n",
      "        Ratio=0.5, Eval score=0.6189275979995728\n",
      "        Ratio=0.6, Eval score=0.6181318759918213\n",
      "        Ratio=0.7, Eval score=0.6220121383666992\n",
      "        Ratio=0.8, Eval score=0.6184888482093811\n",
      "        Ratio=0.9, Eval score=0.621017336845398\n",
      "    Layer: model.conv31.1\n",
      "        Ratio=0.1, Eval score=0.1453636735677719\n",
      "        Ratio=0.2, Eval score=0.14116935431957245\n",
      "        Ratio=0.3, Eval score=0.13496124744415283\n",
      "        Ratio=0.4, Eval score=0.14041569828987122\n",
      "        Ratio=0.5, Eval score=0.1392183005809784\n",
      "        Ratio=0.6, Eval score=0.13907241821289062\n",
      "        Ratio=0.7, Eval score=0.5313757061958313\n",
      "        Ratio=0.8, Eval score=0.5316856503486633\n",
      "        Ratio=0.9, Eval score=0.5278658270835876\n",
      "    Layer: model.conv32.0\n",
      "        Ratio=0.1, Eval score=0.13772474229335785\n",
      "        Ratio=0.2, Eval score=0.6015110611915588\n",
      "        Ratio=0.3, Eval score=0.6027913093566895\n",
      "        Ratio=0.4, Eval score=0.6187316179275513\n",
      "        Ratio=0.5, Eval score=0.5666755437850952\n",
      "        Ratio=0.6, Eval score=0.6208829283714294\n",
      "        Ratio=0.7, Eval score=0.5459118485450745\n",
      "        Ratio=0.8, Eval score=0.5103129148483276\n",
      "        Ratio=0.9, Eval score=0.6218646764755249\n",
      "    Layer: model.conv32.1\n",
      "        Ratio=0.1, Eval score=0.11206990480422974\n",
      "        Ratio=0.2, Eval score=0.525942862033844\n",
      "        Ratio=0.3, Eval score=0.5477707386016846\n",
      "        Ratio=0.4, Eval score=0.5978302359580994\n",
      "        Ratio=0.5, Eval score=0.6053369641304016\n",
      "        Ratio=0.6, Eval score=0.6198815107345581\n",
      "        Ratio=0.7, Eval score=0.616278350353241\n",
      "        Ratio=0.8, Eval score=0.6152521967887878\n",
      "        Ratio=0.9, Eval score=0.6185015439987183\n",
      "    Layer: model.conv33\n",
      "        Ratio=0.1, Eval score=0.19820170104503632\n",
      "        Ratio=0.2, Eval score=0.3898925185203552\n",
      "        Ratio=0.3, Eval score=0.5164583325386047\n",
      "        Ratio=0.4, Eval score=0.5698081254959106\n",
      "        Ratio=0.5, Eval score=0.6111074090003967\n",
      "        Ratio=0.6, Eval score=0.6190447807312012\n",
      "        Ratio=0.7, Eval score=0.6171954870223999\n",
      "        Ratio=0.8, Eval score=0.6223383545875549\n",
      "        Ratio=0.9, Eval score=0.6240441203117371\n",
      "    Layer: model.conv34.0\n",
      "        Ratio=0.1, Eval score=0.07613886147737503\n",
      "        Ratio=0.2, Eval score=0.4040355086326599\n",
      "        Ratio=0.3, Eval score=0.5510308146476746\n",
      "        Ratio=0.4, Eval score=0.5837222933769226\n",
      "        Ratio=0.5, Eval score=0.6100965738296509\n",
      "        Ratio=0.6, Eval score=0.6175271272659302\n",
      "        Ratio=0.7, Eval score=0.6194263696670532\n",
      "        Ratio=0.8, Eval score=0.61883145570755\n",
      "        Ratio=0.9, Eval score=0.6193532347679138\n",
      "    Layer: model.conv34.1\n",
      "        Ratio=0.1, Eval score=0.5034923553466797\n",
      "        Ratio=0.2, Eval score=0.5950093865394592\n",
      "        Ratio=0.3, Eval score=0.6050252318382263\n",
      "        Ratio=0.4, Eval score=0.6094616651535034\n",
      "        Ratio=0.5, Eval score=0.6130545139312744\n",
      "        Ratio=0.6, Eval score=0.6220316290855408\n",
      "        Ratio=0.7, Eval score=0.6198421716690063\n",
      "        Ratio=0.8, Eval score=0.6225361227989197\n",
      "        Ratio=0.9, Eval score=0.6224163770675659\n",
      "    Layer: model.conv41\n",
      "        Ratio=0.1, Eval score=0.06320913136005402\n",
      "        Ratio=0.2, Eval score=0.3315093517303467\n",
      "        Ratio=0.3, Eval score=0.5017557740211487\n",
      "        Ratio=0.4, Eval score=0.55226731300354\n",
      "        Ratio=0.5, Eval score=0.5876803994178772\n",
      "        Ratio=0.6, Eval score=0.6055373549461365\n",
      "        Ratio=0.7, Eval score=0.6105298399925232\n",
      "        Ratio=0.8, Eval score=0.6134889125823975\n",
      "        Ratio=0.9, Eval score=0.615412175655365\n",
      "    Layer: model.conv42.0\n",
      "        Ratio=0.1, Eval score=0.05334997922182083\n",
      "        Ratio=0.2, Eval score=0.16564780473709106\n",
      "        Ratio=0.3, Eval score=0.18603947758674622\n",
      "        Ratio=0.4, Eval score=0.3947692811489105\n",
      "        Ratio=0.5, Eval score=0.5498555898666382\n",
      "        Ratio=0.6, Eval score=0.5927777290344238\n",
      "        Ratio=0.7, Eval score=0.6128590703010559\n",
      "        Ratio=0.8, Eval score=0.6139172315597534\n",
      "        Ratio=0.9, Eval score=0.6202335953712463\n",
      "    Layer: model.conv42.1\n",
      "        Ratio=0.1, Eval score=0.10355184972286224\n",
      "        Ratio=0.2, Eval score=0.45842811465263367\n",
      "        Ratio=0.3, Eval score=0.5832393765449524\n",
      "        Ratio=0.4, Eval score=0.5954607725143433\n",
      "        Ratio=0.5, Eval score=0.6075012683868408\n",
      "        Ratio=0.6, Eval score=0.6100402474403381\n",
      "        Ratio=0.7, Eval score=0.6198663115501404\n",
      "        Ratio=0.8, Eval score=0.6116598844528198\n",
      "        Ratio=0.9, Eval score=0.616726279258728\n",
      "    Layer: model.conv43\n",
      "        Ratio=0.1, Eval score=0.04631702974438667\n",
      "        Ratio=0.2, Eval score=0.17323774099349976\n",
      "        Ratio=0.3, Eval score=0.47226589918136597\n",
      "        Ratio=0.4, Eval score=0.4935566484928131\n",
      "        Ratio=0.5, Eval score=0.5681042075157166\n",
      "        Ratio=0.6, Eval score=0.5849294662475586\n",
      "        Ratio=0.7, Eval score=0.5974664688110352\n",
      "        Ratio=0.8, Eval score=0.6095865368843079\n",
      "        Ratio=0.9, Eval score=0.6167242527008057\n",
      "    Layer: model.conv44.0\n",
      "        Ratio=0.1, Eval score=0.012001348659396172\n",
      "        Ratio=0.2, Eval score=0.0714796632528305\n",
      "        Ratio=0.3, Eval score=0.273711621761322\n",
      "        Ratio=0.4, Eval score=0.4785020649433136\n",
      "        Ratio=0.5, Eval score=0.580920934677124\n",
      "        Ratio=0.6, Eval score=0.5902431607246399\n",
      "        Ratio=0.7, Eval score=0.6001854538917542\n",
      "        Ratio=0.8, Eval score=0.6110943555831909\n",
      "        Ratio=0.9, Eval score=0.6184675693511963\n",
      "    Layer: model.conv44.1\n",
      "        Ratio=0.1, Eval score=0.042609501630067825\n",
      "        Ratio=0.2, Eval score=0.36377331614494324\n",
      "        Ratio=0.3, Eval score=0.519060492515564\n",
      "        Ratio=0.4, Eval score=0.5727347135543823\n",
      "        Ratio=0.5, Eval score=0.6069607734680176\n",
      "        Ratio=0.6, Eval score=0.6101635098457336\n",
      "        Ratio=0.7, Eval score=0.614043653011322\n",
      "        Ratio=0.8, Eval score=0.6185722947120667\n",
      "        Ratio=0.9, Eval score=0.6211338639259338\n",
      "    Layer: model.conv45.0\n",
      "        Ratio=0.1, Eval score=0.009213467128574848\n",
      "        Ratio=0.2, Eval score=0.057053811848163605\n",
      "        Ratio=0.3, Eval score=0.424830824136734\n",
      "        Ratio=0.4, Eval score=0.5116286277770996\n",
      "        Ratio=0.5, Eval score=0.5766397714614868\n",
      "        Ratio=0.6, Eval score=0.5885116457939148\n",
      "        Ratio=0.7, Eval score=0.5959294438362122\n",
      "        Ratio=0.8, Eval score=0.6180444955825806\n",
      "        Ratio=0.9, Eval score=0.619364857673645\n",
      "    Layer: model.conv45.1\n",
      "        Ratio=0.1, Eval score=0.01497145090252161\n",
      "        Ratio=0.2, Eval score=0.13071498274803162\n",
      "        Ratio=0.3, Eval score=0.22133301198482513\n",
      "        Ratio=0.4, Eval score=0.4765229821205139\n",
      "        Ratio=0.5, Eval score=0.5591827034950256\n",
      "        Ratio=0.6, Eval score=0.5904132127761841\n",
      "        Ratio=0.7, Eval score=0.599513590335846\n",
      "        Ratio=0.8, Eval score=0.6174492835998535\n",
      "        Ratio=0.9, Eval score=0.6206991672515869\n",
      "    Layer: model.conv46.0\n",
      "        Ratio=0.1, Eval score=0.012341678142547607\n",
      "        Ratio=0.2, Eval score=0.1344163715839386\n",
      "        Ratio=0.3, Eval score=0.4183940589427948\n",
      "        Ratio=0.4, Eval score=0.48091763257980347\n",
      "        Ratio=0.5, Eval score=0.5570279359817505\n",
      "        Ratio=0.6, Eval score=0.5737124681472778\n",
      "        Ratio=0.7, Eval score=0.6033380031585693\n",
      "        Ratio=0.8, Eval score=0.6111024022102356\n",
      "        Ratio=0.9, Eval score=0.6213716268539429\n",
      "    Layer: model.conv46.1\n",
      "        Ratio=0.1, Eval score=0.3391021192073822\n",
      "        Ratio=0.2, Eval score=0.44614800810813904\n",
      "        Ratio=0.3, Eval score=0.5492890477180481\n",
      "        Ratio=0.4, Eval score=0.59525066614151\n",
      "        Ratio=0.5, Eval score=0.6098505854606628\n",
      "        Ratio=0.6, Eval score=0.6065236926078796\n",
      "        Ratio=0.7, Eval score=0.6171278357505798\n",
      "        Ratio=0.8, Eval score=0.6167668700218201\n",
      "        Ratio=0.9, Eval score=0.6192684173583984\n",
      "    Layer: model.conv51.0\n",
      "        Ratio=0.1, Eval score=0.13047857582569122\n",
      "        Ratio=0.2, Eval score=0.31982460618019104\n",
      "        Ratio=0.3, Eval score=0.49405550956726074\n",
      "        Ratio=0.4, Eval score=0.5797011852264404\n",
      "        Ratio=0.5, Eval score=0.6018173098564148\n",
      "        Ratio=0.6, Eval score=0.6098164319992065\n",
      "        Ratio=0.7, Eval score=0.6134678721427917\n",
      "        Ratio=0.8, Eval score=0.6150358319282532\n",
      "        Ratio=0.9, Eval score=0.6184118986129761\n",
      "    Layer: model.conv51.1\n",
      "        Ratio=0.1, Eval score=0.0016501650679856539\n",
      "        Ratio=0.2, Eval score=0.00020627063349820673\n",
      "        Ratio=0.3, Eval score=0.2557132840156555\n",
      "        Ratio=0.4, Eval score=0.40353062748908997\n",
      "        Ratio=0.5, Eval score=0.5551697611808777\n",
      "        Ratio=0.6, Eval score=0.5846757292747498\n",
      "        Ratio=0.7, Eval score=0.5940593481063843\n",
      "        Ratio=0.8, Eval score=0.6137694120407104\n",
      "        Ratio=0.9, Eval score=0.6173319816589355\n",
      "    Layer: model.conv52.0\n",
      "        Ratio=0.1, Eval score=0.010805911384522915\n",
      "        Ratio=0.2, Eval score=0.15299378335475922\n",
      "        Ratio=0.3, Eval score=0.3914142847061157\n",
      "        Ratio=0.4, Eval score=0.4730529189109802\n",
      "        Ratio=0.5, Eval score=0.581933856010437\n",
      "        Ratio=0.6, Eval score=0.6031976342201233\n",
      "        Ratio=0.7, Eval score=0.6066886186599731\n",
      "        Ratio=0.8, Eval score=0.6146654486656189\n",
      "        Ratio=0.9, Eval score=0.6178717017173767\n",
      "    Layer: model.conv52.1\n",
      "        Ratio=0.1, Eval score=0.15302754938602448\n",
      "        Ratio=0.2, Eval score=0.5379501581192017\n",
      "        Ratio=0.3, Eval score=0.5797591209411621\n",
      "        Ratio=0.4, Eval score=0.6117938756942749\n",
      "        Ratio=0.5, Eval score=0.6108715534210205\n",
      "        Ratio=0.6, Eval score=0.6189190149307251\n",
      "        Ratio=0.7, Eval score=0.6142629384994507\n",
      "        Ratio=0.8, Eval score=0.6213769316673279\n",
      "        Ratio=0.9, Eval score=0.6249376535415649\n",
      "    Layer: model.conv53\n",
      "        Ratio=0.1, Eval score=0.0\n",
      "        Ratio=0.2, Eval score=0.01933903619647026\n",
      "        Ratio=0.3, Eval score=0.23599372804164886\n",
      "        Ratio=0.4, Eval score=0.4144552946090698\n",
      "        Ratio=0.5, Eval score=0.5117390751838684\n",
      "        Ratio=0.6, Eval score=0.5749329328536987\n",
      "        Ratio=0.7, Eval score=0.5834733843803406\n",
      "        Ratio=0.8, Eval score=0.6043109893798828\n",
      "        Ratio=0.9, Eval score=0.6131914258003235\n",
      "    Layer: model.conv54.0\n",
      "        Ratio=0.1, Eval score=0.04258772358298302\n",
      "        Ratio=0.2, Eval score=0.10914070904254913\n",
      "        Ratio=0.3, Eval score=0.1983930915594101\n",
      "        Ratio=0.4, Eval score=0.4309571385383606\n",
      "        Ratio=0.5, Eval score=0.5455002188682556\n",
      "        Ratio=0.6, Eval score=0.5645948052406311\n",
      "        Ratio=0.7, Eval score=0.5842065811157227\n",
      "        Ratio=0.8, Eval score=0.5877406001091003\n",
      "        Ratio=0.9, Eval score=0.6176409721374512\n",
      "    Layer: model.conv54.1\n",
      "        Ratio=0.1, Eval score=0.11105659604072571\n",
      "        Ratio=0.2, Eval score=0.47430846095085144\n",
      "        Ratio=0.3, Eval score=0.5493171811103821\n",
      "        Ratio=0.4, Eval score=0.582129716873169\n",
      "        Ratio=0.5, Eval score=0.5968016386032104\n",
      "        Ratio=0.6, Eval score=0.6124749779701233\n",
      "        Ratio=0.7, Eval score=0.610867977142334\n",
      "        Ratio=0.8, Eval score=0.6203282475471497\n",
      "        Ratio=0.9, Eval score=0.6187703013420105\n",
      "    Layer: model.conv55.0\n",
      "        Ratio=0.1, Eval score=0.004950494971126318\n",
      "        Ratio=0.2, Eval score=0.04328015074133873\n",
      "        Ratio=0.3, Eval score=0.22865641117095947\n",
      "        Ratio=0.4, Eval score=0.45217272639274597\n",
      "        Ratio=0.5, Eval score=0.5040385723114014\n",
      "        Ratio=0.6, Eval score=0.5560656785964966\n",
      "        Ratio=0.7, Eval score=0.57969731092453\n",
      "        Ratio=0.8, Eval score=0.5968093276023865\n",
      "        Ratio=0.9, Eval score=0.6113929152488708\n",
      "    Layer: model.conv55.1\n",
      "        Ratio=0.1, Eval score=0.08473628759384155\n",
      "        Ratio=0.2, Eval score=0.46420642733573914\n",
      "        Ratio=0.3, Eval score=0.5362902879714966\n",
      "        Ratio=0.4, Eval score=0.5799777507781982\n",
      "        Ratio=0.5, Eval score=0.5892304182052612\n",
      "        Ratio=0.6, Eval score=0.6010535359382629\n",
      "        Ratio=0.7, Eval score=0.6010326147079468\n",
      "        Ratio=0.8, Eval score=0.6136212944984436\n",
      "        Ratio=0.9, Eval score=0.6143644452095032\n",
      "    Layer: model.conv56.0\n",
      "        Ratio=0.1, Eval score=0.0066006602719426155\n",
      "        Ratio=0.2, Eval score=0.044173210859298706\n",
      "        Ratio=0.3, Eval score=0.28246942162513733\n",
      "        Ratio=0.4, Eval score=0.357956200838089\n",
      "        Ratio=0.5, Eval score=0.48792627453804016\n",
      "        Ratio=0.6, Eval score=0.49400004744529724\n",
      "        Ratio=0.7, Eval score=0.5569815039634705\n",
      "        Ratio=0.8, Eval score=0.590604841709137\n",
      "        Ratio=0.9, Eval score=0.6008231043815613\n",
      "    Layer: model.conv56.1\n",
      "        Ratio=0.1, Eval score=0.1963789016008377\n",
      "        Ratio=0.2, Eval score=0.4863404631614685\n",
      "        Ratio=0.3, Eval score=0.5638088583946228\n",
      "        Ratio=0.4, Eval score=0.5683611631393433\n",
      "        Ratio=0.5, Eval score=0.5947587490081787\n",
      "        Ratio=0.6, Eval score=0.5999432802200317\n",
      "        Ratio=0.7, Eval score=0.6086433529853821\n",
      "        Ratio=0.8, Eval score=0.6117008328437805\n",
      "        Ratio=0.9, Eval score=0.618371307849884\n",
      "    Layer: model.conv61\n",
      "        Ratio=0.1, Eval score=0.041474856436252594\n",
      "        Ratio=0.2, Eval score=0.19111745059490204\n",
      "        Ratio=0.3, Eval score=0.32018592953681946\n",
      "        Ratio=0.4, Eval score=0.37926119565963745\n",
      "        Ratio=0.5, Eval score=0.4453248083591461\n",
      "        Ratio=0.6, Eval score=0.4872555136680603\n",
      "        Ratio=0.7, Eval score=0.5000112056732178\n",
      "        Ratio=0.8, Eval score=0.5360192656517029\n",
      "        Ratio=0.9, Eval score=0.5614781379699707\n",
      "    Layer: model.conv62\n",
      "        Ratio=0.1, Eval score=0.0021849991753697395\n",
      "        Ratio=0.2, Eval score=0.12985432147979736\n",
      "        Ratio=0.3, Eval score=0.16624221205711365\n",
      "        Ratio=0.4, Eval score=0.29725131392478943\n",
      "        Ratio=0.5, Eval score=0.4006386995315552\n",
      "        Ratio=0.6, Eval score=0.43800443410873413\n",
      "        Ratio=0.7, Eval score=0.4352734386920929\n",
      "        Ratio=0.8, Eval score=0.4596107304096222\n",
      "        Ratio=0.9, Eval score=0.5277999043464661\n",
      "    Layer: model.conv71\n",
      "        Ratio=0.1, Eval score=0.009726609103381634\n",
      "        Ratio=0.2, Eval score=0.004950494971126318\n",
      "        Ratio=0.3, Eval score=0.039998188614845276\n",
      "        Ratio=0.4, Eval score=0.03382931277155876\n",
      "        Ratio=0.5, Eval score=0.2191283106803894\n",
      "        Ratio=0.6, Eval score=0.3226426839828491\n",
      "        Ratio=0.7, Eval score=0.4648386240005493\n",
      "        Ratio=0.8, Eval score=0.5534867644309998\n",
      "        Ratio=0.9, Eval score=0.5998728275299072\n",
      "\n",
      "**********************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(stats)\n",
    "logger.info(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056036ec-672f-4876-86af-2052cbc85495",
   "metadata": {},
   "source": [
    "### Torchinfo: model compressed summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36139480-e444-4ee6-98c0-0dcec0c25f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "SVD_BED_DETECTOR                         [1, 12, 7, 7]             --\n",
      "Sequential: 1-1                        [1, 12, 7, 7]             --\n",
      "    Sequential: 2-1                   [1, 32, 224, 224]         --\n",
      "        Conv2d: 3-1                  [1, 5, 224, 224]          45\n",
      "        Conv2d: 3-2                  [1, 32, 224, 224]         480\n",
      "    BatchNorm2d: 2-2                  [1, 32, 224, 224]         64\n",
      "    ReLU: 2-3                         [1, 32, 224, 224]         --\n",
      "    Dropout2d: 2-4                    [1, 32, 224, 224]         --\n",
      "    MaxPool2d: 2-5                    [1, 32, 112, 112]         --\n",
      "    Sequential: 2-6                   [1, 11, 112, 112]         --\n",
      "        Conv2d: 3-3                  [1, 4, 112, 112]          384\n",
      "        Conv2d: 3-4                  [1, 11, 112, 112]         132\n",
      "    BatchNorm2d: 2-7                  [1, 11, 112, 112]         22\n",
      "    ReLU: 2-8                         [1, 11, 112, 112]         --\n",
      "    Dropout2d: 2-9                    [1, 11, 112, 112]         --\n",
      "    MaxPool2d: 2-10                   [1, 11, 56, 56]           --\n",
      "    Sequential: 2-11                  [1, 14, 56, 56]           --\n",
      "        Conv2d: 3-5                  [1, 3, 56, 56]            33\n",
      "        Conv2d: 3-6                  [1, 14, 56, 56]           42\n",
      "    BatchNorm2d: 2-12                 [1, 14, 56, 56]           28\n",
      "    ReLU: 2-13                        [1, 14, 56, 56]           --\n",
      "    Sequential: 2-14                  [1, 25, 56, 56]           --\n",
      "        Conv2d: 3-7                  [1, 14, 56, 56]           588\n",
      "        Conv2d: 3-8                  [1, 25, 56, 56]           1,050\n",
      "    BatchNorm2d: 2-15                 [1, 25, 56, 56]           50\n",
      "    ReLU: 2-16                        [1, 25, 56, 56]           --\n",
      "    Conv2d: 2-17                      [1, 22, 56, 56]           550\n",
      "    BatchNorm2d: 2-18                 [1, 22, 56, 56]           44\n",
      "    ReLU: 2-19                        [1, 22, 56, 56]           --\n",
      "    Sequential: 2-20                  [1, 64, 56, 56]           --\n",
      "        Conv2d: 3-9                  [1, 30, 56, 56]           1,980\n",
      "        Conv2d: 3-10                 [1, 64, 56, 56]           5,760\n",
      "    BatchNorm2d: 2-21                 [1, 64, 56, 56]           128\n",
      "    ReLU: 2-22                        [1, 64, 56, 56]           --\n",
      "    MaxPool2d: 2-23                   [1, 64, 28, 28]           --\n",
      "    Conv2d: 2-24                      [1, 28, 28, 28]           1,792\n",
      "    BatchNorm2d: 2-25                 [1, 28, 28, 28]           56\n",
      "    ReLU: 2-26                        [1, 28, 28, 28]           --\n",
      "    Sequential: 2-27                  [1, 64, 28, 28]           --\n",
      "        Conv2d: 3-11                 [1, 38, 28, 28]           3,192\n",
      "        Conv2d: 3-12                 [1, 64, 28, 28]           7,296\n",
      "    BatchNorm2d: 2-28                 [1, 64, 28, 28]           128\n",
      "    ReLU: 2-29                        [1, 64, 28, 28]           --\n",
      "    Conv2d: 2-30                      [1, 28, 28, 28]           1,792\n",
      "    BatchNorm2d: 2-31                 [1, 28, 28, 28]           56\n",
      "    ReLU: 2-32                        [1, 28, 28, 28]           --\n",
      "    Sequential: 2-33                  [1, 57, 28, 28]           --\n",
      "        Conv2d: 3-13                 [1, 25, 28, 28]           2,100\n",
      "        Conv2d: 3-14                 [1, 57, 28, 28]           4,275\n",
      "    BatchNorm2d: 2-34                 [1, 57, 28, 28]           114\n",
      "    ReLU: 2-35                        [1, 57, 28, 28]           --\n",
      "    Sequential: 2-36                  [1, 28, 28, 28]           --\n",
      "        Conv2d: 3-15                 [1, 15, 28, 28]           855\n",
      "        Conv2d: 3-16                 [1, 28, 28, 28]           420\n",
      "    BatchNorm2d: 2-37                 [1, 28, 28, 28]           56\n",
      "    ReLU: 2-38                        [1, 28, 28, 28]           --\n",
      "    Sequential: 2-39                  [1, 57, 28, 28]           --\n",
      "        Conv2d: 3-17                 [1, 28, 28, 28]           2,352\n",
      "        Conv2d: 3-18                 [1, 57, 28, 28]           4,788\n",
      "    BatchNorm2d: 2-40                 [1, 57, 28, 28]           114\n",
      "    ReLU: 2-41                        [1, 57, 28, 28]           --\n",
      "    MaxPool2d: 2-42                   [1, 57, 14, 14]           --\n",
      "    Sequential: 2-43                  [1, 32, 14, 14]           --\n",
      "        Conv2d: 3-19                 [1, 14, 14, 14]           798\n",
      "        Conv2d: 3-20                 [1, 32, 14, 14]           448\n",
      "    BatchNorm2d: 2-44                 [1, 32, 14, 14]           64\n",
      "    ReLU: 2-45                        [1, 32, 14, 14]           --\n",
      "    Sequential: 2-46                  [1, 64, 14, 14]           --\n",
      "        Conv2d: 3-21                 [1, 40, 14, 14]           3,840\n",
      "        Conv2d: 3-22                 [1, 64, 14, 14]           7,680\n",
      "    BatchNorm2d: 2-47                 [1, 64, 14, 14]           128\n",
      "    ReLU: 2-48                        [1, 64, 14, 14]           --\n",
      "    Conv2d: 2-49                      [1, 32, 14, 14]           2,048\n",
      "    BatchNorm2d: 2-50                 [1, 32, 14, 14]           64\n",
      "    ReLU: 2-51                        [1, 32, 14, 14]           --\n",
      "    Sequential: 2-52                  [1, 64, 14, 14]           --\n",
      "        Conv2d: 3-23                 [1, 45, 14, 14]           4,320\n",
      "        Conv2d: 3-24                 [1, 64, 14, 14]           8,640\n",
      "    BatchNorm2d: 2-53                 [1, 64, 14, 14]           128\n",
      "    ReLU: 2-54                        [1, 64, 14, 14]           --\n",
      "    Sequential: 2-55                  [1, 64, 14, 14]           --\n",
      "        Conv2d: 3-25                 [1, 67, 14, 14]           12,864\n",
      "        Conv2d: 3-26                 [1, 64, 14, 14]           12,864\n",
      "    BatchNorm2d: 2-56                 [1, 64, 14, 14]           128\n",
      "    ReLU: 2-57                        [1, 64, 14, 14]           --\n",
      "    Sequential: 2-58                  [1, 64, 14, 14]           --\n",
      "        Conv2d: 3-27                 [1, 77, 14, 14]           14,784\n",
      "        Conv2d: 3-28                 [1, 64, 14, 14]           14,784\n",
      "    BatchNorm2d: 2-59                 [1, 64, 14, 14]           128\n",
      "    ReLU: 2-60                        [1, 64, 14, 14]           --\n",
      "    MaxPool2d: 2-61                   [1, 64, 7, 7]             --\n",
      "    Conv2d: 2-62                      [1, 64, 7, 7]             36,864\n",
      "    BatchNorm2d: 2-63                 [1, 64, 7, 7]             128\n",
      "    ReLU: 2-64                        [1, 64, 7, 7]             --\n",
      "    Conv2d: 2-65                      [1, 64, 7, 7]             36,864\n",
      "    BatchNorm2d: 2-66                 [1, 64, 7, 7]             128\n",
      "    ReLU: 2-67                        [1, 64, 7, 7]             --\n",
      "    Conv2d: 2-68                      [1, 64, 7, 7]             4,096\n",
      "    BatchNorm2d: 2-69                 [1, 64, 7, 7]             128\n",
      "    ReLU: 2-70                        [1, 64, 7, 7]             --\n",
      "    Conv2d: 2-71                      [1, 16, 7, 7]             1,024\n",
      "    BatchNorm2d: 2-72                 [1, 16, 7, 7]             32\n",
      "    ReLU: 2-73                        [1, 16, 7, 7]             --\n",
      "    Conv2d: 2-74                      [1, 16, 7, 7]             256\n",
      "    BatchNorm2d: 2-75                 [1, 16, 7, 7]             32\n",
      "    ReLU: 2-76                        [1, 16, 7, 7]             --\n",
      "    Conv2d: 2-77                      [1, 12, 7, 7]             204\n",
      "==========================================================================================\n",
      "Total params: 204,232\n",
      "Trainable params: 204,232\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 106.98\n",
      "==========================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 43.27\n",
      "Params size (MB): 0.82\n",
      "Estimated Total Size (MB): 44.69\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(comp_model, input_size=(1, 3, config.IMG_H, config.IMG_W)))\n",
    "logger.info(\"Compressed Model Summary\")\n",
    "logger.info(summary(comp_model, input_size=(1, 3, config.IMG_H, config.IMG_W)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f636c-be77-49d9-b29f-c347e3a94ebc",
   "metadata": {},
   "source": [
    "### Evaluate Compressed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "beff48c7-7a18-49c3-968c-ec71743df10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val mAP = 0.2888\n"
     ]
    }
   ],
   "source": [
    "comp_mAP = evaluate_model(comp_model, None, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bd2105-474f-439f-b84e-44f29f462b69",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a890a26-99e5-4b39-a766-1efc8842cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_ratios_file_path = './data/greedy_selection_comp_ratios_list.pkl'\n",
    "eval_scores_path = './data/greedy_selection_eval_scores_dict.pkl'\n",
    "\n",
    "unpickled_ratios = pd.read_pickle(comp_ratios_file_path)\n",
    "unpickled_scores = pd.read_pickle(eval_scores_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d644802-87ca-4321-aadd-c66c57bb8763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     model.conv1.1  model.conv2.0  model.conv2.1  model.conv31.0  \\\n",
      "0.1       0.257727       0.262289       0.266260        0.012131   \n",
      "0.2       0.259994       0.436184       0.268609        0.342664   \n",
      "0.3       0.260303       0.560970       0.266243        0.340688   \n",
      "0.4       0.608439       0.608733       0.595722        0.614254   \n",
      "0.5       0.601097       0.606773       0.615182        0.618928   \n",
      "0.6       0.617922       0.613751       0.611310        0.618132   \n",
      "0.7       0.618788       0.615676       0.620876        0.622012   \n",
      "0.8       0.617812       0.615529       0.620346        0.618489   \n",
      "0.9       0.617101       0.616634       0.622989        0.621017   \n",
      "\n",
      "     model.conv31.1  model.conv32.0  model.conv32.1  model.conv33  \\\n",
      "0.1        0.145364        0.137725        0.112070      0.198202   \n",
      "0.2        0.141169        0.601511        0.525943      0.389893   \n",
      "0.3        0.134961        0.602791        0.547771      0.516458   \n",
      "0.4        0.140416        0.618732        0.597830      0.569808   \n",
      "0.5        0.139218        0.566676        0.605337      0.611107   \n",
      "0.6        0.139072        0.620883        0.619882      0.619045   \n",
      "0.7        0.531376        0.545912        0.616278      0.617195   \n",
      "0.8        0.531686        0.510313        0.615252      0.622338   \n",
      "0.9        0.527866        0.621865        0.618502      0.624044   \n",
      "\n",
      "     model.conv34.0  model.conv34.1  ...  model.conv53  model.conv54.0  \\\n",
      "0.1        0.076139        0.503492  ...      0.000000        0.042588   \n",
      "0.2        0.404036        0.595009  ...      0.019339        0.109141   \n",
      "0.3        0.551031        0.605025  ...      0.235994        0.198393   \n",
      "0.4        0.583722        0.609462  ...      0.414455        0.430957   \n",
      "0.5        0.610097        0.613055  ...      0.511739        0.545500   \n",
      "0.6        0.617527        0.622032  ...      0.574933        0.564595   \n",
      "0.7        0.619426        0.619842  ...      0.583473        0.584207   \n",
      "0.8        0.618831        0.622536  ...      0.604311        0.587741   \n",
      "0.9        0.619353        0.622416  ...      0.613191        0.617641   \n",
      "\n",
      "     model.conv54.1  model.conv55.0  model.conv55.1  model.conv56.0  \\\n",
      "0.1        0.111057        0.004950        0.084736        0.006601   \n",
      "0.2        0.474308        0.043280        0.464206        0.044173   \n",
      "0.3        0.549317        0.228656        0.536290        0.282469   \n",
      "0.4        0.582130        0.452173        0.579978        0.357956   \n",
      "0.5        0.596802        0.504039        0.589230        0.487926   \n",
      "0.6        0.612475        0.556066        0.601054        0.494000   \n",
      "0.7        0.610868        0.579697        0.601033        0.556982   \n",
      "0.8        0.620328        0.596809        0.613621        0.590605   \n",
      "0.9        0.618770        0.611393        0.614364        0.600823   \n",
      "\n",
      "     model.conv56.1  model.conv61  model.conv62  model.conv71  \n",
      "0.1        0.196379      0.041475      0.002185      0.009727  \n",
      "0.2        0.486340      0.191117      0.129854      0.004950  \n",
      "0.3        0.563809      0.320186      0.166242      0.039998  \n",
      "0.4        0.568361      0.379261      0.297251      0.033829  \n",
      "0.5        0.594759      0.445325      0.400639      0.219128  \n",
      "0.6        0.599943      0.487256      0.438004      0.322643  \n",
      "0.7        0.608643      0.500011      0.435273      0.464839  \n",
      "0.8        0.611701      0.536019      0.459611      0.553487  \n",
      "0.9        0.618371      0.561478      0.527800      0.599873  \n",
      "\n",
      "[9 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "df_scores = pd.DataFrame(unpickled_scores)\n",
    "df_scores.to_csv(config.RUN_FOLDER + 'scores.csv')\n",
    "print(df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ac07fb2-85ac-467f-bc2d-dea822c28e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0     1\n",
      "0    model.conv1.1  None\n",
      "1    model.conv2.0  None\n",
      "2    model.conv2.1   0.7\n",
      "3   model.conv31.0   0.7\n",
      "4   model.conv31.1  None\n",
      "5   model.conv32.0   0.9\n",
      "6   model.conv32.1   0.9\n",
      "7     model.conv33   0.8\n",
      "8   model.conv34.0   0.7\n",
      "9   model.conv34.1   0.6\n",
      "10    model.conv41  None\n",
      "11  model.conv42.0   0.9\n",
      "12  model.conv42.1  None\n",
      "13    model.conv43  None\n",
      "14  model.conv44.0   0.9\n",
      "15  model.conv44.1   0.8\n",
      "16  model.conv45.0   0.9\n",
      "17  model.conv45.1   0.9\n",
      "18  model.conv46.0   0.9\n",
      "19  model.conv46.1   0.9\n",
      "20  model.conv51.0   0.9\n",
      "21  model.conv51.1  None\n",
      "22  model.conv52.0  None\n",
      "23  model.conv52.1   0.8\n",
      "24    model.conv53  None\n",
      "25  model.conv54.0  None\n",
      "26  model.conv54.1   0.8\n",
      "27  model.conv55.0  None\n",
      "28  model.conv55.1  None\n",
      "29  model.conv56.0  None\n",
      "30  model.conv56.1   0.9\n",
      "31    model.conv61  None\n",
      "32    model.conv62  None\n",
      "33    model.conv71  None\n"
     ]
    }
   ],
   "source": [
    "df_ratios = pd.DataFrame(unpickled_ratios)\n",
    "df_ratios.to_csv(config.RUN_FOLDER + 'ratios.csv')\n",
    "print(df_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c9b36d-9a54-4ce8-8521-41eb277035e8",
   "metadata": {},
   "source": [
    "# Save Compressed Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "602a9d51-aea0-485c-b7af-e0bc2641d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(comp_model, torch.randn(input_shape).to(config.DEVICE), config.RUN_FOLDER + 'comp_model_noTrain.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a9b4e-cc35-497e-ae3a-4973817e85b3",
   "metadata": {},
   "source": [
    "### Optimizer and Scheduler of Compressed Model to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27cd5bba-82a8-4ed5-b764-bcac6c1eb30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(comp_model.parameters(), \n",
    "                       lr=config.LEARNING_RATE, \n",
    "                       weight_decay=config.WEIGHT_DECAY)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                 mode='min',\n",
    "                                                 factor=config.FACTOR, \n",
    "                                                 patience=config.PATIENCE, \n",
    "                                                 threshold=config.THRES, \n",
    "                                                 threshold_mode='abs',\n",
    "                                                 min_lr=config.MIN_LR)\n",
    "\n",
    "utils.save_checkpoint(epoch=0, \n",
    "                      model=comp_model,\n",
    "                      optimizer=optimizer,\n",
    "                      scheduler=scheduler,\n",
    "                      checkpoint_name=config.WEIGHTS_FOLDER + 'comp_model_after_svd.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80898e59-ddee-4670-9054-d443556de710",
   "metadata": {},
   "source": [
    "# Loss and Metrics Loggers and Plotters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a61cff5-0ac7-49f0-9f10-726e07b60c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses_logger = utils.LogLosses()\n",
    "train_metrics_logger = utils.LogMetrics()\n",
    "lr_logger = utils.LogLR(log_path=config.PLOTS_FOLDER)\n",
    "\n",
    "val_losses_logger = utils.LogLosses()\n",
    "val_metrics_logger = utils.LogMetrics()\n",
    "\n",
    "loss_plotter = utils.PlotMetrics(log_path=config.PLOTS_FOLDER, model_name=config.MODEL, loss_or_metric='Loss')\n",
    "metrics_plotter = utils.PlotMetrics(log_path=config.PLOTS_FOLDER, model_name=config.MODEL, loss_or_metric='Metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ff6ca-4e1a-40a3-a173-1de75ba0ef11",
   "metadata": {},
   "source": [
    "# Train Loop Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da2d2348-c75c-4596-9d8f-e6da9144ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, start_epoch=0, epochs_to_train=config.EPOCHS):\n",
    "\n",
    "    ''' ==============================================================\n",
    "                                TRAINING LOOP\n",
    "    ============================================================== '''\n",
    "    start = datetime.datetime.now()\n",
    "    start_time = start.strftime(\"%H:%M:%S\")\n",
    "    print(f'\\n***Start Training: {start_time}\\n')\n",
    "    logger.info(f'\\n***Start Training: {start_time}\\n')\n",
    "    \n",
    "    # Start with infinite validation loss\n",
    "    best_valid_loss = np.inf\n",
    "    best_mAP = torch.tensor(0., dtype=torch.float32)\n",
    "\n",
    "    epochs_loss_plot = []\n",
    "    epochs_metric_plot = []\n",
    "\n",
    "    end_epoch = start_epoch + epochs_to_train\n",
    "        \n",
    "    for epoch in range(start_epoch, end_epoch):\n",
    "\n",
    "        print(f'\\n=== EPOCH {epoch}/{end_epoch-1} ===')\n",
    "        logger.info(f'\\n=== EPOCH {epoch}/{end_epoch-1} ===')\n",
    "        \n",
    "        #====================== TRAINING ========================#\n",
    "        current_lr = train_epoch.get_lr(optimizer=optimizer)\n",
    "        logger.info(f'Learning Rate = {current_lr}\\n')\n",
    "        lr_logger.log_lr(current_lr)\n",
    "            \n",
    "        calculate_mAP = False\n",
    "        if ( (epoch+1) % 5 ) == 0:\n",
    "            calculate_mAP = True\n",
    "            epochs_metric_plot.append(epoch)\n",
    "\n",
    "        train_losses, train_metrics = train_epoch.train_fn(\n",
    "            loader=train_loader, \n",
    "            model=model, \n",
    "            optimizer=optimizer, \n",
    "            loss_fn=loss_fn,\n",
    "            loss_l1_lambda=config.LAMBDA_L1_LOSS,\n",
    "            metric=metrics.map_metric,\n",
    "            device=config.DEVICE,\n",
    "            calculate_mAP=calculate_mAP)\n",
    "        \n",
    "        train_losses_logger.update_losses(train_losses)\n",
    "        if calculate_mAP == True:\n",
    "            train_metrics_logger.update_metrics(train_metrics)\n",
    "                \n",
    "        logger.info(utils.print_metrics_to_logger(\"TRAIN STATS\", train_losses, train_metrics, mAP_available=calculate_mAP))\n",
    "        \n",
    "        #===================== VALIDATING =======================#\n",
    "        with torch.no_grad():\n",
    "            val_losses, val_metrics = val_epoch.eval_fn(\n",
    "                loader=val_loader, \n",
    "                model=model,                         \n",
    "                loss_fn=loss_fn,\n",
    "                metric=metrics.map_metric,\n",
    "                device=config.DEVICE,\n",
    "                calculate_mAP=calculate_mAP)\n",
    "            \n",
    "            scheduler.step(val_losses['Total'])\n",
    "            \n",
    "            val_losses_logger.update_losses(val_losses)\n",
    "            if calculate_mAP == True:\n",
    "                val_metrics_logger.update_metrics(val_metrics)\n",
    "\n",
    "            logger.info(utils.print_metrics_to_logger(\"VAL STATS\", val_losses, val_metrics, mAP_available=calculate_mAP))\n",
    "            \n",
    "        epochs_loss_plot.append(epoch)\n",
    "\n",
    "        # loss_plotter.plot_all_metrics(\n",
    "        #     train_losses_logger.get_losses(),\n",
    "        #     val_losses_logger.get_losses(),\n",
    "        #     epochs_loss_plot)\n",
    "\n",
    "        # if calculate_mAP == True:\n",
    "        #     metrics_plotter.plot_all_metrics(\n",
    "        #         train_metrics_logger.get_metrics(),\n",
    "        #         val_metrics_logger.get_metrics(),\n",
    "        #         epochs_metric_plot)\n",
    "\n",
    "        # lr_logger.plot_lr(epochs_loss_plot)\n",
    "        \n",
    "        #======================= SAVING =========================#\n",
    "        if ( (epoch+1) % 5 ) == 0:\n",
    "            save_name = config.WEIGHTS_FOLDER + config.MODEL + '_detector__5epoch.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name) \n",
    "            \n",
    "        if best_valid_loss > val_losses['Total']:\n",
    "            best_valid_loss = val_losses['Total']\n",
    "            print(f\"\\nSaving model with new best validation loss: {best_valid_loss:.3f}\")\n",
    "            logger.info(f\"Saving model with new best validation loss: {best_valid_loss:.3f}\")\n",
    "            save_name = config.WEIGHTS_FOLDER + config.MODEL + '_detector__' + 'best_loss'  + '.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name)  \n",
    "\n",
    "        # Save model if mAP increases\n",
    "        if calculate_mAP == True:\n",
    "            if ( best_mAP < val_metrics['mAP'] ) :\n",
    "                best_mAP = val_metrics['mAP']\n",
    "                print(f\"\\nSaving model with new best mAP: {best_mAP:.4f}\")\n",
    "                logger.info(f\"Saving model with new best mAP: {best_mAP:.4f}\")\n",
    "                save_precision_name = f'best_mAP={best_mAP:.4f}__epoch={epoch}'\n",
    "                save_name = config.WEIGHTS_FOLDER + config.MODEL + '_detector__' + save_precision_name + '.pt'\n",
    "                utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name)  \n",
    "            # Break if model is good enough\n",
    "            if (best_mAP.item() > 0.65):\n",
    "                break\n",
    "        \n",
    "    logger.info('Saving last model')   \n",
    "    torch.save(model.state_dict(), config.WEIGHTS_FOLDER + 'last_' + config.MODEL + '_detector.pt') \n",
    "    \n",
    "    #======================= FINISH =========================#\n",
    "    end = datetime.datetime.now()\n",
    "    end_time = end.strftime(\"%H:%M:%S\")\n",
    "    print(f'\\n***Script finished: {end_time}\\n')  \n",
    "    print(f'Time elapsed: {end-start}')\n",
    "    logger.info(f'\\n***Script finished: {end_time}\\n')  \n",
    "    logger.info(f'Time elapsed: {end-start}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405eb53c-8e16-4b14-a818-fe53e68c1637",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc5957bb-da57-4e84-ae3d-a83545e04704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting script\n",
      "\n",
      "\n",
      "***Start Training: 02:41:02\n",
      "\n",
      "\n",
      "=== EPOCH 0/39 ===\n",
      "Learning Rate = 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|                                                                                   | 374/1710 [00:51<02:56,  7.56it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  32%|                                                                         | 539/1710 [01:13<02:27,  7.93it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  41%|                                                              | 707/1710 [01:36<01:49,  9.15it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  43%|                                                             | 727/1710 [01:38<01:50,  8.92it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  54%|                                                 | 920/1710 [02:05<01:53,  6.98it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:54<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "71.389      |25.382      |33.412      |6.872       |5.723       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:31<00:00, 11.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "61.756      |23.293      |24.663      |8.953       |4.847       \n",
      "\n",
      "Saving model with new best validation loss: 61.756\n",
      "\n",
      "=== EPOCH 1/39 ===\n",
      "Learning Rate = 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|                                                                                                         | 41/1710 [00:06<02:57,  9.38it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  63%|                                       | 1078/1710 [02:25<01:10,  8.92it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  73%|                            | 1248/1710 [02:48<00:49,  9.31it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 32.23\n",
      "Training:  98%|  | 1670/1710 [03:44<00:03, 10.31it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:49<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "59.613      |20.471      |28.156      |7.446       |3.541       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:31<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "57.990      |21.356      |24.766      |7.540       |4.329       \n",
      "\n",
      "Saving model with new best validation loss: 57.990\n",
      "\n",
      "=== EPOCH 2/39 ===\n",
      "Learning Rate = 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|                                                                       | 573/1710 [01:18<01:40, 11.26it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  37%|                                                                   | 627/1710 [01:26<01:41, 10.70it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  75%|                          | 1281/1710 [02:55<01:10,  6.06it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  80%|                    | 1374/1710 [03:07<00:29, 11.21it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  98%|  | 1675/1710 [03:48<00:03,  9.15it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:52<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "57.237      |19.640      |26.954      |7.440       |3.203       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:31<00:00, 11.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "56.006      |20.696      |23.062      |8.417       |3.831       \n",
      "\n",
      "Saving model with new best validation loss: 56.006\n",
      "\n",
      "=== EPOCH 3/39 ===\n",
      "Learning Rate = 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|                                                           | 761/1710 [01:44<01:53,  8.35it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  47%|                                                        | 810/1710 [01:51<01:28, 10.16it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  48%|                                                       | 818/1710 [01:52<01:22, 10.79it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  53%|                                                  | 911/1710 [02:04<01:21,  9.84it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  97%|   | 1651/1710 [03:42<00:06,  9.19it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training: 100%|| 1710/1710 [03:50<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "55.745      |18.930      |26.311      |7.427       |3.077       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:31<00:00, 11.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "55.441      |20.473      |23.757      |6.957       |4.254       \n",
      "\n",
      "Saving model with new best validation loss: 55.441\n",
      "\n",
      "=== EPOCH 4/39 ===\n",
      "Learning Rate = 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|                                                                                      | 324/1710 [00:46<02:59,  7.72it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  52%|                                                   | 881/1710 [02:03<01:45,  7.85it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  78%|                       | 1337/1710 [03:06<00:47,  7.93it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  83%|                  | 1412/1710 [03:16<00:38,  7.65it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  94%|      | 1610/1710 [03:43<00:12,  8.14it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:56<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "54.639      |18.426      |25.813      |7.415       |2.986       \n",
      "Train mAP = 0.4809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:34<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "53.961      |19.722      |22.956      |7.267       |4.016       \n",
      "Val mAP = 0.5570\n",
      "\n",
      "Saving model with new best validation loss: 53.961\n",
      "\n",
      "Saving model with new best mAP: 0.5570\n",
      "\n",
      "=== EPOCH 5/39 ===\n",
      "Learning Rate = 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  63%|                                       | 1070/1710 [02:24<01:07,  9.51it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  80%|                     | 1371/1710 [03:04<00:35,  9.58it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  87%|             | 1491/1710 [03:20<00:21, 10.37it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  94%|      | 1606/1710 [03:35<00:11,  8.87it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  98%|  | 1671/1710 [03:44<00:05,  7.52it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:49<00:00,  7.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "54.249      |18.345      |25.592      |7.411       |2.900       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "53.284      |19.701      |22.177      |7.424       |3.983       \n",
      "\n",
      "Saving model with new best validation loss: 53.284\n",
      "\n",
      "=== EPOCH 6/39 ===\n",
      "Learning Rate = 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|                                                                                   | 377/1710 [00:51<03:21,  6.60it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  39%|                                                                 | 668/1710 [01:30<01:58,  8.81it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  45%|                                                           | 765/1710 [01:43<01:51,  8.47it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  50%|                                                     | 861/1710 [01:55<01:21, 10.46it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  92%|        | 1579/1710 [03:31<00:13,  9.75it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:48<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "53.733      |18.131      |25.346      |7.391       |2.864       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "53.270      |19.465      |23.413      |6.269       |4.122       \n",
      "\n",
      "Saving model with new best validation loss: 53.270\n",
      "\n",
      "=== EPOCH 7/39 ===\n",
      "Learning Rate = 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|                                                                                                | 170/1710 [00:24<02:32, 10.10it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  29%|                                                                           | 499/1710 [01:08<01:52, 10.78it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  36%|                                                                    | 619/1710 [01:25<01:34, 11.57it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  58%|                                            | 995/1710 [02:14<01:06, 10.76it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  89%|           | 1524/1710 [03:25<00:34,  5.38it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:51<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "53.479      |17.966      |25.209      |7.415       |2.890       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "52.971      |19.379      |22.119      |7.529       |3.945       \n",
      "\n",
      "Saving model with new best validation loss: 52.971\n",
      "\n",
      "=== EPOCH 8/39 ===\n",
      "Learning Rate = 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|                                                                                         | 275/1710 [00:38<02:42,  8.86it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  21%|                                                                                    | 362/1710 [00:50<02:39,  8.46it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  57%|                                              | 973/1710 [02:11<01:09, 10.53it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  67%|                                   | 1143/1710 [02:34<01:11,  7.95it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  86%|              | 1474/1710 [03:18<00:25,  9.13it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:49<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "53.024      |17.753      |25.084      |7.416       |2.772       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "55.009      |20.061      |23.723      |6.581       |4.645       \n",
      "\n",
      "=== EPOCH 9/39 ===\n",
      "Learning Rate = 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|                                                                                                         | 45/1710 [00:07<03:23,  8.19it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  27%|                                                                              | 461/1710 [01:04<03:13,  6.46it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  54%|                                                 | 926/1710 [02:08<01:28,  8.89it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  74%|                           | 1261/1710 [02:52<00:42, 10.55it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  93%|       | 1586/1710 [03:35<00:11, 10.89it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:52<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "52.651      |17.652      |24.891      |7.350       |2.758       \n",
      "Train mAP = 0.4999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:33<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "53.222      |19.644      |21.878      |7.657       |4.044       \n",
      "Val mAP = 0.5861\n",
      "\n",
      "Saving model with new best mAP: 0.5861\n",
      "\n",
      "=== EPOCH 10/39 ===\n",
      "Learning Rate = 0.0004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|                                                                              | 450/1710 [01:02<02:41,  7.79it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  44%|                                                           | 757/1710 [01:42<01:38,  9.67it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  57%|                                              | 967/1710 [02:11<01:09, 10.66it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  64%|                                      | 1095/1710 [02:28<00:57, 10.64it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  91%|         | 1564/1710 [03:31<00:16,  8.78it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:51<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "51.829      |17.309      |24.523      |7.363       |2.634       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "52.964      |19.584      |22.232      |7.149       |4.000       \n",
      "\n",
      "Saving model with new best validation loss: 52.964\n",
      "\n",
      "=== EPOCH 11/39 ===\n",
      "Learning Rate = 0.0004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|                                                                                           | 247/1710 [00:34<02:07, 11.44it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  49%|                                                      | 836/1710 [01:53<02:37,  5.56it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  55%|                                                | 942/1710 [02:07<01:49,  7.02it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  66%|                                    | 1123/1710 [02:30<01:06,  8.83it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  71%|                               | 1208/1710 [02:42<01:15,  6.61it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:47<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "51.401      |17.160      |24.278      |7.369       |2.593       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "52.347      |19.048      |21.517      |7.622       |4.159       \n",
      "\n",
      "Saving model with new best validation loss: 52.347\n",
      "\n",
      "=== EPOCH 12/39 ===\n",
      "Learning Rate = 0.0004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|                                                                                            | 232/1710 [00:32<02:56,  8.38it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  26%|                                                                               | 446/1710 [01:01<01:59, 10.61it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  69%|                                | 1188/1710 [02:40<00:54,  9.55it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  72%|                              | 1227/1710 [02:46<01:02,  7.69it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  95%|     | 1625/1710 [03:38<00:09,  8.78it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:49<00:00,  7.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "51.077      |16.998      |24.187      |7.319       |2.573       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "53.045      |19.012      |21.954      |8.231       |3.847       \n",
      "\n",
      "=== EPOCH 13/39 ===\n",
      "Learning Rate = 0.0004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|                                                                                  | 388/1710 [00:53<02:43,  8.08it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  36%|                                                                    | 613/1710 [01:23<01:38, 11.16it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  42%|                                                             | 724/1710 [01:38<01:36, 10.21it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  66%|                                   | 1134/1710 [02:33<01:00,  9.47it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  92%|        | 1569/1710 [03:34<00:23,  6.08it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:53<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "50.963      |16.928      |24.126      |7.314       |2.596       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "52.047      |19.057      |21.899      |7.172       |3.919       \n",
      "\n",
      "Saving model with new best validation loss: 52.047\n",
      "\n",
      "=== EPOCH 14/39 ===\n",
      "Learning Rate = 0.0004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|                                                                                                      | 92/1710 [00:13<03:33,  7.57it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  33%|                                                                       | 567/1710 [01:18<02:19,  8.19it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  39%|                                                                 | 660/1710 [01:31<02:14,  7.80it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  58%|                                             | 989/1710 [02:15<01:30,  7.99it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  93%|       | 1589/1710 [03:37<00:16,  7.56it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:53<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "50.840      |16.973      |24.029      |7.312       |2.527       \n",
      "Train mAP = 0.5180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:33<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "52.305      |18.961      |21.462      |8.139       |3.744       \n",
      "Val mAP = 0.5846\n",
      "\n",
      "=== EPOCH 15/39 ===\n",
      "Learning Rate = 0.0004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|                                                                                        | 297/1710 [00:41<02:38,  8.91it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  73%|                             | 1241/1710 [02:47<00:44, 10.46it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  75%|                          | 1281/1710 [02:52<00:41, 10.38it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  81%|                    | 1383/1710 [03:05<00:33,  9.82it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  86%|              | 1472/1710 [03:17<00:23, 10.11it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training: 100%|| 1710/1710 [03:49<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "50.609      |16.848      |23.877      |7.349       |2.535       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "52.066      |18.933      |21.019      |7.994       |4.120       \n",
      "\n",
      "=== EPOCH 16/39 ===\n",
      "Learning Rate = 0.00032\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|                                                                                                   | 115/1710 [00:17<04:41,  5.66it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  29%|                                                                            | 496/1710 [01:07<02:00, 10.08it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  33%|                                                                        | 560/1710 [01:16<02:08,  8.94it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  66%|                                    | 1125/1710 [02:32<01:04,  9.04it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  67%|                                   | 1146/1710 [02:34<01:21,  6.95it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:50<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.994      |16.634      |23.662      |7.256       |2.443       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "50.925      |18.586      |21.773      |6.596       |3.970       \n",
      "\n",
      "Saving model with new best validation loss: 50.925\n",
      "\n",
      "=== EPOCH 17/39 ===\n",
      "Learning Rate = 0.00032\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|                                                                                              | 208/1710 [00:29<02:10, 11.47it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  31%|                                                                          | 527/1710 [01:12<01:58,  9.99it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  38%|                                                                  | 648/1710 [01:27<01:43, 10.24it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  66%|                                    | 1128/1710 [02:31<00:55, 10.43it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  80%|                     | 1362/1710 [03:02<00:41,  8.49it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:49<00:00,  7.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.470      |16.350      |23.475      |7.263       |2.382       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "51.375      |18.535      |21.313      |7.440       |4.086       \n",
      "\n",
      "=== EPOCH 18/39 ===\n",
      "Learning Rate = 0.00032\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|                                                                                                       | 74/1710 [00:11<02:46,  9.82it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  20%|                                                                                     | 348/1710 [00:48<02:30,  9.06it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  27%|                                                                              | 457/1710 [01:03<02:34,  8.10it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  39%|                                                                 | 671/1710 [01:32<02:10,  7.97it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  40%|                                                                | 679/1710 [01:33<01:36, 10.71it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:51<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.489      |16.428      |23.436      |7.217       |2.408       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "51.346      |18.698      |21.498      |6.959       |4.191       \n",
      "\n",
      "=== EPOCH 19/39 ===\n",
      "Learning Rate = 0.00025600000000000004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|                                                                                                          | 26/1710 [00:04<03:43,  7.53it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  31%|                                                                         | 532/1710 [01:14<02:00,  9.80it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  60%|                                          | 1027/1710 [02:22<01:35,  7.19it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  75%|                          | 1280/1710 [02:56<00:49,  8.61it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  76%|                         | 1294/1710 [02:58<01:07,  6.15it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training: 100%|| 1710/1710 [03:55<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "48.659      |15.988      |23.144      |7.209       |2.317       \n",
      "Train mAP = 0.5386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:33<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "50.607      |18.293      |21.974      |6.205       |4.134       \n",
      "Val mAP = 0.6039\n",
      "\n",
      "Saving model with new best validation loss: 50.607\n",
      "\n",
      "Saving model with new best mAP: 0.6039\n",
      "\n",
      "=== EPOCH 20/39 ===\n",
      "Learning Rate = 0.00025600000000000004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|                                                                                                        | 50/1710 [00:08<02:59,  9.23it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  13%|                                                                                             | 223/1710 [00:31<03:49,  6.47it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  18%|                                                                                        | 301/1710 [00:42<02:54,  8.08it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  27%|                                                                             | 469/1710 [01:04<01:38, 12.55it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  36%|                                                                    | 613/1710 [01:23<01:45, 10.39it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training: 100%|| 1710/1710 [03:51<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "48.828      |16.126      |23.120      |7.233       |2.349       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "50.542      |18.580      |21.171      |6.758       |4.033       \n",
      "\n",
      "Saving model with new best validation loss: 50.542\n",
      "\n",
      "=== EPOCH 21/39 ===\n",
      "Learning Rate = 0.00025600000000000004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|                                                                                                       | 72/1710 [00:11<02:31, 10.82it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  17%|                                                                                        | 293/1710 [00:41<02:15, 10.47it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  63%|                                       | 1070/1710 [02:24<01:02, 10.17it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  74%|                            | 1257/1710 [02:49<01:00,  7.49it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  92%|        | 1571/1710 [03:31<00:14,  9.71it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:51<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "48.351      |15.869      |23.057      |7.198       |2.228       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "50.307      |18.224      |21.504      |6.651       |3.928       \n",
      "\n",
      "Saving model with new best validation loss: 50.307\n",
      "\n",
      "=== EPOCH 22/39 ===\n",
      "Learning Rate = 0.00025600000000000004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|                                                                                             | 211/1710 [00:29<02:32,  9.84it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  56%|                                               | 950/1710 [02:10<02:15,  5.60it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  71%|                              | 1221/1710 [02:45<00:48, 10.00it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  93%|       | 1586/1710 [03:33<00:12, 10.14it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  93%|       | 1594/1710 [03:34<00:10, 11.09it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training: 100%|| 1710/1710 [03:50<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "48.364      |15.995      |22.973      |7.157       |2.239       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "51.101      |18.867      |21.101      |7.065       |4.069       \n",
      "\n",
      "=== EPOCH 23/39 ===\n",
      "Learning Rate = 0.00025600000000000004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|                                                                                                     | 97/1710 [00:14<04:08,  6.48it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  25%|                                                                                | 421/1710 [00:57<01:59, 10.79it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  59%|                                           | 1017/1710 [02:18<02:23,  4.84it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  73%|                             | 1240/1710 [02:48<00:43, 10.92it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  98%|  | 1676/1710 [03:45<00:03,  9.41it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:50<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "48.392      |15.958      |22.948      |7.214       |2.271       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "50.780      |18.702      |21.584      |6.654       |3.839       \n",
      "\n",
      "=== EPOCH 24/39 ===\n",
      "Learning Rate = 0.00020480000000000004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                            | 5/1710 [00:02<10:27,  2.72it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:   9%|                                                                                                 | 147/1710 [00:22<03:13,  8.07it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  11%|                                                                                               | 191/1710 [00:27<03:12,  7.89it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  40%|                                                                | 686/1710 [01:35<02:37,  6.52it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  71%|                               | 1210/1710 [02:46<01:32,  5.39it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:53<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "47.888      |15.747      |22.759      |7.162       |2.220       \n",
      "Train mAP = 0.5454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:33<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.677      |18.043      |20.946      |6.843       |3.845       \n",
      "Val mAP = 0.6059\n",
      "\n",
      "Saving model with new best validation loss: 49.677\n",
      "\n",
      "Saving model with new best mAP: 0.6059\n",
      "\n",
      "=== EPOCH 25/39 ===\n",
      "Learning Rate = 0.00020480000000000004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|                                                                                                   | 128/1710 [00:18<02:32, 10.40it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  10%|                                                                                                | 172/1710 [00:25<02:53,  8.88it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  50%|                                                     | 856/1710 [01:58<02:09,  6.57it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  78%|                       | 1329/1710 [03:02<00:33, 11.27it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  99%| | 1690/1710 [03:51<00:02,  8.33it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:54<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "47.864      |15.772      |22.780      |7.115       |2.196       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.830      |18.111      |21.503      |6.224       |3.991       \n",
      "\n",
      "=== EPOCH 26/39 ===\n",
      "Learning Rate = 0.00020480000000000004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|                                                                                              | 194/1710 [00:28<04:30,  5.61it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  22%|                                                                                   | 376/1710 [00:51<01:48, 12.28it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  27%|                                                                              | 456/1710 [01:02<02:33,  8.17it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  57%|                                              | 973/1710 [02:11<01:07, 10.85it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  90%|          | 1547/1710 [03:28<00:20,  7.99it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:50<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "47.505      |15.512      |22.672      |7.128       |2.194       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "50.311      |18.195      |21.473      |6.524       |4.119       \n",
      "\n",
      "=== EPOCH 27/39 ===\n",
      "Learning Rate = 0.00016384000000000006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                            | 7/1710 [00:02<06:11,  4.58it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:   5%|                                                                                                      | 92/1710 [00:13<03:45,  7.18it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  10%|                                                                                                | 175/1710 [00:24<04:05,  6.25it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  60%|                                          | 1021/1710 [02:18<01:10,  9.79it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  86%|               | 1465/1710 [03:17<00:24,  9.89it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:51<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "47.075      |15.387      |22.481      |7.142       |2.066       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "50.053      |17.914      |21.545      |6.446       |4.148       \n",
      "\n",
      "=== EPOCH 28/39 ===\n",
      "Learning Rate = 0.00016384000000000006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|                                                                                              | 205/1710 [00:27<02:21, 10.64it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  20%|                                                                                      | 336/1710 [00:45<01:49, 12.55it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  74%|                           | 1265/1710 [02:52<00:44,  9.93it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  82%|                   | 1403/1710 [03:10<00:38,  7.89it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  93%|       | 1598/1710 [03:36<00:11,  9.52it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:51<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "47.059      |15.363      |22.451      |7.096       |2.150       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.874      |17.749      |21.247      |6.705       |4.173       \n",
      "\n",
      "=== EPOCH 29/39 ===\n",
      "Learning Rate = 0.00013107200000000006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|                                                                                        | 292/1710 [00:42<02:23,  9.88it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  20%|                                                                                     | 344/1710 [00:48<02:14, 10.14it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  24%|                                                                                 | 405/1710 [00:56<02:20,  9.30it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  45%|                                                          | 772/1710 [01:46<01:54,  8.18it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  60%|                                          | 1031/1710 [02:21<01:30,  7.49it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:54<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "46.670      |15.178      |22.286      |7.120       |2.086       \n",
      "Train mAP = 0.5603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:33<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.816      |18.000      |21.125      |6.571       |4.120       \n",
      "Val mAP = 0.6172\n",
      "\n",
      "Saving model with new best mAP: 0.6172\n",
      "\n",
      "=== EPOCH 30/39 ===\n",
      "Learning Rate = 0.00013107200000000006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|                                                                                            | 232/1710 [00:33<02:44,  8.99it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  40%|                                                                | 687/1710 [01:34<01:38, 10.39it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  40%|                                                               | 691/1710 [01:35<02:38,  6.42it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  50%|                                                     | 854/1710 [01:57<01:54,  7.51it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  62%|                                       | 1067/1710 [02:25<01:09,  9.30it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:51<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "46.569      |15.192      |22.242      |7.070       |2.065       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.610      |17.729      |20.908      |6.886       |4.086       \n",
      "\n",
      "Saving model with new best validation loss: 49.610\n",
      "\n",
      "=== EPOCH 31/39 ===\n",
      "Learning Rate = 0.00013107200000000006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|                                                      | 846/1710 [01:56<01:32,  9.34it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  70%|                               | 1197/1710 [02:43<00:54,  9.34it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  75%|                          | 1290/1710 [02:56<00:41, 10.16it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  86%|              | 1476/1710 [03:20<00:24,  9.45it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  91%|         | 1562/1710 [03:32<00:13, 10.85it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:52<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "46.565      |15.236      |22.164      |7.052       |2.114       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.205      |17.752      |20.438      |7.173       |3.841       \n",
      "\n",
      "Saving model with new best validation loss: 49.205\n",
      "\n",
      "=== EPOCH 32/39 ===\n",
      "Learning Rate = 0.00013107200000000006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|                                                                                           | 251/1710 [00:36<02:19, 10.48it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  34%|                                                                      | 583/1710 [01:20<02:23,  7.87it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  48%|                                                       | 821/1710 [01:51<01:55,  7.73it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  48%|                                                       | 829/1710 [01:53<01:56,  7.59it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  78%|                       | 1329/1710 [02:59<00:38,  9.85it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:51<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "46.512      |15.198      |22.184      |7.019       |2.112       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.201      |17.766      |20.812      |6.639       |3.984       \n",
      "\n",
      "Saving model with new best validation loss: 49.201\n",
      "\n",
      "=== EPOCH 33/39 ===\n",
      "Learning Rate = 0.00013107200000000006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|                                                                               | 437/1710 [01:01<03:20,  6.36it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  46%|                                                          | 779/1710 [01:46<01:39,  9.36it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  48%|                                                       | 820/1710 [01:52<01:12, 12.29it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  52%|                                                   | 885/1710 [02:00<01:26,  9.57it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  66%|                                   | 1134/1710 [02:34<00:50, 11.41it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:51<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "46.512      |15.209      |22.193      |7.057       |2.053       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.729      |17.878      |21.042      |6.589       |4.219       \n",
      "\n",
      "=== EPOCH 34/39 ===\n",
      "Learning Rate = 0.00010485760000000006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|                                                                    | 624/1710 [01:26<02:41,  6.71it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  43%|                                                             | 729/1710 [01:41<02:32,  6.43it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  78%|                       | 1335/1710 [03:03<00:55,  6.79it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  83%|                  | 1412/1710 [03:14<00:31,  9.42it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  95%|    | 1633/1710 [03:44<00:08,  8.86it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training: 100%|| 1710/1710 [03:55<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "46.240      |15.031      |22.150      |7.034       |2.025       \n",
      "Train mAP = 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:33<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.443      |17.683      |20.857      |6.820       |4.083       \n",
      "Val mAP = 0.6220\n",
      "\n",
      "Saving model with new best mAP: 0.6220\n",
      "\n",
      "=== EPOCH 35/39 ===\n",
      "Learning Rate = 0.00010485760000000006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|                                                                               | 434/1710 [01:00<02:26,  8.72it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  26%|                                                                               | 444/1710 [01:01<02:14,  9.40it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  27%|                                                                              | 460/1710 [01:03<01:53, 11.00it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  62%|                                        | 1059/1710 [02:25<01:07,  9.60it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  79%|                      | 1355/1710 [03:05<00:38,  9.16it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:52<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "45.898      |14.908      |21.963      |7.001       |2.026       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.399      |17.717      |20.557      |6.949       |4.177       \n",
      "\n",
      "=== EPOCH 36/39 ===\n",
      "Learning Rate = 8.388608000000005e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|                                                                                                 | 152/1710 [00:21<02:33, 10.15it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  68%|                                 | 1166/1710 [02:38<01:06,  8.23it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  69%|                                | 1180/1710 [02:40<00:57,  9.22it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  90%|           | 1531/1710 [03:28<00:29,  6.01it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  97%|   | 1660/1710 [03:45<00:04, 10.14it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:52<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "45.737      |14.843      |21.850      |6.995       |2.049       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.907      |17.915      |20.715      |6.918       |4.359       \n",
      "\n",
      "=== EPOCH 37/39 ===\n",
      "Learning Rate = 8.388608000000005e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|                                                                                              | 199/1710 [00:28<02:23, 10.56it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  31%|                                                                          | 527/1710 [01:13<03:17,  5.98it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  50%|                                                     | 854/1710 [01:57<01:43,  8.28it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  54%|                                                 | 928/1710 [02:07<02:26,  5.34it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  97%|   | 1653/1710 [03:42<00:06,  8.15it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:50<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "45.793      |14.866      |21.922      |6.986       |2.018       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.695      |17.800      |20.898      |6.729       |4.269       \n",
      "\n",
      "=== EPOCH 38/39 ===\n",
      "Learning Rate = 6.710886400000004e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|                                                                                                        | 61/1710 [00:09<02:34, 10.70it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  12%|                                                                                              | 207/1710 [00:28<02:18, 10.82it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  53%|                                                  | 901/1710 [02:02<01:25,  9.50it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  74%|                           | 1261/1710 [02:50<00:46,  9.61it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  79%|                      | 1354/1710 [03:02<00:37,  9.53it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:50<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "45.803      |14.854      |21.949      |6.975       |2.025       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.217      |17.645      |20.756      |6.727       |4.089       \n",
      "\n",
      "=== EPOCH 39/39 ===\n",
      "Learning Rate = 6.710886400000004e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|                                                                               | 435/1710 [01:01<02:44,  7.76it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  29%|                                                                            | 490/1710 [01:08<02:20,  8.66it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  64%|                                     | 1100/1710 [02:33<01:25,  7.14it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  68%|                                 | 1164/1710 [02:41<01:05,  8.28it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  73%|                            | 1247/1710 [02:53<01:21,  5.68it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training: 100%|| 1710/1710 [03:56<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "45.780      |14.845      |21.951      |6.974       |2.010       \n",
      "Train mAP = 0.5685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:33<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.183      |17.665      |20.581      |6.831       |4.106       \n",
      "Val mAP = 0.6264\n",
      "\n",
      "Saving model with new best validation loss: 49.183\n",
      "\n",
      "Saving model with new best mAP: 0.6264\n",
      "\n",
      "***Script finished: 05:42:03\n",
      "\n",
      "Time elapsed: 3:01:01.751338\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting script\\n\")\n",
    "logger.info(\"Starting script\\n\")\n",
    "    \n",
    "pruned_model = train_loop(comp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc7d86a-27a6-43ac-89c6-718321bfdd43",
   "metadata": {},
   "source": [
    "# Check Comp Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "079d0c48-20bc-425d-8a16-073bc33de6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable parameters = 204232\n",
      "Total parameters = 204232\n"
     ]
    }
   ],
   "source": [
    "# MODEL PARAMETERS\n",
    "n_trainable = sum(p.numel() for p in comp_model.parameters() if p.requires_grad)\n",
    "print(f'\\nTrainable parameters = {n_trainable}')\n",
    "logger.info(f'\\nTrainable parameters = {n_trainable}')\n",
    "\n",
    "n_params = sum(p.numel() for p in comp_model.parameters())\n",
    "print(f'Total parameters = {n_params}')\n",
    "logger.info(f'Total parameters = {n_params}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c74753ba-1664-4fcf-a3c8-ccc38c0f8612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val mAP = 0.6264\n"
     ]
    }
   ],
   "source": [
    "comp_model_mAP = evaluate_model(comp_model, None, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063616a4-0b56-44a1-bc64-d5cd3960e1ec",
   "metadata": {},
   "source": [
    "# Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8486f8b-283d-41a0-95d1-2ef0fbd4fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(comp_model, torch.randn(input_shape).to(config.DEVICE), config.RUN_FOLDER + 'comp_model_Train.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70959e4d-76a8-475f-8f12-24dd26b0e77e",
   "metadata": {},
   "source": [
    "# Train More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b18ed1f1-99da-46d0-ae6d-8466680b3cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Start Training: 05:53:55\n",
      "\n",
      "\n",
      "=== EPOCH 40/54 ===\n",
      "Learning Rate = 6.710886400000004e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|                                                                                              | 200/1710 [00:28<02:49,  8.90it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  29%|                                                                           | 498/1710 [01:08<01:54, 10.60it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  38%|                                                                  | 652/1710 [01:29<02:41,  6.55it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  73%|                            | 1254/1710 [02:49<00:46,  9.78it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  92%|        | 1570/1710 [03:33<00:17,  7.90it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training: 100%|| 1710/1710 [03:52<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "45.488      |14.748      |21.778      |6.966       |1.997       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.206      |17.594      |20.634      |6.852       |4.126       \n",
      "\n",
      "Saving model with new best validation loss: 49.206\n",
      "\n",
      "=== EPOCH 41/54 ===\n",
      "Learning Rate = 5.3687091200000036e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                            | 8/1710 [00:02<04:33,  6.21it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  15%|                                                                                           | 254/1710 [00:36<02:07, 11.41it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  39%|                                                                 | 662/1710 [01:30<01:39, 10.59it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  59%|                                           | 1007/1710 [02:17<01:03, 11.06it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  61%|                                         | 1041/1710 [02:21<01:39,  6.76it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:51<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "45.231      |14.634      |21.736      |6.913       |1.947       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.108      |17.482      |20.578      |6.907       |4.141       \n",
      "\n",
      "Saving model with new best validation loss: 49.108\n",
      "\n",
      "=== EPOCH 42/54 ===\n",
      "Learning Rate = 5.3687091200000036e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|                                                                                                   | 127/1710 [00:18<02:17, 11.55it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:   8%|                                                                                                  | 143/1710 [00:20<03:20,  7.82it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  14%|                                                                                           | 247/1710 [00:34<02:33,  9.51it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  16%|                                                                                          | 273/1710 [00:38<02:40,  8.97it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  92%|        | 1573/1710 [03:33<00:16,  8.25it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:52<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "45.331      |14.660      |21.764      |6.931       |1.977       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "48.749      |17.411      |20.660      |6.567       |4.111       \n",
      "\n",
      "Saving model with new best validation loss: 48.749\n",
      "\n",
      "=== EPOCH 43/54 ===\n",
      "Learning Rate = 5.3687091200000036e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|                                                                                                         | 47/1710 [00:08<03:04,  8.99it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  21%|                                                                                    | 362/1710 [00:50<02:28,  9.05it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  23%|                                                                                  | 394/1710 [00:55<02:01, 10.87it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  45%|                                                          | 775/1710 [01:45<01:43,  9.02it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  75%|                          | 1281/1710 [02:54<00:57,  7.40it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:52<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "45.181      |14.598      |21.687      |6.917       |1.979       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "48.843      |17.478      |20.742      |6.509       |4.113       \n",
      "\n",
      "=== EPOCH 44/54 ===\n",
      "Learning Rate = 5.3687091200000036e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|                                                                                          | 266/1710 [00:37<03:44,  6.44it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  68%|                                  | 1163/1710 [02:41<01:38,  5.57it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  87%|              | 1483/1710 [03:25<00:28,  7.92it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  91%|          | 1550/1710 [03:34<00:18,  8.86it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  97%|  | 1664/1710 [03:50<00:07,  6.31it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training: 100%|| 1710/1710 [03:56<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "45.099      |14.555      |21.650      |6.966       |1.928       \n",
      "Train mAP = 0.5689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:33<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "48.893      |17.449      |20.452      |6.826       |4.165       \n",
      "Val mAP = 0.6266\n",
      "\n",
      "Saving model with new best mAP: 0.6266\n",
      "\n",
      "=== EPOCH 45/54 ===\n",
      "Learning Rate = 4.2949672960000034e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|                                                                                                   | 122/1710 [00:18<02:47,  9.47it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  40%|                                                                | 685/1710 [01:34<02:20,  7.28it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  54%|                                                 | 928/1710 [02:07<01:19,  9.89it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  72%|                             | 1230/1710 [02:48<00:45, 10.64it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  82%|                   | 1398/1710 [03:11<00:38,  8.11it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training: 100%|| 1710/1710 [03:53<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "45.276      |14.640      |21.725      |6.970       |1.940       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "48.823      |17.454      |20.470      |6.751       |4.149       \n",
      "\n",
      "=== EPOCH 46/54 ===\n",
      "Learning Rate = 4.2949672960000034e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                     | 0/1710 [00:00<?, ?it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  14%|                                                                                            | 233/1710 [00:33<02:54,  8.44it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  15%|                                                                                           | 254/1710 [00:36<03:31,  6.90it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  20%|                                                                                     | 338/1710 [00:47<02:02, 11.16it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  24%|                                                                                 | 417/1710 [00:58<02:19,  9.24it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:55<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "44.880      |14.388      |21.629      |6.935       |1.928       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.049      |17.608      |20.526      |6.788       |4.127       \n",
      "\n",
      "=== EPOCH 47/54 ===\n",
      "Learning Rate = 3.435973836800003e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|                                                                                           | 250/1710 [00:35<02:44,  8.87it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  34%|                                                                      | 580/1710 [01:20<02:21,  7.99it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  49%|                                                      | 846/1710 [01:56<01:29,  9.63it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  62%|                                        | 1061/1710 [02:25<01:22,  7.89it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  63%|                                      | 1083/1710 [02:27<01:01, 10.21it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:53<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "44.966      |14.581      |21.540      |6.916       |1.929       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.034      |17.566      |20.719      |6.530       |4.219       \n",
      "\n",
      "=== EPOCH 48/54 ===\n",
      "Learning Rate = 3.435973836800003e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|                                                                                                           | 17/1710 [00:03<04:50,  5.82it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  51%|                                                    | 871/1710 [01:58<01:14, 11.26it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  77%|                        | 1315/1710 [02:58<00:56,  6.93it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  79%|                      | 1349/1710 [03:03<00:44,  8.14it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  94%|      | 1603/1710 [03:37<00:19,  5.41it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:52<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "45.137      |14.677      |21.615      |6.915       |1.930       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "48.911      |17.516      |20.817      |6.451       |4.126       \n",
      "\n",
      "=== EPOCH 49/54 ===\n",
      "Learning Rate = 2.7487790694400027e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|                                                                                       | 311/1710 [00:44<02:58,  7.84it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  21%|                                                                                    | 366/1710 [00:52<02:34,  8.67it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  28%|                                                                             | 479/1710 [01:08<02:14,  9.15it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  34%|                                                                      | 582/1710 [01:22<02:38,  7.11it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  92%|        | 1579/1710 [03:38<00:15,  8.38it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:56<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "44.751      |14.434      |21.546      |6.896       |1.875       \n",
      "Train mAP = 0.5747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:33<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "49.034      |17.520      |20.788      |6.624       |4.103       \n",
      "Val mAP = 0.6246\n",
      "\n",
      "=== EPOCH 50/54 ===\n",
      "Learning Rate = 2.7487790694400027e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|                                                                                                       | 73/1710 [00:11<03:35,  7.61it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:   5%|                                                                                                      | 85/1710 [00:13<04:44,  5.71it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  27%|                                                                              | 455/1710 [01:04<02:07,  9.85it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  48%|                                                        | 816/1710 [01:52<01:13, 12.15it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  86%|              | 1474/1710 [03:20<00:50,  4.69it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:52<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "44.976      |14.489      |21.659      |6.932       |1.897       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "48.743      |17.437      |20.898      |6.390       |4.018       \n",
      "\n",
      "Saving model with new best validation loss: 48.743\n",
      "\n",
      "=== EPOCH 51/54 ===\n",
      "Learning Rate = 2.1990232555520022e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|                                                                             | 477/1710 [01:05<02:05,  9.84it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  67%|                                   | 1140/1710 [02:35<01:03,  8.95it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  83%|                 | 1424/1710 [03:12<00:45,  6.27it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  89%|           | 1527/1710 [03:26<00:23,  7.70it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  98%|  | 1671/1710 [03:46<00:03, 10.52it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:51<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "44.812      |14.509      |21.552      |6.864       |1.887       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "48.725      |17.383      |20.519      |6.716       |4.106       \n",
      "\n",
      "Saving model with new best validation loss: 48.725\n",
      "\n",
      "=== EPOCH 52/54 ===\n",
      "Learning Rate = 2.1990232555520022e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|                                                                        | 552/1710 [01:17<02:25,  7.95it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  37%|                                                                   | 639/1710 [01:28<02:02,  8.75it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  45%|                                                          | 772/1710 [01:47<01:33, 10.05it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  76%|                         | 1293/1710 [02:57<01:03,  6.55it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  83%|                 | 1425/1710 [03:15<00:27, 10.20it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:54<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "44.800      |14.453      |21.532      |6.897       |1.918       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "48.962      |17.553      |20.694      |6.585       |4.131       \n",
      "\n",
      "=== EPOCH 53/54 ===\n",
      "Learning Rate = 2.1990232555520022e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|                                                                            | 497/1710 [01:09<03:07,  6.46it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  29%|                                                                           | 501/1710 [01:09<02:15,  8.95it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  46%|                                                          | 784/1710 [01:47<01:40,  9.25it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  50%|                                                     | 858/1710 [01:57<01:53,  7.49it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  88%|             | 1498/1710 [03:24<00:20, 10.38it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:53<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "44.790      |14.503      |21.521      |6.873       |1.892       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:32<00:00, 11.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "48.759      |17.487      |20.520      |6.648       |4.105       \n",
      "\n",
      "=== EPOCH 54/54 ===\n",
      "Learning Rate = 1.7592186044416018e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                             | 1/1710 [00:01<52:55,  1.86s/it]Warning: unknown JFIF revision number 32.23\n",
      "Training:  10%|                                                                                                | 175/1710 [00:25<03:16,  7.83it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  30%|                                                                           | 513/1710 [01:12<02:56,  6.79it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  56%|                                               | 950/1710 [02:12<01:40,  7.53it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training:  72%|                             | 1234/1710 [02:50<01:20,  5.88it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "Training: 100%|| 1710/1710 [03:54<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "44.624      |14.311      |21.494      |6.908       |1.911       \n",
      "Train mAP = 0.5747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|| 361/361 [00:33<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  \n",
      "------------ ------------ ------------ ------------ ------------\n",
      "48.774      |17.432      |20.510      |6.750       |4.082       \n",
      "Val mAP = 0.6268\n",
      "\n",
      "Saving model with new best mAP: 0.6268\n",
      "\n",
      "***Script finished: 07:02:11\n",
      "\n",
      "Time elapsed: 1:08:16.263945\n"
     ]
    }
   ],
   "source": [
    "pruned_model = train_loop(\n",
    "    comp_model,\n",
    "    start_epoch=40,\n",
    "    epochs_to_train=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0828c228-8050-442e-8c98-cf03a88380dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
