BED Detector.
	No Sigmoid, No Softmax. Permute as a Layer.
	DFire and FASDD UAV and CV.
	FASDD: train and val datasets to train and test dataset to validate.
	FASDD RS not included, as it only has smoke and it is too different to current pictures.
	Brevitas Quantization.


Datasets Length
	Train: Full
	Val: Full

Load Model: True
	Model: ./experiments/test_35_pruning_090_after_svd_080_simple_model_more_train/weights/BED_detector__best_mAP=0.6289__epoch=14.pt

Device: cuda
Optimizer:
	Learning Rate: 0.0005
	Gradients Clip Norm: 500
	Weight Decay: 0.0005
Scheduler:
	Scheduler factor: 0.8
	Scheduler patience: 3
	Scheduler threshold: 0.01
	Scheduler min learning rate: 1e-06

Batch Size: 64
Num Workers: 8
Pin Memory: True
Epochs: 150

IMG DIMS:
	Width: 224
	Height: 224

Grid, Bounding Boxes, Classes and Thresholds:
	Grid: 7
	Number of Bounding Boxes per Cell: 2
	Number of Classes: 2
	Maximum Number of Objects per Image: 10
	IOU Threshold: 0.5
	Score Threshold: 0.2

Brevitas Config:
	Fixed Point: True
	Weights Bit Width: 4
	Bias Bit Width: 4
	Activations Bit Width: 8

Loss Function: YOLOV1_LOSS
Lambda for L1 regularization: 0

Using BED Detector

Trainable parameters = 204232
Total parameters = 204232
Loading Model. Trained during 14 epochs

Input shape is torch.Size([4, 3, 224, 224])
Model shape is torch.Size([4, 12, 7, 7])

BED Model Arquitecture
PRUNED_AFTER_SVD_BED_DETECTOR(
  (model): Sequential(
    (conv1): Sequential(
      (0): Conv2d(3, 5, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (1): Conv2d(5, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    )
    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu1): ReLU()
    (dropout1): Dropout2d(p=0.3, inplace=False)
    (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv2): Sequential(
      (0): Conv2d(32, 4, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (1): Conv2d(4, 11, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    )
    (bn2): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu2): ReLU()
    (dropout2): Dropout2d(p=0.3, inplace=False)
    (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv31): Sequential(
      (0): Conv2d(11, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(3, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (bn31): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu31): ReLU()
    (conv32): Sequential(
      (0): Conv2d(14, 14, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (1): Conv2d(14, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    )
    (bn32): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu32): ReLU()
    (conv33): Conv2d(25, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn33): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu33): ReLU()
    (conv34): Sequential(
      (0): Conv2d(22, 30, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (1): Conv2d(30, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    )
    (bn34): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu34): ReLU()
    (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv41): Conv2d(64, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn41): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu41): ReLU()
    (conv42): Sequential(
      (0): Conv2d(28, 38, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (1): Conv2d(38, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    )
    (bn42): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu42): ReLU()
    (conv43): Conv2d(64, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn43): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu43): ReLU()
    (conv44): Sequential(
      (0): Conv2d(28, 25, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (1): Conv2d(25, 57, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    )
    (bn44): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu44): ReLU()
    (conv45): Sequential(
      (0): Conv2d(57, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(15, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (bn45): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu45): ReLU()
    (conv46): Sequential(
      (0): Conv2d(28, 28, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (1): Conv2d(28, 57, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    )
    (bn46): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu46): ReLU()
    (maxpool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv51): Sequential(
      (0): Conv2d(57, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(14, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (bn51): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu51): ReLU()
    (conv52): Sequential(
      (0): Conv2d(32, 40, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (1): Conv2d(40, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    )
    (bn52): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu52): ReLU()
    (conv53): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn53): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu53): ReLU()
    (conv54): Sequential(
      (0): Conv2d(32, 45, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (1): Conv2d(45, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    )
    (bn54): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu54): ReLU()
    (conv55): Sequential(
      (0): Conv2d(64, 67, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (1): Conv2d(67, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    )
    (bn55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu55): ReLU()
    (conv56): Sequential(
      (0): Conv2d(64, 77, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
      (1): Conv2d(77, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    )
    (bn56): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu56): ReLU()
    (maxpool6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv61): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu61): ReLU()
    (conv62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn62): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu62): ReLU()
    (conv71): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn71): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu71): ReLU()
    (conv72): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn72): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu72): ReLU()
    (conv73): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu73): ReLU()
    (conv74): Conv2d(16, 12, kernel_size=(1, 1), stride=(1, 1))
  )
)

ORIGINAL Model Summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
PRUNED_AFTER_SVD_BED_DETECTOR            [1, 12, 7, 7]             --
├─Sequential: 1-1                        [1, 12, 7, 7]             --
│    └─Sequential: 2-1                   [1, 32, 224, 224]         --
│    │    └─Conv2d: 3-1                  [1, 5, 224, 224]          45
│    │    └─Conv2d: 3-2                  [1, 32, 224, 224]         480
│    └─BatchNorm2d: 2-2                  [1, 32, 224, 224]         64
│    └─ReLU: 2-3                         [1, 32, 224, 224]         --
│    └─Dropout2d: 2-4                    [1, 32, 224, 224]         --
│    └─MaxPool2d: 2-5                    [1, 32, 112, 112]         --
│    └─Sequential: 2-6                   [1, 11, 112, 112]         --
│    │    └─Conv2d: 3-3                  [1, 4, 112, 112]          384
│    │    └─Conv2d: 3-4                  [1, 11, 112, 112]         132
│    └─BatchNorm2d: 2-7                  [1, 11, 112, 112]         22
│    └─ReLU: 2-8                         [1, 11, 112, 112]         --
│    └─Dropout2d: 2-9                    [1, 11, 112, 112]         --
│    └─MaxPool2d: 2-10                   [1, 11, 56, 56]           --
│    └─Sequential: 2-11                  [1, 14, 56, 56]           --
│    │    └─Conv2d: 3-5                  [1, 3, 56, 56]            33
│    │    └─Conv2d: 3-6                  [1, 14, 56, 56]           42
│    └─BatchNorm2d: 2-12                 [1, 14, 56, 56]           28
│    └─ReLU: 2-13                        [1, 14, 56, 56]           --
│    └─Sequential: 2-14                  [1, 25, 56, 56]           --
│    │    └─Conv2d: 3-7                  [1, 14, 56, 56]           588
│    │    └─Conv2d: 3-8                  [1, 25, 56, 56]           1,050
│    └─BatchNorm2d: 2-15                 [1, 25, 56, 56]           50
│    └─ReLU: 2-16                        [1, 25, 56, 56]           --
│    └─Conv2d: 2-17                      [1, 22, 56, 56]           550
│    └─BatchNorm2d: 2-18                 [1, 22, 56, 56]           44
│    └─ReLU: 2-19                        [1, 22, 56, 56]           --
│    └─Sequential: 2-20                  [1, 64, 56, 56]           --
│    │    └─Conv2d: 3-9                  [1, 30, 56, 56]           1,980
│    │    └─Conv2d: 3-10                 [1, 64, 56, 56]           5,760
│    └─BatchNorm2d: 2-21                 [1, 64, 56, 56]           128
│    └─ReLU: 2-22                        [1, 64, 56, 56]           --
│    └─MaxPool2d: 2-23                   [1, 64, 28, 28]           --
│    └─Conv2d: 2-24                      [1, 28, 28, 28]           1,792
│    └─BatchNorm2d: 2-25                 [1, 28, 28, 28]           56
│    └─ReLU: 2-26                        [1, 28, 28, 28]           --
│    └─Sequential: 2-27                  [1, 64, 28, 28]           --
│    │    └─Conv2d: 3-11                 [1, 38, 28, 28]           3,192
│    │    └─Conv2d: 3-12                 [1, 64, 28, 28]           7,296
│    └─BatchNorm2d: 2-28                 [1, 64, 28, 28]           128
│    └─ReLU: 2-29                        [1, 64, 28, 28]           --
│    └─Conv2d: 2-30                      [1, 28, 28, 28]           1,792
│    └─BatchNorm2d: 2-31                 [1, 28, 28, 28]           56
│    └─ReLU: 2-32                        [1, 28, 28, 28]           --
│    └─Sequential: 2-33                  [1, 57, 28, 28]           --
│    │    └─Conv2d: 3-13                 [1, 25, 28, 28]           2,100
│    │    └─Conv2d: 3-14                 [1, 57, 28, 28]           4,275
│    └─BatchNorm2d: 2-34                 [1, 57, 28, 28]           114
│    └─ReLU: 2-35                        [1, 57, 28, 28]           --
│    └─Sequential: 2-36                  [1, 28, 28, 28]           --
│    │    └─Conv2d: 3-15                 [1, 15, 28, 28]           855
│    │    └─Conv2d: 3-16                 [1, 28, 28, 28]           420
│    └─BatchNorm2d: 2-37                 [1, 28, 28, 28]           56
│    └─ReLU: 2-38                        [1, 28, 28, 28]           --
│    └─Sequential: 2-39                  [1, 57, 28, 28]           --
│    │    └─Conv2d: 3-17                 [1, 28, 28, 28]           2,352
│    │    └─Conv2d: 3-18                 [1, 57, 28, 28]           4,788
│    └─BatchNorm2d: 2-40                 [1, 57, 28, 28]           114
│    └─ReLU: 2-41                        [1, 57, 28, 28]           --
│    └─MaxPool2d: 2-42                   [1, 57, 14, 14]           --
│    └─Sequential: 2-43                  [1, 32, 14, 14]           --
│    │    └─Conv2d: 3-19                 [1, 14, 14, 14]           798
│    │    └─Conv2d: 3-20                 [1, 32, 14, 14]           448
│    └─BatchNorm2d: 2-44                 [1, 32, 14, 14]           64
│    └─ReLU: 2-45                        [1, 32, 14, 14]           --
│    └─Sequential: 2-46                  [1, 64, 14, 14]           --
│    │    └─Conv2d: 3-21                 [1, 40, 14, 14]           3,840
│    │    └─Conv2d: 3-22                 [1, 64, 14, 14]           7,680
│    └─BatchNorm2d: 2-47                 [1, 64, 14, 14]           128
│    └─ReLU: 2-48                        [1, 64, 14, 14]           --
│    └─Conv2d: 2-49                      [1, 32, 14, 14]           2,048
│    └─BatchNorm2d: 2-50                 [1, 32, 14, 14]           64
│    └─ReLU: 2-51                        [1, 32, 14, 14]           --
│    └─Sequential: 2-52                  [1, 64, 14, 14]           --
│    │    └─Conv2d: 3-23                 [1, 45, 14, 14]           4,320
│    │    └─Conv2d: 3-24                 [1, 64, 14, 14]           8,640
│    └─BatchNorm2d: 2-53                 [1, 64, 14, 14]           128
│    └─ReLU: 2-54                        [1, 64, 14, 14]           --
│    └─Sequential: 2-55                  [1, 64, 14, 14]           --
│    │    └─Conv2d: 3-25                 [1, 67, 14, 14]           12,864
│    │    └─Conv2d: 3-26                 [1, 64, 14, 14]           12,864
│    └─BatchNorm2d: 2-56                 [1, 64, 14, 14]           128
│    └─ReLU: 2-57                        [1, 64, 14, 14]           --
│    └─Sequential: 2-58                  [1, 64, 14, 14]           --
│    │    └─Conv2d: 3-27                 [1, 77, 14, 14]           14,784
│    │    └─Conv2d: 3-28                 [1, 64, 14, 14]           14,784
│    └─BatchNorm2d: 2-59                 [1, 64, 14, 14]           128
│    └─ReLU: 2-60                        [1, 64, 14, 14]           --
│    └─MaxPool2d: 2-61                   [1, 64, 7, 7]             --
│    └─Conv2d: 2-62                      [1, 64, 7, 7]             36,864
│    └─BatchNorm2d: 2-63                 [1, 64, 7, 7]             128
│    └─ReLU: 2-64                        [1, 64, 7, 7]             --
│    └─Conv2d: 2-65                      [1, 64, 7, 7]             36,864
│    └─BatchNorm2d: 2-66                 [1, 64, 7, 7]             128
│    └─ReLU: 2-67                        [1, 64, 7, 7]             --
│    └─Conv2d: 2-68                      [1, 64, 7, 7]             4,096
│    └─BatchNorm2d: 2-69                 [1, 64, 7, 7]             128
│    └─ReLU: 2-70                        [1, 64, 7, 7]             --
│    └─Conv2d: 2-71                      [1, 16, 7, 7]             1,024
│    └─BatchNorm2d: 2-72                 [1, 16, 7, 7]             32
│    └─ReLU: 2-73                        [1, 16, 7, 7]             --
│    └─Conv2d: 2-74                      [1, 16, 7, 7]             256
│    └─BatchNorm2d: 2-75                 [1, 16, 7, 7]             32
│    └─ReLU: 2-76                        [1, 16, 7, 7]             --
│    └─Conv2d: 2-77                      [1, 12, 7, 7]             204
==========================================================================================
Total params: 204,232
Trainable params: 204,232
Non-trainable params: 0
Total mult-adds (M): 106.98
==========================================================================================
Input size (MB): 0.60
Forward/backward pass size (MB): 43.27
Params size (MB): 0.82
Estimated Total Size (MB): 44.69
==========================================================================================

*********************** Baseline mAP evaluation of Fused and Original Models ***********************

Non Fused Model mAP metrics:
{'mAP': tensor(0.6288), 'AP': [0.6371049284934998, 0.6205283999443054], 'AR': [0.703927218914032, 0.6705684065818787]}

Fused Model mAP metrics:
{'mAP': tensor(0.6288), 'AP': [0.6370742321014404, 0.6204316020011902], 'AR': [0.7038422226905823, 0.6704747676849365]}

FUSED Model Summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
PRUNED_AFTER_SVD_BED_DETECTOR            [1, 12, 7, 7]             --
├─Sequential: 1-1                        [1, 12, 7, 7]             --
│    └─Sequential: 2-1                   [1, 32, 224, 224]         --
│    │    └─Conv2d: 3-1                  [1, 5, 224, 224]          45
│    │    └─Conv2d: 3-2                  [1, 32, 224, 224]         512
│    └─Identity: 2-2                     [1, 32, 224, 224]         --
│    └─ReLU: 2-3                         [1, 32, 224, 224]         --
│    └─Dropout2d: 2-4                    [1, 32, 224, 224]         --
│    └─MaxPool2d: 2-5                    [1, 32, 112, 112]         --
│    └─Sequential: 2-6                   [1, 11, 112, 112]         --
│    │    └─Conv2d: 3-3                  [1, 4, 112, 112]          384
│    │    └─Conv2d: 3-4                  [1, 11, 112, 112]         143
│    └─Identity: 2-7                     [1, 11, 112, 112]         --
│    └─ReLU: 2-8                         [1, 11, 112, 112]         --
│    └─Dropout2d: 2-9                    [1, 11, 112, 112]         --
│    └─MaxPool2d: 2-10                   [1, 11, 56, 56]           --
│    └─Sequential: 2-11                  [1, 14, 56, 56]           --
│    │    └─Conv2d: 3-5                  [1, 3, 56, 56]            33
│    │    └─Conv2d: 3-6                  [1, 14, 56, 56]           56
│    └─Identity: 2-12                    [1, 14, 56, 56]           --
│    └─ReLU: 2-13                        [1, 14, 56, 56]           --
│    └─Sequential: 2-14                  [1, 25, 56, 56]           --
│    │    └─Conv2d: 3-7                  [1, 14, 56, 56]           588
│    │    └─Conv2d: 3-8                  [1, 25, 56, 56]           1,075
│    └─Identity: 2-15                    [1, 25, 56, 56]           --
│    └─ReLU: 2-16                        [1, 25, 56, 56]           --
│    └─Conv2d: 2-17                      [1, 22, 56, 56]           572
│    └─Identity: 2-18                    [1, 22, 56, 56]           --
│    └─ReLU: 2-19                        [1, 22, 56, 56]           --
│    └─Sequential: 2-20                  [1, 64, 56, 56]           --
│    │    └─Conv2d: 3-9                  [1, 30, 56, 56]           1,980
│    │    └─Conv2d: 3-10                 [1, 64, 56, 56]           5,824
│    └─Identity: 2-21                    [1, 64, 56, 56]           --
│    └─ReLU: 2-22                        [1, 64, 56, 56]           --
│    └─MaxPool2d: 2-23                   [1, 64, 28, 28]           --
│    └─Conv2d: 2-24                      [1, 28, 28, 28]           1,820
│    └─Identity: 2-25                    [1, 28, 28, 28]           --
│    └─ReLU: 2-26                        [1, 28, 28, 28]           --
│    └─Sequential: 2-27                  [1, 64, 28, 28]           --
│    │    └─Conv2d: 3-11                 [1, 38, 28, 28]           3,192
│    │    └─Conv2d: 3-12                 [1, 64, 28, 28]           7,360
│    └─Identity: 2-28                    [1, 64, 28, 28]           --
│    └─ReLU: 2-29                        [1, 64, 28, 28]           --
│    └─Conv2d: 2-30                      [1, 28, 28, 28]           1,820
│    └─Identity: 2-31                    [1, 28, 28, 28]           --
│    └─ReLU: 2-32                        [1, 28, 28, 28]           --
│    └─Sequential: 2-33                  [1, 57, 28, 28]           --
│    │    └─Conv2d: 3-13                 [1, 25, 28, 28]           2,100
│    │    └─Conv2d: 3-14                 [1, 57, 28, 28]           4,332
│    └─Identity: 2-34                    [1, 57, 28, 28]           --
│    └─ReLU: 2-35                        [1, 57, 28, 28]           --
│    └─Sequential: 2-36                  [1, 28, 28, 28]           --
│    │    └─Conv2d: 3-15                 [1, 15, 28, 28]           855
│    │    └─Conv2d: 3-16                 [1, 28, 28, 28]           448
│    └─Identity: 2-37                    [1, 28, 28, 28]           --
│    └─ReLU: 2-38                        [1, 28, 28, 28]           --
│    └─Sequential: 2-39                  [1, 57, 28, 28]           --
│    │    └─Conv2d: 3-17                 [1, 28, 28, 28]           2,352
│    │    └─Conv2d: 3-18                 [1, 57, 28, 28]           4,845
│    └─Identity: 2-40                    [1, 57, 28, 28]           --
│    └─ReLU: 2-41                        [1, 57, 28, 28]           --
│    └─MaxPool2d: 2-42                   [1, 57, 14, 14]           --
│    └─Sequential: 2-43                  [1, 32, 14, 14]           --
│    │    └─Conv2d: 3-19                 [1, 14, 14, 14]           798
│    │    └─Conv2d: 3-20                 [1, 32, 14, 14]           480
│    └─Identity: 2-44                    [1, 32, 14, 14]           --
│    └─ReLU: 2-45                        [1, 32, 14, 14]           --
│    └─Sequential: 2-46                  [1, 64, 14, 14]           --
│    │    └─Conv2d: 3-21                 [1, 40, 14, 14]           3,840
│    │    └─Conv2d: 3-22                 [1, 64, 14, 14]           7,744
│    └─Identity: 2-47                    [1, 64, 14, 14]           --
│    └─ReLU: 2-48                        [1, 64, 14, 14]           --
│    └─Conv2d: 2-49                      [1, 32, 14, 14]           2,080
│    └─Identity: 2-50                    [1, 32, 14, 14]           --
│    └─ReLU: 2-51                        [1, 32, 14, 14]           --
│    └─Sequential: 2-52                  [1, 64, 14, 14]           --
│    │    └─Conv2d: 3-23                 [1, 45, 14, 14]           4,320
│    │    └─Conv2d: 3-24                 [1, 64, 14, 14]           8,704
│    └─Identity: 2-53                    [1, 64, 14, 14]           --
│    └─ReLU: 2-54                        [1, 64, 14, 14]           --
│    └─Sequential: 2-55                  [1, 64, 14, 14]           --
│    │    └─Conv2d: 3-25                 [1, 67, 14, 14]           12,864
│    │    └─Conv2d: 3-26                 [1, 64, 14, 14]           12,928
│    └─Identity: 2-56                    [1, 64, 14, 14]           --
│    └─ReLU: 2-57                        [1, 64, 14, 14]           --
│    └─Sequential: 2-58                  [1, 64, 14, 14]           --
│    │    └─Conv2d: 3-27                 [1, 77, 14, 14]           14,784
│    │    └─Conv2d: 3-28                 [1, 64, 14, 14]           14,848
│    └─Identity: 2-59                    [1, 64, 14, 14]           --
│    └─ReLU: 2-60                        [1, 64, 14, 14]           --
│    └─MaxPool2d: 2-61                   [1, 64, 7, 7]             --
│    └─Conv2d: 2-62                      [1, 64, 7, 7]             36,928
│    └─Identity: 2-63                    [1, 64, 7, 7]             --
│    └─ReLU: 2-64                        [1, 64, 7, 7]             --
│    └─Conv2d: 2-65                      [1, 64, 7, 7]             36,928
│    └─Identity: 2-66                    [1, 64, 7, 7]             --
│    └─ReLU: 2-67                        [1, 64, 7, 7]             --
│    └─Conv2d: 2-68                      [1, 64, 7, 7]             4,160
│    └─Identity: 2-69                    [1, 64, 7, 7]             --
│    └─ReLU: 2-70                        [1, 64, 7, 7]             --
│    └─Conv2d: 2-71                      [1, 16, 7, 7]             1,040
│    └─Identity: 2-72                    [1, 16, 7, 7]             --
│    └─ReLU: 2-73                        [1, 16, 7, 7]             --
│    └─Conv2d: 2-74                      [1, 16, 7, 7]             272
│    └─Identity: 2-75                    [1, 16, 7, 7]             --
│    └─ReLU: 2-76                        [1, 16, 7, 7]             --
│    └─Conv2d: 2-77                      [1, 12, 7, 7]             204
==========================================================================================
Total params: 203,258
Trainable params: 202,284
Non-trainable params: 974
Total mult-adds (M): 109.39
==========================================================================================
Input size (MB): 0.60
Forward/backward pass size (MB): 23.96
Params size (MB): 0.81
Estimated Total Size (MB): 25.37
==========================================================================================

Using Brevitas BED Detector

Trainable parameters = 204672
Total parameters = 204672

Brevitas QUANT Model Summary
==================================================================================================================================
Layer (type:depth-idx)                                                           Output Shape              Param #
==================================================================================================================================
FIXED_POINT_QUANT_PRUNED_AFTER_SVD_BED_DETECTOR                                  [1, 12, 7, 7]             --
├─Sequential: 1-1                                                                [1, 12, 7, 7]             --
│    └─QuantIdentity: 2-1                                                        [1, 3, 224, 224]          --
│    │    └─ActQuantProxyFromInjector: 3-1                                       [1, 3, 224, 224]          --
│    │    └─ActQuantProxyFromInjector: 3-2                                       [1, 3, 224, 224]          --
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantIdentity: 2-3                                                        --                        --
│    │    └─ActQuantProxyFromInjector: 3-4                                       --                        --
│    └─Sequential: 2-4                                                           [1, 32, 224, 224]         --
│    │    └─QuantConv2d: 3-5                                                     [1, 5, 224, 224]          50
│    │    └─QuantConv2d: 3-6                                                     [1, 32, 224, 224]         544
│    └─QuantReLU: 2-5                                                            [1, 32, 224, 224]         --
│    │    └─ActQuantProxyFromInjector: 3-7                                       [1, 32, 224, 224]         --
│    │    └─ActQuantProxyFromInjector: 3-8                                       [1, 32, 224, 224]         1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-7                                                            --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-10                                      --                        (recursive)
│    └─Dropout2d: 2-8                                                            [1, 32, 224, 224]         --
│    └─QuantMaxPool2d: 2-9                                                       [1, 32, 112, 112]         --
│    └─Sequential: 2-10                                                          [1, 11, 112, 112]         --
│    │    └─QuantConv2d: 3-11                                                    [1, 4, 112, 112]          388
│    │    └─QuantConv2d: 3-12                                                    [1, 11, 112, 112]         154
│    └─QuantReLU: 2-11                                                           [1, 11, 112, 112]         --
│    │    └─ActQuantProxyFromInjector: 3-13                                      [1, 11, 112, 112]         --
│    │    └─ActQuantProxyFromInjector: 3-14                                      [1, 11, 112, 112]         1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-13                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-16                                      --                        (recursive)
│    └─Dropout2d: 2-14                                                           [1, 11, 112, 112]         --
│    └─QuantMaxPool2d: 2-15                                                      [1, 11, 56, 56]           --
│    └─Sequential: 2-16                                                          [1, 14, 56, 56]           --
│    │    └─QuantConv2d: 3-17                                                    [1, 3, 56, 56]            36
│    │    └─QuantConv2d: 3-18                                                    [1, 14, 56, 56]           70
│    └─QuantReLU: 2-17                                                           [1, 14, 56, 56]           --
│    │    └─ActQuantProxyFromInjector: 3-19                                      [1, 14, 56, 56]           --
│    │    └─ActQuantProxyFromInjector: 3-20                                      [1, 14, 56, 56]           1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-19                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-22                                      --                        (recursive)
│    └─Sequential: 2-20                                                          [1, 25, 56, 56]           --
│    │    └─QuantConv2d: 3-23                                                    [1, 14, 56, 56]           602
│    │    └─QuantConv2d: 3-24                                                    [1, 25, 56, 56]           1,100
│    └─QuantReLU: 2-21                                                           [1, 25, 56, 56]           --
│    │    └─ActQuantProxyFromInjector: 3-25                                      [1, 25, 56, 56]           --
│    │    └─ActQuantProxyFromInjector: 3-26                                      [1, 25, 56, 56]           1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-23                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-28                                      --                        (recursive)
│    └─QuantConv2d: 2-24                                                         [1, 22, 56, 56]           --
│    │    └─ActQuantProxyFromInjector: 3-29                                      [1, 25, 56, 56]           --
│    │    └─WeightQuantProxyFromInjector: 3-30                                   [22, 25, 1, 1]            572
│    │    └─BiasQuantProxyFromInjector: 3-31                                     [22]                      22
│    │    └─ActQuantProxyFromInjector: 3-32                                      [1, 22, 56, 56]           --
│    └─QuantReLU: 2-25                                                           [1, 22, 56, 56]           --
│    │    └─ActQuantProxyFromInjector: 3-33                                      [1, 22, 56, 56]           --
│    │    └─ActQuantProxyFromInjector: 3-34                                      [1, 22, 56, 56]           1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-27                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-36                                      --                        (recursive)
│    └─Sequential: 2-28                                                          [1, 64, 56, 56]           --
│    │    └─QuantConv2d: 3-37                                                    [1, 30, 56, 56]           2,010
│    │    └─QuantConv2d: 3-38                                                    [1, 64, 56, 56]           5,888
│    └─QuantReLU: 2-29                                                           [1, 64, 56, 56]           --
│    │    └─ActQuantProxyFromInjector: 3-39                                      [1, 64, 56, 56]           --
│    │    └─ActQuantProxyFromInjector: 3-40                                      [1, 64, 56, 56]           1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-31                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-42                                      --                        (recursive)
│    └─QuantMaxPool2d: 2-32                                                      [1, 64, 28, 28]           --
│    └─QuantConv2d: 2-33                                                         [1, 28, 28, 28]           --
│    │    └─ActQuantProxyFromInjector: 3-43                                      [1, 64, 28, 28]           --
│    │    └─WeightQuantProxyFromInjector: 3-44                                   [28, 64, 1, 1]            1,820
│    │    └─BiasQuantProxyFromInjector: 3-45                                     [28]                      28
│    │    └─ActQuantProxyFromInjector: 3-46                                      [1, 28, 28, 28]           --
│    └─QuantReLU: 2-34                                                           [1, 28, 28, 28]           --
│    │    └─ActQuantProxyFromInjector: 3-47                                      [1, 28, 28, 28]           --
│    │    └─ActQuantProxyFromInjector: 3-48                                      [1, 28, 28, 28]           1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-36                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-50                                      --                        (recursive)
│    └─Sequential: 2-37                                                          [1, 64, 28, 28]           --
│    │    └─QuantConv2d: 3-51                                                    [1, 38, 28, 28]           3,230
│    │    └─QuantConv2d: 3-52                                                    [1, 64, 28, 28]           7,424
│    └─QuantReLU: 2-38                                                           [1, 64, 28, 28]           --
│    │    └─ActQuantProxyFromInjector: 3-53                                      [1, 64, 28, 28]           --
│    │    └─ActQuantProxyFromInjector: 3-54                                      [1, 64, 28, 28]           1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-40                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-56                                      --                        (recursive)
│    └─QuantConv2d: 2-41                                                         [1, 28, 28, 28]           --
│    │    └─ActQuantProxyFromInjector: 3-57                                      [1, 64, 28, 28]           --
│    │    └─WeightQuantProxyFromInjector: 3-58                                   [28, 64, 1, 1]            1,820
│    │    └─BiasQuantProxyFromInjector: 3-59                                     [28]                      28
│    │    └─ActQuantProxyFromInjector: 3-60                                      [1, 28, 28, 28]           --
│    └─QuantReLU: 2-42                                                           [1, 28, 28, 28]           --
│    │    └─ActQuantProxyFromInjector: 3-61                                      [1, 28, 28, 28]           --
│    │    └─ActQuantProxyFromInjector: 3-62                                      [1, 28, 28, 28]           1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-44                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-64                                      --                        (recursive)
│    └─Sequential: 2-45                                                          [1, 57, 28, 28]           --
│    │    └─QuantConv2d: 3-65                                                    [1, 25, 28, 28]           2,125
│    │    └─QuantConv2d: 3-66                                                    [1, 57, 28, 28]           4,389
│    └─QuantReLU: 2-46                                                           [1, 57, 28, 28]           --
│    │    └─ActQuantProxyFromInjector: 3-67                                      [1, 57, 28, 28]           --
│    │    └─ActQuantProxyFromInjector: 3-68                                      [1, 57, 28, 28]           1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-48                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-70                                      --                        (recursive)
│    └─Sequential: 2-49                                                          [1, 28, 28, 28]           --
│    │    └─QuantConv2d: 3-71                                                    [1, 15, 28, 28]           870
│    │    └─QuantConv2d: 3-72                                                    [1, 28, 28, 28]           476
│    └─QuantReLU: 2-50                                                           [1, 28, 28, 28]           --
│    │    └─ActQuantProxyFromInjector: 3-73                                      [1, 28, 28, 28]           --
│    │    └─ActQuantProxyFromInjector: 3-74                                      [1, 28, 28, 28]           1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-52                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-76                                      --                        (recursive)
│    └─Sequential: 2-53                                                          [1, 57, 28, 28]           --
│    │    └─QuantConv2d: 3-77                                                    [1, 28, 28, 28]           2,380
│    │    └─QuantConv2d: 3-78                                                    [1, 57, 28, 28]           4,902
│    └─QuantReLU: 2-54                                                           [1, 57, 28, 28]           --
│    │    └─ActQuantProxyFromInjector: 3-79                                      [1, 57, 28, 28]           --
│    │    └─ActQuantProxyFromInjector: 3-80                                      [1, 57, 28, 28]           1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-56                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-82                                      --                        (recursive)
│    └─QuantMaxPool2d: 2-57                                                      [1, 57, 14, 14]           --
│    └─Sequential: 2-58                                                          [1, 32, 14, 14]           --
│    │    └─QuantConv2d: 3-83                                                    [1, 14, 14, 14]           812
│    │    └─QuantConv2d: 3-84                                                    [1, 32, 14, 14]           512
│    └─QuantReLU: 2-59                                                           [1, 32, 14, 14]           --
│    │    └─ActQuantProxyFromInjector: 3-85                                      [1, 32, 14, 14]           --
│    │    └─ActQuantProxyFromInjector: 3-86                                      [1, 32, 14, 14]           1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-61                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-88                                      --                        (recursive)
│    └─Sequential: 2-62                                                          [1, 64, 14, 14]           --
│    │    └─QuantConv2d: 3-89                                                    [1, 40, 14, 14]           3,880
│    │    └─QuantConv2d: 3-90                                                    [1, 64, 14, 14]           7,808
│    └─QuantReLU: 2-63                                                           [1, 64, 14, 14]           --
│    │    └─ActQuantProxyFromInjector: 3-91                                      [1, 64, 14, 14]           --
│    │    └─ActQuantProxyFromInjector: 3-92                                      [1, 64, 14, 14]           1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-65                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-94                                      --                        (recursive)
│    └─QuantConv2d: 2-66                                                         [1, 32, 14, 14]           --
│    │    └─ActQuantProxyFromInjector: 3-95                                      [1, 64, 14, 14]           --
│    │    └─WeightQuantProxyFromInjector: 3-96                                   [32, 64, 1, 1]            2,080
│    │    └─BiasQuantProxyFromInjector: 3-97                                     [32]                      32
│    │    └─ActQuantProxyFromInjector: 3-98                                      [1, 32, 14, 14]           --
│    └─QuantReLU: 2-67                                                           [1, 32, 14, 14]           --
│    │    └─ActQuantProxyFromInjector: 3-99                                      [1, 32, 14, 14]           --
│    │    └─ActQuantProxyFromInjector: 3-100                                     [1, 32, 14, 14]           1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-69                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-102                                     --                        (recursive)
│    └─Sequential: 2-70                                                          [1, 64, 14, 14]           --
│    │    └─QuantConv2d: 3-103                                                   [1, 45, 14, 14]           4,365
│    │    └─QuantConv2d: 3-104                                                   [1, 64, 14, 14]           8,768
│    └─QuantReLU: 2-71                                                           [1, 64, 14, 14]           --
│    │    └─ActQuantProxyFromInjector: 3-105                                     [1, 64, 14, 14]           --
│    │    └─ActQuantProxyFromInjector: 3-106                                     [1, 64, 14, 14]           1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-73                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-108                                     --                        (recursive)
│    └─Sequential: 2-74                                                          [1, 64, 14, 14]           --
│    │    └─QuantConv2d: 3-109                                                   [1, 67, 14, 14]           12,931
│    │    └─QuantConv2d: 3-110                                                   [1, 64, 14, 14]           12,992
│    └─QuantReLU: 2-75                                                           [1, 64, 14, 14]           --
│    │    └─ActQuantProxyFromInjector: 3-111                                     [1, 64, 14, 14]           --
│    │    └─ActQuantProxyFromInjector: 3-112                                     [1, 64, 14, 14]           1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-77                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-114                                     --                        (recursive)
│    └─Sequential: 2-78                                                          [1, 64, 14, 14]           --
│    │    └─QuantConv2d: 3-115                                                   [1, 77, 14, 14]           14,861
│    │    └─QuantConv2d: 3-116                                                   [1, 64, 14, 14]           14,912
│    └─QuantReLU: 2-79                                                           [1, 64, 14, 14]           --
│    │    └─ActQuantProxyFromInjector: 3-117                                     [1, 64, 14, 14]           --
│    │    └─ActQuantProxyFromInjector: 3-118                                     [1, 64, 14, 14]           1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-81                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-120                                     --                        (recursive)
│    └─QuantMaxPool2d: 2-82                                                      [1, 64, 7, 7]             --
│    └─QuantConv2d: 2-83                                                         [1, 64, 7, 7]             --
│    │    └─ActQuantProxyFromInjector: 3-121                                     [1, 64, 7, 7]             --
│    │    └─WeightQuantProxyFromInjector: 3-122                                  [64, 64, 3, 3]            36,928
│    │    └─BiasQuantProxyFromInjector: 3-123                                    [64]                      64
│    │    └─ActQuantProxyFromInjector: 3-124                                     [1, 64, 7, 7]             --
│    └─QuantReLU: 2-84                                                           [1, 64, 7, 7]             --
│    │    └─ActQuantProxyFromInjector: 3-125                                     [1, 64, 7, 7]             --
│    │    └─ActQuantProxyFromInjector: 3-126                                     [1, 64, 7, 7]             1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-86                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-128                                     --                        (recursive)
│    └─QuantConv2d: 2-87                                                         [1, 64, 7, 7]             --
│    │    └─ActQuantProxyFromInjector: 3-129                                     [1, 64, 7, 7]             --
│    │    └─WeightQuantProxyFromInjector: 3-130                                  [64, 64, 3, 3]            36,928
│    │    └─BiasQuantProxyFromInjector: 3-131                                    [64]                      64
│    │    └─ActQuantProxyFromInjector: 3-132                                     [1, 64, 7, 7]             --
│    └─QuantReLU: 2-88                                                           [1, 64, 7, 7]             --
│    │    └─ActQuantProxyFromInjector: 3-133                                     [1, 64, 7, 7]             --
│    │    └─ActQuantProxyFromInjector: 3-134                                     [1, 64, 7, 7]             1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-90                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-136                                     --                        (recursive)
│    └─QuantConv2d: 2-91                                                         [1, 64, 7, 7]             --
│    │    └─ActQuantProxyFromInjector: 3-137                                     [1, 64, 7, 7]             --
│    │    └─WeightQuantProxyFromInjector: 3-138                                  [64, 64, 1, 1]            4,160
│    │    └─BiasQuantProxyFromInjector: 3-139                                    [64]                      64
│    │    └─ActQuantProxyFromInjector: 3-140                                     [1, 64, 7, 7]             --
│    └─QuantReLU: 2-92                                                           [1, 64, 7, 7]             --
│    │    └─ActQuantProxyFromInjector: 3-141                                     [1, 64, 7, 7]             --
│    │    └─ActQuantProxyFromInjector: 3-142                                     [1, 64, 7, 7]             1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-94                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-144                                     --                        (recursive)
│    └─QuantConv2d: 2-95                                                         [1, 16, 7, 7]             --
│    │    └─ActQuantProxyFromInjector: 3-145                                     [1, 64, 7, 7]             --
│    │    └─WeightQuantProxyFromInjector: 3-146                                  [16, 64, 1, 1]            1,040
│    │    └─BiasQuantProxyFromInjector: 3-147                                    [16]                      16
│    │    └─ActQuantProxyFromInjector: 3-148                                     [1, 16, 7, 7]             --
│    └─QuantReLU: 2-96                                                           [1, 16, 7, 7]             --
│    │    └─ActQuantProxyFromInjector: 3-149                                     [1, 16, 7, 7]             --
│    │    └─ActQuantProxyFromInjector: 3-150                                     [1, 16, 7, 7]             1
│    └─QuantReLU: 2-97                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-151                                     --                        (recursive)
│    └─QuantReLU: 2-98                                                           --                        (recursive)
│    │    └─ActQuantProxyFromInjector: 3-152                                     --                        (recursive)
│    └─QuantConv2d: 2-99                                                         [1, 16, 7, 7]             --
│    │    └─ActQuantProxyFromInjector: 3-153                                     [1, 16, 7, 7]             --
│    │    └─WeightQuantProxyFromInjector: 3-154                                  [16, 16, 1, 1]            272
│    │    └─BiasQuantProxyFromInjector: 3-155                                    [16]                      16
│    │    └─ActQuantProxyFromInjector: 3-156                                     [1, 16, 7, 7]             --
│    └─QuantReLU: 2-100                                                          [1, 16, 7, 7]             --
│    │    └─ActQuantProxyFromInjector: 3-157                                     [1, 16, 7, 7]             --
│    │    └─ActQuantProxyFromInjector: 3-158                                     [1, 16, 7, 7]             1
│    └─QuantConv2d: 2-101                                                        [1, 12, 7, 7]             --
│    │    └─ActQuantProxyFromInjector: 3-159                                     [1, 16, 7, 7]             --
│    │    └─WeightQuantProxyFromInjector: 3-160                                  [12, 16, 1, 1]            204
│    │    └─BiasQuantProxyFromInjector: 3-161                                    [12]                      12
│    │    └─ActQuantProxyFromInjector: 3-162                                     [1, 12, 7, 7]             --
==================================================================================================================================
Total params: 204,672
Trainable params: 204,672
Non-trainable params: 0
Total mult-adds (M): 0
==================================================================================================================================
Input size (MB): 0.60
Forward/backward pass size (MB): 0.00
Params size (MB): 0.00
Estimated Total Size (MB): 0.60
==================================================================================================================================

Loading Pretrained Weights from Fused Model to Quant Model
original model name:  - QNN model name: 
Module type: <class 'modules.models.PRUNED_AFTER_SVD_BED_DETECTOR'>
	______ Ignore weights or params of layer fused  and QNN 
original model name: model - QNN model name: model
Module type: <class 'torch.nn.modules.container.Sequential'>
	______ Ignore weights or params of layer fused model and QNN model
original model name: model.conv1 - QNN model name: model.conv1
Module type: <class 'torch.nn.modules.container.Sequential'>
	______ Ignore weights or params of layer fused model.conv1 and QNN model.conv1
original model name: model.conv1.0 - QNN model name: model.conv1.0
	****** Loading weights of Conv2d layer fused model.conv1.0 into QNN model.conv1.0
original model name: model.conv1.1 - QNN model name: model.conv1.1
	****** Loading weights of Conv2d layer fused model.conv1.1 into QNN model.conv1.1
original model name: model.relu1 - QNN model name: model.relu1
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu1 and QNN model.relu1
original model name: model.dropout1 - QNN model name: model.dropout1
Module type: <class 'torch.nn.modules.dropout.Dropout2d'>
	______ Ignore weights or params of layer fused model.dropout1 and QNN model.dropout1
original model name: model.maxpool2 - QNN model name: model.maxpool2
Module type: <class 'torch.nn.modules.pooling.MaxPool2d'>
	______ Ignore weights or params of layer fused model.maxpool2 and QNN model.maxpool2
original model name: model.conv2 - QNN model name: model.conv2
Module type: <class 'torch.nn.modules.container.Sequential'>
	______ Ignore weights or params of layer fused model.conv2 and QNN model.conv2
original model name: model.conv2.0 - QNN model name: model.conv2.0
	****** Loading weights of Conv2d layer fused model.conv2.0 into QNN model.conv2.0
original model name: model.conv2.1 - QNN model name: model.conv2.1
	****** Loading weights of Conv2d layer fused model.conv2.1 into QNN model.conv2.1
original model name: model.relu2 - QNN model name: model.relu2
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu2 and QNN model.relu2
original model name: model.dropout2 - QNN model name: model.dropout2
Module type: <class 'torch.nn.modules.dropout.Dropout2d'>
	______ Ignore weights or params of layer fused model.dropout2 and QNN model.dropout2
original model name: model.maxpool3 - QNN model name: model.maxpool3
Module type: <class 'torch.nn.modules.pooling.MaxPool2d'>
	______ Ignore weights or params of layer fused model.maxpool3 and QNN model.maxpool3
original model name: model.conv31 - QNN model name: model.conv31
Module type: <class 'torch.nn.modules.container.Sequential'>
	______ Ignore weights or params of layer fused model.conv31 and QNN model.conv31
original model name: model.conv31.0 - QNN model name: model.conv31.0
	****** Loading weights of Conv2d layer fused model.conv31.0 into QNN model.conv31.0
original model name: model.conv31.1 - QNN model name: model.conv31.1
	****** Loading weights of Conv2d layer fused model.conv31.1 into QNN model.conv31.1
original model name: model.relu31 - QNN model name: model.relu31
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu31 and QNN model.relu31
original model name: model.conv32 - QNN model name: model.conv32
Module type: <class 'torch.nn.modules.container.Sequential'>
	______ Ignore weights or params of layer fused model.conv32 and QNN model.conv32
original model name: model.conv32.0 - QNN model name: model.conv32.0
	****** Loading weights of Conv2d layer fused model.conv32.0 into QNN model.conv32.0
original model name: model.conv32.1 - QNN model name: model.conv32.1
	****** Loading weights of Conv2d layer fused model.conv32.1 into QNN model.conv32.1
original model name: model.relu32 - QNN model name: model.relu32
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu32 and QNN model.relu32
original model name: model.conv33 - QNN model name: model.conv33
	****** Loading weights of Conv2d layer fused model.conv33 into QNN model.conv33
original model name: model.relu33 - QNN model name: model.relu33
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu33 and QNN model.relu33
original model name: model.conv34 - QNN model name: model.conv34
Module type: <class 'torch.nn.modules.container.Sequential'>
	______ Ignore weights or params of layer fused model.conv34 and QNN model.conv34
original model name: model.conv34.0 - QNN model name: model.conv34.0
	****** Loading weights of Conv2d layer fused model.conv34.0 into QNN model.conv34.0
original model name: model.conv34.1 - QNN model name: model.conv34.1
	****** Loading weights of Conv2d layer fused model.conv34.1 into QNN model.conv34.1
original model name: model.relu34 - QNN model name: model.relu34
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu34 and QNN model.relu34
original model name: model.maxpool4 - QNN model name: model.maxpool4
Module type: <class 'torch.nn.modules.pooling.MaxPool2d'>
	______ Ignore weights or params of layer fused model.maxpool4 and QNN model.maxpool4
original model name: model.conv41 - QNN model name: model.conv41
	****** Loading weights of Conv2d layer fused model.conv41 into QNN model.conv41
original model name: model.relu41 - QNN model name: model.relu41
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu41 and QNN model.relu41
original model name: model.conv42 - QNN model name: model.conv42
Module type: <class 'torch.nn.modules.container.Sequential'>
	______ Ignore weights or params of layer fused model.conv42 and QNN model.conv42
original model name: model.conv42.0 - QNN model name: model.conv42.0
	****** Loading weights of Conv2d layer fused model.conv42.0 into QNN model.conv42.0
original model name: model.conv42.1 - QNN model name: model.conv42.1
	****** Loading weights of Conv2d layer fused model.conv42.1 into QNN model.conv42.1
original model name: model.relu42 - QNN model name: model.relu42
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu42 and QNN model.relu42
original model name: model.conv43 - QNN model name: model.conv43
	****** Loading weights of Conv2d layer fused model.conv43 into QNN model.conv43
original model name: model.relu43 - QNN model name: model.relu43
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu43 and QNN model.relu43
original model name: model.conv44 - QNN model name: model.conv44
Module type: <class 'torch.nn.modules.container.Sequential'>
	______ Ignore weights or params of layer fused model.conv44 and QNN model.conv44
original model name: model.conv44.0 - QNN model name: model.conv44.0
	****** Loading weights of Conv2d layer fused model.conv44.0 into QNN model.conv44.0
original model name: model.conv44.1 - QNN model name: model.conv44.1
	****** Loading weights of Conv2d layer fused model.conv44.1 into QNN model.conv44.1
original model name: model.relu44 - QNN model name: model.relu44
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu44 and QNN model.relu44
original model name: model.conv45 - QNN model name: model.conv45
Module type: <class 'torch.nn.modules.container.Sequential'>
	______ Ignore weights or params of layer fused model.conv45 and QNN model.conv45
original model name: model.conv45.0 - QNN model name: model.conv45.0
	****** Loading weights of Conv2d layer fused model.conv45.0 into QNN model.conv45.0
original model name: model.conv45.1 - QNN model name: model.conv45.1
	****** Loading weights of Conv2d layer fused model.conv45.1 into QNN model.conv45.1
original model name: model.relu45 - QNN model name: model.relu45
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu45 and QNN model.relu45
original model name: model.conv46 - QNN model name: model.conv46
Module type: <class 'torch.nn.modules.container.Sequential'>
	______ Ignore weights or params of layer fused model.conv46 and QNN model.conv46
original model name: model.conv46.0 - QNN model name: model.conv46.0
	****** Loading weights of Conv2d layer fused model.conv46.0 into QNN model.conv46.0
original model name: model.conv46.1 - QNN model name: model.conv46.1
	****** Loading weights of Conv2d layer fused model.conv46.1 into QNN model.conv46.1
original model name: model.relu46 - QNN model name: model.relu46
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu46 and QNN model.relu46
original model name: model.maxpool5 - QNN model name: model.maxpool5
Module type: <class 'torch.nn.modules.pooling.MaxPool2d'>
	______ Ignore weights or params of layer fused model.maxpool5 and QNN model.maxpool5
original model name: model.conv51 - QNN model name: model.conv51
Module type: <class 'torch.nn.modules.container.Sequential'>
	______ Ignore weights or params of layer fused model.conv51 and QNN model.conv51
original model name: model.conv51.0 - QNN model name: model.conv51.0
	****** Loading weights of Conv2d layer fused model.conv51.0 into QNN model.conv51.0
original model name: model.conv51.1 - QNN model name: model.conv51.1
	****** Loading weights of Conv2d layer fused model.conv51.1 into QNN model.conv51.1
original model name: model.relu51 - QNN model name: model.relu51
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu51 and QNN model.relu51
original model name: model.conv52 - QNN model name: model.conv52
Module type: <class 'torch.nn.modules.container.Sequential'>
	______ Ignore weights or params of layer fused model.conv52 and QNN model.conv52
original model name: model.conv52.0 - QNN model name: model.conv52.0
	****** Loading weights of Conv2d layer fused model.conv52.0 into QNN model.conv52.0
original model name: model.conv52.1 - QNN model name: model.conv52.1
	****** Loading weights of Conv2d layer fused model.conv52.1 into QNN model.conv52.1
original model name: model.relu52 - QNN model name: model.relu52
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu52 and QNN model.relu52
original model name: model.conv53 - QNN model name: model.conv53
	****** Loading weights of Conv2d layer fused model.conv53 into QNN model.conv53
original model name: model.relu53 - QNN model name: model.relu53
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu53 and QNN model.relu53
original model name: model.conv54 - QNN model name: model.conv54
Module type: <class 'torch.nn.modules.container.Sequential'>
	______ Ignore weights or params of layer fused model.conv54 and QNN model.conv54
original model name: model.conv54.0 - QNN model name: model.conv54.0
	****** Loading weights of Conv2d layer fused model.conv54.0 into QNN model.conv54.0
original model name: model.conv54.1 - QNN model name: model.conv54.1
	****** Loading weights of Conv2d layer fused model.conv54.1 into QNN model.conv54.1
original model name: model.relu54 - QNN model name: model.relu54
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu54 and QNN model.relu54
original model name: model.conv55 - QNN model name: model.conv55
Module type: <class 'torch.nn.modules.container.Sequential'>
	______ Ignore weights or params of layer fused model.conv55 and QNN model.conv55
original model name: model.conv55.0 - QNN model name: model.conv55.0
	****** Loading weights of Conv2d layer fused model.conv55.0 into QNN model.conv55.0
original model name: model.conv55.1 - QNN model name: model.conv55.1
	****** Loading weights of Conv2d layer fused model.conv55.1 into QNN model.conv55.1
original model name: model.relu55 - QNN model name: model.relu55
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu55 and QNN model.relu55
original model name: model.conv56 - QNN model name: model.conv56
Module type: <class 'torch.nn.modules.container.Sequential'>
	______ Ignore weights or params of layer fused model.conv56 and QNN model.conv56
original model name: model.conv56.0 - QNN model name: model.conv56.0
	****** Loading weights of Conv2d layer fused model.conv56.0 into QNN model.conv56.0
original model name: model.conv56.1 - QNN model name: model.conv56.1
	****** Loading weights of Conv2d layer fused model.conv56.1 into QNN model.conv56.1
original model name: model.relu56 - QNN model name: model.relu56
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu56 and QNN model.relu56
original model name: model.maxpool6 - QNN model name: model.maxpool6
Module type: <class 'torch.nn.modules.pooling.MaxPool2d'>
	______ Ignore weights or params of layer fused model.maxpool6 and QNN model.maxpool6
original model name: model.conv61 - QNN model name: model.conv61
	****** Loading weights of Conv2d layer fused model.conv61 into QNN model.conv61
original model name: model.relu61 - QNN model name: model.relu61
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu61 and QNN model.relu61
original model name: model.conv62 - QNN model name: model.conv62
	****** Loading weights of Conv2d layer fused model.conv62 into QNN model.conv62
original model name: model.relu62 - QNN model name: model.relu62
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu62 and QNN model.relu62
original model name: model.conv71 - QNN model name: model.conv71
	****** Loading weights of Conv2d layer fused model.conv71 into QNN model.conv71
original model name: model.relu71 - QNN model name: model.relu71
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu71 and QNN model.relu71
original model name: model.conv72 - QNN model name: model.conv72
	****** Loading weights of Conv2d layer fused model.conv72 into QNN model.conv72
original model name: model.relu72 - QNN model name: model.relu72
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu72 and QNN model.relu72
original model name: model.conv73 - QNN model name: model.conv73
	****** Loading weights of Conv2d layer fused model.conv73 into QNN model.conv73
original model name: model.relu73 - QNN model name: model.relu73
Module type: <class 'torch.nn.modules.activation.ReLU'>
	______ Ignore weights or params of layer fused model.relu73 and QNN model.relu73
original model name: model.conv74 - QNN model name: model.conv74
	****** Loading weights of Conv2d layer fused model.conv74 into QNN model.conv74
Starting script


***Start Training: 21:39:55


=== EPOCH 0/149 ===
Learning Rate = 0.0005

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
81.24      |29.73     |36.48     |8.65      |6.38      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
73.66      |27.75     |34.60     |4.08      |7.23      |

Saving model with new best validation loss: 73.660

=== EPOCH 1/149 ===
Learning Rate = 0.0005

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
71.00      |25.47     |31.81     |8.37      |5.35      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
69.39      |27.29     |30.05     |5.95      |6.10      |

Saving model with new best validation loss: 69.388

=== EPOCH 2/149 ===
Learning Rate = 0.0005

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
69.61      |25.05     |30.96     |8.28      |5.33      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
65.56      |26.15     |25.34     |8.70      |5.36      |

Saving model with new best validation loss: 65.557

=== EPOCH 3/149 ===
Learning Rate = 0.0005

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
69.33      |24.75     |30.38     |9.21      |4.99      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
74.48      |29.49     |24.86     |12.44     |7.69      |


=== EPOCH 4/149 ===
Learning Rate = 0.0005

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
68.71      |24.86     |30.32     |8.65      |4.89      |    |0.3194     |0.4509    |0.2637    |0.4528    |0.2915    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
63.27      |24.65     |26.15     |7.25      |5.22      |    |0.4056     |0.5269    |0.3897    |0.5100    |0.3977    |

Saving model with new best validation loss: 63.271
Saving model with new best mAP: 0.3977

=== EPOCH 5/149 ===
Learning Rate = 0.0005

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
68.68      |24.72     |30.03     |8.84      |5.09      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
72.90      |26.88     |23.19     |17.00     |5.82      |


=== EPOCH 6/149 ===
Learning Rate = 0.0005

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
68.10      |24.55     |29.80     |8.69      |5.06      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
64.24      |24.85     |25.26     |8.75      |5.38      |


=== EPOCH 7/149 ===
Learning Rate = 0.0005

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
67.19      |24.15     |29.55     |8.67      |4.82      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
67.75      |27.89     |24.27     |10.57     |5.02      |


=== EPOCH 8/149 ===
Learning Rate = 0.0005

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
67.51      |24.32     |29.60     |8.86      |4.73      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
66.19      |24.92     |25.57     |9.09      |6.61      |


=== EPOCH 9/149 ===
Learning Rate = 0.0004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
65.95      |23.54     |28.94     |8.66      |4.81      |    |0.3651     |0.4947    |0.3278    |0.5092    |0.3464    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
67.35      |25.01     |26.77     |7.57      |8.00      |    |0.4013     |0.5355    |0.4688    |0.5457    |0.4351    |

Saving model with new best mAP: 0.4351

=== EPOCH 10/149 ===
Learning Rate = 0.0004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
64.79      |23.13     |28.74     |8.25      |4.67      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
63.57      |24.76     |26.60     |7.05      |5.16      |


=== EPOCH 11/149 ===
Learning Rate = 0.0004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
64.36      |23.19     |28.63     |8.08      |4.47      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
66.44      |25.53     |22.81     |12.22     |5.89      |


=== EPOCH 12/149 ===
Learning Rate = 0.0004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
63.56      |22.87     |28.41     |7.89      |4.39      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
65.45      |25.00     |28.98     |5.34      |6.12      |


=== EPOCH 13/149 ===
Learning Rate = 0.00032

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
62.02      |22.19     |27.71     |7.87      |4.25      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
62.37      |24.32     |24.68     |8.82      |4.56      |

Saving model with new best validation loss: 62.371

=== EPOCH 14/149 ===
Learning Rate = 0.00032

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
61.63      |22.11     |27.64     |7.87      |4.01      |    |0.3930     |0.5194    |0.3471    |0.5270    |0.3701    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
61.53      |24.72     |25.30     |7.02      |4.50      |    |0.4030     |0.5411    |0.4482    |0.5712    |0.4256    |

Saving model with new best validation loss: 61.534

=== EPOCH 15/149 ===
Learning Rate = 0.00032

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
61.45      |21.81     |27.43     |8.31      |3.90      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
59.41      |22.37     |24.19     |7.86      |4.99      |

Saving model with new best validation loss: 59.408

=== EPOCH 16/149 ===
Learning Rate = 0.00032

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
61.73      |21.92     |27.60     |8.27      |3.94      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
61.71      |24.09     |26.61     |6.58      |4.43      |


=== EPOCH 17/149 ===
Learning Rate = 0.00032

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
61.43      |21.76     |27.37     |8.27      |4.03      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
59.53      |22.35     |25.84     |6.95      |4.39      |


=== EPOCH 18/149 ===
Learning Rate = 0.00032

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
61.50      |21.76     |27.36     |8.22      |4.16      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
60.55      |22.65     |24.64     |7.16      |6.09      |


=== EPOCH 19/149 ===
Learning Rate = 0.00032

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
61.29      |21.77     |27.20     |8.24      |4.08      |    |0.4031     |0.5282    |0.3263    |0.5188    |0.3647    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
64.42      |24.87     |26.62     |7.66      |5.27      |    |0.2849     |0.4710    |0.2754    |0.4700    |0.2801    |


=== EPOCH 20/149 ===
Learning Rate = 0.00025600000000000004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
60.05      |21.20     |26.84     |8.21      |3.79      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
60.70      |24.19     |23.09     |8.41      |5.01      |


=== EPOCH 21/149 ===
Learning Rate = 0.00025600000000000004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
59.73      |21.10     |26.67     |8.17      |3.79      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
60.53      |23.03     |24.67     |7.75      |5.09      |


=== EPOCH 22/149 ===
Learning Rate = 0.00025600000000000004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
59.50      |20.95     |26.74     |8.01      |3.80      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
58.48      |22.30     |25.05     |6.24      |4.89      |

Saving model with new best validation loss: 58.481

=== EPOCH 23/149 ===
Learning Rate = 0.00025600000000000004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
58.99      |20.82     |26.47     |7.99      |3.70      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
62.56      |23.70     |20.26     |12.60     |5.99      |


=== EPOCH 24/149 ===
Learning Rate = 0.00025600000000000004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
59.12      |20.86     |26.45     |8.09      |3.73      |    |0.4268     |0.5431    |0.3648    |0.5491    |0.3958    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
58.84      |22.10     |24.45     |7.46      |4.83      |    |0.3360     |0.5084    |0.3010    |0.4485    |0.3185    |


=== EPOCH 25/149 ===
Learning Rate = 0.00025600000000000004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
58.84      |20.74     |26.49     |7.92      |3.68      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
61.23      |23.89     |21.15     |11.19     |5.00      |


=== EPOCH 26/149 ===
Learning Rate = 0.00025600000000000004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
58.71      |20.74     |26.41     |7.94      |3.62      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
62.05      |23.72     |27.02     |6.20      |5.11      |


=== EPOCH 27/149 ===
Learning Rate = 0.00020480000000000004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
57.93      |20.34     |26.17     |7.84      |3.58      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
61.03      |24.06     |24.69     |7.56      |4.72      |


=== EPOCH 28/149 ===
Learning Rate = 0.00020480000000000004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
57.78      |20.38     |26.01     |7.91      |3.48      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
57.26      |21.42     |23.36     |7.48      |5.01      |

Saving model with new best validation loss: 57.262

=== EPOCH 29/149 ===
Learning Rate = 0.00020480000000000004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
57.35      |20.14     |25.95     |7.77      |3.50      |    |0.4236     |0.5468    |0.3784    |0.5575    |0.4010    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
57.04      |21.18     |24.02     |6.67      |5.16      |    |0.4504     |0.5733    |0.4160    |0.5393    |0.4332    |

Saving model with new best validation loss: 57.043

=== EPOCH 30/149 ===
Learning Rate = 0.00020480000000000004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
57.45      |20.18     |25.94     |7.84      |3.50      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
58.62      |22.34     |21.58     |9.62      |5.08      |


=== EPOCH 31/149 ===
Learning Rate = 0.00020480000000000004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
57.49      |20.22     |25.85     |7.91      |3.51      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
58.27      |23.26     |24.03     |6.21      |4.76      |


=== EPOCH 32/149 ===
Learning Rate = 0.00020480000000000004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
57.20      |20.20     |25.77     |7.78      |3.45      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
58.62      |22.42     |23.82     |7.03      |5.35      |


=== EPOCH 33/149 ===
Learning Rate = 0.00020480000000000004

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
57.06      |20.18     |25.68     |7.84      |3.37      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
57.31      |21.72     |25.99     |5.34      |4.26      |


=== EPOCH 34/149 ===
Learning Rate = 0.00016384000000000006

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
56.50      |19.87     |25.44     |7.93      |3.26      |    |0.4322     |0.5544    |0.3692    |0.5547    |0.4007    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
58.13      |22.72     |25.65     |5.03      |4.73      |    |0.4735     |0.5793    |0.4264    |0.5492    |0.4499    |

Saving model with new best mAP: 0.4499

=== EPOCH 35/149 ===
Learning Rate = 0.00016384000000000006

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
56.26      |19.67     |25.50     |7.79      |3.30      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
55.19      |20.95     |22.99     |7.22      |4.03      |

Saving model with new best validation loss: 55.188

=== EPOCH 36/149 ===
Learning Rate = 0.00016384000000000006

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
56.09      |19.67     |25.42     |7.75      |3.25      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
59.76      |22.98     |22.96     |9.11      |4.72      |


=== EPOCH 37/149 ===
Learning Rate = 0.00016384000000000006

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
56.27      |19.92     |25.43     |7.71      |3.21      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
59.22      |23.85     |23.83     |6.43      |5.10      |


=== EPOCH 38/149 ===
Learning Rate = 0.00016384000000000006

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
55.63      |19.43     |25.30     |7.64      |3.26      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
57.38      |21.76     |24.47     |5.56      |5.60      |


=== EPOCH 39/149 ===
Learning Rate = 0.00016384000000000006

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
56.01      |19.64     |25.35     |7.69      |3.33      |    |0.4534     |0.5615    |0.4098    |0.5808    |0.4316    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
56.67      |22.14     |22.55     |7.86      |4.12      |    |0.4790     |0.6026    |0.3995    |0.5656    |0.4393    |


=== EPOCH 40/149 ===
Learning Rate = 0.00013107200000000006

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
55.36      |19.28     |25.14     |7.68      |3.27      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
58.10      |22.59     |22.93     |7.96      |4.61      |


=== EPOCH 41/149 ===
Learning Rate = 0.00013107200000000006

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
55.28      |19.33     |25.07     |7.63      |3.25      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
58.85      |22.43     |22.85     |8.81      |4.76      |


=== EPOCH 42/149 ===
Learning Rate = 0.00013107200000000006

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
55.08      |19.21     |25.13     |7.62      |3.12      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
55.93      |21.42     |22.27     |7.71      |4.53      |


=== EPOCH 43/149 ===
Learning Rate = 0.00013107200000000006

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
55.09      |19.32     |24.91     |7.65      |3.20      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
56.32      |22.53     |22.67     |7.04      |4.09      |


=== EPOCH 44/149 ===
Learning Rate = 0.00010485760000000006

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
54.46      |19.04     |24.72     |7.62      |3.08      |    |0.4564     |0.5713    |0.3961    |0.5798    |0.4263    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
57.98      |23.48     |24.16     |5.74      |4.60      |    |0.2823     |0.4736    |0.2398    |0.4337    |0.2610    |


=== EPOCH 45/149 ===
Learning Rate = 0.00010485760000000006

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.48      |19.11     |24.72     |7.59      |3.06      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
56.84      |21.73     |22.02     |8.38      |4.70      |


=== EPOCH 46/149 ===
Learning Rate = 0.00010485760000000006

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.49      |19.11     |24.69     |7.64      |3.05      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
56.10      |21.08     |22.49     |7.49      |5.05      |


=== EPOCH 47/149 ===
Learning Rate = 0.00010485760000000006

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.32      |18.99     |24.68     |7.62      |3.03      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
55.96      |21.08     |20.12     |10.65     |4.10      |


=== EPOCH 48/149 ===
Learning Rate = 8.388608000000005e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.47      |18.61     |24.39     |7.55      |2.92      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
56.23      |21.77     |21.02     |9.06      |4.38      |


=== EPOCH 49/149 ===
Learning Rate = 8.388608000000005e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
53.50      |18.66     |24.36     |7.55      |2.93      |    |0.4629     |0.5791    |0.4105    |0.5833    |0.4367    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
54.44      |21.01     |23.38     |5.86      |4.19      |    |0.4394     |0.5757    |0.5458    |0.6238    |0.4926    |

Saving model with new best validation loss: 54.445
Saving model with new best mAP: 0.4926

=== EPOCH 50/149 ===
Learning Rate = 8.388608000000005e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.67      |18.70     |24.45     |7.65      |2.87      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.64      |20.67     |22.75     |6.45      |4.78      |


=== EPOCH 51/149 ===
Learning Rate = 8.388608000000005e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.50      |18.62     |24.38     |7.62      |2.88      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
56.08      |21.18     |21.53     |8.37      |5.01      |


=== EPOCH 52/149 ===
Learning Rate = 8.388608000000005e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.47      |18.57     |24.38     |7.62      |2.90      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.61      |21.53     |21.31     |7.65      |4.11      |


=== EPOCH 53/149 ===
Learning Rate = 8.388608000000005e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.46      |18.63     |24.34     |7.59      |2.89      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
55.62      |21.31     |22.57     |7.16      |4.57      |


=== EPOCH 54/149 ===
Learning Rate = 6.710886400000004e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
52.74      |18.24     |24.03     |7.58      |2.89      |    |0.4854     |0.5906    |0.4250    |0.5935    |0.4552    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
54.74      |20.73     |22.16     |7.42      |4.43      |    |0.5134     |0.6216    |0.3984    |0.5135    |0.4559    |


=== EPOCH 55/149 ===
Learning Rate = 6.710886400000004e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.02      |18.39     |24.21     |7.59      |2.83      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
56.05      |22.27     |22.30     |7.14      |4.33      |


=== EPOCH 56/149 ===
Learning Rate = 6.710886400000004e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.08      |18.39     |24.21     |7.64      |2.84      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.63      |20.92     |22.43     |7.09      |4.18      |


=== EPOCH 57/149 ===
Learning Rate = 6.710886400000004e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.05      |18.31     |24.18     |7.72      |2.83      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.61      |20.33     |21.59     |8.53      |4.17      |


=== EPOCH 58/149 ===
Learning Rate = 5.3687091200000036e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.48      |18.00     |23.91     |7.75      |2.81      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.79      |20.25     |22.17     |7.15      |4.21      |

Saving model with new best validation loss: 53.792

=== EPOCH 59/149 ===
Learning Rate = 5.3687091200000036e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
52.43      |18.10     |23.89     |7.68      |2.75      |    |0.4831     |0.5937    |0.4069    |0.5855    |0.4450    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
55.84      |21.44     |23.45     |6.44      |4.50      |    |0.5389     |0.6292    |0.5208    |0.5943    |0.5299    |

Saving model with new best mAP: 0.5299

=== EPOCH 60/149 ===
Learning Rate = 5.3687091200000036e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.13      |17.99     |23.77     |7.60      |2.77      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.53      |20.36     |22.35     |7.79      |4.02      |


=== EPOCH 61/149 ===
Learning Rate = 5.3687091200000036e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.26      |17.88     |23.98     |7.63      |2.77      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.81      |20.99     |21.83     |7.44      |4.55      |


=== EPOCH 62/149 ===
Learning Rate = 5.3687091200000036e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.59      |18.15     |23.92     |7.75      |2.77      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.87      |20.65     |24.06     |5.74      |4.43      |


=== EPOCH 63/149 ===
Learning Rate = 4.2949672960000034e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.00      |17.93     |23.74     |7.62      |2.71      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.69      |20.45     |23.48     |5.40      |4.35      |

Saving model with new best validation loss: 53.685

=== EPOCH 64/149 ===
Learning Rate = 4.2949672960000034e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
51.83      |17.84     |23.73     |7.54      |2.73      |    |0.4871     |0.5960    |0.4114    |0.5874    |0.4492    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
53.11      |19.77     |21.30     |7.20      |4.84      |    |0.5500     |0.6426    |0.5105    |0.6041    |0.5302    |

Saving model with new best validation loss: 53.106
Saving model with new best mAP: 0.5302

=== EPOCH 65/149 ===
Learning Rate = 4.2949672960000034e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.13      |18.08     |23.69     |7.61      |2.74      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
55.88      |20.34     |23.92     |6.59      |5.03      |


=== EPOCH 66/149 ===
Learning Rate = 4.2949672960000034e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.22      |18.00     |23.68     |7.72      |2.82      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
55.27      |21.89     |21.92     |7.05      |4.41      |


=== EPOCH 67/149 ===
Learning Rate = 4.2949672960000034e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.26      |17.99     |23.67     |7.81      |2.79      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
58.29      |22.67     |20.00     |10.29     |5.33      |


=== EPOCH 68/149 ===
Learning Rate = 4.2949672960000034e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.25      |17.99     |23.65     |7.72      |2.88      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.65      |20.04     |21.31     |8.27      |5.03      |


=== EPOCH 69/149 ===
Learning Rate = 3.435973836800003e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
51.95      |17.89     |23.59     |7.66      |2.80      |    |0.4766     |0.5922    |0.3952    |0.5743    |0.4359    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
56.40      |23.13     |21.46     |7.52      |4.28      |    |0.3652     |0.5448    |0.2416    |0.4308    |0.3034    |


=== EPOCH 70/149 ===
Learning Rate = 3.435973836800003e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
51.92      |17.88     |23.54     |7.71      |2.79      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
56.21      |22.16     |21.00     |8.06      |5.00      |


=== EPOCH 71/149 ===
Learning Rate = 3.435973836800003e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
51.83      |17.89     |23.49     |7.66      |2.79      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.40      |20.14     |22.32     |6.36      |4.59      |


=== EPOCH 72/149 ===
Learning Rate = 3.435973836800003e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.08      |17.98     |23.54     |7.79      |2.77      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.75      |20.49     |21.84     |6.75      |4.67      |


=== EPOCH 73/149 ===
Learning Rate = 2.7487790694400027e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
51.63      |17.76     |23.43     |7.75      |2.69      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.86      |20.45     |21.43     |7.52      |4.46      |


=== EPOCH 74/149 ===
Learning Rate = 2.7487790694400027e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
51.66      |17.77     |23.39     |7.77      |2.73      |    |0.4775     |0.5919    |0.4055    |0.5803    |0.4415    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
53.41      |19.49     |21.55     |7.57      |4.79      |    |0.5934     |0.6713    |0.5751    |0.6383    |0.5843    |

Saving model with new best mAP: 0.5843

=== EPOCH 75/149 ===
Learning Rate = 2.7487790694400027e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
51.61      |17.74     |23.45     |7.75      |2.68      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.85      |21.07     |21.22     |8.25      |4.32      |


=== EPOCH 76/149 ===
Learning Rate = 2.7487790694400027e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
51.80      |17.81     |23.55     |7.71      |2.72      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.39      |19.91     |24.21     |5.55      |4.72      |


=== EPOCH 77/149 ===
Learning Rate = 2.1990232555520022e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
51.39      |17.52     |23.43     |7.79      |2.66      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.66      |20.06     |22.21     |6.95      |4.43      |


=== EPOCH 78/149 ===
Learning Rate = 2.1990232555520022e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
51.68      |17.68     |23.42     |7.80      |2.78      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.45      |19.57     |21.86     |7.31      |4.71      |


=== EPOCH 79/149 ===
Learning Rate = 2.1990232555520022e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
51.39      |17.65     |23.35     |7.73      |2.66      |    |0.4877     |0.5997    |0.4210    |0.5917    |0.4543    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
52.05      |19.26     |21.82     |6.92      |4.04      |    |0.5339     |0.6368    |0.4961    |0.6037    |0.5150    |

Saving model with new best validation loss: 52.051

=== EPOCH 80/149 ===
Learning Rate = 2.1990232555520022e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
51.11      |17.44     |23.33     |7.67      |2.67      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.79      |19.99     |22.64     |6.35      |4.81      |


=== EPOCH 81/149 ===
Learning Rate = 2.1990232555520022e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
51.32      |17.46     |23.40     |7.73      |2.72      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.20      |19.77     |22.94     |6.61      |3.87      |


=== EPOCH 82/149 ===
Learning Rate = 2.1990232555520022e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
51.23      |17.44     |23.39     |7.71      |2.69      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
55.08      |20.56     |23.18     |6.27      |5.06      |


=== EPOCH 83/149 ===
Learning Rate = 2.1990232555520022e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
51.58      |17.55     |23.45     |7.76      |2.82      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.51      |21.20     |22.40     |6.63      |4.27      |


=== EPOCH 84/149 ===
Learning Rate = 1.7592186044416018e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
51.01      |17.41     |23.23     |7.66      |2.71      |    |0.4918     |0.6034    |0.4240    |0.5947    |0.4579    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
54.86      |21.03     |20.85     |8.00      |4.98      |    |0.4937     |0.6250    |0.4406    |0.5719    |0.4671    |


=== EPOCH 85/149 ===
Learning Rate = 1.7592186044416018e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.90      |17.42     |23.22     |7.58      |2.67      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.57      |19.93     |20.57     |7.75      |4.32      |


=== EPOCH 86/149 ===
Learning Rate = 1.7592186044416018e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.97      |17.44     |23.29     |7.62      |2.63      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.77      |20.13     |21.75     |6.78      |5.10      |


=== EPOCH 87/149 ===
Learning Rate = 1.7592186044416018e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.87      |17.36     |23.24     |7.55      |2.72      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.01      |20.03     |20.61     |7.84      |4.53      |


=== EPOCH 88/149 ===
Learning Rate = 1.4073748835532815e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.86      |17.42     |23.19     |7.58      |2.67      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.82      |19.79     |22.58     |6.29      |4.17      |


=== EPOCH 89/149 ===
Learning Rate = 1.4073748835532815e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
50.62      |17.28     |23.18     |7.57      |2.59      |    |0.4925     |0.5992    |0.4341    |0.6006    |0.4633    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
55.32      |21.23     |22.82     |6.11      |5.15      |    |0.5067     |0.6102    |0.5008    |0.5894    |0.5037    |


=== EPOCH 90/149 ===
Learning Rate = 1.4073748835532815e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.61      |17.24     |23.17     |7.57      |2.63      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.16      |19.59     |21.07     |8.42      |4.07      |


=== EPOCH 91/149 ===
Learning Rate = 1.4073748835532815e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.54      |17.30     |23.10     |7.51      |2.63      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.15      |19.75     |21.62     |6.86      |3.92      |


=== EPOCH 92/149 ===
Learning Rate = 1.1258999068426253e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.41      |17.25     |23.02     |7.55      |2.59      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.92      |19.34     |20.79     |7.87      |4.91      |


=== EPOCH 93/149 ===
Learning Rate = 1.1258999068426253e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.70      |17.41     |23.12     |7.54      |2.64      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.59      |20.62     |23.04     |5.99      |4.94      |


=== EPOCH 94/149 ===
Learning Rate = 1.1258999068426253e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
50.78      |17.41     |23.17     |7.58      |2.62      |    |0.5019     |0.6038    |0.4263    |0.5954    |0.4641    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
55.51      |21.85     |23.36     |5.78      |4.52      |    |0.4900     |0.6036    |0.4796    |0.5784    |0.4848    |


=== EPOCH 95/149 ===
Learning Rate = 1.1258999068426253e-05

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.63      |17.34     |23.10     |7.58      |2.61      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.21      |19.08     |20.93     |7.95      |4.25      |


=== EPOCH 96/149 ===
Learning Rate = 9.007199254741003e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.74      |17.45     |23.13     |7.54      |2.63      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.52      |21.00     |21.18     |7.38      |3.95      |


=== EPOCH 97/149 ===
Learning Rate = 9.007199254741003e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.69      |17.42     |22.99     |7.61      |2.67      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.56      |20.90     |23.75     |5.79      |4.13      |


=== EPOCH 98/149 ===
Learning Rate = 9.007199254741003e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.64      |17.37     |23.06     |7.58      |2.64      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.04      |19.98     |22.74     |6.24      |4.07      |


=== EPOCH 99/149 ===
Learning Rate = 9.007199254741003e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
50.54      |17.25     |23.10     |7.63      |2.55      |    |0.5011     |0.6039    |0.4372    |0.6072    |0.4692    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
52.79      |19.26     |23.30     |5.98      |4.25      |    |0.5457     |0.6312    |0.5202    |0.6135    |0.5329    |


=== EPOCH 100/149 ===
Learning Rate = 7.205759403792802e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.30      |17.22     |22.97     |7.55      |2.56      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.59      |20.17     |20.33     |8.37      |4.72      |


=== EPOCH 101/149 ===
Learning Rate = 7.205759403792802e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.32      |17.25     |22.94     |7.53      |2.60      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.41      |19.66     |20.75     |7.51      |4.48      |


=== EPOCH 102/149 ===
Learning Rate = 7.205759403792802e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.56      |17.39     |23.02     |7.53      |2.62      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.68      |19.35     |22.91     |5.74      |4.69      |


=== EPOCH 103/149 ===
Learning Rate = 7.205759403792802e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.50      |17.26     |23.06     |7.55      |2.63      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.77      |19.90     |22.69     |6.01      |4.16      |


=== EPOCH 104/149 ===
Learning Rate = 5.764607523034242e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
50.39      |17.31     |22.97     |7.53      |2.58      |    |0.5014     |0.6044    |0.4249    |0.5978    |0.4632    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
54.29      |19.63     |21.99     |7.77      |4.90      |    |0.5359     |0.6406    |0.5708    |0.6393    |0.5533    |


=== EPOCH 105/149 ===
Learning Rate = 5.764607523034242e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.59      |17.45     |23.03     |7.51      |2.60      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.40      |20.88     |22.31     |6.70      |4.50      |


=== EPOCH 106/149 ===
Learning Rate = 5.764607523034242e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.25      |17.35     |22.92     |7.45      |2.53      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.83      |21.00     |22.10     |6.47      |4.26      |


=== EPOCH 107/149 ===
Learning Rate = 5.764607523034242e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.49      |17.38     |23.02     |7.50      |2.60      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.56      |20.03     |21.89     |6.31      |4.34      |


=== EPOCH 108/149 ===
Learning Rate = 4.611686018427394e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.21      |17.26     |22.91     |7.50      |2.55      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.35      |20.31     |21.93     |6.56      |4.55      |


=== EPOCH 109/149 ===
Learning Rate = 4.611686018427394e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
50.35      |17.29     |22.92     |7.55      |2.59      |    |0.4933     |0.6012    |0.4114    |0.5895    |0.4524    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
54.03      |20.17     |21.69     |6.47      |5.70      |    |0.4877     |0.6178    |0.4690    |0.5872    |0.4783    |


=== EPOCH 110/149 ===
Learning Rate = 4.611686018427394e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.49      |17.34     |23.01     |7.56      |2.58      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.96      |20.31     |20.66     |8.71      |4.28      |


=== EPOCH 111/149 ===
Learning Rate = 4.611686018427394e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.31      |17.22     |23.00     |7.51      |2.57      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.09      |20.67     |20.28     |8.30      |3.85      |


=== EPOCH 112/149 ===
Learning Rate = 3.6893488147419155e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.15      |17.32     |22.82     |7.48      |2.54      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.55      |21.53     |22.40     |6.14      |4.48      |


=== EPOCH 113/149 ===
Learning Rate = 3.6893488147419155e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.13      |17.21     |22.88     |7.56      |2.47      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
56.15      |20.43     |21.85     |8.51      |5.35      |


=== EPOCH 114/149 ===
Learning Rate = 3.6893488147419155e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
50.31      |17.34     |22.94     |7.46      |2.56      |    |0.4949     |0.6030    |0.4125    |0.5889    |0.4537    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
55.66      |21.80     |20.83     |8.55      |4.48      |    |0.5110     |0.6244    |0.4686    |0.5705    |0.4898    |


=== EPOCH 115/149 ===
Learning Rate = 3.6893488147419155e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.27      |17.25     |22.91     |7.54      |2.57      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
55.00      |22.05     |22.20     |6.27      |4.49      |


=== EPOCH 116/149 ===
Learning Rate = 2.9514790517935326e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.02      |17.16     |22.84     |7.51      |2.52      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.38      |20.71     |20.95     |8.08      |4.64      |


=== EPOCH 117/149 ===
Learning Rate = 2.9514790517935326e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.03      |17.15     |22.85     |7.51      |2.51      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.16      |21.07     |22.57     |6.13      |4.39      |


=== EPOCH 118/149 ===
Learning Rate = 2.9514790517935326e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.39      |17.31     |22.95     |7.57      |2.56      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.66      |20.57     |19.63     |9.92      |4.53      |


=== EPOCH 119/149 ===
Learning Rate = 2.9514790517935326e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
50.30      |17.34     |22.83     |7.56      |2.57      |    |0.4951     |0.6033    |0.4108    |0.5889    |0.4530    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
53.01      |19.95     |21.37     |7.37      |4.32      |    |0.5137     |0.6256    |0.5246    |0.6138    |0.5192    |


=== EPOCH 120/149 ===
Learning Rate = 2.361183241434826e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
49.97      |17.05     |22.85     |7.56      |2.51      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
55.45      |19.89     |26.25     |4.64      |4.66      |


=== EPOCH 121/149 ===
Learning Rate = 2.361183241434826e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.08      |17.26     |22.86     |7.47      |2.49      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.07      |19.69     |21.74     |6.50      |4.13      |


=== EPOCH 122/149 ===
Learning Rate = 2.361183241434826e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.07      |17.27     |22.82     |7.50      |2.48      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.88      |19.87     |22.09     |6.51      |4.41      |


=== EPOCH 123/149 ===
Learning Rate = 2.361183241434826e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.01      |17.21     |22.79     |7.49      |2.51      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.20      |19.82     |22.24     |6.59      |4.55      |


=== EPOCH 124/149 ===
Learning Rate = 1.888946593147861e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
49.89      |17.09     |22.82     |7.50      |2.49      |    |0.4968     |0.6054    |0.4243    |0.5967    |0.4605    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
52.30      |19.59     |20.65     |7.74      |4.32      |    |0.5856     |0.6681    |0.5665    |0.6343    |0.5760    |


=== EPOCH 125/149 ===
Learning Rate = 1.888946593147861e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
49.83      |17.15     |22.73     |7.45      |2.50      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.73      |19.64     |22.76     |5.94      |4.38      |


=== EPOCH 126/149 ===
Learning Rate = 1.888946593147861e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
49.91      |17.14     |22.78     |7.50      |2.49      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.90      |20.59     |23.34     |5.48      |4.49      |


=== EPOCH 127/149 ===
Learning Rate = 1.888946593147861e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
49.92      |17.10     |22.83     |7.47      |2.52      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.29      |20.45     |22.72     |6.04      |5.09      |


=== EPOCH 128/149 ===
Learning Rate = 1.511157274518289e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.00      |17.18     |22.76     |7.47      |2.58      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.06      |19.91     |22.00     |6.68      |4.47      |


=== EPOCH 129/149 ===
Learning Rate = 1.511157274518289e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
49.89      |17.15     |22.77     |7.47      |2.50      |    |0.4988     |0.6056    |0.4198    |0.5947    |0.4593    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
53.59      |20.14     |22.85     |6.00      |4.59      |    |0.5254     |0.6316    |0.5459    |0.6287    |0.5356    |


=== EPOCH 130/149 ===
Learning Rate = 1.511157274518289e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
49.87      |17.09     |22.81     |7.49      |2.48      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.12      |19.94     |22.88     |5.61      |4.68      |


=== EPOCH 131/149 ===
Learning Rate = 1.511157274518289e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.11      |17.25     |22.76     |7.58      |2.52      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.88      |20.23     |22.37     |5.87      |4.41      |


=== EPOCH 132/149 ===
Learning Rate = 1.2089258196146312e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
49.87      |17.03     |22.75     |7.56      |2.53      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.66      |20.43     |21.75     |6.79      |4.69      |


=== EPOCH 133/149 ===
Learning Rate = 1.2089258196146312e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.01      |17.12     |22.86     |7.54      |2.50      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
55.20      |21.42     |21.53     |7.63      |4.61      |


=== EPOCH 134/149 ===
Learning Rate = 1.2089258196146312e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
50.06      |17.23     |22.76     |7.51      |2.57      |    |0.4987     |0.6048    |0.4185    |0.5939    |0.4586    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
54.33      |21.12     |22.05     |6.68      |4.48      |    |0.4514     |0.5792    |0.4230    |0.5295    |0.4372    |


=== EPOCH 135/149 ===
Learning Rate = 1.2089258196146312e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
49.80      |17.07     |22.67     |7.52      |2.53      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.49      |20.68     |20.90     |7.31      |4.61      |


=== EPOCH 136/149 ===
Learning Rate = 1e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.04      |17.17     |22.77     |7.57      |2.54      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.78      |20.54     |20.41     |8.91      |4.93      |


=== EPOCH 137/149 ===
Learning Rate = 1e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
49.93      |17.22     |22.71     |7.52      |2.48      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
51.76      |19.12     |22.54     |5.93      |4.16      |

Saving model with new best validation loss: 51.762

=== EPOCH 138/149 ===
Learning Rate = 1e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
49.92      |17.12     |22.77     |7.52      |2.52      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.14      |19.69     |21.43     |6.61      |4.41      |


=== EPOCH 139/149 ===
Learning Rate = 1e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
49.80      |17.03     |22.70     |7.52      |2.55      |    |0.4998     |0.6080    |0.4278    |0.6019    |0.4638    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
51.91      |19.02     |19.99     |8.81      |4.10      |    |0.5905     |0.6725    |0.5857    |0.6636    |0.5881    |

Saving model with new best mAP: 0.5881

=== EPOCH 140/149 ===
Learning Rate = 1e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
49.72      |17.11     |22.73     |7.46      |2.42      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.16      |20.02     |21.09     |7.62      |4.43      |


=== EPOCH 141/149 ===
Learning Rate = 1e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.00      |17.11     |22.79     |7.55      |2.55      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.37      |21.04     |20.77     |8.50      |4.06      |


=== EPOCH 142/149 ===
Learning Rate = 1e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
49.83      |17.07     |22.67     |7.52      |2.58      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.63      |19.55     |21.80     |6.65      |4.64      |


=== EPOCH 143/149 ===
Learning Rate = 1e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
49.89      |17.15     |22.72     |7.52      |2.51      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
52.32      |19.64     |20.13     |8.32      |4.23      |


=== EPOCH 144/149 ===
Learning Rate = 1e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
49.84      |17.12     |22.70     |7.53      |2.49      |    |0.4967     |0.6083    |0.4308    |0.6014    |0.4638    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
52.97      |19.91     |20.44     |8.20      |4.42      |    |0.5334     |0.6413    |0.5093    |0.6067    |0.5214    |


=== EPOCH 145/149 ===
Learning Rate = 1e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
49.81      |17.08     |22.76     |7.51      |2.47      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.18      |19.99     |23.33     |5.46      |4.40      |


=== EPOCH 146/149 ===
Learning Rate = 1e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
49.86      |17.00     |22.76     |7.57      |2.52      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
53.60      |20.94     |21.85     |6.38      |4.43      |


=== EPOCH 147/149 ===
Learning Rate = 1e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
49.92      |17.20     |22.73     |7.48      |2.50      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.73      |21.09     |22.38     |7.25      |4.02      |


=== EPOCH 148/149 ===
Learning Rate = 1e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
50.13      |17.22     |22.82     |7.55      |2.54      |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|     | No mAP in this epoch |
-----------|----------|--------------------------------|
54.98      |21.85     |22.03     |6.28      |4.82      |


=== EPOCH 149/149 ===
Learning Rate = 1e-06

TRAIN STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
50.11      |17.18     |22.85     |7.53      |2.54      |    |0.5004     |0.6053    |0.4260    |0.6003    |0.4632    |

VAL STATS
Total Loss |Box Loss  |Conf Loss |NoObj Loss|Class Loss|    |Smoke AP   |Smoke AR  |Fire AP   |Fire AR   |mAP:0.50  |
-----------|----------|--------------------------------|    |-----------|----------|--------------------------------|
53.72      |20.63     |20.23     |8.47      |4.39      |    |0.4967     |0.6114    |0.4595    |0.5704    |0.4781    |

Saving last model

***Script finished: 10:14:16

Time elapsed: 12:34:21.071898
