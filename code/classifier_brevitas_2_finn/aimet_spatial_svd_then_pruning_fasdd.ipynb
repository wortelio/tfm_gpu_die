{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8a513a-1549-4be7-af63-4f9542994187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "from decimal import Decimal\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import torch.nn as nn \n",
    "from torch.nn.utils import parameters_to_vector\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "import config\n",
    "import modules.dataloaders as dataloaders\n",
    "import modules.models_bed_evolution.bed_01_downto_28 as cnv_model\n",
    "import modules.loss as loss\n",
    "import modules.metrics as metrics\n",
    "import modules.train_epoch as train_epoch\n",
    "import modules.val_epoch as val_epoch\n",
    "import modules.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f7873-fc40-4e71-b3ad-7e3aadf45081",
   "metadata": {},
   "source": [
    "# AIMET imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b1b731b-4520-4b6c-8cc2-5d601081a059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-26 02:16:37,435 - root - INFO - AIMET\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.1.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"jspanel\"], function(jsPanel) {\n",
       "\twindow.jsPanel = jsPanel\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-modal\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-tooltip\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-hint\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-layout\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-contextmenu\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-dock\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 9;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      Bokeh = root.Bokeh;\n",
       "      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      if (!reloading && (!bokeh_loaded || is_dev)) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.1.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from aimet_torch.compress import ModelCompressor\n",
    "from aimet_torch.defs import SpatialSvdParameters\n",
    "from aimet_torch.defs import ChannelPruningParameters\n",
    "from aimet_torch.onnx_utils import OnnxSaver\n",
    "from aimet_common.defs import CostMetric, CompressionScheme, GreedySelectionParameters\n",
    "# from aimet_common.utils import start_bokeh_server_session\n",
    "# from aimet_torch.visualize_serialized_data import VisualizeCompression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d8132b-9f5b-403d-aa2b-bfa50ecf25d5",
   "metadata": {},
   "source": [
    "# Define Matplot Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3728c53e-0c8c-4a8c-92fa-8f676e65b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpl.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfc923c-eb11-4077-88d4-82c09c17e1a1",
   "metadata": {},
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4e5f0e-110e-4319-aeb1-ea3fcc692ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = config.LOGS_FOLDER\n",
    "\n",
    "logger = logging.getLogger(\"GonLogger\")\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.INFO)\n",
    "file_handler = logging.FileHandler(log_path + 'logfile.log')\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# add file handler to logger\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.info('BED Classifier XS Tiny.\\n' +  \n",
    "            '\\tOne Head.\\n' +\n",
    "            '\\tAdding best mean F1 save.\\n' +\n",
    "            '\\tWeighted for Precision.\\n' +\n",
    "            '\\tModules.\\n'+ \n",
    "            '\\tLosses and Metrics Loggers.\\n' +\n",
    "            f'\\tSVD Compression Ratio  = {config.SVD_COMPRESSION_RATIO}\\n' +\n",
    "            f'\\tPruning Compression Ratio  = {config.PRUNING_COMPRESSION_RATIO}\\n' +\n",
    "            f'\\t{config.EPOCHS} epochs.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b274c0-aa2f-4612-bc62-41e977152fa6",
   "metadata": {},
   "source": [
    "# Hyperparameters Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29fe02bc-8653-4de0-9508-d54b99e36e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Brevitas Model = False\n",
      "Training AIMET Model = True\n",
      "\n",
      "Datasets Length\n",
      "\tTrain and Val: 128\n",
      "\n",
      "Load Model: True\n",
      "\tModel: ./experiments_bed_evolution/11_downto_28__full_ds/weights/BED_Downto_28_classifier__best_mean_F1.pt\n",
      "Device: cuda\n",
      "Optimizer:\n",
      "\tLearning Rate: 0.001\n",
      "\tWeight Decay: 0.001\n",
      "Scheduler:\n",
      "\tScheduler factor: 0.8\n",
      "\tScheduler patience: 2\n",
      "\tScheduler threshold: 0.001\n",
      "\tScheduler min learning rate: 1e-06\n",
      "Batch Size: 64\n",
      "Num Workers: 8\n",
      "Pin Memory: True\n",
      "Epochs: 2\n",
      "\n",
      "IMG DIMS:\n",
      "\tWidth: 224\n",
      "\tHeight: 224\n",
      "\n",
      "Brevitas Config:\n",
      "\tFixed Point: True\n",
      "\tWeights Bit Width: 4\n",
      "\tBig Layers Weights Bit Width: 2\n",
      "\tBias Bit Width: 4\n",
      "\tActivations Bit Width: 4\n"
     ]
    }
   ],
   "source": [
    "''' ============================\n",
    "    Print Config Values\n",
    "============================ '''\n",
    "print(f'Training Brevitas Model = {config.BREVITAS_MODEL}')\n",
    "print(f'Training AIMET Model = {config.AIMET_RUN}')\n",
    "print('\\nDatasets Length')\n",
    "print(f'\\tTrain and Val: {\"Full\" if config.DS_LEN == None else config.DS_LEN}')\n",
    "print(f'\\nLoad Model: {config.LOAD_MODEL}')\n",
    "if (config.LOAD_MODEL == True):\n",
    "    print(f'\\tModel: {config.LOAD_MODEL_FILE}')\n",
    "print(f'Device: {config.DEVICE}')\n",
    "print('Optimizer:')\n",
    "print(f'\\tLearning Rate: {config.LEARNING_RATE}')\n",
    "print(f'\\tWeight Decay: {config.WEIGHT_DECAY}')\n",
    "print('Scheduler:')\n",
    "print(f'\\tScheduler factor: {config.FACTOR}')\n",
    "print(f'\\tScheduler patience: {config.PATIENCE}')\n",
    "print(f'\\tScheduler threshold: {config.THRES}')\n",
    "print(f'\\tScheduler min learning rate: {config.MIN_LR}')\n",
    "print(f'Batch Size: {config.BATCH_SIZE}')\n",
    "print(f'Num Workers: {config.NUM_WORKERS}')\n",
    "print(f'Pin Memory: {config.PIN_MEMORY}')\n",
    "print(f'Epochs: {config.EPOCHS}')\n",
    "print('\\nIMG DIMS:')\n",
    "print(f'\\tWidth: {config.IMG_W}\\n\\tHeight: {config.IMG_H}')\n",
    "print('\\nBrevitas Config:')\n",
    "print(f'\\tFixed Point: {config.FIXED_POINT}')\n",
    "print(f'\\tWeights Bit Width: {config.WEIGHTS_BIT_WIDTH}')\n",
    "print(f'\\tBig Layers Weights Bit Width: {config.BIG_LAYERS_WEIGHTS_BIT_WIDTH}')\n",
    "print(f'\\tBias Bit Width: {config.BIAS_BIT_WIDTH}')\n",
    "print(f'\\tActivations Bit Width: {config.ACTIVATIONS_BIT_WIDTH}')\n",
    "\n",
    "logger.info(f'Training Brevitas Model = {config.BREVITAS_MODEL}')\n",
    "logger.info(f'Training AIMET Model = {config.AIMET_RUN}')\n",
    "logger.info('\\nDatasets Length')\n",
    "logger.info(f'\\tTrain and Val: {\"Full\" if config.DS_LEN == None else config.DS_LEN}')\n",
    "logger.info(f'\\nLoad Model: {config.LOAD_MODEL}')\n",
    "if (config.LOAD_MODEL == True):\n",
    "    logger.info(f'\\tModel: {config.LOAD_MODEL_FILE}')\n",
    "logger.info(f'\\nDevice: {config.DEVICE}')\n",
    "logger.info('Optimizer:')\n",
    "logger.info(f'\\tLearning Rate: {config.LEARNING_RATE}')\n",
    "logger.info(f'\\tWeight Decay: {config.WEIGHT_DECAY}')\n",
    "logger.info('Scheduler:')\n",
    "logger.info(f'\\tScheduler factor: {config.FACTOR}')\n",
    "logger.info(f'\\tScheduler patience: {config.PATIENCE}')\n",
    "logger.info(f'\\tScheduler threshold: {config.THRES}')\n",
    "logger.info(f'\\tScheduler min learning rate: {config.MIN_LR}')\n",
    "logger.info(f'\\nBatch Size: {config.BATCH_SIZE}')\n",
    "logger.info(f'Num Workers: {config.NUM_WORKERS}')\n",
    "logger.info(f'Pin Memory: {config.PIN_MEMORY}')\n",
    "logger.info(f'Epochs: {config.EPOCHS}')\n",
    "logger.info('\\nIMG DIMS:')\n",
    "logger.info(f'\\tWidth: {config.IMG_W}\\n\\tHeight: {config.IMG_H}')\n",
    "logger.info('\\nBrevitas Config:')\n",
    "logger.info(f'\\tFixed Point: {config.FIXED_POINT}')\n",
    "logger.info(f'\\tWeights Bit Width: {config.WEIGHTS_BIT_WIDTH}')\n",
    "logger.info(f'\\tBig Layers Weights Bit Width: {config.BIG_LAYERS_WEIGHTS_BIT_WIDTH}')\n",
    "logger.info(f'\\tBias Bit Width: {config.BIAS_BIT_WIDTH}')\n",
    "logger.info(f'\\tActivations Bit Width: {config.ACTIVATIONS_BIT_WIDTH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9374d99a-7746-4bd2-b6b5-548f2b6f95bd",
   "metadata": {},
   "source": [
    "# Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50319596-f4bd-499c-a063-7612aa2c641b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "TRAIN DFIRE dataset\n",
      "DFire Removed wrong images: 0\n",
      "DFire empty images: 56\n",
      "DFire only smoke images: 37\n",
      "DFire only fire images: 8\n",
      "DFire smoke and fire images: 27\n",
      "\n",
      "Train DFire dataset len: 128\n",
      "\n",
      "====================\n",
      "TRAIN FASDD UAV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD empty images: 58\n",
      "FASDD only smoke images: 22\n",
      "FASDD only fire images: 2\n",
      "FASDD smoke and fire images: 46\n",
      "\n",
      "Train FASDD UAV dataset len: 128\n",
      "\n",
      "====================\n",
      "VAL FASDD UAV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD empty images: 59\n",
      "FASDD only smoke images: 26\n",
      "FASDD only fire images: 2\n",
      "FASDD smoke and fire images: 41\n",
      "\n",
      "Val FASDD UAV dataset len: 128\n",
      "\n",
      "====================\n",
      "TRAIN FASDD CV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD empty images: 53\n",
      "FASDD only smoke images: 36\n",
      "FASDD only fire images: 19\n",
      "FASDD smoke and fire images: 20\n",
      "\n",
      "Train FASDD CV dataset len: 128\n",
      "\n",
      "====================\n",
      "Val FASDD CV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD empty images: 50\n",
      "FASDD only smoke images: 32\n",
      "FASDD only fire images: 20\n",
      "FASDD smoke and fire images: 26\n",
      "\n",
      "Val FASDD CV dataset len: 128\n",
      "\n",
      "Concatenate Train DFire and Train FASDD UAV datasets\n",
      "Train dataset len: 256\n",
      "Concatenate with Val FASDD UAV dataset\n",
      "Train dataset len: 384\n",
      "Concatenate with Train FASDD CV dataset\n",
      "Train dataset len: 512\n",
      "Concatenate with Val FASDD CV dataset\n",
      "Train dataset len: 640\n",
      "\n",
      "====================\n",
      "TEST DFire dataset\n",
      "DFire Removed wrong images: 0\n",
      "DFire empty images: 62\n",
      "DFire only smoke images: 31\n",
      "DFire only fire images: 5\n",
      "DFire smoke and fire images: 30\n",
      "\n",
      "Test dataset len: 128\n",
      "\n",
      "====================\n",
      "TEST FASDD UAV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD empty images: 57\n",
      "FASDD only smoke images: 28\n",
      "FASDD only fire images: 1\n",
      "FASDD smoke and fire images: 42\n",
      "\n",
      "Test FASDD UAV dataset len: 128\n",
      "\n",
      "====================\n",
      "TEST FASDD CV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD empty images: 59\n",
      "FASDD only smoke images: 31\n",
      "FASDD only fire images: 12\n",
      "FASDD smoke and fire images: 26\n",
      "\n",
      "Test FASDD CV dataset len: 128\n",
      "Concatenate Test DFire and FASDD UAV datasets\n",
      "Test dataset len: 256\n",
      "Concatenate with FASDD CV dataset\n",
      "Test dataset len: 384\n",
      "\n",
      "====================\n",
      "TEST DFire dataset\n",
      "DFire Removed wrong images: 0\n",
      "DFire empty images: 62\n",
      "DFire only smoke images: 31\n",
      "DFire only fire images: 5\n",
      "DFire smoke and fire images: 30\n",
      "\n",
      "Test dataset len: 128\n",
      "\n",
      "====================\n",
      "TEST FASDD UAV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD empty images: 57\n",
      "FASDD only smoke images: 28\n",
      "FASDD only fire images: 1\n",
      "FASDD smoke and fire images: 42\n",
      "\n",
      "Test FASDD UAV dataset len: 128\n",
      "\n",
      "====================\n",
      "TEST FASDD CV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD empty images: 59\n",
      "FASDD only smoke images: 31\n",
      "FASDD only fire images: 12\n",
      "FASDD smoke and fire images: 26\n",
      "\n",
      "Test FASDD CV dataset len: 128\n",
      "Concatenate Test DFire and FASDD UAV datasets\n",
      "Test dataset len: 256\n",
      "Concatenate with FASDD CV dataset\n",
      "Test dataset len: 384\n"
     ]
    }
   ],
   "source": [
    "train_loader = dataloaders.get_train_loader()\n",
    "val_loader = dataloaders.get_val_loader()\n",
    "\n",
    "aimet_val_len = 2048\n",
    "aimet_val_loader = dataloaders.get_val_loader(val_ds_len = aimet_val_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b70d24-3934-4636-860f-7ab8c4e7b99a",
   "metadata": {},
   "source": [
    "### Dataset Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4a66723-f873-40a7-996d-0640db481f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Length: 640\n",
      "Test Dataset Length: 384\n",
      "Aimet Test Dataset Length: 384\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"\\n********* Datasets Length *********\")\n",
    "\n",
    "print(f'Train Dataset Length: {len(train_loader.dataset)}')\n",
    "logger.info(f'Train Dataset Length: {len(train_loader.dataset)}')\n",
    "\n",
    "print(f'Test Dataset Length: {len(val_loader.dataset)}')\n",
    "logger.info(f'Test Dataset Length: {len(val_loader.dataset)}')\n",
    "\n",
    "print(f'Aimet Test Dataset Length: {len(aimet_val_loader.dataset)}')\n",
    "logger.info(f'Aimet Test Dataset Length: {len(aimet_val_loader.dataset)}')\n",
    "logger.info(f'Aimet Val Loader individual lenght = {aimet_val_len}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15183310-3690-45fe-a282-d67b55e9cc4c",
   "metadata": {},
   "source": [
    "# Models Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac4fcfec-6bfb-42dd-b4b3-227a40ae8469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using BED Classifier\n",
      "\n",
      "Trainable parameters = 93266\n",
      "Total parameters = 93266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if config.MODEL == \"BED_AIMET\":   \n",
    "    print(\"Using BED Classifier\")\n",
    "    logger.info(\"\\nUsing BED Classifier\")\n",
    "    fp32_model = cnv_model.BED_CLASSIFIER_DOWNTO_28().to(config.DEVICE)    \n",
    "else:\n",
    "    print(\"Wrong Model\")\n",
    "    logger.info(\"Wrong Model\")\n",
    "    raise SystemExit(\"Wrong Model\")\n",
    "\n",
    "# MODEL PARAMETERS\n",
    "n_trainable = sum(p.numel() for p in fp32_model.parameters() if p.requires_grad)\n",
    "print(f'\\nTrainable parameters = {n_trainable}')\n",
    "logger.info(f'\\nTrainable parameters = {n_trainable}')\n",
    "\n",
    "n_params = parameters_to_vector(fp32_model.parameters()).numel()\n",
    "print(f'Total parameters = {n_params}\\n')\n",
    "logger.info(f'Total parameters = {n_params}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ca70e-262b-4c78-88d1-ec9e81176f4d",
   "metadata": {},
   "source": [
    "### Check Model Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce04b628-4a5b-4aa7-8668-0ad7b5a834c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model shape is tensor([[-0.0010, -0.1882],\n",
      "        [-0.0030, -0.1812],\n",
      "        [-0.0025, -0.1836],\n",
      "        [ 0.0005, -0.1826]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "BED Model Arquitecture\n",
      "BED_CLASSIFIER_DOWNTO_28(\n",
      "  (model): Sequential(\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv31): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu31): ReLU()\n",
      "    (conv32): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn32): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu32): ReLU()\n",
      "    (conv33): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu33): ReLU()\n",
      "    (conv34): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn34): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu34): ReLU()\n",
      "    (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv41): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu41): ReLU()\n",
      "    (conv42): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn42): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu42): ReLU()\n",
      "    (conv43): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu43): ReLU()\n",
      "    (conv44): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn44): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu44): ReLU()\n",
      "    (conv45): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn45): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu45): ReLU()\n",
      "    (conv46): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn46): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu46): ReLU()\n",
      "    (avgpool5): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (flatten5): Flatten(start_dim=1, end_dim=-1)\n",
      "    (linear51): Linear(in_features=64, out_features=16, bias=True)\n",
      "    (relu5): ReLU()\n",
      "    (linear52): Linear(in_features=16, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "in_rand_np = np.random.rand(4, 3, config.IMG_H, config.IMG_W)\n",
    "in_rand = torch.tensor(in_rand_np, dtype=torch.float32, device=config.DEVICE)\n",
    "out_test = fp32_model(in_rand)\n",
    "print(f'Model shape is {out_test}')\n",
    "print(f'BED Model Arquitecture\\n{fp32_model}')\n",
    "logger.info(f'Model shape is {out_test}')\n",
    "logger.info(f'BED Model Arquitecture\\n{fp32_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9011174c-9def-44c1-beb1-102bddb9f00b",
   "metadata": {},
   "source": [
    "# Torchinfo: model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d67b889d-874a-4ab2-b9f5-eafc49c5ee14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "BED_CLASSIFIER_DOWNTO_28                 [1, 2]                    --\n",
      "├─Sequential: 1-1                        [1, 2]                    --\n",
      "│    └─Conv2d: 2-1                       [1, 32, 224, 224]         864\n",
      "│    └─BatchNorm2d: 2-2                  [1, 32, 224, 224]         64\n",
      "│    └─ReLU: 2-3                         [1, 32, 224, 224]         --\n",
      "│    └─MaxPool2d: 2-4                    [1, 32, 112, 112]         --\n",
      "│    └─Conv2d: 2-5                       [1, 16, 112, 112]         4,608\n",
      "│    └─BatchNorm2d: 2-6                  [1, 16, 112, 112]         32\n",
      "│    └─ReLU: 2-7                         [1, 16, 112, 112]         --\n",
      "│    └─MaxPool2d: 2-8                    [1, 16, 56, 56]           --\n",
      "│    └─Conv2d: 2-9                       [1, 16, 56, 56]           256\n",
      "│    └─BatchNorm2d: 2-10                 [1, 16, 56, 56]           32\n",
      "│    └─ReLU: 2-11                        [1, 16, 56, 56]           --\n",
      "│    └─Conv2d: 2-12                      [1, 32, 56, 56]           4,608\n",
      "│    └─BatchNorm2d: 2-13                 [1, 32, 56, 56]           64\n",
      "│    └─ReLU: 2-14                        [1, 32, 56, 56]           --\n",
      "│    └─Conv2d: 2-15                      [1, 32, 56, 56]           1,024\n",
      "│    └─BatchNorm2d: 2-16                 [1, 32, 56, 56]           64\n",
      "│    └─ReLU: 2-17                        [1, 32, 56, 56]           --\n",
      "│    └─Conv2d: 2-18                      [1, 64, 56, 56]           18,432\n",
      "│    └─BatchNorm2d: 2-19                 [1, 64, 56, 56]           128\n",
      "│    └─ReLU: 2-20                        [1, 64, 56, 56]           --\n",
      "│    └─MaxPool2d: 2-21                   [1, 64, 28, 28]           --\n",
      "│    └─Conv2d: 2-22                      [1, 32, 28, 28]           2,048\n",
      "│    └─BatchNorm2d: 2-23                 [1, 32, 28, 28]           64\n",
      "│    └─ReLU: 2-24                        [1, 32, 28, 28]           --\n",
      "│    └─Conv2d: 2-25                      [1, 64, 28, 28]           18,432\n",
      "│    └─BatchNorm2d: 2-26                 [1, 64, 28, 28]           128\n",
      "│    └─ReLU: 2-27                        [1, 64, 28, 28]           --\n",
      "│    └─Conv2d: 2-28                      [1, 32, 28, 28]           2,048\n",
      "│    └─BatchNorm2d: 2-29                 [1, 32, 28, 28]           64\n",
      "│    └─ReLU: 2-30                        [1, 32, 28, 28]           --\n",
      "│    └─Conv2d: 2-31                      [1, 64, 28, 28]           18,432\n",
      "│    └─BatchNorm2d: 2-32                 [1, 64, 28, 28]           128\n",
      "│    └─ReLU: 2-33                        [1, 64, 28, 28]           --\n",
      "│    └─Conv2d: 2-34                      [1, 32, 28, 28]           2,048\n",
      "│    └─BatchNorm2d: 2-35                 [1, 32, 28, 28]           64\n",
      "│    └─ReLU: 2-36                        [1, 32, 28, 28]           --\n",
      "│    └─Conv2d: 2-37                      [1, 64, 28, 28]           18,432\n",
      "│    └─BatchNorm2d: 2-38                 [1, 64, 28, 28]           128\n",
      "│    └─ReLU: 2-39                        [1, 64, 28, 28]           --\n",
      "│    └─AdaptiveAvgPool2d: 2-40           [1, 64, 1, 1]             --\n",
      "│    └─Flatten: 2-41                     [1, 64]                   --\n",
      "│    └─Linear: 2-42                      [1, 16]                   1,040\n",
      "│    └─ReLU: 2-43                        [1, 16]                   --\n",
      "│    └─Linear: 2-44                      [1, 2]                    34\n",
      "==========================================================================================\n",
      "Total params: 93,266\n",
      "Trainable params: 93,266\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 225.59\n",
      "==========================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 39.74\n",
      "Params size (MB): 0.37\n",
      "Estimated Total Size (MB): 40.71\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(fp32_model, input_size=(1, 3, config.IMG_H, config.IMG_W)))\n",
    "logger.info(\"Original FP32 Model Summary\")\n",
    "logger.info(summary(fp32_model, input_size=(config.BATCH_SIZE, 3, config.IMG_H, config.IMG_W)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0f708-5b0a-40a8-a587-89fd3ac364f8",
   "metadata": {},
   "source": [
    "# Load Pretrained or Initialize Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39cf7f82-ad2c-4e60-b4cc-e71f0c676a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model. Trained during 62 epochs\n"
     ]
    }
   ],
   "source": [
    "epochs_trained = utils.load_checkpoint(config.LOAD_MODEL_FILE, \n",
    "                                       fp32_model, \n",
    "                                       optimizer=None, \n",
    "                                       scheduler=None, \n",
    "                                       device=config.DEVICE)\n",
    "\n",
    "fp32_model.eval()\n",
    "logger.info(f\"Loading Model. Trained during {epochs_trained} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb73ad-53e7-41f5-a6c7-2ed6c471b835",
   "metadata": {},
   "source": [
    "# Save ONNX original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "359d083d-5bff-4527-8151-81f454dfd493",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 3, config.IMG_H, config.IMG_W)\n",
    "\n",
    "torch.onnx.export(fp32_model, torch.randn(input_shape).to(config.DEVICE), config.RUN_FOLDER + 'fp32_model.onnx')\n",
    "#OnnxSaver.set_node_names('/models/fp32_model.onnx', fp32_model, input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a7b3d-ba26-4d62-a0c0-9132bb9fb35f",
   "metadata": {},
   "source": [
    "# AIMET Spatial SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f564b84-b70c-4e68-b8d5-6ae540ed069d",
   "metadata": {},
   "source": [
    "### Configure SVD Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43798232-a5fb-4ef5-b89c-2f5d87db0dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modules_to_ignore = [fp32_model.model.conv1]\n",
    "modules_to_ignore = [] # Let the first conv be splitted\n",
    "greedy_params = GreedySelectionParameters(\n",
    "    target_comp_ratio=Decimal(config.SVD_COMPRESSION_RATIO), \n",
    "    saved_eval_scores_dict=config.SVD_DIC_FILE)\n",
    "auto_params = SpatialSvdParameters.AutoModeParams(\n",
    "    greedy_params,\n",
    "    modules_to_ignore=modules_to_ignore)\n",
    "spatial_svd_params = SpatialSvdParameters(\n",
    "    mode=SpatialSvdParameters.Mode.auto,\n",
    "    params=auto_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136cbbb0-74c8-4ed1-bb30-6af7db2ea077",
   "metadata": {},
   "source": [
    "### Evaluate Model Callback\n",
    "\n",
    "Signature: (model, iterations, use_cuda)\n",
    "Return an accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ce9495c-ff17-4be7-b87a-f8720087dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, iterations, use_cuda):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    #for batch_idx, (x, y) in enumerate(val_loader):\n",
    "    for batch_idx, (x, y) in enumerate(aimet_val_loader):\n",
    "        if use_cuda == True:\n",
    "            x, y = x.to('cuda'), y.to('cuda')\n",
    "        else:\n",
    "            model.to('cpu')\n",
    "        out = model(x)\n",
    "        if iterations is not None:\n",
    "            if batch_idx == iterations:\n",
    "                break\n",
    "        \n",
    "        # F1 average Macro   \n",
    "        yhat = torch.sigmoid(out.detach())\n",
    "        metrics.f1_metric_mean.update(yhat, y)\n",
    "    \n",
    "    f1_mean = metrics.f1_metric_mean.compute()\n",
    "    metrics.f1_metric_mean.reset()\n",
    "\n",
    "    print(f'F1 mean: {f1_mean:.4f}')\n",
    "    \n",
    "    return f1_mean.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953badff-069f-4e95-8a9e-4f96a54ab344",
   "metadata": {},
   "source": [
    "### Baseline F1 Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1827951-a0f9-4ebf-8c7d-3be08fa1bf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 mean: 0.9522\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "baseline_f1 = evaluate_model(fp32_model, None, True)\n",
    "print(type(baseline_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64e4c418-6d55-4445-985e-3b652b0bc9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-26 02:16:55,939 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:16:55,943 - Svd - INFO - Spatial SVD splitting layer: model.conv1 using rank: 1\n",
      "F1 mean: 0.0305\n",
      "2025-01-26 02:16:57,771 - CompRatioSelect - INFO - Layer model.conv1, comp_ratio 0.100000 ==> eval_score=0.030501\n",
      "2025-01-26 02:16:57,772 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:16:57,775 - Svd - INFO - Spatial SVD splitting layer: model.conv1 using rank: 1\n",
      "F1 mean: 0.0305\n",
      "2025-01-26 02:16:59,602 - CompRatioSelect - INFO - Layer model.conv1, comp_ratio 0.200000 ==> eval_score=0.030501\n",
      "2025-01-26 02:16:59,602 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:16:59,606 - Svd - INFO - Spatial SVD splitting layer: model.conv1 using rank: 2\n",
      "F1 mean: 0.4674\n",
      "2025-01-26 02:17:01,444 - CompRatioSelect - INFO - Layer model.conv1, comp_ratio 0.300000 ==> eval_score=0.467391\n",
      "2025-01-26 02:17:01,444 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:17:01,448 - Svd - INFO - Spatial SVD splitting layer: model.conv1 using rank: 3\n",
      "F1 mean: 0.5579\n",
      "2025-01-26 02:17:03,269 - CompRatioSelect - INFO - Layer model.conv1, comp_ratio 0.400000 ==> eval_score=0.557912\n",
      "2025-01-26 02:17:03,269 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:17:03,273 - Svd - INFO - Spatial SVD splitting layer: model.conv1 using rank: 4\n",
      "F1 mean: 0.5983\n",
      "2025-01-26 02:17:05,096 - CompRatioSelect - INFO - Layer model.conv1, comp_ratio 0.500000 ==> eval_score=0.598291\n",
      "2025-01-26 02:17:05,097 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:17:05,100 - Svd - INFO - Spatial SVD splitting layer: model.conv1 using rank: 4\n",
      "F1 mean: 0.5983\n",
      "2025-01-26 02:17:06,925 - CompRatioSelect - INFO - Layer model.conv1, comp_ratio 0.600000 ==> eval_score=0.598291\n",
      "2025-01-26 02:17:06,926 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:17:06,929 - Svd - INFO - Spatial SVD splitting layer: model.conv1 using rank: 5\n",
      "F1 mean: 0.6903\n",
      "2025-01-26 02:17:08,743 - CompRatioSelect - INFO - Layer model.conv1, comp_ratio 0.700000 ==> eval_score=0.690273\n",
      "2025-01-26 02:17:08,743 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:17:08,750 - Svd - INFO - Spatial SVD splitting layer: model.conv1 using rank: 6\n",
      "F1 mean: 0.9489\n",
      "2025-01-26 02:17:10,589 - CompRatioSelect - INFO - Layer model.conv1, comp_ratio 0.800000 ==> eval_score=0.948903\n",
      "2025-01-26 02:17:10,590 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:17:10,593 - Svd - INFO - Spatial SVD splitting layer: model.conv1 using rank: 7\n",
      "F1 mean: 0.9467\n",
      "2025-01-26 02:17:12,416 - CompRatioSelect - INFO - Layer model.conv1, comp_ratio 0.900000 ==> eval_score=0.946728\n",
      "2025-01-26 02:17:12,417 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:17:12,424 - Svd - INFO - Spatial SVD splitting layer: model.conv2 using rank: 3\n",
      "F1 mean: 0.6280\n",
      "2025-01-26 02:17:14,262 - CompRatioSelect - INFO - Layer model.conv2, comp_ratio 0.100000 ==> eval_score=0.627974\n",
      "2025-01-26 02:17:14,263 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:17:14,266 - Svd - INFO - Spatial SVD splitting layer: model.conv2 using rank: 6\n",
      "F1 mean: 0.8084\n",
      "2025-01-26 02:17:16,101 - CompRatioSelect - INFO - Layer model.conv2, comp_ratio 0.200000 ==> eval_score=0.808363\n",
      "2025-01-26 02:17:16,101 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:17:16,105 - Svd - INFO - Spatial SVD splitting layer: model.conv2 using rank: 9\n",
      "F1 mean: 0.8721\n",
      "2025-01-26 02:17:17,927 - CompRatioSelect - INFO - Layer model.conv2, comp_ratio 0.300000 ==> eval_score=0.872104\n",
      "2025-01-26 02:17:17,928 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:17:17,931 - Svd - INFO - Spatial SVD splitting layer: model.conv2 using rank: 12\n",
      "F1 mean: 0.8604\n",
      "2025-01-26 02:17:19,773 - CompRatioSelect - INFO - Layer model.conv2, comp_ratio 0.400000 ==> eval_score=0.860360\n",
      "2025-01-26 02:17:19,773 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:17:19,776 - Svd - INFO - Spatial SVD splitting layer: model.conv2 using rank: 16\n",
      "F1 mean: 0.8885\n",
      "2025-01-26 02:17:21,593 - CompRatioSelect - INFO - Layer model.conv2, comp_ratio 0.500000 ==> eval_score=0.888460\n",
      "2025-01-26 02:17:21,594 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:17:21,597 - Svd - INFO - Spatial SVD splitting layer: model.conv2 using rank: 19\n",
      "F1 mean: 0.9231\n",
      "2025-01-26 02:17:23,433 - CompRatioSelect - INFO - Layer model.conv2, comp_ratio 0.600000 ==> eval_score=0.923112\n",
      "2025-01-26 02:17:23,433 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:17:23,440 - Svd - INFO - Spatial SVD splitting layer: model.conv2 using rank: 22\n",
      "F1 mean: 0.9376\n",
      "2025-01-26 02:17:25,279 - CompRatioSelect - INFO - Layer model.conv2, comp_ratio 0.700000 ==> eval_score=0.937649\n",
      "2025-01-26 02:17:25,280 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:17:25,283 - Svd - INFO - Spatial SVD splitting layer: model.conv2 using rank: 25\n",
      "F1 mean: 0.9467\n",
      "2025-01-26 02:17:27,109 - CompRatioSelect - INFO - Layer model.conv2, comp_ratio 0.800000 ==> eval_score=0.946663\n",
      "2025-01-26 02:17:27,109 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:17:27,113 - Svd - INFO - Spatial SVD splitting layer: model.conv2 using rank: 28\n",
      "F1 mean: 0.9528\n",
      "2025-01-26 02:17:28,958 - CompRatioSelect - INFO - Layer model.conv2, comp_ratio 0.900000 ==> eval_score=0.952776\n",
      "2025-01-26 02:17:28,958 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:17:28,963 - Svd - INFO - Spatial SVD splitting layer: model.conv31 using rank: 1\n",
      "F1 mean: 0.3169\n",
      "2025-01-26 02:17:30,794 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.100000 ==> eval_score=0.316864\n",
      "2025-01-26 02:17:30,794 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:17:30,801 - Svd - INFO - Spatial SVD splitting layer: model.conv31 using rank: 1\n",
      "F1 mean: 0.3169\n",
      "2025-01-26 02:17:32,664 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.200000 ==> eval_score=0.316864\n",
      "2025-01-26 02:17:32,664 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:17:32,667 - Svd - INFO - Spatial SVD splitting layer: model.conv31 using rank: 2\n",
      "F1 mean: 0.4000\n",
      "2025-01-26 02:17:34,496 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.300000 ==> eval_score=0.399972\n",
      "2025-01-26 02:17:34,497 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:17:34,506 - Svd - INFO - Spatial SVD splitting layer: model.conv31 using rank: 3\n",
      "F1 mean: 0.5977\n",
      "2025-01-26 02:17:36,331 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.400000 ==> eval_score=0.597683\n",
      "2025-01-26 02:17:36,331 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:17:36,334 - Svd - INFO - Spatial SVD splitting layer: model.conv31 using rank: 4\n",
      "F1 mean: 0.6262\n",
      "2025-01-26 02:17:38,158 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.500000 ==> eval_score=0.626242\n",
      "2025-01-26 02:17:38,159 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:17:38,162 - Svd - INFO - Spatial SVD splitting layer: model.conv31 using rank: 4\n",
      "F1 mean: 0.6262\n",
      "2025-01-26 02:17:39,992 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.600000 ==> eval_score=0.626242\n",
      "2025-01-26 02:17:39,992 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:17:39,996 - Svd - INFO - Spatial SVD splitting layer: model.conv31 using rank: 5\n",
      "F1 mean: 0.7374\n",
      "2025-01-26 02:17:41,824 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.700000 ==> eval_score=0.737392\n",
      "2025-01-26 02:17:41,825 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:17:41,828 - Svd - INFO - Spatial SVD splitting layer: model.conv31 using rank: 6\n",
      "F1 mean: 0.8274\n",
      "2025-01-26 02:17:43,660 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.800000 ==> eval_score=0.827370\n",
      "2025-01-26 02:17:43,661 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:17:43,668 - Svd - INFO - Spatial SVD splitting layer: model.conv31 using rank: 7\n",
      "F1 mean: 0.8521\n",
      "2025-01-26 02:17:45,490 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.900000 ==> eval_score=0.852138\n",
      "2025-01-26 02:17:45,491 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:17:45,494 - Svd - INFO - Spatial SVD splitting layer: model.conv32 using rank: 3\n",
      "F1 mean: 0.2236\n",
      "2025-01-26 02:17:47,346 - CompRatioSelect - INFO - Layer model.conv32, comp_ratio 0.100000 ==> eval_score=0.223588\n",
      "2025-01-26 02:17:47,347 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:17:47,350 - Svd - INFO - Spatial SVD splitting layer: model.conv32 using rank: 6\n",
      "F1 mean: 0.2122\n",
      "2025-01-26 02:17:49,182 - CompRatioSelect - INFO - Layer model.conv32, comp_ratio 0.200000 ==> eval_score=0.212155\n",
      "2025-01-26 02:17:49,182 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:17:49,186 - Svd - INFO - Spatial SVD splitting layer: model.conv32 using rank: 9\n",
      "F1 mean: 0.3384\n",
      "2025-01-26 02:17:51,011 - CompRatioSelect - INFO - Layer model.conv32, comp_ratio 0.300000 ==> eval_score=0.338384\n",
      "2025-01-26 02:17:51,012 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:17:51,015 - Svd - INFO - Spatial SVD splitting layer: model.conv32 using rank: 12\n",
      "F1 mean: 0.2267\n",
      "2025-01-26 02:17:52,845 - CompRatioSelect - INFO - Layer model.conv32, comp_ratio 0.400000 ==> eval_score=0.226675\n",
      "2025-01-26 02:17:52,845 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:17:52,850 - Svd - INFO - Spatial SVD splitting layer: model.conv32 using rank: 16\n",
      "F1 mean: 0.8768\n",
      "2025-01-26 02:17:54,670 - CompRatioSelect - INFO - Layer model.conv32, comp_ratio 0.500000 ==> eval_score=0.876839\n",
      "2025-01-26 02:17:54,670 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:17:54,674 - Svd - INFO - Spatial SVD splitting layer: model.conv32 using rank: 19\n",
      "F1 mean: 0.8714\n",
      "2025-01-26 02:17:56,520 - CompRatioSelect - INFO - Layer model.conv32, comp_ratio 0.600000 ==> eval_score=0.871368\n",
      "2025-01-26 02:17:56,521 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:17:56,524 - Svd - INFO - Spatial SVD splitting layer: model.conv32 using rank: 22\n",
      "F1 mean: 0.9064\n",
      "2025-01-26 02:17:58,361 - CompRatioSelect - INFO - Layer model.conv32, comp_ratio 0.700000 ==> eval_score=0.906371\n",
      "2025-01-26 02:17:58,362 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:17:58,365 - Svd - INFO - Spatial SVD splitting layer: model.conv32 using rank: 25\n",
      "F1 mean: 0.9224\n",
      "2025-01-26 02:18:00,195 - CompRatioSelect - INFO - Layer model.conv32, comp_ratio 0.800000 ==> eval_score=0.922411\n",
      "2025-01-26 02:18:00,195 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:18:00,202 - Svd - INFO - Spatial SVD splitting layer: model.conv32 using rank: 28\n",
      "F1 mean: 0.9385\n",
      "2025-01-26 02:18:02,057 - CompRatioSelect - INFO - Layer model.conv32, comp_ratio 0.900000 ==> eval_score=0.938452\n",
      "2025-01-26 02:18:02,058 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:18:02,063 - Svd - INFO - Spatial SVD splitting layer: model.conv33 using rank: 1\n",
      "F1 mean: 0.0053\n",
      "2025-01-26 02:18:03,878 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.100000 ==> eval_score=0.005263\n",
      "2025-01-26 02:18:03,879 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:18:03,882 - Svd - INFO - Spatial SVD splitting layer: model.conv33 using rank: 3\n",
      "F1 mean: 0.0000\n",
      "2025-01-26 02:18:05,706 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.200000 ==> eval_score=0.000000\n",
      "2025-01-26 02:18:05,707 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:18:05,710 - Svd - INFO - Spatial SVD splitting layer: model.conv33 using rank: 4\n",
      "F1 mean: 0.0000\n",
      "2025-01-26 02:18:07,540 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.300000 ==> eval_score=0.000000\n",
      "2025-01-26 02:18:07,540 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:18:07,544 - Svd - INFO - Spatial SVD splitting layer: model.conv33 using rank: 6\n",
      "F1 mean: 0.5772\n",
      "2025-01-26 02:18:09,378 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.400000 ==> eval_score=0.577160\n",
      "2025-01-26 02:18:09,378 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:18:09,382 - Svd - INFO - Spatial SVD splitting layer: model.conv33 using rank: 8\n",
      "F1 mean: 0.6844\n",
      "2025-01-26 02:18:11,225 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.500000 ==> eval_score=0.684384\n",
      "2025-01-26 02:18:11,226 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:18:11,233 - Svd - INFO - Spatial SVD splitting layer: model.conv33 using rank: 9\n",
      "F1 mean: 0.7734\n",
      "2025-01-26 02:18:13,056 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.600000 ==> eval_score=0.773400\n",
      "2025-01-26 02:18:13,056 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:18:13,060 - Svd - INFO - Spatial SVD splitting layer: model.conv33 using rank: 11\n",
      "F1 mean: 0.8210\n",
      "2025-01-26 02:18:14,901 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.700000 ==> eval_score=0.821031\n",
      "2025-01-26 02:18:14,902 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:18:14,909 - Svd - INFO - Spatial SVD splitting layer: model.conv33 using rank: 12\n",
      "F1 mean: 0.8511\n",
      "2025-01-26 02:18:16,747 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.800000 ==> eval_score=0.851065\n",
      "2025-01-26 02:18:16,747 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:18:16,750 - Svd - INFO - Spatial SVD splitting layer: model.conv33 using rank: 14\n",
      "F1 mean: 0.9074\n",
      "2025-01-26 02:18:18,586 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.900000 ==> eval_score=0.907386\n",
      "2025-01-26 02:18:18,587 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:18:18,590 - Svd - INFO - Spatial SVD splitting layer: model.conv34 using rank: 6\n",
      "F1 mean: 0.4207\n",
      "2025-01-26 02:18:20,426 - CompRatioSelect - INFO - Layer model.conv34, comp_ratio 0.100000 ==> eval_score=0.420712\n",
      "2025-01-26 02:18:20,427 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:18:20,430 - Svd - INFO - Spatial SVD splitting layer: model.conv34 using rank: 12\n",
      "F1 mean: 0.6452\n",
      "2025-01-26 02:18:22,264 - CompRatioSelect - INFO - Layer model.conv34, comp_ratio 0.200000 ==> eval_score=0.645164\n",
      "2025-01-26 02:18:22,265 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:18:22,270 - Svd - INFO - Spatial SVD splitting layer: model.conv34 using rank: 19\n",
      "F1 mean: 0.8250\n",
      "2025-01-26 02:18:24,114 - CompRatioSelect - INFO - Layer model.conv34, comp_ratio 0.300000 ==> eval_score=0.824999\n",
      "2025-01-26 02:18:24,115 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:18:24,118 - Svd - INFO - Spatial SVD splitting layer: model.conv34 using rank: 25\n",
      "F1 mean: 0.8638\n",
      "2025-01-26 02:18:25,956 - CompRatioSelect - INFO - Layer model.conv34, comp_ratio 0.400000 ==> eval_score=0.863774\n",
      "2025-01-26 02:18:25,957 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:18:25,960 - Svd - INFO - Spatial SVD splitting layer: model.conv34 using rank: 32\n",
      "F1 mean: 0.8926\n",
      "2025-01-26 02:18:27,790 - CompRatioSelect - INFO - Layer model.conv34, comp_ratio 0.500000 ==> eval_score=0.892556\n",
      "2025-01-26 02:18:27,790 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:18:27,793 - Svd - INFO - Spatial SVD splitting layer: model.conv34 using rank: 38\n",
      "F1 mean: 0.9209\n",
      "2025-01-26 02:18:29,617 - CompRatioSelect - INFO - Layer model.conv34, comp_ratio 0.600000 ==> eval_score=0.920950\n",
      "2025-01-26 02:18:29,618 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:18:29,621 - Svd - INFO - Spatial SVD splitting layer: model.conv34 using rank: 44\n",
      "F1 mean: 0.9348\n",
      "2025-01-26 02:18:31,450 - CompRatioSelect - INFO - Layer model.conv34, comp_ratio 0.700000 ==> eval_score=0.934827\n",
      "2025-01-26 02:18:31,450 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:18:31,454 - Svd - INFO - Spatial SVD splitting layer: model.conv34 using rank: 51\n",
      "F1 mean: 0.9457\n",
      "2025-01-26 02:18:33,290 - CompRatioSelect - INFO - Layer model.conv34, comp_ratio 0.800000 ==> eval_score=0.945740\n",
      "2025-01-26 02:18:33,291 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:18:33,294 - Svd - INFO - Spatial SVD splitting layer: model.conv34 using rank: 57\n",
      "F1 mean: 0.9525\n",
      "2025-01-26 02:18:35,136 - CompRatioSelect - INFO - Layer model.conv34, comp_ratio 0.900000 ==> eval_score=0.952498\n",
      "2025-01-26 02:18:35,137 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:18:35,140 - Svd - INFO - Spatial SVD splitting layer: model.conv41 using rank: 2\n",
      "F1 mean: 0.0000\n",
      "2025-01-26 02:18:36,968 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.100000 ==> eval_score=0.000000\n",
      "2025-01-26 02:18:36,969 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:18:36,972 - Svd - INFO - Spatial SVD splitting layer: model.conv41 using rank: 4\n",
      "F1 mean: 0.0354\n",
      "2025-01-26 02:18:38,801 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.200000 ==> eval_score=0.035354\n",
      "2025-01-26 02:18:38,801 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:18:38,804 - Svd - INFO - Spatial SVD splitting layer: model.conv41 using rank: 6\n",
      "F1 mean: 0.1810\n",
      "2025-01-26 02:18:40,629 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.300000 ==> eval_score=0.181043\n",
      "2025-01-26 02:18:40,630 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:18:40,633 - Svd - INFO - Spatial SVD splitting layer: model.conv41 using rank: 8\n",
      "F1 mean: 0.4407\n",
      "2025-01-26 02:18:42,466 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.400000 ==> eval_score=0.440739\n",
      "2025-01-26 02:18:42,466 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:18:42,470 - Svd - INFO - Spatial SVD splitting layer: model.conv41 using rank: 10\n",
      "F1 mean: 0.6842\n",
      "2025-01-26 02:18:44,286 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.500000 ==> eval_score=0.684159\n",
      "2025-01-26 02:18:44,287 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:18:44,290 - Svd - INFO - Spatial SVD splitting layer: model.conv41 using rank: 12\n",
      "F1 mean: 0.7418\n",
      "2025-01-26 02:18:46,153 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.600000 ==> eval_score=0.741842\n",
      "2025-01-26 02:18:46,154 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:18:46,157 - Svd - INFO - Spatial SVD splitting layer: model.conv41 using rank: 14\n",
      "F1 mean: 0.8469\n",
      "2025-01-26 02:18:47,986 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.700000 ==> eval_score=0.846850\n",
      "2025-01-26 02:18:47,986 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:18:47,990 - Svd - INFO - Spatial SVD splitting layer: model.conv41 using rank: 17\n",
      "F1 mean: 0.9076\n",
      "2025-01-26 02:18:49,808 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.800000 ==> eval_score=0.907624\n",
      "2025-01-26 02:18:49,809 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:18:49,814 - Svd - INFO - Spatial SVD splitting layer: model.conv41 using rank: 19\n",
      "F1 mean: 0.9184\n",
      "2025-01-26 02:18:51,638 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.900000 ==> eval_score=0.918375\n",
      "2025-01-26 02:18:51,639 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:18:51,642 - Svd - INFO - Spatial SVD splitting layer: model.conv42 using rank: 6\n",
      "F1 mean: 0.7569\n",
      "2025-01-26 02:18:53,470 - CompRatioSelect - INFO - Layer model.conv42, comp_ratio 0.100000 ==> eval_score=0.756926\n",
      "2025-01-26 02:18:53,470 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:18:53,475 - Svd - INFO - Spatial SVD splitting layer: model.conv42 using rank: 12\n",
      "F1 mean: 0.8588\n",
      "2025-01-26 02:18:55,307 - CompRatioSelect - INFO - Layer model.conv42, comp_ratio 0.200000 ==> eval_score=0.858814\n",
      "2025-01-26 02:18:55,307 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:18:55,310 - Svd - INFO - Spatial SVD splitting layer: model.conv42 using rank: 19\n",
      "F1 mean: 0.8925\n",
      "2025-01-26 02:18:57,139 - CompRatioSelect - INFO - Layer model.conv42, comp_ratio 0.300000 ==> eval_score=0.892521\n",
      "2025-01-26 02:18:57,140 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:18:57,143 - Svd - INFO - Spatial SVD splitting layer: model.conv42 using rank: 25\n",
      "F1 mean: 0.9181\n",
      "2025-01-26 02:18:58,972 - CompRatioSelect - INFO - Layer model.conv42, comp_ratio 0.400000 ==> eval_score=0.918064\n",
      "2025-01-26 02:18:58,972 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:18:58,976 - Svd - INFO - Spatial SVD splitting layer: model.conv42 using rank: 32\n",
      "F1 mean: 0.9296\n",
      "2025-01-26 02:19:00,815 - CompRatioSelect - INFO - Layer model.conv42, comp_ratio 0.500000 ==> eval_score=0.929562\n",
      "2025-01-26 02:19:00,815 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:19:00,819 - Svd - INFO - Spatial SVD splitting layer: model.conv42 using rank: 38\n",
      "F1 mean: 0.9394\n",
      "2025-01-26 02:19:02,653 - CompRatioSelect - INFO - Layer model.conv42, comp_ratio 0.600000 ==> eval_score=0.939353\n",
      "2025-01-26 02:19:02,654 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:19:02,657 - Svd - INFO - Spatial SVD splitting layer: model.conv42 using rank: 44\n",
      "F1 mean: 0.9389\n",
      "2025-01-26 02:19:04,495 - CompRatioSelect - INFO - Layer model.conv42, comp_ratio 0.700000 ==> eval_score=0.938944\n",
      "2025-01-26 02:19:04,495 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:19:04,499 - Svd - INFO - Spatial SVD splitting layer: model.conv42 using rank: 51\n",
      "F1 mean: 0.9428\n",
      "2025-01-26 02:19:06,339 - CompRatioSelect - INFO - Layer model.conv42, comp_ratio 0.800000 ==> eval_score=0.942761\n",
      "2025-01-26 02:19:06,340 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:19:06,345 - Svd - INFO - Spatial SVD splitting layer: model.conv42 using rank: 57\n",
      "F1 mean: 0.9448\n",
      "2025-01-26 02:19:08,183 - CompRatioSelect - INFO - Layer model.conv42, comp_ratio 0.900000 ==> eval_score=0.944799\n",
      "2025-01-26 02:19:08,183 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:19:08,187 - Svd - INFO - Spatial SVD splitting layer: model.conv43 using rank: 2\n",
      "F1 mean: 0.3863\n",
      "2025-01-26 02:19:10,010 - CompRatioSelect - INFO - Layer model.conv43, comp_ratio 0.100000 ==> eval_score=0.386256\n",
      "2025-01-26 02:19:10,011 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:19:10,014 - Svd - INFO - Spatial SVD splitting layer: model.conv43 using rank: 4\n",
      "F1 mean: 0.4531\n",
      "2025-01-26 02:19:11,854 - CompRatioSelect - INFO - Layer model.conv43, comp_ratio 0.200000 ==> eval_score=0.453103\n",
      "2025-01-26 02:19:11,855 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:19:11,858 - Svd - INFO - Spatial SVD splitting layer: model.conv43 using rank: 6\n",
      "F1 mean: 0.7310\n",
      "2025-01-26 02:19:13,685 - CompRatioSelect - INFO - Layer model.conv43, comp_ratio 0.300000 ==> eval_score=0.731003\n",
      "2025-01-26 02:19:13,686 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:19:13,796 - Svd - INFO - Spatial SVD splitting layer: model.conv43 using rank: 8\n",
      "F1 mean: 0.7534\n",
      "2025-01-26 02:19:15,634 - CompRatioSelect - INFO - Layer model.conv43, comp_ratio 0.400000 ==> eval_score=0.753441\n",
      "2025-01-26 02:19:15,634 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:19:15,637 - Svd - INFO - Spatial SVD splitting layer: model.conv43 using rank: 10\n",
      "F1 mean: 0.8960\n",
      "2025-01-26 02:19:17,462 - CompRatioSelect - INFO - Layer model.conv43, comp_ratio 0.500000 ==> eval_score=0.896046\n",
      "2025-01-26 02:19:17,463 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:19:17,466 - Svd - INFO - Spatial SVD splitting layer: model.conv43 using rank: 12\n",
      "F1 mean: 0.9017\n",
      "2025-01-26 02:19:19,329 - CompRatioSelect - INFO - Layer model.conv43, comp_ratio 0.600000 ==> eval_score=0.901694\n",
      "2025-01-26 02:19:19,330 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:19:19,333 - Svd - INFO - Spatial SVD splitting layer: model.conv43 using rank: 14\n",
      "F1 mean: 0.9158\n",
      "2025-01-26 02:19:21,171 - CompRatioSelect - INFO - Layer model.conv43, comp_ratio 0.700000 ==> eval_score=0.915835\n",
      "2025-01-26 02:19:21,172 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:19:21,175 - Svd - INFO - Spatial SVD splitting layer: model.conv43 using rank: 17\n",
      "F1 mean: 0.9454\n",
      "2025-01-26 02:19:23,003 - CompRatioSelect - INFO - Layer model.conv43, comp_ratio 0.800000 ==> eval_score=0.945384\n",
      "2025-01-26 02:19:23,004 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:19:23,007 - Svd - INFO - Spatial SVD splitting layer: model.conv43 using rank: 19\n",
      "F1 mean: 0.9435\n",
      "2025-01-26 02:19:24,834 - CompRatioSelect - INFO - Layer model.conv43, comp_ratio 0.900000 ==> eval_score=0.943541\n",
      "2025-01-26 02:19:24,835 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:19:24,838 - Svd - INFO - Spatial SVD splitting layer: model.conv44 using rank: 6\n",
      "F1 mean: 0.6250\n",
      "2025-01-26 02:19:26,673 - CompRatioSelect - INFO - Layer model.conv44, comp_ratio 0.100000 ==> eval_score=0.624998\n",
      "2025-01-26 02:19:26,673 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:19:26,678 - Svd - INFO - Spatial SVD splitting layer: model.conv44 using rank: 12\n",
      "F1 mean: 0.9194\n",
      "2025-01-26 02:19:28,502 - CompRatioSelect - INFO - Layer model.conv44, comp_ratio 0.200000 ==> eval_score=0.919361\n",
      "2025-01-26 02:19:28,502 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:19:28,506 - Svd - INFO - Spatial SVD splitting layer: model.conv44 using rank: 19\n",
      "F1 mean: 0.9340\n",
      "2025-01-26 02:19:30,342 - CompRatioSelect - INFO - Layer model.conv44, comp_ratio 0.300000 ==> eval_score=0.934031\n",
      "2025-01-26 02:19:30,343 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:19:30,346 - Svd - INFO - Spatial SVD splitting layer: model.conv44 using rank: 25\n",
      "F1 mean: 0.9417\n",
      "2025-01-26 02:19:32,186 - CompRatioSelect - INFO - Layer model.conv44, comp_ratio 0.400000 ==> eval_score=0.941662\n",
      "2025-01-26 02:19:32,187 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:19:32,190 - Svd - INFO - Spatial SVD splitting layer: model.conv44 using rank: 32\n",
      "F1 mean: 0.9458\n",
      "2025-01-26 02:19:34,019 - CompRatioSelect - INFO - Layer model.conv44, comp_ratio 0.500000 ==> eval_score=0.945765\n",
      "2025-01-26 02:19:34,020 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:19:34,023 - Svd - INFO - Spatial SVD splitting layer: model.conv44 using rank: 38\n",
      "F1 mean: 0.9491\n",
      "2025-01-26 02:19:35,863 - CompRatioSelect - INFO - Layer model.conv44, comp_ratio 0.600000 ==> eval_score=0.949136\n",
      "2025-01-26 02:19:35,863 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:19:35,867 - Svd - INFO - Spatial SVD splitting layer: model.conv44 using rank: 44\n",
      "F1 mean: 0.9504\n",
      "2025-01-26 02:19:37,697 - CompRatioSelect - INFO - Layer model.conv44, comp_ratio 0.700000 ==> eval_score=0.950395\n",
      "2025-01-26 02:19:37,698 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:19:37,701 - Svd - INFO - Spatial SVD splitting layer: model.conv44 using rank: 51\n",
      "F1 mean: 0.9537\n",
      "2025-01-26 02:19:39,539 - CompRatioSelect - INFO - Layer model.conv44, comp_ratio 0.800000 ==> eval_score=0.953667\n",
      "2025-01-26 02:19:39,540 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:19:39,543 - Svd - INFO - Spatial SVD splitting layer: model.conv44 using rank: 57\n",
      "F1 mean: 0.9537\n",
      "2025-01-26 02:19:41,393 - CompRatioSelect - INFO - Layer model.conv44, comp_ratio 0.900000 ==> eval_score=0.953667\n",
      "2025-01-26 02:19:41,394 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:19:41,397 - Svd - INFO - Spatial SVD splitting layer: model.conv45 using rank: 2\n",
      "F1 mean: 0.7520\n",
      "2025-01-26 02:19:43,224 - CompRatioSelect - INFO - Layer model.conv45, comp_ratio 0.100000 ==> eval_score=0.751990\n",
      "2025-01-26 02:19:43,225 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:19:43,228 - Svd - INFO - Spatial SVD splitting layer: model.conv45 using rank: 4\n",
      "F1 mean: 0.9351\n",
      "2025-01-26 02:19:45,070 - CompRatioSelect - INFO - Layer model.conv45, comp_ratio 0.200000 ==> eval_score=0.935134\n",
      "2025-01-26 02:19:45,070 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:19:45,074 - Svd - INFO - Spatial SVD splitting layer: model.conv45 using rank: 6\n",
      "F1 mean: 0.9538\n",
      "2025-01-26 02:19:46,898 - CompRatioSelect - INFO - Layer model.conv45, comp_ratio 0.300000 ==> eval_score=0.953805\n",
      "2025-01-26 02:19:46,898 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:19:46,905 - Svd - INFO - Spatial SVD splitting layer: model.conv45 using rank: 8\n",
      "F1 mean: 0.9478\n",
      "2025-01-26 02:19:48,734 - CompRatioSelect - INFO - Layer model.conv45, comp_ratio 0.400000 ==> eval_score=0.947849\n",
      "2025-01-26 02:19:48,735 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:19:48,739 - Svd - INFO - Spatial SVD splitting layer: model.conv45 using rank: 10\n",
      "F1 mean: 0.9393\n",
      "2025-01-26 02:19:50,581 - CompRatioSelect - INFO - Layer model.conv45, comp_ratio 0.500000 ==> eval_score=0.939250\n",
      "2025-01-26 02:19:50,582 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:19:50,587 - Svd - INFO - Spatial SVD splitting layer: model.conv45 using rank: 12\n",
      "F1 mean: 0.9482\n",
      "2025-01-26 02:19:52,414 - CompRatioSelect - INFO - Layer model.conv45, comp_ratio 0.600000 ==> eval_score=0.948194\n",
      "2025-01-26 02:19:52,415 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:19:52,418 - Svd - INFO - Spatial SVD splitting layer: model.conv45 using rank: 14\n",
      "F1 mean: 0.9473\n",
      "2025-01-26 02:19:54,240 - CompRatioSelect - INFO - Layer model.conv45, comp_ratio 0.700000 ==> eval_score=0.947320\n",
      "2025-01-26 02:19:54,241 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:19:54,245 - Svd - INFO - Spatial SVD splitting layer: model.conv45 using rank: 17\n",
      "F1 mean: 0.9522\n",
      "2025-01-26 02:19:56,068 - CompRatioSelect - INFO - Layer model.conv45, comp_ratio 0.800000 ==> eval_score=0.952233\n",
      "2025-01-26 02:19:56,069 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:19:56,076 - Svd - INFO - Spatial SVD splitting layer: model.conv45 using rank: 19\n",
      "F1 mean: 0.9522\n",
      "2025-01-26 02:19:57,902 - CompRatioSelect - INFO - Layer model.conv45, comp_ratio 0.900000 ==> eval_score=0.952233\n",
      "2025-01-26 02:19:57,903 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:19:57,908 - Svd - INFO - Spatial SVD splitting layer: model.conv46 using rank: 6\n",
      "F1 mean: 0.9498\n",
      "2025-01-26 02:19:59,746 - CompRatioSelect - INFO - Layer model.conv46, comp_ratio 0.100000 ==> eval_score=0.949770\n",
      "2025-01-26 02:19:59,746 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:19:59,750 - Svd - INFO - Spatial SVD splitting layer: model.conv46 using rank: 12\n",
      "F1 mean: 0.9537\n",
      "2025-01-26 02:20:01,584 - CompRatioSelect - INFO - Layer model.conv46, comp_ratio 0.200000 ==> eval_score=0.953667\n",
      "2025-01-26 02:20:01,585 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:20:01,588 - Svd - INFO - Spatial SVD splitting layer: model.conv46 using rank: 19\n",
      "F1 mean: 0.9522\n",
      "2025-01-26 02:20:03,422 - CompRatioSelect - INFO - Layer model.conv46, comp_ratio 0.300000 ==> eval_score=0.952233\n",
      "2025-01-26 02:20:03,423 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:20:03,426 - Svd - INFO - Spatial SVD splitting layer: model.conv46 using rank: 25\n",
      "F1 mean: 0.9522\n",
      "2025-01-26 02:20:05,252 - CompRatioSelect - INFO - Layer model.conv46, comp_ratio 0.400000 ==> eval_score=0.952233\n",
      "2025-01-26 02:20:05,253 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:20:05,260 - Svd - INFO - Spatial SVD splitting layer: model.conv46 using rank: 32\n",
      "F1 mean: 0.9522\n",
      "2025-01-26 02:20:07,102 - CompRatioSelect - INFO - Layer model.conv46, comp_ratio 0.500000 ==> eval_score=0.952233\n",
      "2025-01-26 02:20:07,103 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:20:07,110 - Svd - INFO - Spatial SVD splitting layer: model.conv46 using rank: 38\n",
      "F1 mean: 0.9522\n",
      "2025-01-26 02:20:08,958 - CompRatioSelect - INFO - Layer model.conv46, comp_ratio 0.600000 ==> eval_score=0.952233\n",
      "2025-01-26 02:20:08,958 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:20:08,965 - Svd - INFO - Spatial SVD splitting layer: model.conv46 using rank: 44\n",
      "F1 mean: 0.9522\n",
      "2025-01-26 02:20:10,795 - CompRatioSelect - INFO - Layer model.conv46, comp_ratio 0.700000 ==> eval_score=0.952233\n",
      "2025-01-26 02:20:10,796 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:20:10,799 - Svd - INFO - Spatial SVD splitting layer: model.conv46 using rank: 51\n",
      "F1 mean: 0.9522\n",
      "2025-01-26 02:20:12,630 - CompRatioSelect - INFO - Layer model.conv46, comp_ratio 0.800000 ==> eval_score=0.952233\n",
      "2025-01-26 02:20:12,630 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:20:12,634 - Svd - INFO - Spatial SVD splitting layer: model.conv46 using rank: 57\n",
      "F1 mean: 0.9522\n",
      "2025-01-26 02:20:14,458 - CompRatioSelect - INFO - Layer model.conv46, comp_ratio 0.900000 ==> eval_score=0.952233\n",
      "2025-01-26 02:20:14,458 - CompRatioSelect - INFO - Greedy selection: Saved eval dict to ./data/greedy_selection_eval_scores_dict.pkl\n",
      "2025-01-26 02:20:14,459 - CompRatioSelect - INFO - Greedy selection: overall_min_score=0.000000, overall_max_score=0.953805\n",
      "2025-01-26 02:20:14,459 - CompRatioSelect - INFO - Greedy selection: Original model cost=(Cost: memory=92288, mac=225592352)\n",
      "2025-01-26 02:20:14,463 - CompRatioSelect - INFO - Greedy selection: final choice - comp_ratio=0.649468, score=0.934245\n",
      "2025-01-26 02:20:14,466 - Svd - INFO - Spatial SVD splitting layer: model.conv1 using rank: 6\n",
      "2025-01-26 02:20:14,467 - Svd - INFO - Spatial SVD splitting layer: model.conv2 using rank: 22\n",
      "2025-01-26 02:20:14,477 - Svd - INFO - Spatial SVD splitting layer: model.conv32 using rank: 28\n",
      "2025-01-26 02:20:14,479 - Svd - INFO - Spatial SVD splitting layer: model.conv34 using rank: 44\n",
      "2025-01-26 02:20:14,483 - Svd - INFO - Spatial SVD splitting layer: model.conv42 using rank: 38\n",
      "2025-01-26 02:20:14,488 - Svd - INFO - Spatial SVD splitting layer: model.conv43 using rank: 17\n",
      "2025-01-26 02:20:14,490 - Svd - INFO - Spatial SVD splitting layer: model.conv44 using rank: 25\n",
      "2025-01-26 02:20:14,496 - Svd - INFO - Spatial SVD splitting layer: model.conv45 using rank: 4\n",
      "2025-01-26 02:20:14,497 - Svd - INFO - Spatial SVD splitting layer: model.conv46 using rank: 6\n",
      "F1 mean: 0.9522\n",
      "F1 mean: 0.8512\n"
     ]
    }
   ],
   "source": [
    "svd_model, stats = ModelCompressor.compress_model(\n",
    "    fp32_model,\n",
    "    input_shape=input_shape,\n",
    "    eval_callback=evaluate_model,\n",
    "    eval_iterations=None,\n",
    "    compress_scheme=CompressionScheme.spatial_svd,\n",
    "    cost_metric=CostMetric.mac,\n",
    "    parameters=spatial_svd_params,\n",
    "    visualization_url=None)                                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230034a4-077c-4934-af2c-55eb1b0e3f1a",
   "metadata": {},
   "source": [
    "### Copy Data Files to Running Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7a50476-093c-4576-85a8-f4c515be5b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments_bed_evolution/15_downto_28_aimet__big_aimet_ds__MAC__128_ds//svd_comp_ratios.pkl'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copyfile(\n",
    "    './data/greedy_selection_eval_scores_dict.pkl', \n",
    "    config.RUN_FOLDER + 'svd_eval_scores.pkl')\n",
    "shutil.copyfile(\n",
    "    './data/greedy_selection_comp_ratios_list.pkl', \n",
    "    config.RUN_FOLDER + 'svd_comp_ratios.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c76311-21bf-4f16-9d03-bae8220f5f6f",
   "metadata": {},
   "source": [
    "### Print Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "667d2c30-8733-4b30-aa77-0432f95135d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************************************\n",
      "Compressed Model Statistics\n",
      "Baseline model accuracy: 0.952233, Compressed model accuracy: 0.851159\n",
      "Compression ratio for memory=0.506826, mac=0.649468\n",
      "\n",
      "**********************************************************************************************\n",
      "\n",
      "Per-layer Stats\n",
      "    Name:model.conv1, compression-ratio: 0.8\n",
      "    Name:model.conv2, compression-ratio: 0.7\n",
      "    Name:model.conv31, compression-ratio: None\n",
      "    Name:model.conv32, compression-ratio: 0.9\n",
      "    Name:model.conv33, compression-ratio: None\n",
      "    Name:model.conv34, compression-ratio: 0.7\n",
      "    Name:model.conv41, compression-ratio: None\n",
      "    Name:model.conv42, compression-ratio: 0.6\n",
      "    Name:model.conv43, compression-ratio: 0.8\n",
      "    Name:model.conv44, compression-ratio: 0.4\n",
      "    Name:model.conv45, compression-ratio: 0.2\n",
      "    Name:model.conv46, compression-ratio: 0.1\n",
      "\n",
      "**********************************************************************************************\n",
      "\n",
      "Greedy Eval Dict\n",
      "    Layer: model.conv1\n",
      "        Ratio=0.1, Eval score=0.030501089990139008\n",
      "        Ratio=0.2, Eval score=0.030501089990139008\n",
      "        Ratio=0.3, Eval score=0.46739131212234497\n",
      "        Ratio=0.4, Eval score=0.5579122304916382\n",
      "        Ratio=0.5, Eval score=0.5982906222343445\n",
      "        Ratio=0.6, Eval score=0.5982906222343445\n",
      "        Ratio=0.7, Eval score=0.6902731657028198\n",
      "        Ratio=0.8, Eval score=0.9489027261734009\n",
      "        Ratio=0.9, Eval score=0.946727991104126\n",
      "    Layer: model.conv2\n",
      "        Ratio=0.1, Eval score=0.6279742121696472\n",
      "        Ratio=0.2, Eval score=0.808362603187561\n",
      "        Ratio=0.3, Eval score=0.8721039891242981\n",
      "        Ratio=0.4, Eval score=0.8603603839874268\n",
      "        Ratio=0.5, Eval score=0.8884599208831787\n",
      "        Ratio=0.6, Eval score=0.9231124520301819\n",
      "        Ratio=0.7, Eval score=0.9376488924026489\n",
      "        Ratio=0.8, Eval score=0.9466627240180969\n",
      "        Ratio=0.9, Eval score=0.952776312828064\n",
      "    Layer: model.conv31\n",
      "        Ratio=0.1, Eval score=0.3168635070323944\n",
      "        Ratio=0.2, Eval score=0.3168635070323944\n",
      "        Ratio=0.3, Eval score=0.39997169375419617\n",
      "        Ratio=0.4, Eval score=0.5976834297180176\n",
      "        Ratio=0.5, Eval score=0.6262422800064087\n",
      "        Ratio=0.6, Eval score=0.6262422800064087\n",
      "        Ratio=0.7, Eval score=0.7373924255371094\n",
      "        Ratio=0.8, Eval score=0.827370285987854\n",
      "        Ratio=0.9, Eval score=0.8521378040313721\n",
      "    Layer: model.conv32\n",
      "        Ratio=0.1, Eval score=0.2235882431268692\n",
      "        Ratio=0.2, Eval score=0.2121552973985672\n",
      "        Ratio=0.3, Eval score=0.3383844196796417\n",
      "        Ratio=0.4, Eval score=0.22667528688907623\n",
      "        Ratio=0.5, Eval score=0.8768386840820312\n",
      "        Ratio=0.6, Eval score=0.8713677525520325\n",
      "        Ratio=0.7, Eval score=0.9063711166381836\n",
      "        Ratio=0.8, Eval score=0.9224109649658203\n",
      "        Ratio=0.9, Eval score=0.9384523630142212\n",
      "    Layer: model.conv33\n",
      "        Ratio=0.1, Eval score=0.005263158120214939\n",
      "        Ratio=0.2, Eval score=0.0\n",
      "        Ratio=0.3, Eval score=0.0\n",
      "        Ratio=0.4, Eval score=0.5771604776382446\n",
      "        Ratio=0.5, Eval score=0.6843841671943665\n",
      "        Ratio=0.6, Eval score=0.7733999490737915\n",
      "        Ratio=0.7, Eval score=0.8210312128067017\n",
      "        Ratio=0.8, Eval score=0.8510650396347046\n",
      "        Ratio=0.9, Eval score=0.9073862433433533\n",
      "    Layer: model.conv34\n",
      "        Ratio=0.1, Eval score=0.4207119941711426\n",
      "        Ratio=0.2, Eval score=0.6451639533042908\n",
      "        Ratio=0.3, Eval score=0.8249989748001099\n",
      "        Ratio=0.4, Eval score=0.8637740015983582\n",
      "        Ratio=0.5, Eval score=0.8925555944442749\n",
      "        Ratio=0.6, Eval score=0.9209496974945068\n",
      "        Ratio=0.7, Eval score=0.9348269701004028\n",
      "        Ratio=0.8, Eval score=0.9457404613494873\n",
      "        Ratio=0.9, Eval score=0.9524977207183838\n",
      "    Layer: model.conv41\n",
      "        Ratio=0.1, Eval score=0.0\n",
      "        Ratio=0.2, Eval score=0.035353533923625946\n",
      "        Ratio=0.3, Eval score=0.18104338645935059\n",
      "        Ratio=0.4, Eval score=0.4407389760017395\n",
      "        Ratio=0.5, Eval score=0.6841587424278259\n",
      "        Ratio=0.6, Eval score=0.7418420910835266\n",
      "        Ratio=0.7, Eval score=0.8468502759933472\n",
      "        Ratio=0.8, Eval score=0.9076236486434937\n",
      "        Ratio=0.9, Eval score=0.9183752536773682\n",
      "    Layer: model.conv42\n",
      "        Ratio=0.1, Eval score=0.7569260001182556\n",
      "        Ratio=0.2, Eval score=0.858814001083374\n",
      "        Ratio=0.3, Eval score=0.892520546913147\n",
      "        Ratio=0.4, Eval score=0.918063759803772\n",
      "        Ratio=0.5, Eval score=0.929561972618103\n",
      "        Ratio=0.6, Eval score=0.9393530488014221\n",
      "        Ratio=0.7, Eval score=0.9389439821243286\n",
      "        Ratio=0.8, Eval score=0.9427613019943237\n",
      "        Ratio=0.9, Eval score=0.9447994828224182\n",
      "    Layer: model.conv43\n",
      "        Ratio=0.1, Eval score=0.3862559199333191\n",
      "        Ratio=0.2, Eval score=0.45310309529304504\n",
      "        Ratio=0.3, Eval score=0.7310030460357666\n",
      "        Ratio=0.4, Eval score=0.7534409165382385\n",
      "        Ratio=0.5, Eval score=0.8960457444190979\n",
      "        Ratio=0.6, Eval score=0.90169358253479\n",
      "        Ratio=0.7, Eval score=0.9158347249031067\n",
      "        Ratio=0.8, Eval score=0.9453843235969543\n",
      "        Ratio=0.9, Eval score=0.9435412883758545\n",
      "    Layer: model.conv44\n",
      "        Ratio=0.1, Eval score=0.6249977350234985\n",
      "        Ratio=0.2, Eval score=0.9193614721298218\n",
      "        Ratio=0.3, Eval score=0.9340312480926514\n",
      "        Ratio=0.4, Eval score=0.9416620135307312\n",
      "        Ratio=0.5, Eval score=0.9457648992538452\n",
      "        Ratio=0.6, Eval score=0.9491360187530518\n",
      "        Ratio=0.7, Eval score=0.9503947496414185\n",
      "        Ratio=0.8, Eval score=0.953667402267456\n",
      "        Ratio=0.9, Eval score=0.953667402267456\n",
      "    Layer: model.conv45\n",
      "        Ratio=0.1, Eval score=0.7519900798797607\n",
      "        Ratio=0.2, Eval score=0.9351338744163513\n",
      "        Ratio=0.3, Eval score=0.9538054466247559\n",
      "        Ratio=0.4, Eval score=0.9478493332862854\n",
      "        Ratio=0.5, Eval score=0.9392502307891846\n",
      "        Ratio=0.6, Eval score=0.9481937885284424\n",
      "        Ratio=0.7, Eval score=0.9473199844360352\n",
      "        Ratio=0.8, Eval score=0.9522332549095154\n",
      "        Ratio=0.9, Eval score=0.9522332549095154\n",
      "    Layer: model.conv46\n",
      "        Ratio=0.1, Eval score=0.949769914150238\n",
      "        Ratio=0.2, Eval score=0.953667402267456\n",
      "        Ratio=0.3, Eval score=0.9522332549095154\n",
      "        Ratio=0.4, Eval score=0.9522332549095154\n",
      "        Ratio=0.5, Eval score=0.9522332549095154\n",
      "        Ratio=0.6, Eval score=0.9522332549095154\n",
      "        Ratio=0.7, Eval score=0.9522332549095154\n",
      "        Ratio=0.8, Eval score=0.9522332549095154\n",
      "        Ratio=0.9, Eval score=0.9522332549095154\n",
      "\n",
      "**********************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(stats)\n",
    "logger.info(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbccfe1-310b-4463-9e48-d2cf0e3f6a7b",
   "metadata": {},
   "source": [
    "### Print Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a2a90fb-8ba0-4965-a897-9eda4cfa7c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BED_CLASSIFIER_DOWNTO_28(\n",
      "  (model): Sequential(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(3, 6, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(6, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(32, 22, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(22, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv31): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu31): ReLU()\n",
      "    (conv32): Sequential(\n",
      "      (0): Conv2d(16, 28, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(28, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn32): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu32): ReLU()\n",
      "    (conv33): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu33): ReLU()\n",
      "    (conv34): Sequential(\n",
      "      (0): Conv2d(32, 44, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(44, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn34): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu34): ReLU()\n",
      "    (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv41): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu41): ReLU()\n",
      "    (conv42): Sequential(\n",
      "      (0): Conv2d(32, 38, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(38, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn42): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu42): ReLU()\n",
      "    (conv43): Sequential(\n",
      "      (0): Conv2d(64, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): Conv2d(17, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu43): ReLU()\n",
      "    (conv44): Sequential(\n",
      "      (0): Conv2d(32, 25, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(25, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn44): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu44): ReLU()\n",
      "    (conv45): Sequential(\n",
      "      (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn45): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu45): ReLU()\n",
      "    (conv46): Sequential(\n",
      "      (0): Conv2d(32, 6, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(6, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn46): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu46): ReLU()\n",
      "    (avgpool5): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (flatten5): Flatten(start_dim=1, end_dim=-1)\n",
      "    (linear51): Linear(in_features=64, out_features=16, bias=True)\n",
      "    (relu5): ReLU()\n",
      "    (linear52): Linear(in_features=16, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(svd_model)\n",
    "logger.info(\"\\nSVD Model\")\n",
    "logger.info(svd_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056036ec-672f-4876-86af-2052cbc85495",
   "metadata": {},
   "source": [
    "### Torchinfo: model compressed summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36139480-e444-4ee6-98c0-0dcec0c25f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "BED_CLASSIFIER_DOWNTO_28                 [1, 2]                    --\n",
      "├─Sequential: 1-1                        [1, 2]                    --\n",
      "│    └─Sequential: 2-1                   [1, 32, 224, 224]         --\n",
      "│    │    └─Conv2d: 3-1                  [1, 6, 224, 224]          54\n",
      "│    │    └─Conv2d: 3-2                  [1, 32, 224, 224]         576\n",
      "│    └─BatchNorm2d: 2-2                  [1, 32, 224, 224]         64\n",
      "│    └─ReLU: 2-3                         [1, 32, 224, 224]         --\n",
      "│    └─MaxPool2d: 2-4                    [1, 32, 112, 112]         --\n",
      "│    └─Sequential: 2-5                   [1, 16, 112, 112]         --\n",
      "│    │    └─Conv2d: 3-3                  [1, 22, 112, 112]         2,112\n",
      "│    │    └─Conv2d: 3-4                  [1, 16, 112, 112]         1,056\n",
      "│    └─BatchNorm2d: 2-6                  [1, 16, 112, 112]         32\n",
      "│    └─ReLU: 2-7                         [1, 16, 112, 112]         --\n",
      "│    └─MaxPool2d: 2-8                    [1, 16, 56, 56]           --\n",
      "│    └─Conv2d: 2-9                       [1, 16, 56, 56]           256\n",
      "│    └─BatchNorm2d: 2-10                 [1, 16, 56, 56]           32\n",
      "│    └─ReLU: 2-11                        [1, 16, 56, 56]           --\n",
      "│    └─Sequential: 2-12                  [1, 32, 56, 56]           --\n",
      "│    │    └─Conv2d: 3-5                  [1, 28, 56, 56]           1,344\n",
      "│    │    └─Conv2d: 3-6                  [1, 32, 56, 56]           2,688\n",
      "│    └─BatchNorm2d: 2-13                 [1, 32, 56, 56]           64\n",
      "│    └─ReLU: 2-14                        [1, 32, 56, 56]           --\n",
      "│    └─Conv2d: 2-15                      [1, 32, 56, 56]           1,024\n",
      "│    └─BatchNorm2d: 2-16                 [1, 32, 56, 56]           64\n",
      "│    └─ReLU: 2-17                        [1, 32, 56, 56]           --\n",
      "│    └─Sequential: 2-18                  [1, 64, 56, 56]           --\n",
      "│    │    └─Conv2d: 3-7                  [1, 44, 56, 56]           4,224\n",
      "│    │    └─Conv2d: 3-8                  [1, 64, 56, 56]           8,448\n",
      "│    └─BatchNorm2d: 2-19                 [1, 64, 56, 56]           128\n",
      "│    └─ReLU: 2-20                        [1, 64, 56, 56]           --\n",
      "│    └─MaxPool2d: 2-21                   [1, 64, 28, 28]           --\n",
      "│    └─Conv2d: 2-22                      [1, 32, 28, 28]           2,048\n",
      "│    └─BatchNorm2d: 2-23                 [1, 32, 28, 28]           64\n",
      "│    └─ReLU: 2-24                        [1, 32, 28, 28]           --\n",
      "│    └─Sequential: 2-25                  [1, 64, 28, 28]           --\n",
      "│    │    └─Conv2d: 3-9                  [1, 38, 28, 28]           3,648\n",
      "│    │    └─Conv2d: 3-10                 [1, 64, 28, 28]           7,296\n",
      "│    └─BatchNorm2d: 2-26                 [1, 64, 28, 28]           128\n",
      "│    └─ReLU: 2-27                        [1, 64, 28, 28]           --\n",
      "│    └─Sequential: 2-28                  [1, 32, 28, 28]           --\n",
      "│    │    └─Conv2d: 3-11                 [1, 17, 28, 28]           1,088\n",
      "│    │    └─Conv2d: 3-12                 [1, 32, 28, 28]           544\n",
      "│    └─BatchNorm2d: 2-29                 [1, 32, 28, 28]           64\n",
      "│    └─ReLU: 2-30                        [1, 32, 28, 28]           --\n",
      "│    └─Sequential: 2-31                  [1, 64, 28, 28]           --\n",
      "│    │    └─Conv2d: 3-13                 [1, 25, 28, 28]           2,400\n",
      "│    │    └─Conv2d: 3-14                 [1, 64, 28, 28]           4,800\n",
      "│    └─BatchNorm2d: 2-32                 [1, 64, 28, 28]           128\n",
      "│    └─ReLU: 2-33                        [1, 64, 28, 28]           --\n",
      "│    └─Sequential: 2-34                  [1, 32, 28, 28]           --\n",
      "│    │    └─Conv2d: 3-15                 [1, 4, 28, 28]            256\n",
      "│    │    └─Conv2d: 3-16                 [1, 32, 28, 28]           128\n",
      "│    └─BatchNorm2d: 2-35                 [1, 32, 28, 28]           64\n",
      "│    └─ReLU: 2-36                        [1, 32, 28, 28]           --\n",
      "│    └─Sequential: 2-37                  [1, 64, 28, 28]           --\n",
      "│    │    └─Conv2d: 3-17                 [1, 6, 28, 28]            576\n",
      "│    │    └─Conv2d: 3-18                 [1, 64, 28, 28]           1,152\n",
      "│    └─BatchNorm2d: 2-38                 [1, 64, 28, 28]           128\n",
      "│    └─ReLU: 2-39                        [1, 64, 28, 28]           --\n",
      "│    └─AdaptiveAvgPool2d: 2-40           [1, 64, 1, 1]             --\n",
      "│    └─Flatten: 2-41                     [1, 64]                   --\n",
      "│    └─Linear: 2-42                      [1, 16]                   1,040\n",
      "│    └─ReLU: 2-43                        [1, 16]                   --\n",
      "│    └─Linear: 2-44                      [1, 2]                    34\n",
      "==========================================================================================\n",
      "Total params: 47,752\n",
      "Trainable params: 47,752\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 146.52\n",
      "==========================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 46.73\n",
      "Params size (MB): 0.19\n",
      "Estimated Total Size (MB): 47.52\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "svd_model.eval()\n",
    "\n",
    "print(summary(svd_model, input_size=(1, 3, config.IMG_H, config.IMG_W)))\n",
    "\n",
    "logger.info(\"Compressed Model Summary\")\n",
    "logger.info(summary(svd_model, input_size=(1, 3, config.IMG_H, config.IMG_W)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f636c-be77-49d9-b29f-c347e3a94ebc",
   "metadata": {},
   "source": [
    "### Evaluate Compressed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beff48c7-7a18-49c3-968c-ec71743df10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 mean: 0.8512\n"
     ]
    }
   ],
   "source": [
    "svd_f1 = evaluate_model(svd_model, None, True)\n",
    "logger.info(f'\\nSVD Model evaluation with Aimet Val Loader before training: {svd_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bd2105-474f-439f-b84e-44f29f462b69",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a890a26-99e5-4b39-a766-1efc8842cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_ratios_file_path = './data/greedy_selection_comp_ratios_list.pkl'\n",
    "eval_scores_path = './data/greedy_selection_eval_scores_dict.pkl'\n",
    "\n",
    "unpickled_ratios = pd.read_pickle(comp_ratios_file_path)\n",
    "unpickled_scores = pd.read_pickle(eval_scores_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d644802-87ca-4321-aadd-c66c57bb8763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     model.conv1  model.conv2  model.conv31  model.conv32  model.conv33  \\\n",
      "0.1     0.030501     0.627974      0.316864      0.223588      0.005263   \n",
      "0.2     0.030501     0.808363      0.316864      0.212155      0.000000   \n",
      "0.3     0.467391     0.872104      0.399972      0.338384      0.000000   \n",
      "0.4     0.557912     0.860360      0.597683      0.226675      0.577160   \n",
      "0.5     0.598291     0.888460      0.626242      0.876839      0.684384   \n",
      "0.6     0.598291     0.923112      0.626242      0.871368      0.773400   \n",
      "0.7     0.690273     0.937649      0.737392      0.906371      0.821031   \n",
      "0.8     0.948903     0.946663      0.827370      0.922411      0.851065   \n",
      "0.9     0.946728     0.952776      0.852138      0.938452      0.907386   \n",
      "\n",
      "     model.conv34  model.conv41  model.conv42  model.conv43  model.conv44  \\\n",
      "0.1      0.420712      0.000000      0.756926      0.386256      0.624998   \n",
      "0.2      0.645164      0.035354      0.858814      0.453103      0.919361   \n",
      "0.3      0.824999      0.181043      0.892521      0.731003      0.934031   \n",
      "0.4      0.863774      0.440739      0.918064      0.753441      0.941662   \n",
      "0.5      0.892556      0.684159      0.929562      0.896046      0.945765   \n",
      "0.6      0.920950      0.741842      0.939353      0.901694      0.949136   \n",
      "0.7      0.934827      0.846850      0.938944      0.915835      0.950395   \n",
      "0.8      0.945740      0.907624      0.942761      0.945384      0.953667   \n",
      "0.9      0.952498      0.918375      0.944799      0.943541      0.953667   \n",
      "\n",
      "     model.conv45  model.conv46  \n",
      "0.1      0.751990      0.949770  \n",
      "0.2      0.935134      0.953667  \n",
      "0.3      0.953805      0.952233  \n",
      "0.4      0.947849      0.952233  \n",
      "0.5      0.939250      0.952233  \n",
      "0.6      0.948194      0.952233  \n",
      "0.7      0.947320      0.952233  \n",
      "0.8      0.952233      0.952233  \n",
      "0.9      0.952233      0.952233  \n"
     ]
    }
   ],
   "source": [
    "df_scores = pd.DataFrame(unpickled_scores)\n",
    "df_scores.to_csv(config.RUN_FOLDER + 'scores_svd.csv')\n",
    "print(df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ac07fb2-85ac-467f-bc2d-dea822c28e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0     1\n",
      "0    model.conv1   0.8\n",
      "1    model.conv2   0.7\n",
      "2   model.conv31  None\n",
      "3   model.conv32   0.9\n",
      "4   model.conv33  None\n",
      "5   model.conv34   0.7\n",
      "6   model.conv41  None\n",
      "7   model.conv42   0.6\n",
      "8   model.conv43   0.8\n",
      "9   model.conv44   0.4\n",
      "10  model.conv45   0.2\n",
      "11  model.conv46   0.1\n"
     ]
    }
   ],
   "source": [
    "df_ratios = pd.DataFrame(unpickled_ratios)\n",
    "df_ratios.to_csv(config.RUN_FOLDER + 'ratios_svd.csv')\n",
    "print(df_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c9b36d-9a54-4ce8-8521-41eb277035e8",
   "metadata": {},
   "source": [
    "# Save Compressed Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "602a9d51-aea0-485c-b7af-e0bc2641d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(svd_model, torch.randn(input_shape).to(config.DEVICE), config.RUN_FOLDER + 'svd_model_noTrain.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a9b4e-cc35-497e-ae3a-4973817e85b3",
   "metadata": {},
   "source": [
    "### Optimizer and Scheduler of Compressed Model to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27cd5bba-82a8-4ed5-b764-bcac6c1eb30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(svd_model.parameters(), \n",
    "                       lr=config.LEARNING_RATE, \n",
    "                       weight_decay=config.WEIGHT_DECAY)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                 mode='min',\n",
    "                                                 factor=config.FACTOR, \n",
    "                                                 patience=config.PATIENCE, \n",
    "                                                 threshold=config.THRES, \n",
    "                                                 threshold_mode='abs',\n",
    "                                                 min_lr=config.MIN_LR)\n",
    "\n",
    "utils.save_checkpoint(epoch=0, \n",
    "                      model=svd_model,\n",
    "                      optimizer=optimizer,\n",
    "                      scheduler=scheduler,\n",
    "                      checkpoint_name=config.WEIGHTS_FOLDER + 'comp_model_after_svd.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285c03d3-6401-434e-812f-f7ae3d96a09e",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f8977bc-ced2-4143-9478-f41f538ff95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function: BCE\n",
      "Smoke Precision Weight: 0.8\n"
     ]
    }
   ],
   "source": [
    "if config.LOSS_FN == \"BCE\":\n",
    "    print(f'Loss Function: BCE')\n",
    "    logger.info(f'\\nLoss Function: BCE')\n",
    "    print(f'Smoke Precision Weight: {config.SMOKE_PRECISION_WEIGHT}')\n",
    "    logger.info(f'Smoke Precision Weight: {config.SMOKE_PRECISION_WEIGHT}')\n",
    "    loss_fn = loss.BCE_LOSS(device=config.DEVICE, smoke_precision_weight=config.SMOKE_PRECISION_WEIGHT)\n",
    "else:\n",
    "    print(\"Wrong loss function\")\n",
    "    logger.info(\"Wrong loss function\")\n",
    "    raise SystemExit(\"Wrong loss function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80898e59-ddee-4670-9054-d443556de710",
   "metadata": {},
   "source": [
    "# Loss and Metrics Loggers and Plotters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a61cff5-0ac7-49f0-9f10-726e07b60c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses_logger = utils.LogLosses()\n",
    "train_metrics_logger = utils.LogMetrics()\n",
    "lr_logger = utils.LogLR(log_path=config.PLOTS_FOLDER)\n",
    "\n",
    "val_losses_logger = utils.LogLosses()\n",
    "val_metrics_logger = utils.LogMetrics()\n",
    "\n",
    "loss_plotter = utils.PlotMetrics(log_path=config.PLOTS_FOLDER, model_name=config.MODEL, loss_or_metric='Loss')\n",
    "metrics_plotter = utils.PlotMetrics(log_path=config.PLOTS_FOLDER, model_name=config.MODEL, loss_or_metric='Metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ff6ca-4e1a-40a3-a173-1de75ba0ef11",
   "metadata": {},
   "source": [
    "# Train Loop Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da2d2348-c75c-4596-9d8f-e6da9144ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, start_epoch=0, epochs_to_train=config.EPOCHS):\n",
    "\n",
    "    ''' ==============================================================\n",
    "                                TRAINING LOOP\n",
    "    ============================================================== '''\n",
    "    start = datetime.datetime.now()\n",
    "    start_time = start.strftime(\"%H:%M:%S\")\n",
    "    print(f'\\n***Start Training: {start_time}\\n')\n",
    "    logger.info(f'\\n***Start Training: {start_time}\\n')\n",
    "    \n",
    "    # Start with infinite validation loss\n",
    "    best_valid_loss = np.inf\n",
    "    best_smoke_precision = 0. #torch.tensor([0.])\n",
    "    smoke_f1_min_save = 0.9 #torch.tensor([0.9])\n",
    "    best_mean_f1 = 0.\n",
    "\n",
    "    if start_epoch == 0:\n",
    "        epochs_plot = []\n",
    "    else:\n",
    "        epochs_plot = [i for i in range(start_epoch)]    \n",
    "\n",
    "    end_epoch = start_epoch + epochs_to_train\n",
    "        \n",
    "    for epoch in range(start_epoch, end_epoch):\n",
    "\n",
    "        print(f'\\n=== EPOCH {epoch}/{end_epoch-1} ===')\n",
    "        logger.info(f'\\n=== EPOCH {epoch}/{end_epoch-1} ===')\n",
    "        \n",
    "        #====================== TRAINING ========================#\n",
    "        current_lr = train_epoch.get_lr(optimizer=optimizer)\n",
    "        logger.info(f'Learning Rate = {current_lr}\\n')\n",
    "        lr_logger.log_lr(current_lr)\n",
    "                \n",
    "        train_losses, train_metrics = train_epoch.train_fn(\n",
    "            loader=train_loader, \n",
    "            model=model, \n",
    "            optimizer=optimizer, \n",
    "            loss_fn=loss_fn,\n",
    "            device=config.DEVICE)\n",
    "        \n",
    "        train_losses_logger.update_metrics(train_losses)\n",
    "        train_metrics_logger.update_metrics(train_metrics)\n",
    "                \n",
    "        logger.info(utils.print_metrics_to_logger(\"TRAIN Stats\", train_losses, train_metrics))\n",
    "        \n",
    "        #===================== VALIDATING =======================#\n",
    "        with torch.no_grad():\n",
    "            val_losses, val_metrics = val_epoch.eval_fn(\n",
    "                loader=val_loader, \n",
    "                model=model,                         \n",
    "                loss_fn=loss_fn,\n",
    "                device=config.DEVICE)\n",
    "            \n",
    "            scheduler.step(val_losses['Total'])\n",
    "            \n",
    "            val_losses_logger.update_metrics(val_losses)\n",
    "            val_metrics_logger.update_metrics(val_metrics)\n",
    "\n",
    "            logger.info(utils.print_metrics_to_logger(\"VAL Stats\", val_losses, val_metrics))\n",
    "            \n",
    "        epochs_plot.append(epoch)\n",
    "\n",
    "        loss_plotter.plot_all_metrics(\n",
    "            train_losses_logger.get_metrics(),\n",
    "            val_losses_logger.get_metrics(),\n",
    "            epochs_plot)\n",
    "\n",
    "        metrics_plotter.plot_all_metrics(\n",
    "            train_metrics_logger.get_metrics(),\n",
    "            val_metrics_logger.get_metrics(),\n",
    "            epochs_plot)\n",
    "\n",
    "        lr_logger.plot_lr(epochs_plot)\n",
    "        #======================= SAVING =========================#\n",
    "        if ( (epoch+1) % 5 ) == 0:\n",
    "            save_name = config.WEIGHTS_FOLDER + config.MODEL + '_classifier__5epoch.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name) \n",
    "            \n",
    "        if best_valid_loss > val_losses['Total']:\n",
    "            best_valid_loss = val_losses['Total']\n",
    "            print(f\"\\nSaving model with new best validation loss: {best_valid_loss:.4f}\")\n",
    "            logger.info(f\"Saving model with new best validation loss: {best_valid_loss:.4f}\")\n",
    "            save_name = config.WEIGHTS_FOLDER + config.MODEL + '_classifier__' + 'best_loss'  + '.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name) \n",
    "            if config.BREVITAS_MODEL == True:\n",
    "                save_onnx = config.ONNX_FOLDER + config.MODEL + '_classifier__' + 'best_loss'  #+ '.onnx'\n",
    "                utils.export_onnx(model, (1, config.NUM_CHANNELS, config.IMG_H, config.IMG_W), save_onnx, config.DEVICE)\n",
    "\n",
    "        # Save model if best mean F1 increases\n",
    "        val_f1_mean = (val_metrics['F1'][0] + val_metrics['F1'][1]) / 2\n",
    "        if (val_f1_mean > best_mean_f1) :\n",
    "            best_mean_f1 = val_f1_mean\n",
    "            print(f'Saving model with best Mean F1: {best_mean_f1:.4f}')\n",
    "            logger.info(f'Saving model with best Mean F1: {best_mean_f1:.4f}')\n",
    "            save_f1_name = 'best_mean_F1'\n",
    "            save_name = config.WEIGHTS_FOLDER + config.MODEL + '_classifier__' + save_f1_name + '.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name) \n",
    "            if config.BREVITAS_MODEL == True:\n",
    "                save_onnx = config.ONNX_FOLDER + config.MODEL + '_classifier__' + save_f1_name #+ '.onnx'\n",
    "                utils.export_onnx(model, (1, config.NUM_CHANNELS, config.IMG_H, config.IMG_W), save_onnx, config.DEVICE)\n",
    "        \n",
    "    logger.info('Saving last model')   \n",
    "    torch.save(model.state_dict(), config.WEIGHTS_FOLDER + 'last_' + config.MODEL + '_classifier.pt') \n",
    "    \n",
    "    #======================= FINISH =========================#\n",
    "    end = datetime.datetime.now()\n",
    "    end_time = end.strftime(\"%H:%M:%S\")\n",
    "    print(f'\\n***Script finished: {end_time}\\n')  \n",
    "    print(f'Time elapsed: {end-start}')\n",
    "    logger.info(f'\\n***Script finished: {end_time}\\n')  \n",
    "    logger.info(f'Time elapsed: {end-start}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405eb53c-8e16-4b14-a818-fe53e68c1637",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc5957bb-da57-4e84-ae3d-a83545e04704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "\n",
      "\n",
      "***Start Training: 02:20:21\n",
      "\n",
      "\n",
      "=== EPOCH 0/1 ===\n",
      "Learning Rate = 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Smoke Loss  |Fire Loss   \n",
      "------------ ------------ ------------\n",
      "28.229      |15.963      |12.266      \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Smoke Loss  |Fire Loss   \n",
      "------------ ------------ ------------\n",
      "64.773      |46.330      |18.443      \n",
      "SMOKE -> Precision: 0.6754 - Recall: 0.9628 - Accuracy: 0.7552 - F1: 0.7939\n",
      "FIRE -> Precision: 0.7786 - Recall: 0.9397 - Accuracy: 0.9010 - F1: 0.8516\n",
      "\n",
      "Saving model with new best validation loss: 64.7730\n",
      "Saving model with best Mean F1: 0.8227\n",
      "\n",
      "=== EPOCH 1/1 ===\n",
      "Learning Rate = 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Smoke Loss  |Fire Loss   \n",
      "------------ ------------ ------------\n",
      "21.033      |15.457      |5.576       \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Smoke Loss  |Fire Loss   \n",
      "------------ ------------ ------------\n",
      "33.359      |25.818      |7.540       \n",
      "SMOKE -> Precision: 0.8533 - Recall: 0.8351 - Accuracy: 0.8490 - F1: 0.8441\n",
      "FIRE -> Precision: 0.9714 - Recall: 0.8793 - Accuracy: 0.9557 - F1: 0.9231\n",
      "\n",
      "Saving model with new best validation loss: 33.3588\n",
      "Saving model with best Mean F1: 0.8836\n",
      "\n",
      "***Script finished: 02:20:33\n",
      "\n",
      "Time elapsed: 0:00:12.066482\n"
     ]
    }
   ],
   "source": [
    "print(\"Start Training\\n\")\n",
    "logger.info(\"Start Training\\n\")\n",
    "\n",
    "svd_model_trained = train_loop(svd_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc7d86a-27a6-43ac-89c6-718321bfdd43",
   "metadata": {},
   "source": [
    "# Check Comp Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "079d0c48-20bc-425d-8a16-073bc33de6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable parameters = 47752\n",
      "Total parameters = 47752\n"
     ]
    }
   ],
   "source": [
    "svd_model_trained.eval()\n",
    "logger.info(f'\\n########################################### SVD Model\\n')\n",
    "logger.info(svd_model_trained)\n",
    "\n",
    "# MODEL PARAMETERS\n",
    "n_trainable = sum(p.numel() for p in svd_model_trained.parameters() if p.requires_grad)\n",
    "print(f'\\nTrainable parameters = {n_trainable}')\n",
    "logger.info(f'\\nTrainable parameters = {n_trainable}')\n",
    "\n",
    "n_params = sum(p.numel() for p in svd_model_trained.parameters())\n",
    "print(f'Total parameters = {n_params}')\n",
    "logger.info(f'Total parameters = {n_params}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063616a4-0b56-44a1-bc64-d5cd3960e1ec",
   "metadata": {},
   "source": [
    "# Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8486f8b-283d-41a0-95d1-2ef0fbd4fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(svd_model_trained, torch.randn(input_shape).to(config.DEVICE), config.RUN_FOLDER + 'svd_model_trained.onnx')\n",
    "#OnnxSaver.set_node_names('/models/fp32_model.onnx', trained_model, input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6088e4c2-a306-4d8a-bd58-42ec8220a5b9",
   "metadata": {},
   "source": [
    "# Pruning the Model after Training the SVD one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cbf0d8-2cc8-4bc7-b091-fd36ee481bb1",
   "metadata": {},
   "source": [
    "### Supress Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfd6ee31-e8ec-440b-942c-e3c938a28abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed9e594-7962-4610-ae38-c14a6d653ffb",
   "metadata": {},
   "source": [
    "### Baseline SVD Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cd22493-19f4-49c9-ad46-8b610fb0c594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 mean: 0.8836\n"
     ]
    }
   ],
   "source": [
    "svd_trained_f1 = evaluate_model(svd_model_trained, None, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59be1d98-4e7d-4f76-8324-7223a635344e",
   "metadata": {},
   "source": [
    "### Pruning Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35cc58-407b-4c16-82f5-27e5533c4055",
   "metadata": {},
   "source": [
    "#### Check first layer to setup modules to ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70cc89f9-dfcc-40d9-bdab-6f7a381c771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(svd_model_trained.model.conv1, nn.Sequential):  \n",
    "    modules_to_ignore = [svd_model_trained.model.conv1[0]]\n",
    "    print(\"Ignore conv1[0] due to SVD\")\n",
    "    logger.info(\"\\nPruning params: conv1 is Sequential, so it was splitted in SVD -> update modules to ignore\")\n",
    "else:\n",
    "    modules_to_ignore = [svd_model_trained.model.conv1]\n",
    "    logger.info(\"\\nPruning params: conv1 is not Sequential, so it was not splitted in SVD\")\n",
    "    print(\"Ignore conv1 due to SVD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02338086-7684-4e71-84af-f235e3bb42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modules_to_ignore = [svd_model_trained.model.conv1]\n",
    "greedy_params = GreedySelectionParameters(\n",
    "    target_comp_ratio=Decimal(config.PRUNING_COMPRESSION_RATIO),\n",
    "    saved_eval_scores_dict=config.PRUNING_DIC_FILE)\n",
    "auto_params = ChannelPruningParameters.AutoModeParams(\n",
    "    greedy_params,\n",
    "    modules_to_ignore=modules_to_ignore)\n",
    "cp_params = ChannelPruningParameters(\n",
    "    mode=ChannelPruningParameters.Mode.auto,\n",
    "    params=auto_params,\n",
    "    data_loader=aimet_val_loader, #val_loader,\n",
    "    num_reconstruction_samples=500,\n",
    "    allow_custom_downsample_ops=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d6ce3e8-746e-4feb-a85e-f917aaf66b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-26 02:23:20,193 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:23:22,130 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.4133\n",
      "2025-01-26 02:23:23,977 - CompRatioSelect - INFO - Layer model.conv1.1, comp_ratio 0.100000 ==> eval_score=0.413258\n",
      "2025-01-26 02:23:23,978 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:23:26,034 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.4174\n",
      "2025-01-26 02:23:27,919 - CompRatioSelect - INFO - Layer model.conv1.1, comp_ratio 0.200000 ==> eval_score=0.417427\n",
      "2025-01-26 02:23:27,920 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 722, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 720, in rmtree\n",
      "    os.rmdir(path)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-ukixjicq'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-26 02:23:29,842 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.4372\n",
      "2025-01-26 02:23:31,730 - CompRatioSelect - INFO - Layer model.conv1.1, comp_ratio 0.300000 ==> eval_score=0.437224\n",
      "2025-01-26 02:23:31,730 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:23:33,642 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8170\n",
      "2025-01-26 02:23:35,502 - CompRatioSelect - INFO - Layer model.conv1.1, comp_ratio 0.400000 ==> eval_score=0.817048\n",
      "2025-01-26 02:23:35,503 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:23:37,432 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8116\n",
      "2025-01-26 02:23:39,287 - CompRatioSelect - INFO - Layer model.conv1.1, comp_ratio 0.500000 ==> eval_score=0.811621\n",
      "2025-01-26 02:23:39,287 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:23:41,197 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8046\n",
      "2025-01-26 02:23:43,056 - CompRatioSelect - INFO - Layer model.conv1.1, comp_ratio 0.600000 ==> eval_score=0.804583\n",
      "2025-01-26 02:23:43,056 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:23:44,956 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8491\n",
      "2025-01-26 02:23:46,827 - CompRatioSelect - INFO - Layer model.conv1.1, comp_ratio 0.700000 ==> eval_score=0.849062\n",
      "2025-01-26 02:23:46,828 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:23:48,743 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8422\n",
      "2025-01-26 02:23:50,592 - CompRatioSelect - INFO - Layer model.conv1.1, comp_ratio 0.800000 ==> eval_score=0.842224\n",
      "2025-01-26 02:23:50,593 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:23:52,481 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8897\n",
      "2025-01-26 02:23:54,341 - CompRatioSelect - INFO - Layer model.conv1.1, comp_ratio 0.900000 ==> eval_score=0.889656\n",
      "2025-01-26 02:23:54,342 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:23:56,217 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.3489\n",
      "2025-01-26 02:23:58,070 - CompRatioSelect - INFO - Layer model.conv2.0, comp_ratio 0.100000 ==> eval_score=0.348857\n",
      "2025-01-26 02:23:58,071 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:23:59,962 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7437\n",
      "2025-01-26 02:24:01,805 - CompRatioSelect - INFO - Layer model.conv2.0, comp_ratio 0.200000 ==> eval_score=0.743735\n",
      "2025-01-26 02:24:01,806 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:24:03,701 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7619\n",
      "2025-01-26 02:24:05,548 - CompRatioSelect - INFO - Layer model.conv2.0, comp_ratio 0.300000 ==> eval_score=0.761934\n",
      "2025-01-26 02:24:05,549 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:24:07,440 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8316\n",
      "2025-01-26 02:24:09,290 - CompRatioSelect - INFO - Layer model.conv2.0, comp_ratio 0.400000 ==> eval_score=0.831584\n",
      "2025-01-26 02:24:09,290 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:24:11,185 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8661\n",
      "2025-01-26 02:24:13,038 - CompRatioSelect - INFO - Layer model.conv2.0, comp_ratio 0.500000 ==> eval_score=0.866073\n",
      "2025-01-26 02:24:13,038 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:24:14,930 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8712\n",
      "2025-01-26 02:24:16,764 - CompRatioSelect - INFO - Layer model.conv2.0, comp_ratio 0.600000 ==> eval_score=0.871171\n",
      "2025-01-26 02:24:16,765 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:24:18,671 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8778\n",
      "2025-01-26 02:24:20,514 - CompRatioSelect - INFO - Layer model.conv2.0, comp_ratio 0.700000 ==> eval_score=0.877758\n",
      "2025-01-26 02:24:20,515 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 722, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 720, in rmtree\n",
      "    os.rmdir(path)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-ybfoghe6'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-26 02:24:22,403 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8784\n",
      "2025-01-26 02:24:24,299 - CompRatioSelect - INFO - Layer model.conv2.0, comp_ratio 0.800000 ==> eval_score=0.878446\n",
      "2025-01-26 02:24:24,299 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 722, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 720, in rmtree\n",
      "    os.rmdir(path)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-2f6snyfh'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-26 02:24:26,202 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8836\n",
      "2025-01-26 02:24:28,048 - CompRatioSelect - INFO - Layer model.conv2.0, comp_ratio 0.900000 ==> eval_score=0.883582\n",
      "2025-01-26 02:24:28,049 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:24:29,934 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.4537\n",
      "2025-01-26 02:24:31,789 - CompRatioSelect - INFO - Layer model.conv2.1, comp_ratio 0.100000 ==> eval_score=0.453750\n",
      "2025-01-26 02:24:31,790 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:24:33,662 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8058\n",
      "2025-01-26 02:24:35,519 - CompRatioSelect - INFO - Layer model.conv2.1, comp_ratio 0.200000 ==> eval_score=0.805826\n",
      "2025-01-26 02:24:35,520 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:24:37,407 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8358\n",
      "2025-01-26 02:24:39,269 - CompRatioSelect - INFO - Layer model.conv2.1, comp_ratio 0.300000 ==> eval_score=0.835839\n",
      "2025-01-26 02:24:39,270 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:24:41,154 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8669\n",
      "2025-01-26 02:24:43,014 - CompRatioSelect - INFO - Layer model.conv2.1, comp_ratio 0.400000 ==> eval_score=0.866907\n",
      "2025-01-26 02:24:43,014 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:24:44,914 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8742\n",
      "2025-01-26 02:24:46,814 - CompRatioSelect - INFO - Layer model.conv2.1, comp_ratio 0.500000 ==> eval_score=0.874174\n",
      "2025-01-26 02:24:46,814 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:24:48,706 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8656\n",
      "2025-01-26 02:24:50,572 - CompRatioSelect - INFO - Layer model.conv2.1, comp_ratio 0.600000 ==> eval_score=0.865562\n",
      "2025-01-26 02:24:50,573 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:24:52,474 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8761\n",
      "2025-01-26 02:24:54,333 - CompRatioSelect - INFO - Layer model.conv2.1, comp_ratio 0.700000 ==> eval_score=0.876123\n",
      "2025-01-26 02:24:54,334 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:24:56,232 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8749\n",
      "2025-01-26 02:24:58,085 - CompRatioSelect - INFO - Layer model.conv2.1, comp_ratio 0.800000 ==> eval_score=0.874852\n",
      "2025-01-26 02:24:58,086 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:24:59,988 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8789\n",
      "2025-01-26 02:25:01,845 - CompRatioSelect - INFO - Layer model.conv2.1, comp_ratio 0.900000 ==> eval_score=0.878877\n",
      "2025-01-26 02:25:01,845 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:25:03,731 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.0000\n",
      "2025-01-26 02:25:05,588 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.100000 ==> eval_score=0.000000\n",
      "2025-01-26 02:25:05,588 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:25:07,487 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.1976\n",
      "2025-01-26 02:25:09,350 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.200000 ==> eval_score=0.197581\n",
      "2025-01-26 02:25:09,351 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:25:11,260 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.2957\n",
      "2025-01-26 02:25:13,181 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.300000 ==> eval_score=0.295744\n",
      "2025-01-26 02:25:13,181 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:25:15,070 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.6455\n",
      "2025-01-26 02:25:16,941 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.400000 ==> eval_score=0.645459\n",
      "2025-01-26 02:25:16,942 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:25:18,835 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.5723\n",
      "2025-01-26 02:25:20,706 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.500000 ==> eval_score=0.572345\n",
      "2025-01-26 02:25:20,706 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:25:22,609 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8424\n",
      "2025-01-26 02:25:24,483 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.600000 ==> eval_score=0.842398\n",
      "2025-01-26 02:25:24,483 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:25:26,373 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8651\n",
      "2025-01-26 02:25:28,256 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.700000 ==> eval_score=0.865087\n",
      "2025-01-26 02:25:28,256 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:25:30,155 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8599\n",
      "2025-01-26 02:25:32,042 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.800000 ==> eval_score=0.859882\n",
      "2025-01-26 02:25:32,042 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:25:33,945 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8748\n",
      "2025-01-26 02:25:35,826 - CompRatioSelect - INFO - Layer model.conv31, comp_ratio 0.900000 ==> eval_score=0.874752\n",
      "2025-01-26 02:25:35,827 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:25:37,734 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.0157\n",
      "2025-01-26 02:25:39,603 - CompRatioSelect - INFO - Layer model.conv32.0, comp_ratio 0.100000 ==> eval_score=0.015707\n",
      "2025-01-26 02:25:39,603 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 722, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 720, in rmtree\n",
      "    os.rmdir(path)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-y6qqaoi_'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-26 02:25:41,505 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.2334\n",
      "2025-01-26 02:25:43,387 - CompRatioSelect - INFO - Layer model.conv32.0, comp_ratio 0.200000 ==> eval_score=0.233449\n",
      "2025-01-26 02:25:43,388 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:25:45,307 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.6274\n",
      "2025-01-26 02:25:47,202 - CompRatioSelect - INFO - Layer model.conv32.0, comp_ratio 0.300000 ==> eval_score=0.627384\n",
      "2025-01-26 02:25:47,203 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:25:49,113 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.6778\n",
      "2025-01-26 02:25:51,038 - CompRatioSelect - INFO - Layer model.conv32.0, comp_ratio 0.400000 ==> eval_score=0.677828\n",
      "2025-01-26 02:25:51,039 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:25:52,945 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8039\n",
      "2025-01-26 02:25:54,834 - CompRatioSelect - INFO - Layer model.conv32.0, comp_ratio 0.500000 ==> eval_score=0.803913\n",
      "2025-01-26 02:25:54,835 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:25:56,723 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8459\n",
      "2025-01-26 02:25:58,603 - CompRatioSelect - INFO - Layer model.conv32.0, comp_ratio 0.600000 ==> eval_score=0.845931\n",
      "2025-01-26 02:25:58,603 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:26:00,516 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8698\n",
      "2025-01-26 02:26:02,400 - CompRatioSelect - INFO - Layer model.conv32.0, comp_ratio 0.700000 ==> eval_score=0.869790\n",
      "2025-01-26 02:26:02,401 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:26:04,314 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8760\n",
      "2025-01-26 02:26:06,220 - CompRatioSelect - INFO - Layer model.conv32.0, comp_ratio 0.800000 ==> eval_score=0.876035\n",
      "2025-01-26 02:26:06,220 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:26:08,127 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8750\n",
      "2025-01-26 02:26:10,017 - CompRatioSelect - INFO - Layer model.conv32.0, comp_ratio 0.900000 ==> eval_score=0.875046\n",
      "2025-01-26 02:26:10,018 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:26:11,916 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.0402\n",
      "2025-01-26 02:26:13,794 - CompRatioSelect - INFO - Layer model.conv32.1, comp_ratio 0.100000 ==> eval_score=0.040215\n",
      "2025-01-26 02:26:13,794 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 722, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 720, in rmtree\n",
      "    os.rmdir(path)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-kmtj26u2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-26 02:26:15,711 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.6784\n",
      "2025-01-26 02:26:17,607 - CompRatioSelect - INFO - Layer model.conv32.1, comp_ratio 0.200000 ==> eval_score=0.678430\n",
      "2025-01-26 02:26:17,608 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:26:19,526 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7887\n",
      "2025-01-26 02:26:21,414 - CompRatioSelect - INFO - Layer model.conv32.1, comp_ratio 0.300000 ==> eval_score=0.788656\n",
      "2025-01-26 02:26:21,415 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:26:23,331 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8244\n",
      "2025-01-26 02:26:25,203 - CompRatioSelect - INFO - Layer model.conv32.1, comp_ratio 0.400000 ==> eval_score=0.824410\n",
      "2025-01-26 02:26:25,203 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:26:27,115 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8707\n",
      "2025-01-26 02:26:28,986 - CompRatioSelect - INFO - Layer model.conv32.1, comp_ratio 0.500000 ==> eval_score=0.870683\n",
      "2025-01-26 02:26:28,987 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:26:30,900 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8739\n",
      "2025-01-26 02:26:32,773 - CompRatioSelect - INFO - Layer model.conv32.1, comp_ratio 0.600000 ==> eval_score=0.873886\n",
      "2025-01-26 02:26:32,773 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:26:34,676 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8722\n",
      "2025-01-26 02:26:36,550 - CompRatioSelect - INFO - Layer model.conv32.1, comp_ratio 0.700000 ==> eval_score=0.872205\n",
      "2025-01-26 02:26:36,550 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:26:38,459 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8728\n",
      "2025-01-26 02:26:40,339 - CompRatioSelect - INFO - Layer model.conv32.1, comp_ratio 0.800000 ==> eval_score=0.872793\n",
      "2025-01-26 02:26:40,339 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:26:42,248 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8728\n",
      "2025-01-26 02:26:44,123 - CompRatioSelect - INFO - Layer model.conv32.1, comp_ratio 0.900000 ==> eval_score=0.872829\n",
      "2025-01-26 02:26:44,124 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:26:46,032 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.0450\n",
      "2025-01-26 02:26:47,924 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.100000 ==> eval_score=0.045000\n",
      "2025-01-26 02:26:47,925 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:26:49,842 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.2694\n",
      "2025-01-26 02:26:51,738 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.200000 ==> eval_score=0.269417\n",
      "2025-01-26 02:26:51,738 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:26:53,662 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.3363\n",
      "2025-01-26 02:26:55,557 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.300000 ==> eval_score=0.336283\n",
      "2025-01-26 02:26:55,558 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:26:57,489 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.6380\n",
      "2025-01-26 02:26:59,366 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.400000 ==> eval_score=0.638014\n",
      "2025-01-26 02:26:59,366 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:27:01,270 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8079\n",
      "2025-01-26 02:27:03,150 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.500000 ==> eval_score=0.807871\n",
      "2025-01-26 02:27:03,150 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:27:05,052 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7897\n",
      "2025-01-26 02:27:06,962 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.600000 ==> eval_score=0.789659\n",
      "2025-01-26 02:27:06,962 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:27:08,874 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8250\n",
      "2025-01-26 02:27:10,771 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.700000 ==> eval_score=0.825000\n",
      "2025-01-26 02:27:10,772 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:27:12,689 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8571\n",
      "2025-01-26 02:27:14,569 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.800000 ==> eval_score=0.857113\n",
      "2025-01-26 02:27:14,570 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:27:16,472 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8671\n",
      "2025-01-26 02:27:18,345 - CompRatioSelect - INFO - Layer model.conv33, comp_ratio 0.900000 ==> eval_score=0.867107\n",
      "2025-01-26 02:27:18,346 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:27:20,236 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.0538\n",
      "2025-01-26 02:27:22,120 - CompRatioSelect - INFO - Layer model.conv34.0, comp_ratio 0.100000 ==> eval_score=0.053846\n",
      "2025-01-26 02:27:22,121 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:27:24,047 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.5971\n",
      "2025-01-26 02:27:25,922 - CompRatioSelect - INFO - Layer model.conv34.0, comp_ratio 0.200000 ==> eval_score=0.597110\n",
      "2025-01-26 02:27:25,922 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:27:27,833 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.6253\n",
      "2025-01-26 02:27:29,709 - CompRatioSelect - INFO - Layer model.conv34.0, comp_ratio 0.300000 ==> eval_score=0.625293\n",
      "2025-01-26 02:27:29,710 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:27:31,617 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7017\n",
      "2025-01-26 02:27:33,507 - CompRatioSelect - INFO - Layer model.conv34.0, comp_ratio 0.400000 ==> eval_score=0.701689\n",
      "2025-01-26 02:27:33,507 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:27:35,422 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8090\n",
      "2025-01-26 02:27:37,308 - CompRatioSelect - INFO - Layer model.conv34.0, comp_ratio 0.500000 ==> eval_score=0.809047\n",
      "2025-01-26 02:27:37,309 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:27:39,235 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8105\n",
      "2025-01-26 02:27:41,119 - CompRatioSelect - INFO - Layer model.conv34.0, comp_ratio 0.600000 ==> eval_score=0.810483\n",
      "2025-01-26 02:27:41,120 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:27:43,043 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8541\n",
      "2025-01-26 02:27:44,938 - CompRatioSelect - INFO - Layer model.conv34.0, comp_ratio 0.700000 ==> eval_score=0.854128\n",
      "2025-01-26 02:27:44,939 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:27:46,855 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8654\n",
      "2025-01-26 02:27:48,743 - CompRatioSelect - INFO - Layer model.conv34.0, comp_ratio 0.800000 ==> eval_score=0.865401\n",
      "2025-01-26 02:27:48,743 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:27:50,668 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8749\n",
      "2025-01-26 02:27:52,573 - CompRatioSelect - INFO - Layer model.conv34.0, comp_ratio 0.900000 ==> eval_score=0.874923\n",
      "2025-01-26 02:27:52,574 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:27:54,515 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.5505\n",
      "2025-01-26 02:27:56,415 - CompRatioSelect - INFO - Layer model.conv34.1, comp_ratio 0.100000 ==> eval_score=0.550539\n",
      "2025-01-26 02:27:56,416 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:27:58,351 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7923\n",
      "2025-01-26 02:28:00,250 - CompRatioSelect - INFO - Layer model.conv34.1, comp_ratio 0.200000 ==> eval_score=0.792303\n",
      "2025-01-26 02:28:00,251 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:28:02,178 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8235\n",
      "2025-01-26 02:28:04,071 - CompRatioSelect - INFO - Layer model.conv34.1, comp_ratio 0.300000 ==> eval_score=0.823471\n",
      "2025-01-26 02:28:04,071 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:28:06,136 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8537\n",
      "2025-01-26 02:28:08,046 - CompRatioSelect - INFO - Layer model.conv34.1, comp_ratio 0.400000 ==> eval_score=0.853738\n",
      "2025-01-26 02:28:08,046 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:28:09,981 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8549\n",
      "2025-01-26 02:28:11,884 - CompRatioSelect - INFO - Layer model.conv34.1, comp_ratio 0.500000 ==> eval_score=0.854864\n",
      "2025-01-26 02:28:11,884 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:28:13,817 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8564\n",
      "2025-01-26 02:28:15,718 - CompRatioSelect - INFO - Layer model.conv34.1, comp_ratio 0.600000 ==> eval_score=0.856406\n",
      "2025-01-26 02:28:15,718 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:28:17,638 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8613\n",
      "2025-01-26 02:28:19,544 - CompRatioSelect - INFO - Layer model.conv34.1, comp_ratio 0.700000 ==> eval_score=0.861269\n",
      "2025-01-26 02:28:19,544 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:28:21,484 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8726\n",
      "2025-01-26 02:28:23,389 - CompRatioSelect - INFO - Layer model.conv34.1, comp_ratio 0.800000 ==> eval_score=0.872604\n",
      "2025-01-26 02:28:23,389 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:28:25,327 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8780\n",
      "2025-01-26 02:28:27,237 - CompRatioSelect - INFO - Layer model.conv34.1, comp_ratio 0.900000 ==> eval_score=0.878010\n",
      "2025-01-26 02:28:27,238 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:28:29,163 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.0500\n",
      "2025-01-26 02:28:31,081 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.100000 ==> eval_score=0.050000\n",
      "2025-01-26 02:28:31,082 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:28:33,024 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7039\n",
      "2025-01-26 02:28:34,938 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.200000 ==> eval_score=0.703852\n",
      "2025-01-26 02:28:34,939 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:28:36,866 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.6277\n",
      "2025-01-26 02:28:38,765 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.300000 ==> eval_score=0.627694\n",
      "2025-01-26 02:28:38,765 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:28:40,681 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8219\n",
      "2025-01-26 02:28:42,586 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.400000 ==> eval_score=0.821914\n",
      "2025-01-26 02:28:42,586 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:28:44,512 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8579\n",
      "2025-01-26 02:28:46,410 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.500000 ==> eval_score=0.857907\n",
      "2025-01-26 02:28:46,410 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:28:48,331 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8496\n",
      "2025-01-26 02:28:50,227 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.600000 ==> eval_score=0.849583\n",
      "2025-01-26 02:28:50,228 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:28:52,164 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8555\n",
      "2025-01-26 02:28:54,057 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.700000 ==> eval_score=0.855475\n",
      "2025-01-26 02:28:54,058 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:28:55,987 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8681\n",
      "2025-01-26 02:28:57,897 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.800000 ==> eval_score=0.868106\n",
      "2025-01-26 02:28:57,898 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:28:59,825 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8819\n",
      "2025-01-26 02:29:01,734 - CompRatioSelect - INFO - Layer model.conv41, comp_ratio 0.900000 ==> eval_score=0.881938\n",
      "2025-01-26 02:29:01,734 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:29:03,662 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.4234\n",
      "2025-01-26 02:29:05,565 - CompRatioSelect - INFO - Layer model.conv42.0, comp_ratio 0.100000 ==> eval_score=0.423421\n",
      "2025-01-26 02:29:05,566 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:29:07,493 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7214\n",
      "2025-01-26 02:29:09,410 - CompRatioSelect - INFO - Layer model.conv42.0, comp_ratio 0.200000 ==> eval_score=0.721383\n",
      "2025-01-26 02:29:09,410 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:29:11,340 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7747\n",
      "2025-01-26 02:29:13,242 - CompRatioSelect - INFO - Layer model.conv42.0, comp_ratio 0.300000 ==> eval_score=0.774656\n",
      "2025-01-26 02:29:13,243 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:29:15,171 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7790\n",
      "2025-01-26 02:29:17,074 - CompRatioSelect - INFO - Layer model.conv42.0, comp_ratio 0.400000 ==> eval_score=0.779041\n",
      "2025-01-26 02:29:17,074 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:29:19,002 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7830\n",
      "2025-01-26 02:29:20,907 - CompRatioSelect - INFO - Layer model.conv42.0, comp_ratio 0.500000 ==> eval_score=0.783034\n",
      "2025-01-26 02:29:20,908 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:29:22,842 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8219\n",
      "2025-01-26 02:29:24,746 - CompRatioSelect - INFO - Layer model.conv42.0, comp_ratio 0.600000 ==> eval_score=0.821906\n",
      "2025-01-26 02:29:24,746 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:29:26,679 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8606\n",
      "2025-01-26 02:29:28,586 - CompRatioSelect - INFO - Layer model.conv42.0, comp_ratio 0.700000 ==> eval_score=0.860625\n",
      "2025-01-26 02:29:28,587 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:29:30,524 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8665\n",
      "2025-01-26 02:29:32,428 - CompRatioSelect - INFO - Layer model.conv42.0, comp_ratio 0.800000 ==> eval_score=0.866481\n",
      "2025-01-26 02:29:32,429 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:29:34,361 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8792\n",
      "2025-01-26 02:29:36,267 - CompRatioSelect - INFO - Layer model.conv42.0, comp_ratio 0.900000 ==> eval_score=0.879186\n",
      "2025-01-26 02:29:36,267 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:29:38,211 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.1984\n",
      "2025-01-26 02:29:40,114 - CompRatioSelect - INFO - Layer model.conv42.1, comp_ratio 0.100000 ==> eval_score=0.198394\n",
      "2025-01-26 02:29:40,114 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:29:42,049 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7358\n",
      "2025-01-26 02:29:43,950 - CompRatioSelect - INFO - Layer model.conv42.1, comp_ratio 0.200000 ==> eval_score=0.735835\n",
      "2025-01-26 02:29:43,951 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:29:45,884 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7988\n",
      "2025-01-26 02:29:47,793 - CompRatioSelect - INFO - Layer model.conv42.1, comp_ratio 0.300000 ==> eval_score=0.798809\n",
      "2025-01-26 02:29:47,793 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:29:49,755 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8534\n",
      "2025-01-26 02:29:51,705 - CompRatioSelect - INFO - Layer model.conv42.1, comp_ratio 0.400000 ==> eval_score=0.853374\n",
      "2025-01-26 02:29:51,706 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:29:53,647 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8631\n",
      "2025-01-26 02:29:55,559 - CompRatioSelect - INFO - Layer model.conv42.1, comp_ratio 0.500000 ==> eval_score=0.863057\n",
      "2025-01-26 02:29:55,560 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:29:57,503 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8517\n",
      "2025-01-26 02:29:59,416 - CompRatioSelect - INFO - Layer model.conv42.1, comp_ratio 0.600000 ==> eval_score=0.851697\n",
      "2025-01-26 02:29:59,416 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:30:01,363 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8591\n",
      "2025-01-26 02:30:03,273 - CompRatioSelect - INFO - Layer model.conv42.1, comp_ratio 0.700000 ==> eval_score=0.859072\n",
      "2025-01-26 02:30:03,274 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:30:05,221 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8547\n",
      "2025-01-26 02:30:07,139 - CompRatioSelect - INFO - Layer model.conv42.1, comp_ratio 0.800000 ==> eval_score=0.854731\n",
      "2025-01-26 02:30:07,139 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:30:09,086 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8789\n",
      "2025-01-26 02:30:11,006 - CompRatioSelect - INFO - Layer model.conv42.1, comp_ratio 0.900000 ==> eval_score=0.878883\n",
      "2025-01-26 02:30:11,006 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:30:12,963 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.3014\n",
      "2025-01-26 02:30:14,882 - CompRatioSelect - INFO - Layer model.conv43.0, comp_ratio 0.100000 ==> eval_score=0.301435\n",
      "2025-01-26 02:30:14,883 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:30:16,837 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.3991\n",
      "2025-01-26 02:30:18,763 - CompRatioSelect - INFO - Layer model.conv43.0, comp_ratio 0.200000 ==> eval_score=0.399126\n",
      "2025-01-26 02:30:18,764 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:30:20,714 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.5305\n",
      "2025-01-26 02:30:22,630 - CompRatioSelect - INFO - Layer model.conv43.0, comp_ratio 0.300000 ==> eval_score=0.530464\n",
      "2025-01-26 02:30:22,630 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:30:24,567 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.6905\n",
      "2025-01-26 02:30:26,489 - CompRatioSelect - INFO - Layer model.conv43.0, comp_ratio 0.400000 ==> eval_score=0.690545\n",
      "2025-01-26 02:30:26,490 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:30:28,427 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8110\n",
      "2025-01-26 02:30:30,349 - CompRatioSelect - INFO - Layer model.conv43.0, comp_ratio 0.500000 ==> eval_score=0.811012\n",
      "2025-01-26 02:30:30,350 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:30:32,292 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8473\n",
      "2025-01-26 02:30:34,215 - CompRatioSelect - INFO - Layer model.conv43.0, comp_ratio 0.600000 ==> eval_score=0.847287\n",
      "2025-01-26 02:30:34,216 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:30:36,147 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8543\n",
      "2025-01-26 02:30:38,070 - CompRatioSelect - INFO - Layer model.conv43.0, comp_ratio 0.700000 ==> eval_score=0.854307\n",
      "2025-01-26 02:30:38,071 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:30:40,015 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8694\n",
      "2025-01-26 02:30:41,933 - CompRatioSelect - INFO - Layer model.conv43.0, comp_ratio 0.800000 ==> eval_score=0.869406\n",
      "2025-01-26 02:30:41,933 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:30:43,890 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8811\n",
      "2025-01-26 02:30:45,839 - CompRatioSelect - INFO - Layer model.conv43.0, comp_ratio 0.900000 ==> eval_score=0.881134\n",
      "2025-01-26 02:30:45,839 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:30:47,786 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.0157\n",
      "2025-01-26 02:30:49,698 - CompRatioSelect - INFO - Layer model.conv43.1, comp_ratio 0.100000 ==> eval_score=0.015707\n",
      "2025-01-26 02:30:49,699 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:30:51,639 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.3634\n",
      "2025-01-26 02:30:53,538 - CompRatioSelect - INFO - Layer model.conv43.1, comp_ratio 0.200000 ==> eval_score=0.363380\n",
      "2025-01-26 02:30:53,538 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:30:55,474 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.6472\n",
      "2025-01-26 02:30:57,384 - CompRatioSelect - INFO - Layer model.conv43.1, comp_ratio 0.300000 ==> eval_score=0.647229\n",
      "2025-01-26 02:30:57,385 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:30:59,317 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7859\n",
      "2025-01-26 02:31:01,226 - CompRatioSelect - INFO - Layer model.conv43.1, comp_ratio 0.400000 ==> eval_score=0.785945\n",
      "2025-01-26 02:31:01,227 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:31:03,172 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8318\n",
      "2025-01-26 02:31:05,077 - CompRatioSelect - INFO - Layer model.conv43.1, comp_ratio 0.500000 ==> eval_score=0.831825\n",
      "2025-01-26 02:31:05,078 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:31:07,025 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8526\n",
      "2025-01-26 02:31:08,940 - CompRatioSelect - INFO - Layer model.conv43.1, comp_ratio 0.600000 ==> eval_score=0.852601\n",
      "2025-01-26 02:31:08,940 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:31:10,883 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8538\n",
      "2025-01-26 02:31:12,794 - CompRatioSelect - INFO - Layer model.conv43.1, comp_ratio 0.700000 ==> eval_score=0.853831\n",
      "2025-01-26 02:31:12,794 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 722, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 720, in rmtree\n",
      "    os.rmdir(path)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-g40_sy27'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-26 02:31:14,729 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8673\n",
      "2025-01-26 02:31:16,640 - CompRatioSelect - INFO - Layer model.conv43.1, comp_ratio 0.800000 ==> eval_score=0.867305\n",
      "2025-01-26 02:31:16,641 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:31:18,593 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8740\n",
      "2025-01-26 02:31:20,512 - CompRatioSelect - INFO - Layer model.conv43.1, comp_ratio 0.900000 ==> eval_score=0.873985\n",
      "2025-01-26 02:31:20,513 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:31:22,454 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.6060\n",
      "2025-01-26 02:31:24,373 - CompRatioSelect - INFO - Layer model.conv44.0, comp_ratio 0.100000 ==> eval_score=0.605977\n",
      "2025-01-26 02:31:24,374 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:31:26,312 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.6942\n",
      "2025-01-26 02:31:28,229 - CompRatioSelect - INFO - Layer model.conv44.0, comp_ratio 0.200000 ==> eval_score=0.694199\n",
      "2025-01-26 02:31:28,229 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:31:30,179 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8116\n",
      "2025-01-26 02:31:32,094 - CompRatioSelect - INFO - Layer model.conv44.0, comp_ratio 0.300000 ==> eval_score=0.811586\n",
      "2025-01-26 02:31:32,094 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:31:34,038 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8518\n",
      "2025-01-26 02:31:35,958 - CompRatioSelect - INFO - Layer model.conv44.0, comp_ratio 0.400000 ==> eval_score=0.851750\n",
      "2025-01-26 02:31:35,959 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:31:37,898 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8558\n",
      "2025-01-26 02:31:39,814 - CompRatioSelect - INFO - Layer model.conv44.0, comp_ratio 0.500000 ==> eval_score=0.855804\n",
      "2025-01-26 02:31:39,815 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:31:41,749 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8601\n",
      "2025-01-26 02:31:43,685 - CompRatioSelect - INFO - Layer model.conv44.0, comp_ratio 0.600000 ==> eval_score=0.860119\n",
      "2025-01-26 02:31:43,686 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:31:45,631 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8756\n",
      "2025-01-26 02:31:47,548 - CompRatioSelect - INFO - Layer model.conv44.0, comp_ratio 0.700000 ==> eval_score=0.875599\n",
      "2025-01-26 02:31:47,548 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 722, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 720, in rmtree\n",
      "    os.rmdir(path)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-psanxufp'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-26 02:31:49,505 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8743\n",
      "2025-01-26 02:31:51,442 - CompRatioSelect - INFO - Layer model.conv44.0, comp_ratio 0.800000 ==> eval_score=0.874310\n",
      "2025-01-26 02:31:51,442 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:31:53,399 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8836\n",
      "2025-01-26 02:31:55,326 - CompRatioSelect - INFO - Layer model.conv44.0, comp_ratio 0.900000 ==> eval_score=0.883582\n",
      "2025-01-26 02:31:55,326 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:31:57,285 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.5139\n",
      "2025-01-26 02:31:59,218 - CompRatioSelect - INFO - Layer model.conv44.1, comp_ratio 0.100000 ==> eval_score=0.513898\n",
      "2025-01-26 02:31:59,218 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:32:01,163 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7553\n",
      "2025-01-26 02:32:03,086 - CompRatioSelect - INFO - Layer model.conv44.1, comp_ratio 0.200000 ==> eval_score=0.755267\n",
      "2025-01-26 02:32:03,086 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 722, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 720, in rmtree\n",
      "    os.rmdir(path)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-p2ts3jqz'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-26 02:32:05,042 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8047\n",
      "2025-01-26 02:32:06,962 - CompRatioSelect - INFO - Layer model.conv44.1, comp_ratio 0.300000 ==> eval_score=0.804714\n",
      "2025-01-26 02:32:06,962 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:32:08,921 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8802\n",
      "2025-01-26 02:32:10,851 - CompRatioSelect - INFO - Layer model.conv44.1, comp_ratio 0.400000 ==> eval_score=0.880182\n",
      "2025-01-26 02:32:10,852 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:32:12,804 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8749\n",
      "2025-01-26 02:32:14,728 - CompRatioSelect - INFO - Layer model.conv44.1, comp_ratio 0.500000 ==> eval_score=0.874928\n",
      "2025-01-26 02:32:14,729 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:32:16,702 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8798\n",
      "2025-01-26 02:32:18,633 - CompRatioSelect - INFO - Layer model.conv44.1, comp_ratio 0.600000 ==> eval_score=0.879759\n",
      "2025-01-26 02:32:18,634 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:32:20,583 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8806\n",
      "2025-01-26 02:32:22,510 - CompRatioSelect - INFO - Layer model.conv44.1, comp_ratio 0.700000 ==> eval_score=0.880616\n",
      "2025-01-26 02:32:22,510 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:32:24,473 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8711\n",
      "2025-01-26 02:32:26,403 - CompRatioSelect - INFO - Layer model.conv44.1, comp_ratio 0.800000 ==> eval_score=0.871069\n",
      "2025-01-26 02:32:26,404 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:32:28,367 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8773\n",
      "2025-01-26 02:32:30,306 - CompRatioSelect - INFO - Layer model.conv44.1, comp_ratio 0.900000 ==> eval_score=0.877299\n",
      "2025-01-26 02:32:30,307 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:32:32,268 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.5282\n",
      "2025-01-26 02:32:34,208 - CompRatioSelect - INFO - Layer model.conv45.0, comp_ratio 0.100000 ==> eval_score=0.528187\n",
      "2025-01-26 02:32:34,209 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:32:36,169 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7301\n",
      "2025-01-26 02:32:38,094 - CompRatioSelect - INFO - Layer model.conv45.0, comp_ratio 0.200000 ==> eval_score=0.730059\n",
      "2025-01-26 02:32:38,094 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:32:40,050 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8331\n",
      "2025-01-26 02:32:41,978 - CompRatioSelect - INFO - Layer model.conv45.0, comp_ratio 0.300000 ==> eval_score=0.833116\n",
      "2025-01-26 02:32:41,978 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:32:43,932 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8820\n",
      "2025-01-26 02:32:45,855 - CompRatioSelect - INFO - Layer model.conv45.0, comp_ratio 0.400000 ==> eval_score=0.881953\n",
      "2025-01-26 02:32:45,855 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:32:47,805 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8884\n",
      "2025-01-26 02:32:49,728 - CompRatioSelect - INFO - Layer model.conv45.0, comp_ratio 0.500000 ==> eval_score=0.888417\n",
      "2025-01-26 02:32:49,728 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:32:51,675 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8840\n",
      "2025-01-26 02:32:53,605 - CompRatioSelect - INFO - Layer model.conv45.0, comp_ratio 0.600000 ==> eval_score=0.884018\n",
      "2025-01-26 02:32:53,605 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:32:55,558 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8836\n",
      "2025-01-26 02:32:57,490 - CompRatioSelect - INFO - Layer model.conv45.0, comp_ratio 0.700000 ==> eval_score=0.883582\n",
      "2025-01-26 02:32:57,491 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:32:59,600 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8836\n",
      "2025-01-26 02:33:01,549 - CompRatioSelect - INFO - Layer model.conv45.0, comp_ratio 0.800000 ==> eval_score=0.883582\n",
      "2025-01-26 02:33:01,549 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:33:03,534 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8836\n",
      "2025-01-26 02:33:05,464 - CompRatioSelect - INFO - Layer model.conv45.0, comp_ratio 0.900000 ==> eval_score=0.883582\n",
      "2025-01-26 02:33:05,465 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:33:07,423 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.3176\n",
      "2025-01-26 02:33:09,352 - CompRatioSelect - INFO - Layer model.conv45.1, comp_ratio 0.100000 ==> eval_score=0.317647\n",
      "2025-01-26 02:33:09,353 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:33:11,314 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.2658\n",
      "2025-01-26 02:33:13,246 - CompRatioSelect - INFO - Layer model.conv45.1, comp_ratio 0.200000 ==> eval_score=0.265823\n",
      "2025-01-26 02:33:13,246 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:33:15,197 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.3237\n",
      "2025-01-26 02:33:17,130 - CompRatioSelect - INFO - Layer model.conv45.1, comp_ratio 0.300000 ==> eval_score=0.323699\n",
      "2025-01-26 02:33:17,130 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:33:19,080 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.3464\n",
      "2025-01-26 02:33:21,009 - CompRatioSelect - INFO - Layer model.conv45.1, comp_ratio 0.400000 ==> eval_score=0.346369\n",
      "2025-01-26 02:33:21,009 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:33:22,973 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7947\n",
      "2025-01-26 02:33:24,898 - CompRatioSelect - INFO - Layer model.conv45.1, comp_ratio 0.500000 ==> eval_score=0.794742\n",
      "2025-01-26 02:33:24,898 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:33:26,881 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8035\n",
      "2025-01-26 02:33:28,814 - CompRatioSelect - INFO - Layer model.conv45.1, comp_ratio 0.600000 ==> eval_score=0.803504\n",
      "2025-01-26 02:33:28,814 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:33:30,777 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.7816\n",
      "2025-01-26 02:33:32,713 - CompRatioSelect - INFO - Layer model.conv45.1, comp_ratio 0.700000 ==> eval_score=0.781648\n",
      "2025-01-26 02:33:32,713 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:33:34,683 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8652\n",
      "2025-01-26 02:33:36,614 - CompRatioSelect - INFO - Layer model.conv45.1, comp_ratio 0.800000 ==> eval_score=0.865210\n",
      "2025-01-26 02:33:36,615 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:33:38,581 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8646\n",
      "2025-01-26 02:33:40,519 - CompRatioSelect - INFO - Layer model.conv45.1, comp_ratio 0.900000 ==> eval_score=0.864583\n",
      "2025-01-26 02:33:40,519 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:33:42,493 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8603\n",
      "2025-01-26 02:33:44,427 - CompRatioSelect - INFO - Layer model.conv46.0, comp_ratio 0.100000 ==> eval_score=0.860291\n",
      "2025-01-26 02:33:44,427 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:33:46,387 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8585\n",
      "2025-01-26 02:33:48,325 - CompRatioSelect - INFO - Layer model.conv46.0, comp_ratio 0.200000 ==> eval_score=0.858509\n",
      "2025-01-26 02:33:48,325 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:33:50,281 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8864\n",
      "2025-01-26 02:33:52,220 - CompRatioSelect - INFO - Layer model.conv46.0, comp_ratio 0.300000 ==> eval_score=0.886401\n",
      "2025-01-26 02:33:52,221 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:33:54,186 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8781\n",
      "2025-01-26 02:33:56,124 - CompRatioSelect - INFO - Layer model.conv46.0, comp_ratio 0.400000 ==> eval_score=0.878126\n",
      "2025-01-26 02:33:56,125 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:33:58,100 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8800\n",
      "2025-01-26 02:34:00,042 - CompRatioSelect - INFO - Layer model.conv46.0, comp_ratio 0.500000 ==> eval_score=0.880002\n",
      "2025-01-26 02:34:00,042 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:34:02,002 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8836\n",
      "2025-01-26 02:34:03,928 - CompRatioSelect - INFO - Layer model.conv46.0, comp_ratio 0.600000 ==> eval_score=0.883582\n",
      "2025-01-26 02:34:03,929 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:34:05,901 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8836\n",
      "2025-01-26 02:34:07,842 - CompRatioSelect - INFO - Layer model.conv46.0, comp_ratio 0.700000 ==> eval_score=0.883582\n",
      "2025-01-26 02:34:07,843 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:34:09,808 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8836\n",
      "2025-01-26 02:34:11,748 - CompRatioSelect - INFO - Layer model.conv46.0, comp_ratio 0.800000 ==> eval_score=0.883582\n",
      "2025-01-26 02:34:11,748 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 722, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/opt/conda/envs/pytorch_aimet/lib/python3.8/shutil.py\", line 720, in rmtree\n",
      "    os.rmdir(path)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-kemnbyb1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-26 02:34:13,715 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8836\n",
      "2025-01-26 02:34:15,658 - CompRatioSelect - INFO - Layer model.conv46.0, comp_ratio 0.900000 ==> eval_score=0.883582\n",
      "2025-01-26 02:34:15,659 - CompRatioSelect - INFO - Analyzing compression ratio: 0.1 =====================>\n",
      "2025-01-26 02:34:17,616 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.4000\n",
      "2025-01-26 02:34:19,562 - CompRatioSelect - INFO - Layer model.conv46.1, comp_ratio 0.100000 ==> eval_score=0.400000\n",
      "2025-01-26 02:34:19,562 - CompRatioSelect - INFO - Analyzing compression ratio: 0.2 =====================>\n",
      "2025-01-26 02:34:21,568 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.4025\n",
      "2025-01-26 02:34:23,515 - CompRatioSelect - INFO - Layer model.conv46.1, comp_ratio 0.200000 ==> eval_score=0.402469\n",
      "2025-01-26 02:34:23,516 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3 =====================>\n",
      "2025-01-26 02:34:25,490 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.4010\n",
      "2025-01-26 02:34:27,435 - CompRatioSelect - INFO - Layer model.conv46.1, comp_ratio 0.300000 ==> eval_score=0.400966\n",
      "2025-01-26 02:34:27,435 - CompRatioSelect - INFO - Analyzing compression ratio: 0.4 =====================>\n",
      "2025-01-26 02:34:29,410 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8474\n",
      "2025-01-26 02:34:31,357 - CompRatioSelect - INFO - Layer model.conv46.1, comp_ratio 0.400000 ==> eval_score=0.847407\n",
      "2025-01-26 02:34:31,358 - CompRatioSelect - INFO - Analyzing compression ratio: 0.5 =====================>\n",
      "2025-01-26 02:34:33,340 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8826\n",
      "2025-01-26 02:34:35,283 - CompRatioSelect - INFO - Layer model.conv46.1, comp_ratio 0.500000 ==> eval_score=0.882586\n",
      "2025-01-26 02:34:35,284 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6 =====================>\n",
      "2025-01-26 02:34:37,245 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8776\n",
      "2025-01-26 02:34:39,175 - CompRatioSelect - INFO - Layer model.conv46.1, comp_ratio 0.600000 ==> eval_score=0.877611\n",
      "2025-01-26 02:34:39,176 - CompRatioSelect - INFO - Analyzing compression ratio: 0.7 =====================>\n",
      "2025-01-26 02:34:41,142 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8820\n",
      "2025-01-26 02:34:43,085 - CompRatioSelect - INFO - Layer model.conv46.1, comp_ratio 0.700000 ==> eval_score=0.882024\n",
      "2025-01-26 02:34:43,086 - CompRatioSelect - INFO - Analyzing compression ratio: 0.8 =====================>\n",
      "2025-01-26 02:34:45,071 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8777\n",
      "2025-01-26 02:34:47,031 - CompRatioSelect - INFO - Layer model.conv46.1, comp_ratio 0.800000 ==> eval_score=0.877690\n",
      "2025-01-26 02:34:47,031 - CompRatioSelect - INFO - Analyzing compression ratio: 0.9 =====================>\n",
      "2025-01-26 02:34:49,002 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8809\n",
      "2025-01-26 02:34:50,957 - CompRatioSelect - INFO - Layer model.conv46.1, comp_ratio 0.900000 ==> eval_score=0.880893\n",
      "2025-01-26 02:34:50,958 - CompRatioSelect - INFO - Greedy selection: Saved eval dict to ./data/greedy_selection_eval_scores_dict.pkl\n",
      "2025-01-26 02:34:50,959 - CompRatioSelect - INFO - Greedy selection: overall_min_score=0.000000, overall_max_score=0.889656\n",
      "2025-01-26 02:34:50,959 - CompRatioSelect - INFO - Greedy selection: Original model cost=(Cost: memory=46774, mac=146514976)\n",
      "2025-01-26 02:35:02,411 - CompRatioSelect - INFO - Greedy selection: final choice - comp_ratio=0.800312, score=0.878361\n",
      "2025-01-26 02:35:04,444 - ChannelPruning - INFO - finished linear regression fit \n",
      "2025-01-26 02:35:06,484 - ChannelPruning - INFO - finished linear regression fit \n",
      "2025-01-26 02:35:08,523 - ChannelPruning - INFO - finished linear regression fit \n",
      "2025-01-26 02:35:10,550 - ChannelPruning - INFO - finished linear regression fit \n",
      "2025-01-26 02:35:12,591 - ChannelPruning - INFO - finished linear regression fit \n",
      "2025-01-26 02:35:14,633 - ChannelPruning - INFO - finished linear regression fit \n",
      "2025-01-26 02:35:16,683 - ChannelPruning - INFO - finished linear regression fit \n",
      "2025-01-26 02:35:18,724 - ChannelPruning - INFO - finished linear regression fit \n",
      "2025-01-26 02:35:20,759 - ChannelPruning - INFO - finished linear regression fit \n",
      "2025-01-26 02:35:22,786 - ChannelPruning - INFO - finished linear regression fit \n",
      "2025-01-26 02:35:24,826 - ChannelPruning - INFO - finished linear regression fit \n",
      "F1 mean: 0.8836\n",
      "F1 mean: 0.8424\n"
     ]
    }
   ],
   "source": [
    "comp_model, stats = ModelCompressor.compress_model(svd_model_trained,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   eval_callback=evaluate_model,\n",
    "                                                   eval_iterations=None,\n",
    "                                                   compress_scheme=CompressionScheme.channel_pruning,\n",
    "                                                   cost_metric=CostMetric.mac,\n",
    "                                                   parameters=cp_params,\n",
    "                                                   visualization_url=None)                                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c8ca6a-4660-4f79-8563-3243249bce7d",
   "metadata": {},
   "source": [
    "### Copy Data Files to Running Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92481f68-1755-4a0d-a014-5b5270f09db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments_bed_evolution/15_downto_28_aimet__big_aimet_ds__MAC__128_ds/pruning_comp_ratios.pkl'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copyfile(\n",
    "    './data/greedy_selection_eval_scores_dict.pkl', \n",
    "    config.RUN_FOLDER + 'pruning_eval_scores.pkl')\n",
    "shutil.copyfile(\n",
    "    './data/greedy_selection_comp_ratios_list.pkl', \n",
    "    config.RUN_FOLDER + 'pruning_comp_ratios.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e2b3e-9a30-4f98-ba5d-2266103a3b88",
   "metadata": {},
   "source": [
    "# Print Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3bcc403-1f96-40a9-8fd4-3a1b44372950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************************************\n",
      "Compressed Model Statistics\n",
      "Baseline model accuracy: 0.883582, Compressed model accuracy: 0.842376\n",
      "Compression ratio for memory=0.810771, mac=0.800312\n",
      "\n",
      "**********************************************************************************************\n",
      "\n",
      "Per-layer Stats\n",
      "    Name:model.conv1.1, compression-ratio: 0.9\n",
      "    Name:model.conv2.0, compression-ratio: 0.8\n",
      "    Name:model.conv2.1, compression-ratio: 0.9\n",
      "    Name:model.conv31, compression-ratio: None\n",
      "    Name:model.conv32.0, compression-ratio: None\n",
      "    Name:model.conv32.1, compression-ratio: None\n",
      "    Name:model.conv33, compression-ratio: None\n",
      "    Name:model.conv34.0, compression-ratio: None\n",
      "    Name:model.conv34.1, compression-ratio: None\n",
      "    Name:model.conv41, compression-ratio: 0.9\n",
      "    Name:model.conv42.0, compression-ratio: 0.9\n",
      "    Name:model.conv42.1, compression-ratio: 0.9\n",
      "    Name:model.conv43.0, compression-ratio: 0.9\n",
      "    Name:model.conv43.1, compression-ratio: None\n",
      "    Name:model.conv44.0, compression-ratio: 0.9\n",
      "    Name:model.conv44.1, compression-ratio: None\n",
      "    Name:model.conv45.0, compression-ratio: 0.4\n",
      "    Name:model.conv45.1, compression-ratio: None\n",
      "    Name:model.conv46.0, compression-ratio: 0.5\n",
      "    Name:model.conv46.1, compression-ratio: 0.9\n",
      "\n",
      "**********************************************************************************************\n",
      "\n",
      "Greedy Eval Dict\n",
      "    Layer: model.conv1.1\n",
      "        Ratio=0.1, Eval score=0.41325798630714417\n",
      "        Ratio=0.2, Eval score=0.4174272418022156\n",
      "        Ratio=0.3, Eval score=0.43722429871559143\n",
      "        Ratio=0.4, Eval score=0.8170480132102966\n",
      "        Ratio=0.5, Eval score=0.8116211891174316\n",
      "        Ratio=0.6, Eval score=0.8045831918716431\n",
      "        Ratio=0.7, Eval score=0.849062442779541\n",
      "        Ratio=0.8, Eval score=0.8422242403030396\n",
      "        Ratio=0.9, Eval score=0.8896558284759521\n",
      "    Layer: model.conv2.0\n",
      "        Ratio=0.1, Eval score=0.3488571345806122\n",
      "        Ratio=0.2, Eval score=0.7437352538108826\n",
      "        Ratio=0.3, Eval score=0.7619338035583496\n",
      "        Ratio=0.4, Eval score=0.8315842747688293\n",
      "        Ratio=0.5, Eval score=0.8660726547241211\n",
      "        Ratio=0.6, Eval score=0.8711711764335632\n",
      "        Ratio=0.7, Eval score=0.8777575492858887\n",
      "        Ratio=0.8, Eval score=0.8784457445144653\n",
      "        Ratio=0.9, Eval score=0.8835815191268921\n",
      "    Layer: model.conv2.1\n",
      "        Ratio=0.1, Eval score=0.4537496268749237\n",
      "        Ratio=0.2, Eval score=0.8058258891105652\n",
      "        Ratio=0.3, Eval score=0.8358389139175415\n",
      "        Ratio=0.4, Eval score=0.8669068813323975\n",
      "        Ratio=0.5, Eval score=0.874174177646637\n",
      "        Ratio=0.6, Eval score=0.865561842918396\n",
      "        Ratio=0.7, Eval score=0.8761230707168579\n",
      "        Ratio=0.8, Eval score=0.8748518228530884\n",
      "        Ratio=0.9, Eval score=0.8788770437240601\n",
      "    Layer: model.conv31\n",
      "        Ratio=0.1, Eval score=0.0\n",
      "        Ratio=0.2, Eval score=0.19758065044879913\n",
      "        Ratio=0.3, Eval score=0.29574424028396606\n",
      "        Ratio=0.4, Eval score=0.6454591751098633\n",
      "        Ratio=0.5, Eval score=0.5723451375961304\n",
      "        Ratio=0.6, Eval score=0.8423976302146912\n",
      "        Ratio=0.7, Eval score=0.8650869131088257\n",
      "        Ratio=0.8, Eval score=0.859882116317749\n",
      "        Ratio=0.9, Eval score=0.8747520446777344\n",
      "    Layer: model.conv32.0\n",
      "        Ratio=0.1, Eval score=0.015706805512309074\n",
      "        Ratio=0.2, Eval score=0.23344947397708893\n",
      "        Ratio=0.3, Eval score=0.627383828163147\n",
      "        Ratio=0.4, Eval score=0.6778279542922974\n",
      "        Ratio=0.5, Eval score=0.8039132952690125\n",
      "        Ratio=0.6, Eval score=0.8459314107894897\n",
      "        Ratio=0.7, Eval score=0.8697900772094727\n",
      "        Ratio=0.8, Eval score=0.8760353326797485\n",
      "        Ratio=0.9, Eval score=0.8750463724136353\n",
      "    Layer: model.conv32.1\n",
      "        Ratio=0.1, Eval score=0.04021516442298889\n",
      "        Ratio=0.2, Eval score=0.6784301996231079\n",
      "        Ratio=0.3, Eval score=0.7886557579040527\n",
      "        Ratio=0.4, Eval score=0.8244099617004395\n",
      "        Ratio=0.5, Eval score=0.870683491230011\n",
      "        Ratio=0.6, Eval score=0.8738856315612793\n",
      "        Ratio=0.7, Eval score=0.8722051382064819\n",
      "        Ratio=0.8, Eval score=0.8727927803993225\n",
      "        Ratio=0.9, Eval score=0.8728287816047668\n",
      "    Layer: model.conv33\n",
      "        Ratio=0.1, Eval score=0.04500000178813934\n",
      "        Ratio=0.2, Eval score=0.26941657066345215\n",
      "        Ratio=0.3, Eval score=0.3362831771373749\n",
      "        Ratio=0.4, Eval score=0.6380139589309692\n",
      "        Ratio=0.5, Eval score=0.8078711032867432\n",
      "        Ratio=0.6, Eval score=0.7896592020988464\n",
      "        Ratio=0.7, Eval score=0.8250003457069397\n",
      "        Ratio=0.8, Eval score=0.8571127653121948\n",
      "        Ratio=0.9, Eval score=0.8671068549156189\n",
      "    Layer: model.conv34.0\n",
      "        Ratio=0.1, Eval score=0.05384615808725357\n",
      "        Ratio=0.2, Eval score=0.5971104502677917\n",
      "        Ratio=0.3, Eval score=0.6252925992012024\n",
      "        Ratio=0.4, Eval score=0.7016893625259399\n",
      "        Ratio=0.5, Eval score=0.8090471029281616\n",
      "        Ratio=0.6, Eval score=0.8104826807975769\n",
      "        Ratio=0.7, Eval score=0.8541284799575806\n",
      "        Ratio=0.8, Eval score=0.8654007911682129\n",
      "        Ratio=0.9, Eval score=0.8749228715896606\n",
      "    Layer: model.conv34.1\n",
      "        Ratio=0.1, Eval score=0.5505393147468567\n",
      "        Ratio=0.2, Eval score=0.7923034429550171\n",
      "        Ratio=0.3, Eval score=0.8234711289405823\n",
      "        Ratio=0.4, Eval score=0.8537381887435913\n",
      "        Ratio=0.5, Eval score=0.8548636436462402\n",
      "        Ratio=0.6, Eval score=0.8564063906669617\n",
      "        Ratio=0.7, Eval score=0.8612688779830933\n",
      "        Ratio=0.8, Eval score=0.8726044297218323\n",
      "        Ratio=0.9, Eval score=0.8780097961425781\n",
      "    Layer: model.conv41\n",
      "        Ratio=0.1, Eval score=0.05000000074505806\n",
      "        Ratio=0.2, Eval score=0.7038518190383911\n",
      "        Ratio=0.3, Eval score=0.6276944875717163\n",
      "        Ratio=0.4, Eval score=0.8219143748283386\n",
      "        Ratio=0.5, Eval score=0.8579068183898926\n",
      "        Ratio=0.6, Eval score=0.8495829105377197\n",
      "        Ratio=0.7, Eval score=0.8554751873016357\n",
      "        Ratio=0.8, Eval score=0.8681061863899231\n",
      "        Ratio=0.9, Eval score=0.8819376230239868\n",
      "    Layer: model.conv42.0\n",
      "        Ratio=0.1, Eval score=0.42342105507850647\n",
      "        Ratio=0.2, Eval score=0.7213828563690186\n",
      "        Ratio=0.3, Eval score=0.7746556401252747\n",
      "        Ratio=0.4, Eval score=0.7790409326553345\n",
      "        Ratio=0.5, Eval score=0.7830339670181274\n",
      "        Ratio=0.6, Eval score=0.821906328201294\n",
      "        Ratio=0.7, Eval score=0.8606249094009399\n",
      "        Ratio=0.8, Eval score=0.8664805889129639\n",
      "        Ratio=0.9, Eval score=0.8791859745979309\n",
      "    Layer: model.conv42.1\n",
      "        Ratio=0.1, Eval score=0.19839444756507874\n",
      "        Ratio=0.2, Eval score=0.7358348369598389\n",
      "        Ratio=0.3, Eval score=0.7988089323043823\n",
      "        Ratio=0.4, Eval score=0.8533743619918823\n",
      "        Ratio=0.5, Eval score=0.863057017326355\n",
      "        Ratio=0.6, Eval score=0.8516969680786133\n",
      "        Ratio=0.7, Eval score=0.8590720891952515\n",
      "        Ratio=0.8, Eval score=0.8547308444976807\n",
      "        Ratio=0.9, Eval score=0.878882646560669\n",
      "    Layer: model.conv43.0\n",
      "        Ratio=0.1, Eval score=0.3014354109764099\n",
      "        Ratio=0.2, Eval score=0.39912649989128113\n",
      "        Ratio=0.3, Eval score=0.5304644703865051\n",
      "        Ratio=0.4, Eval score=0.6905447244644165\n",
      "        Ratio=0.5, Eval score=0.8110120296478271\n",
      "        Ratio=0.6, Eval score=0.8472870588302612\n",
      "        Ratio=0.7, Eval score=0.8543069362640381\n",
      "        Ratio=0.8, Eval score=0.8694064021110535\n",
      "        Ratio=0.9, Eval score=0.8811339139938354\n",
      "    Layer: model.conv43.1\n",
      "        Ratio=0.1, Eval score=0.015706805512309074\n",
      "        Ratio=0.2, Eval score=0.3633802831172943\n",
      "        Ratio=0.3, Eval score=0.6472287178039551\n",
      "        Ratio=0.4, Eval score=0.7859454154968262\n",
      "        Ratio=0.5, Eval score=0.8318246006965637\n",
      "        Ratio=0.6, Eval score=0.8526014685630798\n",
      "        Ratio=0.7, Eval score=0.8538306355476379\n",
      "        Ratio=0.8, Eval score=0.8673046231269836\n",
      "        Ratio=0.9, Eval score=0.8739845752716064\n",
      "    Layer: model.conv44.0\n",
      "        Ratio=0.1, Eval score=0.605976939201355\n",
      "        Ratio=0.2, Eval score=0.6941986083984375\n",
      "        Ratio=0.3, Eval score=0.811585545539856\n",
      "        Ratio=0.4, Eval score=0.8517502546310425\n",
      "        Ratio=0.5, Eval score=0.8558036088943481\n",
      "        Ratio=0.6, Eval score=0.8601190447807312\n",
      "        Ratio=0.7, Eval score=0.8755985498428345\n",
      "        Ratio=0.8, Eval score=0.874309778213501\n",
      "        Ratio=0.9, Eval score=0.8835815191268921\n",
      "    Layer: model.conv44.1\n",
      "        Ratio=0.1, Eval score=0.5138981342315674\n",
      "        Ratio=0.2, Eval score=0.755266547203064\n",
      "        Ratio=0.3, Eval score=0.8047143220901489\n",
      "        Ratio=0.4, Eval score=0.8801816701889038\n",
      "        Ratio=0.5, Eval score=0.8749278783798218\n",
      "        Ratio=0.6, Eval score=0.8797587752342224\n",
      "        Ratio=0.7, Eval score=0.8806157112121582\n",
      "        Ratio=0.8, Eval score=0.8710689544677734\n",
      "        Ratio=0.9, Eval score=0.8772993087768555\n",
      "    Layer: model.conv45.0\n",
      "        Ratio=0.1, Eval score=0.5281869173049927\n",
      "        Ratio=0.2, Eval score=0.730059027671814\n",
      "        Ratio=0.3, Eval score=0.8331162929534912\n",
      "        Ratio=0.4, Eval score=0.8819533586502075\n",
      "        Ratio=0.5, Eval score=0.8884173631668091\n",
      "        Ratio=0.6, Eval score=0.8840181827545166\n",
      "        Ratio=0.7, Eval score=0.8835815191268921\n",
      "        Ratio=0.8, Eval score=0.8835815191268921\n",
      "        Ratio=0.9, Eval score=0.8835815191268921\n",
      "    Layer: model.conv45.1\n",
      "        Ratio=0.1, Eval score=0.3176470696926117\n",
      "        Ratio=0.2, Eval score=0.26582279801368713\n",
      "        Ratio=0.3, Eval score=0.323699414730072\n",
      "        Ratio=0.4, Eval score=0.3463687002658844\n",
      "        Ratio=0.5, Eval score=0.7947419881820679\n",
      "        Ratio=0.6, Eval score=0.803504228591919\n",
      "        Ratio=0.7, Eval score=0.7816480398178101\n",
      "        Ratio=0.8, Eval score=0.8652101755142212\n",
      "        Ratio=0.9, Eval score=0.8645833730697632\n",
      "    Layer: model.conv46.0\n",
      "        Ratio=0.1, Eval score=0.8602907061576843\n",
      "        Ratio=0.2, Eval score=0.858508825302124\n",
      "        Ratio=0.3, Eval score=0.886400580406189\n",
      "        Ratio=0.4, Eval score=0.8781261444091797\n",
      "        Ratio=0.5, Eval score=0.8800024390220642\n",
      "        Ratio=0.6, Eval score=0.8835815191268921\n",
      "        Ratio=0.7, Eval score=0.8835815191268921\n",
      "        Ratio=0.8, Eval score=0.8835815191268921\n",
      "        Ratio=0.9, Eval score=0.8835815191268921\n",
      "    Layer: model.conv46.1\n",
      "        Ratio=0.1, Eval score=0.4000000059604645\n",
      "        Ratio=0.2, Eval score=0.40246912837028503\n",
      "        Ratio=0.3, Eval score=0.40096619725227356\n",
      "        Ratio=0.4, Eval score=0.847407341003418\n",
      "        Ratio=0.5, Eval score=0.8825856447219849\n",
      "        Ratio=0.6, Eval score=0.8776111602783203\n",
      "        Ratio=0.7, Eval score=0.8820236325263977\n",
      "        Ratio=0.8, Eval score=0.8776900172233582\n",
      "        Ratio=0.9, Eval score=0.8808932900428772\n",
      "\n",
      "**********************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(stats)\n",
    "logger.info(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591811c-f19d-4d30-acd9-143ea6685f57",
   "metadata": {},
   "source": [
    "### Torchinfo: model compressed summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c41151b6-c294-4b0d-9263-33c502b69618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BED_CLASSIFIER_DOWNTO_28(\n",
      "  (model): Sequential(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(3, 5, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(5, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(25, 19, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(19, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv31): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu31): ReLU()\n",
      "    (conv32): Sequential(\n",
      "      (0): Conv2d(16, 28, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(28, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn32): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu32): ReLU()\n",
      "    (conv33): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu33): ReLU()\n",
      "    (conv34): Sequential(\n",
      "      (0): Conv2d(32, 44, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(44, 57, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn34): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu34): ReLU()\n",
      "    (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv41): Conv2d(57, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn41): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu41): ReLU()\n",
      "    (conv42): Sequential(\n",
      "      (0): Conv2d(28, 34, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(34, 57, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn42): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu42): ReLU()\n",
      "    (conv43): Sequential(\n",
      "      (0): Conv2d(57, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): Conv2d(17, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn43): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu43): ReLU()\n",
      "    (conv44): Sequential(\n",
      "      (0): Conv2d(28, 25, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(25, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn44): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu44): ReLU()\n",
      "    (conv45): Sequential(\n",
      "      (0): Conv2d(25, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu45): ReLU()\n",
      "    (conv46): Sequential(\n",
      "      (0): Conv2d(16, 5, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (1): Conv2d(5, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    )\n",
      "    (bn46): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu46): ReLU()\n",
      "    (avgpool5): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (flatten5): Flatten(start_dim=1, end_dim=-1)\n",
      "    (linear51): Linear(in_features=64, out_features=16, bias=True)\n",
      "    (relu5): ReLU()\n",
      "    (linear52): Linear(in_features=16, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(comp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "faec9b53-5deb-4f6b-b5f7-5bf7d61d01f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "BED_CLASSIFIER_DOWNTO_28                 [1, 2]                    --\n",
      "├─Sequential: 1-1                        [1, 2]                    --\n",
      "│    └─Sequential: 2-1                   [1, 25, 224, 224]         --\n",
      "│    │    └─Conv2d: 3-1                  [1, 5, 224, 224]          45\n",
      "│    │    └─Conv2d: 3-2                  [1, 25, 224, 224]         375\n",
      "│    └─BatchNorm2d: 2-2                  [1, 25, 224, 224]         50\n",
      "│    └─ReLU: 2-3                         [1, 25, 224, 224]         --\n",
      "│    └─MaxPool2d: 2-4                    [1, 25, 112, 112]         --\n",
      "│    └─Sequential: 2-5                   [1, 16, 112, 112]         --\n",
      "│    │    └─Conv2d: 3-3                  [1, 19, 112, 112]         1,425\n",
      "│    │    └─Conv2d: 3-4                  [1, 16, 112, 112]         912\n",
      "│    └─BatchNorm2d: 2-6                  [1, 16, 112, 112]         32\n",
      "│    └─ReLU: 2-7                         [1, 16, 112, 112]         --\n",
      "│    └─MaxPool2d: 2-8                    [1, 16, 56, 56]           --\n",
      "│    └─Conv2d: 2-9                       [1, 16, 56, 56]           256\n",
      "│    └─BatchNorm2d: 2-10                 [1, 16, 56, 56]           32\n",
      "│    └─ReLU: 2-11                        [1, 16, 56, 56]           --\n",
      "│    └─Sequential: 2-12                  [1, 32, 56, 56]           --\n",
      "│    │    └─Conv2d: 3-5                  [1, 28, 56, 56]           1,344\n",
      "│    │    └─Conv2d: 3-6                  [1, 32, 56, 56]           2,688\n",
      "│    └─BatchNorm2d: 2-13                 [1, 32, 56, 56]           64\n",
      "│    └─ReLU: 2-14                        [1, 32, 56, 56]           --\n",
      "│    └─Conv2d: 2-15                      [1, 32, 56, 56]           1,024\n",
      "│    └─BatchNorm2d: 2-16                 [1, 32, 56, 56]           64\n",
      "│    └─ReLU: 2-17                        [1, 32, 56, 56]           --\n",
      "│    └─Sequential: 2-18                  [1, 57, 56, 56]           --\n",
      "│    │    └─Conv2d: 3-7                  [1, 44, 56, 56]           4,224\n",
      "│    │    └─Conv2d: 3-8                  [1, 57, 56, 56]           7,524\n",
      "│    └─BatchNorm2d: 2-19                 [1, 57, 56, 56]           114\n",
      "│    └─ReLU: 2-20                        [1, 57, 56, 56]           --\n",
      "│    └─MaxPool2d: 2-21                   [1, 57, 28, 28]           --\n",
      "│    └─Conv2d: 2-22                      [1, 28, 28, 28]           1,596\n",
      "│    └─BatchNorm2d: 2-23                 [1, 28, 28, 28]           56\n",
      "│    └─ReLU: 2-24                        [1, 28, 28, 28]           --\n",
      "│    └─Sequential: 2-25                  [1, 57, 28, 28]           --\n",
      "│    │    └─Conv2d: 3-9                  [1, 34, 28, 28]           2,856\n",
      "│    │    └─Conv2d: 3-10                 [1, 57, 28, 28]           5,814\n",
      "│    └─BatchNorm2d: 2-26                 [1, 57, 28, 28]           114\n",
      "│    └─ReLU: 2-27                        [1, 57, 28, 28]           --\n",
      "│    └─Sequential: 2-28                  [1, 28, 28, 28]           --\n",
      "│    │    └─Conv2d: 3-11                 [1, 17, 28, 28]           969\n",
      "│    │    └─Conv2d: 3-12                 [1, 28, 28, 28]           476\n",
      "│    └─BatchNorm2d: 2-29                 [1, 28, 28, 28]           56\n",
      "│    └─ReLU: 2-30                        [1, 28, 28, 28]           --\n",
      "│    └─Sequential: 2-31                  [1, 25, 28, 28]           --\n",
      "│    │    └─Conv2d: 3-13                 [1, 25, 28, 28]           2,100\n",
      "│    │    └─Conv2d: 3-14                 [1, 25, 28, 28]           1,875\n",
      "│    └─BatchNorm2d: 2-32                 [1, 25, 28, 28]           50\n",
      "│    └─ReLU: 2-33                        [1, 25, 28, 28]           --\n",
      "│    └─Sequential: 2-34                  [1, 16, 28, 28]           --\n",
      "│    │    └─Conv2d: 3-15                 [1, 4, 28, 28]            100\n",
      "│    │    └─Conv2d: 3-16                 [1, 16, 28, 28]           64\n",
      "│    └─BatchNorm2d: 2-35                 [1, 16, 28, 28]           32\n",
      "│    └─ReLU: 2-36                        [1, 16, 28, 28]           --\n",
      "│    └─Sequential: 2-37                  [1, 64, 28, 28]           --\n",
      "│    │    └─Conv2d: 3-17                 [1, 5, 28, 28]            240\n",
      "│    │    └─Conv2d: 3-18                 [1, 64, 28, 28]           960\n",
      "│    └─BatchNorm2d: 2-38                 [1, 64, 28, 28]           128\n",
      "│    └─ReLU: 2-39                        [1, 64, 28, 28]           --\n",
      "│    └─AdaptiveAvgPool2d: 2-40           [1, 64, 1, 1]             --\n",
      "│    └─Flatten: 2-41                     [1, 64]                   --\n",
      "│    └─Linear: 2-42                      [1, 16]                   1,040\n",
      "│    └─ReLU: 2-43                        [1, 16]                   --\n",
      "│    └─Linear: 2-44                      [1, 2]                    34\n",
      "==========================================================================================\n",
      "Total params: 38,733\n",
      "Trainable params: 38,733\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 117.26\n",
      "==========================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 39.14\n",
      "Params size (MB): 0.15\n",
      "Estimated Total Size (MB): 39.90\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "comp_model.eval()\n",
    "\n",
    "print(summary(comp_model, input_size=(1, 3, config.IMG_H, config.IMG_W)))\n",
    "\n",
    "logger.info(\"\\nPruned Model\")\n",
    "logger.info(comp_model)\n",
    "\n",
    "logger.info(\"\\nCompressed Model Summary\")\n",
    "logger.info(summary(comp_model, input_size=(1, 3, config.IMG_H, config.IMG_W)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21552ff8-5f05-4d06-adab-ebfaf15547f3",
   "metadata": {},
   "source": [
    "# Evaluate Compressed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ba9bafc-85b4-4d77-adc2-840a2ad49100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 mean: 0.8424\n"
     ]
    }
   ],
   "source": [
    "comp_f1 = evaluate_model(comp_model, None, True)\n",
    "logger.info(f'\\nPruned Model evaluation with Aimet Val Loader before training: {comp_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513b69ea-faa2-4acd-ac45-6def58505bd6",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8562899f-7f8c-4778-a3aa-c636e69d1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_ratios_file_path = './data/greedy_selection_comp_ratios_list.pkl'\n",
    "eval_scores_path = './data/greedy_selection_eval_scores_dict.pkl'\n",
    "\n",
    "unpickled_ratios = pd.read_pickle(comp_ratios_file_path)\n",
    "unpickled_scores = pd.read_pickle(eval_scores_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b5978656-c606-47c3-a853-c57893540fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     model.conv1.1  model.conv2.0  model.conv2.1  model.conv31  \\\n",
      "0.1       0.413258       0.348857       0.453750      0.000000   \n",
      "0.2       0.417427       0.743735       0.805826      0.197581   \n",
      "0.3       0.437224       0.761934       0.835839      0.295744   \n",
      "0.4       0.817048       0.831584       0.866907      0.645459   \n",
      "0.5       0.811621       0.866073       0.874174      0.572345   \n",
      "0.6       0.804583       0.871171       0.865562      0.842398   \n",
      "0.7       0.849062       0.877758       0.876123      0.865087   \n",
      "0.8       0.842224       0.878446       0.874852      0.859882   \n",
      "0.9       0.889656       0.883582       0.878877      0.874752   \n",
      "\n",
      "     model.conv32.0  model.conv32.1  model.conv33  model.conv34.0  \\\n",
      "0.1        0.015707        0.040215      0.045000        0.053846   \n",
      "0.2        0.233449        0.678430      0.269417        0.597110   \n",
      "0.3        0.627384        0.788656      0.336283        0.625293   \n",
      "0.4        0.677828        0.824410      0.638014        0.701689   \n",
      "0.5        0.803913        0.870683      0.807871        0.809047   \n",
      "0.6        0.845931        0.873886      0.789659        0.810483   \n",
      "0.7        0.869790        0.872205      0.825000        0.854128   \n",
      "0.8        0.876035        0.872793      0.857113        0.865401   \n",
      "0.9        0.875046        0.872829      0.867107        0.874923   \n",
      "\n",
      "     model.conv34.1  model.conv41  model.conv42.0  model.conv42.1  \\\n",
      "0.1        0.550539      0.050000        0.423421        0.198394   \n",
      "0.2        0.792303      0.703852        0.721383        0.735835   \n",
      "0.3        0.823471      0.627694        0.774656        0.798809   \n",
      "0.4        0.853738      0.821914        0.779041        0.853374   \n",
      "0.5        0.854864      0.857907        0.783034        0.863057   \n",
      "0.6        0.856406      0.849583        0.821906        0.851697   \n",
      "0.7        0.861269      0.855475        0.860625        0.859072   \n",
      "0.8        0.872604      0.868106        0.866481        0.854731   \n",
      "0.9        0.878010      0.881938        0.879186        0.878883   \n",
      "\n",
      "     model.conv43.0  model.conv43.1  model.conv44.0  model.conv44.1  \\\n",
      "0.1        0.301435        0.015707        0.605977        0.513898   \n",
      "0.2        0.399126        0.363380        0.694199        0.755267   \n",
      "0.3        0.530464        0.647229        0.811586        0.804714   \n",
      "0.4        0.690545        0.785945        0.851750        0.880182   \n",
      "0.5        0.811012        0.831825        0.855804        0.874928   \n",
      "0.6        0.847287        0.852601        0.860119        0.879759   \n",
      "0.7        0.854307        0.853831        0.875599        0.880616   \n",
      "0.8        0.869406        0.867305        0.874310        0.871069   \n",
      "0.9        0.881134        0.873985        0.883582        0.877299   \n",
      "\n",
      "     model.conv45.0  model.conv45.1  model.conv46.0  model.conv46.1  \n",
      "0.1        0.528187        0.317647        0.860291        0.400000  \n",
      "0.2        0.730059        0.265823        0.858509        0.402469  \n",
      "0.3        0.833116        0.323699        0.886401        0.400966  \n",
      "0.4        0.881953        0.346369        0.878126        0.847407  \n",
      "0.5        0.888417        0.794742        0.880002        0.882586  \n",
      "0.6        0.884018        0.803504        0.883582        0.877611  \n",
      "0.7        0.883582        0.781648        0.883582        0.882024  \n",
      "0.8        0.883582        0.865210        0.883582        0.877690  \n",
      "0.9        0.883582        0.864583        0.883582        0.880893  \n"
     ]
    }
   ],
   "source": [
    "df_scores = pd.DataFrame(unpickled_scores)\n",
    "df_scores.to_csv(config.RUN_FOLDER + 'scores_pruning.csv')\n",
    "print(df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "21d1a37f-3705-4cab-82db-4a1be53a7ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0     1\n",
      "0    model.conv1.1   0.9\n",
      "1    model.conv2.0   0.8\n",
      "2    model.conv2.1   0.9\n",
      "3     model.conv31  None\n",
      "4   model.conv32.0  None\n",
      "5   model.conv32.1  None\n",
      "6     model.conv33  None\n",
      "7   model.conv34.0  None\n",
      "8   model.conv34.1  None\n",
      "9     model.conv41   0.9\n",
      "10  model.conv42.0   0.9\n",
      "11  model.conv42.1   0.9\n",
      "12  model.conv43.0   0.9\n",
      "13  model.conv43.1  None\n",
      "14  model.conv44.0   0.9\n",
      "15  model.conv44.1  None\n",
      "16  model.conv45.0   0.4\n",
      "17  model.conv45.1  None\n",
      "18  model.conv46.0   0.5\n",
      "19  model.conv46.1   0.9\n"
     ]
    }
   ],
   "source": [
    "df_ratios = pd.DataFrame(unpickled_ratios)\n",
    "df_ratios.to_csv(config.RUN_FOLDER + 'ratios_pruning.csv')\n",
    "print(df_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdcaa0e-4468-42ba-8f7d-947b329de9bd",
   "metadata": {},
   "source": [
    "# Save Compressed Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "732f764a-36ec-4514-9ed9-2b39d82c772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(comp_model, torch.randn(input_shape).to(config.DEVICE), config.RUN_FOLDER + 'pruned_model_noTrain.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3202ea-af8e-4fd4-8267-086b1981a5fb",
   "metadata": {},
   "source": [
    "### Optimizer and Scheduler of Compressed Model to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b69e5c83-f6ce-4a59-967e-f9eee8d12c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(comp_model.parameters(), \n",
    "                       lr=config.LEARNING_RATE, \n",
    "                       weight_decay=config.WEIGHT_DECAY)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                 mode='min',\n",
    "                                                 factor=config.FACTOR, \n",
    "                                                 patience=config.PATIENCE, \n",
    "                                                 threshold=config.THRES, \n",
    "                                                 threshold_mode='abs',\n",
    "                                                 min_lr=config.MIN_LR)\n",
    "\n",
    "utils.save_checkpoint(epoch=0, \n",
    "                      model=comp_model,\n",
    "                      optimizer=optimizer,\n",
    "                      scheduler=scheduler,\n",
    "                      checkpoint_name=config.WEIGHTS_FOLDER + 'comp_model_after_pruning.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c8971f-0ed8-43ec-a5a5-fa500bde8363",
   "metadata": {},
   "source": [
    "# Define Plotters again to restart them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5831bb53-8df7-4d82-a76e-93f941f868f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_logger = utils.LogLosses()\n",
    "train_metrics_logger = utils.LogMetrics()\n",
    "lr_logger = utils.LogLR(log_path=config.PLOTS_FOLDER_2)\n",
    "\n",
    "val_losses_logger = utils.LogLosses()\n",
    "val_metrics_logger = utils.LogMetrics()\n",
    "\n",
    "loss_plotter = utils.PlotMetrics(log_path=config.PLOTS_FOLDER_2, model_name=config.MODEL, loss_or_metric='Loss')\n",
    "metrics_plotter = utils.PlotMetrics(log_path=config.PLOTS_FOLDER_2, model_name=config.MODEL, loss_or_metric='Metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da10ab6a-f4be-4e4d-b4a8-4d917b6534d9",
   "metadata": {},
   "source": [
    "# Define Train Function Again to restart it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "48fe082f-0783-45b4-a1bc-74dd0a8b619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svd_loop(model, start_epoch=0):\n",
    "\n",
    "    ''' ==============================================================\n",
    "                                TRAINING LOOP\n",
    "    ============================================================== '''\n",
    "    start = datetime.datetime.now()\n",
    "    start_time = start.strftime(\"%H:%M:%S\")\n",
    "    print(f'\\n***Start Training: {start_time}\\n')\n",
    "    logger.info(f'\\n***Start Training: {start_time}\\n')\n",
    "    \n",
    "    # Start with infinite validation loss\n",
    "    best_valid_loss = np.inf\n",
    "    best_smoke_precision = 0. #torch.tensor([0.])\n",
    "    smoke_f1_min_save = 0.9 #torch.tensor([0.9])\n",
    "    best_mean_f1 = 0.\n",
    "\n",
    "    #start_epoch = 0\n",
    "    epochs_plot = []\n",
    "        \n",
    "    for epoch in range(start_epoch, config.EPOCHS):\n",
    "\n",
    "        print(f'\\n=== EPOCH {epoch}/{config.EPOCHS-1} ===')\n",
    "        logger.info(f'\\n=== EPOCH {epoch}/{config.EPOCHS-1} ===')\n",
    "        \n",
    "        #====================== TRAINING ========================#\n",
    "        current_lr = train_epoch.get_lr(optimizer=optimizer)\n",
    "        logger.info(f'Learning Rate = {current_lr}\\n')\n",
    "        lr_logger.log_lr(current_lr)\n",
    "                \n",
    "        train_losses, train_metrics = train_epoch.train_fn(\n",
    "            loader=train_loader, \n",
    "            model=model, \n",
    "            optimizer=optimizer, \n",
    "            loss_fn=loss_fn,\n",
    "            device=config.DEVICE)\n",
    "        \n",
    "        train_losses_logger.update_metrics(train_losses)\n",
    "        train_metrics_logger.update_metrics(train_metrics)\n",
    "                \n",
    "        logger.info(utils.print_metrics_to_logger(\"TRAIN Stats\", train_losses, train_metrics))\n",
    "        \n",
    "        #===================== VALIDATING =======================#\n",
    "        with torch.no_grad():\n",
    "            val_losses, val_metrics = val_epoch.eval_fn(\n",
    "                loader=val_loader, \n",
    "                model=model,                         \n",
    "                loss_fn=loss_fn,\n",
    "                device=config.DEVICE)\n",
    "            \n",
    "            scheduler.step(val_losses['Total'])\n",
    "            \n",
    "            val_losses_logger.update_metrics(val_losses)\n",
    "            val_metrics_logger.update_metrics(val_metrics)\n",
    "\n",
    "            logger.info(utils.print_metrics_to_logger(\"VAL Stats\", val_losses, val_metrics))\n",
    "            \n",
    "        epochs_plot.append(epoch)\n",
    "\n",
    "        loss_plotter.plot_all_metrics(\n",
    "            train_losses_logger.get_metrics(),\n",
    "            val_losses_logger.get_metrics(),\n",
    "            epochs_plot)\n",
    "\n",
    "        metrics_plotter.plot_all_metrics(\n",
    "            train_metrics_logger.get_metrics(),\n",
    "            val_metrics_logger.get_metrics(),\n",
    "            epochs_plot)\n",
    "\n",
    "        lr_logger.plot_lr(epochs_plot)\n",
    "        #======================= SAVING =========================#\n",
    "        if ( (epoch+1) % 5 ) == 0:\n",
    "            save_name = config.WEIGHTS_FOLDER_2 + config.MODEL + '_classifier__5epoch.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name) \n",
    "            \n",
    "        if best_valid_loss > val_losses['Total']:\n",
    "            best_valid_loss = val_losses['Total']\n",
    "            print(f\"\\nSaving model with new best validation loss: {best_valid_loss:.3f}\")\n",
    "            logger.info(f\"Saving model with new best validation loss: {best_valid_loss:.3f}\")\n",
    "            save_name = config.WEIGHTS_FOLDER_2 + config.MODEL + '_classifier__' + 'best_loss'  + '.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name)  \n",
    "\n",
    "        # Save model if best mean F1 increases\n",
    "        val_f1_mean = (val_metrics['F1'][0] + val_metrics['F1'][1]) / 2\n",
    "        if (val_f1_mean > best_mean_f1) :\n",
    "            best_mean_f1 = val_f1_mean\n",
    "            print(f'Saving model with best Mean F1: {best_mean_f1:.4f}')\n",
    "            logger.info(f'Saving model with best Mean F1: {best_mean_f1:.4f}')\n",
    "            save_f1_name = 'best_mean_F1'\n",
    "            save_name = config.WEIGHTS_FOLDER_2 + config.MODEL + '_classifier__' + save_f1_name + '.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name) \n",
    "\n",
    "        \n",
    "    logger.info('Saving last model')   \n",
    "    torch.save(model.state_dict(), config.WEIGHTS_FOLDER_2 + 'last_' + config.MODEL + '_classifier.pt') \n",
    "    \n",
    "    #======================= FINISH =========================#\n",
    "    end = datetime.datetime.now()\n",
    "    end_time = end.strftime(\"%H:%M:%S\")\n",
    "    print(f'\\n***Script finished: {end_time}\\n')  \n",
    "    print(f'Time elapsed: {end-start}')\n",
    "    logger.info(f'\\n***Script finished: {end_time}\\n')  \n",
    "    logger.info(f'Time elapsed: {end-start}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670bf35e-fd01-4ad3-a14d-1624b3a023c6",
   "metadata": {},
   "source": [
    "# Train the model pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1deeeff0-801d-410e-92b4-dd437c0dd131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "\n",
      "\n",
      "***Start Training: 02:40:48\n",
      "\n",
      "\n",
      "=== EPOCH 0/1 ===\n",
      "Learning Rate = 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Smoke Loss  |Fire Loss   \n",
      "------------ ------------ ------------\n",
      "26.647      |17.449      |9.199       \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Smoke Loss  |Fire Loss   \n",
      "------------ ------------ ------------\n",
      "39.895      |28.572      |11.322      \n",
      "SMOKE -> Precision: 0.8274 - Recall: 0.7394 - Accuracy: 0.7969 - F1: 0.7809\n",
      "FIRE -> Precision: 0.8889 - Recall: 0.8966 - Accuracy: 0.9349 - F1: 0.8927\n",
      "\n",
      "Saving model with new best validation loss: 39.895\n",
      "Saving model with best Mean F1: 0.8368\n",
      "\n",
      "=== EPOCH 1/1 ===\n",
      "Learning Rate = 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Smoke Loss  |Fire Loss   \n",
      "------------ ------------ ------------\n",
      "20.146      |12.867      |7.279       \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Smoke Loss  |Fire Loss   \n",
      "------------ ------------ ------------\n",
      "39.628      |28.028      |11.600      \n",
      "SMOKE -> Precision: 0.8425 - Recall: 0.6543 - Accuracy: 0.7708 - F1: 0.7365\n",
      "FIRE -> Precision: 0.8770 - Recall: 0.9224 - Accuracy: 0.9375 - F1: 0.8992\n",
      "\n",
      "Saving model with new best validation loss: 39.628\n",
      "\n",
      "***Script finished: 02:41:01\n",
      "\n",
      "Time elapsed: 0:00:12.219919\n"
     ]
    }
   ],
   "source": [
    "print(\"Start Training\\n\")\n",
    "logger.info(\"Start Training\\n\")\n",
    "\n",
    "pruned_model = train_svd_loop(comp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578ea94-aa94-4033-9db3-b60eb4b48bcb",
   "metadata": {},
   "source": [
    "# Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4fbe095c-794a-4572-9842-ed7b79cc69d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.onnx.export(pruned_model, torch.randn(input_shape).to(config.DEVICE), config.RUN_FOLDER + 'pruned_model_trained.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f871e352-cdd4-4098-8afd-70748a1de961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
