BED_Original.
	One Head.
	Weighted for Precision.
	Dataset images divided by 255.

Training Brevitas Model = False

Datasets Length
	Train and Val: 128

Load Model: False

Device: cuda
Optimizer:
	Learning Rate: 0.001
	Weight Decay: 0.001
Scheduler:
	Scheduler factor: 0.8
	Scheduler patience: 2
	Scheduler threshold: 0.001
	Scheduler min learning rate: 1e-06

Batch Size: 64
Num Workers: 8
Pin Memory: True
Epochs: 5

IMG DIMS:
	Width: 224
	Height: 224

Brevitas Config:
	Fixed Point: True
	Weights Bit Width: 4
	Big Layers Weights Bit Width: 2
	Bias Bit Width: 4
	Activations Bit Width: 4

Trainable parameters = 292866
Total parameters = 292866

==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
ORIGINAL_BED_CLASSIFIER                  [1, 2]                    --
├─Sequential: 1-1                        [1, 2]                    --
│    └─Conv2d: 2-1                       [1, 64, 224, 224]         1,728
│    └─BatchNorm2d: 2-2                  [1, 64, 224, 224]         128
│    └─ReLU: 2-3                         [1, 64, 224, 224]         --
│    └─MaxPool2d: 2-4                    [1, 64, 112, 112]         --
│    └─Conv2d: 2-5                       [1, 24, 112, 112]         13,824
│    └─BatchNorm2d: 2-6                  [1, 24, 112, 112]         48
│    └─ReLU: 2-7                         [1, 24, 112, 112]         --
│    └─MaxPool2d: 2-8                    [1, 24, 56, 56]           --
│    └─Conv2d: 2-9                       [1, 16, 56, 56]           384
│    └─BatchNorm2d: 2-10                 [1, 16, 56, 56]           32
│    └─ReLU: 2-11                        [1, 16, 56, 56]           --
│    └─Conv2d: 2-12                      [1, 32, 56, 56]           4,608
│    └─BatchNorm2d: 2-13                 [1, 32, 56, 56]           64
│    └─ReLU: 2-14                        [1, 32, 56, 56]           --
│    └─Conv2d: 2-15                      [1, 32, 56, 56]           1,024
│    └─BatchNorm2d: 2-16                 [1, 32, 56, 56]           64
│    └─ReLU: 2-17                        [1, 32, 56, 56]           --
│    └─Conv2d: 2-18                      [1, 64, 56, 56]           18,432
│    └─BatchNorm2d: 2-19                 [1, 64, 56, 56]           128
│    └─ReLU: 2-20                        [1, 64, 56, 56]           --
│    └─MaxPool2d: 2-21                   [1, 64, 28, 28]           --
│    └─Conv2d: 2-22                      [1, 32, 28, 28]           2,048
│    └─BatchNorm2d: 2-23                 [1, 32, 28, 28]           64
│    └─ReLU: 2-24                        [1, 32, 28, 28]           --
│    └─Conv2d: 2-25                      [1, 64, 28, 28]           18,432
│    └─BatchNorm2d: 2-26                 [1, 64, 28, 28]           128
│    └─ReLU: 2-27                        [1, 64, 28, 28]           --
│    └─Conv2d: 2-28                      [1, 32, 28, 28]           2,048
│    └─BatchNorm2d: 2-29                 [1, 32, 28, 28]           64
│    └─ReLU: 2-30                        [1, 32, 28, 28]           --
│    └─Conv2d: 2-31                      [1, 64, 28, 28]           18,432
│    └─BatchNorm2d: 2-32                 [1, 64, 28, 28]           128
│    └─ReLU: 2-33                        [1, 64, 28, 28]           --
│    └─Conv2d: 2-34                      [1, 32, 28, 28]           2,048
│    └─BatchNorm2d: 2-35                 [1, 32, 28, 28]           64
│    └─ReLU: 2-36                        [1, 32, 28, 28]           --
│    └─Conv2d: 2-37                      [1, 64, 28, 28]           18,432
│    └─BatchNorm2d: 2-38                 [1, 64, 28, 28]           128
│    └─ReLU: 2-39                        [1, 64, 28, 28]           --
│    └─MaxPool2d: 2-40                   [1, 64, 14, 14]           --
│    └─Conv2d: 2-41                      [1, 32, 14, 14]           2,048
│    └─BatchNorm2d: 2-42                 [1, 32, 14, 14]           64
│    └─ReLU: 2-43                        [1, 32, 14, 14]           --
│    └─Conv2d: 2-44                      [1, 64, 14, 14]           18,432
│    └─BatchNorm2d: 2-45                 [1, 64, 14, 14]           128
│    └─ReLU: 2-46                        [1, 64, 14, 14]           --
│    └─Conv2d: 2-47                      [1, 32, 14, 14]           2,048
│    └─BatchNorm2d: 2-48                 [1, 32, 14, 14]           64
│    └─ReLU: 2-49                        [1, 32, 14, 14]           --
│    └─Conv2d: 2-50                      [1, 64, 14, 14]           18,432
│    └─BatchNorm2d: 2-51                 [1, 64, 14, 14]           128
│    └─ReLU: 2-52                        [1, 64, 14, 14]           --
│    └─Conv2d: 2-53                      [1, 64, 14, 14]           36,864
│    └─BatchNorm2d: 2-54                 [1, 64, 14, 14]           128
│    └─ReLU: 2-55                        [1, 64, 14, 14]           --
│    └─Conv2d: 2-56                      [1, 64, 14, 14]           36,864
│    └─BatchNorm2d: 2-57                 [1, 64, 14, 14]           128
│    └─ReLU: 2-58                        [1, 64, 14, 14]           --
│    └─MaxPool2d: 2-59                   [1, 64, 7, 7]             --
│    └─Conv2d: 2-60                      [1, 64, 7, 7]             36,864
│    └─BatchNorm2d: 2-61                 [1, 64, 7, 7]             128
│    └─ReLU: 2-62                        [1, 64, 7, 7]             --
│    └─Conv2d: 2-63                      [1, 64, 7, 7]             36,864
│    └─BatchNorm2d: 2-64                 [1, 64, 7, 7]             128
│    └─ReLU: 2-65                        [1, 64, 7, 7]             --
│    └─AdaptiveAvgPool2d: 2-66           [1, 64, 1, 1]             --
│    └─Flatten: 2-67                     [1, 64]                   --
│    └─Linear: 2-68                      [1, 16]                   1,040
│    └─ReLU: 2-69                        [1, 16]                   --
│    └─Linear: 2-70                      [1, 2]                    34
==========================================================================================
Total params: 292,866
Trainable params: 292,866
Non-trainable params: 0
Total mult-adds (M): 411.04
==========================================================================================
Input size (MB): 0.60
Forward/backward pass size (MB): 68.14
Params size (MB): 1.17
Estimated Total Size (MB): 69.91
==========================================================================================

Loss Function: BCE
Smoke Precision Weight: 0.8
Starting script


***Start Training: 00:42:15


=== EPOCH 0/4 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5203   |0.8750   |0.0224   |0.0436   |
82.64      |38.78     |43.86     |    Fire   |0.5016   |0.3937   |0.9479   |0.5563   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5104   |0.0000   |0.0000   |0.0000   |
85.61      |39.55     |46.06     |    Fire   |0.3021   |0.3021   |1.0000   |0.4640   |

Saving model with new best validation loss: 85.6094
Saving model with best Mean F1: 0.2320

=== EPOCH 1/4 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5719   |0.8197   |0.1597   |0.2674   |
75.16      |37.19     |37.97     |    Fire   |0.7125   |0.5389   |0.8863   |0.6703   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5104   |0.0000   |0.0000   |0.0000   |
85.26      |39.66     |45.61     |    Fire   |0.3021   |0.3021   |1.0000   |0.4640   |

Saving model with new best validation loss: 85.2630

=== EPOCH 2/4 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.6031   |0.8041   |0.2492   |0.3805   |
69.56      |35.98     |33.58     |    Fire   |0.7859   |0.6303   |0.8483   |0.7232   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5260   |0.6154   |0.0851   |0.1495   |
80.01      |39.00     |41.01     |    Fire   |0.7370   |0.6596   |0.2672   |0.3804   |

Saving model with new best validation loss: 80.0096
Saving model with best Mean F1: 0.2650

=== EPOCH 3/4 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.6516   |0.8309   |0.3610   |0.5033   |
65.31      |35.45     |29.86     |    Fire   |0.8516   |0.7762   |0.7725   |0.7743   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5391   |0.5902   |0.1915   |0.2892   |
72.80      |37.81     |34.99     |    Fire   |0.8021   |0.7222   |0.5603   |0.6311   |

Saving model with new best validation loss: 72.8003
Saving model with best Mean F1: 0.4601

=== EPOCH 4/4 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.6609   |0.8288   |0.3866   |0.5272   |
62.72      |34.97     |27.75     |    Fire   |0.8781   |0.8482   |0.7678   |0.8060   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.7031   |0.7803   |0.5479   |0.6438   |
66.98      |35.39     |31.59     |    Fire   |0.7734   |0.5924   |0.8017   |0.6813   |

Saving model with new best validation loss: 66.9791
Saving model with best Mean F1: 0.6625
Saving last model

***Script finished: 00:42:48

Time elapsed: 0:00:32.576858

Testing with FULL TEST LOADER
{'Accuracy': [0.703125, 0.7734375], 'Precision': [0.7803030014038086, 0.5923566818237305], 'Recall': [0.5478723645210266, 0.8017241358757019], 'F1': [0.643750011920929, 0.6813187003135681]}
