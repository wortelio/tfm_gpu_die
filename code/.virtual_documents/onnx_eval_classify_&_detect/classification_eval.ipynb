import logging
import time

import config
import modules.classification_dataloader as classification_loader

from tqdm import tqdm

import onnx
import onnxruntime

import numpy as np
import torch
import torchmetrics

import matplotlib.pyplot as plt





log_path = 'experiments/'

logger = logging.getLogger("GonLogger")
logger.propagate = False
logger.setLevel(logging.INFO)
file_handler = logging.FileHandler(log_path + '02_classification_logfile_final_models_dfire_mini.log')
formatter = logging.Formatter('%(message)s')
file_handler.setFormatter(formatter)

# add file handler to logger
logger.addHandler(file_handler)

logger.info('Eval ONNX Classifiers.\n' + 
            '\tBED compressed and quantized, Mobilenet, ShuffleNet, SqueezeNet.')








val_loader = classification_loader.get_val_loader(shuffle=False)





plt.subplots(4,4, figsize=(8, 8))

for batch_idx, (img, label) in enumerate(val_loader):
              
    for idx in range(config.BATCH_SIZE):
        plt.subplot(4, 4, batch_idx*config.BATCH_SIZE + idx + 1)
        plt.imshow(img[idx].permute(1, 2, 0))
        title = ""
        if label[idx][0] == 1 and label[idx][1] == 1:
            title += "Smoke and Fire"
        elif label[idx][0] == 1 and label[idx][1] == 0:
            title += "Only Smoke"
        elif label[idx][0] == 0 and label[idx][1] == 1:
            title += "Only Fire"
        else:
            title += "Empty"
        plt.title(title)
        
        if (batch_idx*config.BATCH_SIZE + idx + 1 == 16):
            break
    
    if (batch_idx*config.BATCH_SIZE + idx + 1 == 16):
        plt.tight_layout()
        plt.show()
        break








onnx_dir = './onnx_classification_models/'

bed_dir = onnx_dir + 'final_models/'
bed_no_comp_onnx_path = bed_dir + 'BED__no_comp__best_mean_f1__cpu.onnx'
bed_aimet_onnx_path = bed_dir + 'BED__med_comp__341_big__best_mean_f1__cpu.onnx'

mobilenet_onnx_path = onnx_dir + 'mobilenet_classifier.onnx'
shufflenet_onnx_path = onnx_dir + 'shufflenet_classifier.onnx'
squeezenet_onnx_path = onnx_dir + 'squeezenet_classifier.onnx'





bed_no_comp_classifier = onnx.load(bed_no_comp_onnx_path)
onnx.checker.check_model(bed_no_comp_classifier)





bed_aimet_classifier = onnx.load(bed_aimet_onnx_path)
onnx.checker.check_model(bed_aimet_classifier)





mobilenet_classifier = onnx.load(mobilenet_onnx_path)
onnx.checker.check_model(mobilenet_classifier)





shufflenet_classifier = onnx.load(shufflenet_onnx_path)
onnx.checker.check_model(shufflenet_classifier)





squeezenet_classifier = onnx.load(squeezenet_onnx_path)
onnx.checker.check_model(squeezenet_classifier)





precision_metric = torchmetrics.classification.MultilabelPrecision(num_labels = config.N_CLASSES, 
                                                                   threshold = 0.5, 
                                                                   average = None).to('cpu')
recall_metric = torchmetrics.classification.MultilabelRecall(num_labels = config.N_CLASSES, 
                                                             threshold = 0.5, 
                                                             average = None).to('cpu')
accuracy_metric = torchmetrics.classification.MultilabelAccuracy(num_labels = config.N_CLASSES, 
                                                                 threshold = 0.5, 
                                                                 average = None).to('cpu')
f1_metric = torchmetrics.classification.MultilabelF1Score(num_labels = config.N_CLASSES, 
                                                          threshold = 0.5, 
                                                          average = None).to('cpu')

f1_metric_mean = torchmetrics.classification.MultilabelF1Score(num_labels = config.N_CLASSES, 
                                                               threshold = 0.5, 
                                                               average = 'macro').to('cpu')





def to_numpy(tensor):
    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()


def eval_classifier_onnx(loader, model_name):

    ort_session = onnxruntime.InferenceSession(model_name, providers=["CPUExecutionProvider"])

    precision_metric.reset()
    recall_metric.reset()
    accuracy_metric.reset()
    f1_metric.reset()
    f1_metric_mean.reset()
    
    loop = tqdm(loader, desc='Validating', leave=True)
    
    loop_i = 0
    loop_times = []

    for batch_idx, (img, label) in enumerate(loop):

        for idx in range(config.BATCH_SIZE):
            
            ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img[idx].unsqueeze(dim=0))}
            
            start = time.perf_counter_ns()
            
            yhat = ort_session.run(None, ort_inputs)
            
            end = time.perf_counter_ns()
            pred_time = end-start
            
            yhat = np.array(yhat)
            #yhat = torch.tensor(yhat).squeeze(dim=0)
            yhat = torch.sigmoid(torch.tensor(yhat).squeeze(dim=0))
            target = label[idx].unsqueeze(dim=0)

            precision_metric.update(yhat, target)
            recall_metric.update(yhat, target)
            accuracy_metric.update(yhat, target)
            f1_metric.update(yhat, target)
            f1_metric_mean.update(yhat, target)
            
            loop_i += 1
            loop_times.append(pred_time)
    
    precision = precision_metric.compute()
    recall = recall_metric.compute()
    accuracy = accuracy_metric.compute()
    f1 = f1_metric.compute()
    f1_mean = f1_metric_mean.compute()

    precision_metric.reset()
    recall_metric.reset()
    accuracy_metric.reset()
    f1_metric.reset()
    f1_metric_mean.reset()
    
    mean_pred_time = ( sum(loop_times) / len(loop_times) ) * 1e-6

    print(f'SMOKE -> Precision: {precision[0]:.4f} - Recall: {recall[0]:.4f} - Accuracy: {accuracy[0]:.4f} - F1: {f1[0]:.4f}')
    print(f'FIRE -> Precision: {precision[1]:.4f} - Recall: {recall[1]:.4f} - Accuracy: {accuracy[1]:.4f} - F1: {f1[1]:.4f}')
    print(f'Mean F1 Score: {f1_mean.item():.4f}')
    print(f'Mean Pred Time: {mean_pred_time:.3f} ms')

    logger.info(f'\tSMOKE -> Precision: {precision[0]:.4f} - Recall: {recall[0]:.4f} - Accuracy: {accuracy[0]:.4f} - F1: {f1[0]:.4f}')
    logger.info(f'\tFIRE -> Precision: {precision[1]:.4f} - Recall: {recall[1]:.4f} - Accuracy: {accuracy[1]:.4f} - F1: {f1[1]:.4f}')
    logger.info(f'\tMean F1 Score: {f1_mean.item():.4f}')
    logger.info(f'\tMean Pred Time: {mean_pred_time:.3f} ms')
    
    return (
        loop_times,
        {
        'Accuracy': [accuracy[0].item(), accuracy[1].item()],
        'Precision': [precision[0].item(), precision[1].item()],
        'Recall': [recall[0].item(), recall[1].item()],
        'F1': [f1[0].item(), f1[1].item()],
        'F1 mean': f1_mean.item(),
        }
    )





logger.info("\nBED NO COMP ONNX Metrics")
bed_no_comp_time, bed_no_comp_onnx_metrics = eval_classifier_onnx(val_loader, bed_no_comp_onnx_path)





logger.info("\nBED AIMET ONNX Metrics")
bed_aimet_time, bed_aimet_onnx_metrics = eval_classifier_onnx(val_loader, bed_aimet_onnx_path)





logger.info("\nMobilenet ONNX Metrics")
mobilenet_time, mobilenet_onnx_metrics = eval_classifier_onnx(val_loader, mobilenet_onnx_path)





logger.info("\nShufflenet ONNX Metrics")
shufflenet_time, shufflenet_onnx_metrics = eval_classifier_onnx(val_loader, shufflenet_onnx_path)





logger.info("\nSqueezenet ONNX Metrics")
squeezenet_time, squeezenet_onnx_metrics = eval_classifier_onnx(val_loader, squeezenet_onnx_path)
