import numpy as np
import torch
from torchinfo import summary

import modules.dataloaders as dataloaders
import modules.models.model_CNV_imagenet as cnv_model
# import modules.model_CNV_AIMET_imagenet as cnv_aimet_model

import modules.models.model_CNV_AIMET_NoPadding_FPGA_imagenet as cnv_aimet_model

import modules.metrics as metrics
import modules.val_final_model as val_final_model
import modules.utils as utils


# from brevitas.export import export_onnx_qcdq
from brevitas.export import export_qonnx





AIMET = "YES"
if AIMET == "NO":
    model = cnv_model.CNV().to('cuda')
elif AIMET == "YES":
    model = cnv_aimet_model.CNV_AIMET().to('cuda')
else:
    print("Wrong Model")


NO_PADDING = True





if NO_PADDING:
    print("Using No Padding Model -> DIMS (230, 230)")
    print(summary(model, input_size=(1, 3, 230, 230)))
else:
    print("Using Padding Model -> DIMS (224, 224)")
    print(summary(model, input_size=(1, 3, 224, 224)))





# weights_folder = './experiments/test_v04__imagenetQuant__w2a4_PerChannel_FixedPoint/weights'
# model_ckpnt = weights_folder + '/BED_classifier__best_mean_F1.pt'

# weights_folder = './experiments/test_v10__AIMET/weights'
# model_ckpnt = weights_folder + '/BED_classifier__best_mean_F1.pt'

weights_folder = './experiments/test_v13__AIMET_BN_ReLU_added__NoPadding__QuantIdentity/weights'
model_ckpnt = weights_folder + '/BED_classifier__best_mean_F1.pt'


utils.load_checkpoint(
    model_path = model_ckpnt, 
    model = model,
    device = 'cuda'
)


model.to('cpu')
model.eval();





# import importlib
# importlib.reload(config)
# importlib.reload(dataloaders)


# train_dfire_mini_loader = dataloaders.get_dfire_mini_train_loader()
test_dfire_mini_loader = dataloaders.get_dfire_mini_test_loader()





with torch.no_grad():
    val_metrics = val_final_model.eval_fn(
        loader=test_dfire_mini_loader, 
        model=model,                         
        device='cpu')


print('\nTesting with DFire MINI TEST after LOADING F1 Best Mean CHECKPOINT')  
print(val_metrics)





test_dfire_loader = dataloaders.get_dfire_val_loader()


with torch.no_grad():
    val_metrics = val_final_model.eval_fn(
        loader=test_dfire_loader, 
        model=model,                         
        device='cpu')











# import brevitas.nn as qnn
# import torch.nn as nn


# class CNV_BIPOLAR_OUT(nn.Module):
#     def __init__(self, base_model):
#         super(CNV_BIPOLAR_OUT, self).__init__()
#         self.base_model = base_model
#         self.qnt_output = qnn.QuantIdentity(
#             quant_type='binary', 
#             scaling_impl_type='const',
#             bit_width=1, min_val=-1.0, max_val=1.0)

#     def forward(self, x):
#         x = self.base_model(x)
#         x = self.qnt_output(x)
#         return x


# cnv_bipolar_out = CNV_BIPOLAR_OUT(model).to('cpu')





# from tqdm import tqdm

# def eval_bipolar_fn(loader, model, device):
    
#     model.eval()
#     loop = tqdm(loader, desc='Validating', leave=True)

#     for batch_idx, (x, y) in enumerate(loop):
#         x, y = x.to(device), y.to(device)
#         yhat = model(x)

#         # print(y.shape)
#         # print(yhat.shape)
        
#         #yhat[yhat < 1] = 0
#         #yhat = torch.sigmoid(yhat.detach())
#         # print(f'Label {y} - Pred {yhat}')
#         metrics.precision_metric_cpu.update(yhat, y)
#         metrics.recall_metric_cpu.update(yhat, y)
#         metrics.accuracy_metric_cpu.update(yhat, y)
#         metrics.f1_metric_cpu.update(yhat, y)
    
#     precision = metrics.precision_metric_cpu.compute()
#     recall = metrics.recall_metric_cpu.compute()
#     accuracy = metrics.accuracy_metric_cpu.compute()
#     f1 = metrics.f1_metric_cpu.compute()
    
#     metrics.precision_metric_cpu.reset()
#     metrics.recall_metric_cpu.reset()
#     metrics.accuracy_metric_cpu.reset()
#     metrics.f1_metric_cpu.reset()

#     print(f'SMOKE -> Precision: {precision[0]:.4f} - Recall: {recall[0]:.4f} - Accuracy: {accuracy[0]:.4f} - F1: {f1[0]:.4f}')
#     print(f'FIRE -> Precision: {precision[1]:.4f} - Recall: {recall[1]:.4f} - Accuracy: {accuracy[1]:.4f} - F1: {f1[1]:.4f}')
    
#     return (
#         {
#         'Accuracy': [accuracy[0].item(), accuracy[1].item()],
#         'Precision': [precision[0].item(), precision[1].item()],
#         'Recall': [recall[0].item(), recall[1].item()],
#         'F1': [f1[0].item(), f1[1].item()] 
#         }
#     )





# with torch.no_grad():
#     val_metrics = eval_bipolar_fn(
#         loader=test_dfire_mini_loader, 
#         model=cnv_bipolar_out,                         
#         device='cpu')





# onnx_no_bipolar_filename = 'Best_F1_AIMET__NO_Bipolar.onnx'
# export_qonnx(cnv_bipolar_out, torch.randn(1, 3, 224, 224), onnx_no_bipolar_filename);


# onnx_bipolar_filename = 'Best_F1_AIMET__Bipolar.onnx'
# export_qonnx(cnv_bipolar_out, torch.randn(1, 3, 224, 224), onnx_bipolar_filename);





# from qonnx.util.cleanup import cleanup as qonnx_cleanup
# from qonnx.core.modelwrapper import ModelWrapper
# import qonnx.core.onnx_exec as qonnx_exec

# from qonnx.transformation.infer_shapes import InferShapes
# from qonnx.transformation.fold_constants import FoldConstants
# from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs





# clean_no_bipolar_onnx_filename = 'Best_F1_AIMET__NO_Bipolar__CLEAN.onnx'
# qonnx_cleanup(onnx_no_bipolar_filename, out_file=clean_no_bipolar_onnx_filename)

# clean_bipolar_onnx_filename = 'Best_F1_AIMET__Bipolar__CLEAN.onnx'
# qonnx_cleanup(onnx_bipolar_filename, out_file=clean_bipolar_onnx_filename)


# def eval_qonnx(loader, model_filename):
    
#     model_wrapped = ModelWrapper(model_filename)
#     # model_wrapped = model_wrapped.transform(InferShapes())
#     # model_wrapped = model_wrapped.transform(FoldConstants())
#     # model_wrapped = model_wrapped.transform(GiveUniqueNodeNames())
#     # model_wrapped = model_wrapped.transform(GiveReadableTensorNames())
#     # model_wrapped = model_wrapped.transform(RemoveStaticGraphInputs())
    
#     loop = tqdm(loader, desc='Validating', leave=True)

#     for batch_idx, (x, y) in enumerate(loop):
#         x, y = x.to('cpu'), y.to('cpu')
#         img = x.detach().numpy()
#         inp_dict = {"onnx::Mul_0": img}
#         yhat = qonnx_exec.execute_onnx(model_wrapped, inp_dict)
#         # print(y.shape)
#         # print(yhat.shape)

#         yhat = torch.tensor(yhat["global_out"], dtype=torch.float32)
#         # print(f'Label {y} - Pred {yhat}')

#         # yhat[yhat < 1] = 0
#         yhat = torch.sigmoid(yhat.detach())

#         print(f'Label {y} - Pred {yhat}')
#         metrics.precision_metric_cpu.update(yhat, y)
#         metrics.recall_metric_cpu.update(yhat, y)
#         metrics.accuracy_metric_cpu.update(yhat, y)
#         metrics.f1_metric_cpu.update(yhat, y)
    
#     precision = metrics.precision_metric_cpu.compute()
#     recall = metrics.recall_metric_cpu.compute()
#     accuracy = metrics.accuracy_metric_cpu.compute()
#     f1 = metrics.f1_metric_cpu.compute()
    
#     metrics.precision_metric_cpu.reset()
#     metrics.recall_metric_cpu.reset()
#     metrics.accuracy_metric_cpu.reset()
#     metrics.f1_metric_cpu.reset()

#     print(f'SMOKE -> Precision: {precision[0]:.4f} - Recall: {recall[0]:.4f} - Accuracy: {accuracy[0]:.4f} - F1: {f1[0]:.4f}')
#     print(f'FIRE -> Precision: {precision[1]:.4f} - Recall: {recall[1]:.4f} - Accuracy: {accuracy[1]:.4f} - F1: {f1[1]:.4f}')
    
#     return (
#         {
#         'Accuracy': [accuracy[0].item(), accuracy[1].item()],
#         'Precision': [precision[0].item(), precision[1].item()],
#         'Recall': [recall[0].item(), recall[1].item()],
#         'F1': [f1[0].item(), f1[1].item()] 
#         }
#     )


# val_metrics = eval_qonnx(
#     loader=test_dfire_mini_loader, 
#     model_filename=clean_no_bipolar_onnx_filename)


# val_metrics = eval_qonnx(
#     loader=test_dfire_mini_loader, 
#     model_filename=clean_bipolar_onnx_filename)
