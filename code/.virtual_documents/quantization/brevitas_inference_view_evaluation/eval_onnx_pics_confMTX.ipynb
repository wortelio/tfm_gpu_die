import os
import logging
from pathlib import Path
import datetime
from tqdm import tqdm

import config
import datasets

import numpy as np
import math
import pandas as pd
import random

import torch

import matplotlib.pyplot as plt
import matplotlib.patches as patches 

import torchmetrics
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix
import seaborn as sns


import onnx
import onnxruntime





DEVICE = 'cpu'
N_CLASSES = 2





shuffle_val_imgs = True





val_loader = datasets.get_val_loader(shuffle=False)





#dfire_val_loader = datasets.get_dfire_val_loader(shuffle_val_imgs)
dfire_val_loader = datasets.get_dfire_val_loader(shuffle=False)





fasdd_uav_val_loader = datasets.get_fasdd_uav_val_loader(shuffle_val_imgs)





fasdd_cv_val_loader = datasets.get_fasdd_cv_val_loader(shuffle_val_imgs)





# NO COMP MODEL
#model_name = './models/onnx_final_models/BED__no_comp__best_mean_f1__cpu.onnx'

# AIMET COMP MODEL
model_name = './models/onnx_final_models/BED__med_comp__341_big__best_mean_f1__cpu.onnx'

# OLD models
#model_name = './models/onnx_fasdd/medium_fassd__conv341_big__epoch=93.onnx'

# model_fasdd_med = onnx.load(model_name)
# onnx.checker.check_model(model_fasdd_med)

ort_session = onnxruntime.InferenceSession(model_name, providers=["CPUExecutionProvider"])


def to_numpy(tensor):
    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()





def plot_predictions(loader, n_imgs, filename):

    n_imgs_plot = n_imgs
    cols = 4
    rows = int( n_imgs_plot / cols )

    #plot_height = config.BATCH_SIZE * 5
    fig, ax = plt.subplots(rows, cols, figsize=(9, 80)) # BATCH_SIZE(64)*8 -> 320

    for batch_idx, (img, label) in enumerate(loader):
        for i in range(int(config.BATCH_SIZE/cols)):
            for j in range(cols):

                plot_idx = batch_idx*config.BATCH_SIZE + i*cols + j + 1
                sample_idx = i*cols + j
                ax_idx = batch_idx*(int(config.BATCH_SIZE/cols)) + i 
                # print(f'Plot idx: {plot_idx}')
                # print(f'Sample idx: {sample_idx}')
                # print(f'Ax idx: {ax_idx}')

                plt.subplot(rows, cols, plot_idx)
                plt.imshow(img[sample_idx].permute(1, 2, 0))

                label_txt = ""
                #print(f'Label: {label[i*cols + j]}')
                if label[sample_idx, 0] == 1 and label[sample_idx, 1] == 1:
                    label_txt += "Smoke & Fire"
                elif label[sample_idx, 0] == 1 and label[sample_idx, 1] == 0:
                    label_txt += "Only Smoke"
                elif label[sample_idx, 0] == 0 and label[sample_idx, 1] == 1:
                    label_txt += "Only Fire"
                else:
                    label_txt += "Empty"

                ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img[sample_idx].unsqueeze(dim=0))}
                yhat = ort_session.run(None, ort_inputs)
                yhat = np.array(yhat)
                pred = torch.sigmoid(torch.tensor(yhat).squeeze(dim=0))

                #print(f'Pred: {pred}')
                pred_txt = ""
                if pred[..., 0] > 0.5 and pred[..., 1] > 0.5:
                    pred_txt += "Smoke & Fire"
                elif pred[..., 0] > 0.5 and pred[..., 1] < 0.5:
                    pred_txt += "Only Smoke"
                elif pred[..., 0] < 0.5 and pred[..., 1] > 0.5:
                    pred_txt += "Only Fire"
                else:
                    pred_txt += "Empty"

                if pred_txt == label_txt:
                    rect = patches.Rectangle((1, 1), config.IMG_W-2, config.IMG_W-3, linewidth=4, edgecolor='g', facecolor="none")
                elif label_txt == "Smoke & Fire" and (pred_txt == "Only Smoke" or pred_txt == "Only Fire"):
                    rect = patches.Rectangle((1, 1), config.IMG_W-2, config.IMG_W-3, linewidth=4, edgecolor='b', facecolor="none")
                elif label_txt == "Only Smoke" and pred_txt == "Smoke & Fire":
                    rect = patches.Rectangle((1, 1), config.IMG_W-2, config.IMG_W-3, linewidth=4, edgecolor='b', facecolor="none")
                elif label_txt == "Only Fire" and pred_txt == "Smoke & Fire":
                    rect = patches.Rectangle((1, 1), config.IMG_W-2, config.IMG_W-3, linewidth=4, edgecolor='b', facecolor="none")
                else:
                    rect = patches.Rectangle((1, 1), config.IMG_W-2, config.IMG_H-3, linewidth=4, edgecolor='r', facecolor="none")

                ax[ax_idx, j].add_patch(rect)
                ax[ax_idx, j].axis('off')

                title = "Label: " + label_txt + " | " + "Pred: " + pred_txt
                smoke_score = np.round(pred[..., 0].detach().numpy(), 3)
                fire_score = np.round(pred[..., 1].detach().numpy(), 3)
                title += "\n" + "Smoke: " + f'{str(smoke_score)[1:-1]}' + " - Fire: " + f'{str(fire_score)[1:-1]}'
                plt.title(title, fontsize=7, loc='left')

        if (plot_idx == n_imgs_plot):
            plt.tight_layout()
            plt.savefig(filename + '.png')
            #plt.show()
            plt.close()
            break





n_imgs_plot = config.BATCH_SIZE * 2





save_folder = './pred_imgs__conf_mtx/onnx_final_models/aimet_comp/'





plot_predictions(dfire_val_loader, n_imgs_plot, save_folder + 'dfire_preds')





plot_predictions(fasdd_uav_val_loader, n_imgs_plot, save_folder + 'fasdd_uav_preds')





plot_predictions(fasdd_cv_val_loader, n_imgs_plot, save_folder + 'fasdd_cv_preds')





precision_metric = torchmetrics.classification.MultilabelPrecision(num_labels = N_CLASSES, 
                                                                   threshold = 0.5, 
                                                                   average = None).to(DEVICE)
recall_metric = torchmetrics.classification.MultilabelRecall(num_labels = N_CLASSES, 
                                                             threshold = 0.5, 
                                                             average = None).to(DEVICE)
accuracy_metric = torchmetrics.classification.MultilabelAccuracy(num_labels = N_CLASSES, 
                                                                 threshold = 0.5, 
                                                                 average = None).to(DEVICE)
f1_metric = torchmetrics.classification.MultilabelF1Score(num_labels = N_CLASSES, 
                                                          threshold = 0.5, 
                                                          average = None).to(DEVICE)
smoke_conf_mtx_metric = torchmetrics.classification.BinaryConfusionMatrix(threshold = 0.5).to(DEVICE)
fire_conf_mtx_metric = torchmetrics.classification.BinaryConfusionMatrix(threshold = 0.5).to(DEVICE)





'''
Evaluation Function
'''
def eval_fn(loader):
    
    # Reset all metrics before start
    precision_metric.reset()
    recall_metric.reset()
    accuracy_metric.reset()
    f1_metric.reset()
    smoke_conf_mtx_metric.reset()
    fire_conf_mtx_metric.reset()
    

    # Equal values to compare
    empty = torch.tensor([[0, 0]], dtype= torch.float32).to(DEVICE)
    smoke = torch.tensor([[1, 0]], dtype= torch.float32).to(DEVICE)
    fire = torch.tensor([[0, 1]], dtype= torch.float32).to(DEVICE)
    smoke_fire = torch.tensor([[1, 1]], dtype= torch.float32).to(DEVICE)

    loop = tqdm(loader, desc='Validating', leave=True)

    y_true = []
    y_pred = []

    for batch_idx, (x, y) in enumerate(loop):
              
        for idx in range(x.shape[0]):
            
            target = y[idx].unsqueeze(dim=0)
            
            ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x[idx].unsqueeze(dim=0))}
            yhat = ort_session.run(None, ort_inputs)
            yhat = np.array(yhat)
            yhat = torch.sigmoid(torch.tensor(yhat).squeeze(dim=0))
            #yhat = torch.tensor(yhat).squeeze(dim=0)
            
            precision_metric.update(yhat, target)
            recall_metric.update(yhat, target)
            accuracy_metric.update(yhat, target)
            f1_metric.update(yhat, target)
            smoke_conf_mtx_metric.update(yhat[..., 0], target[..., 0])
            fire_conf_mtx_metric.update(yhat[..., 1], target[..., 1])

            yhat = torch.round(yhat)

            # print(f'yhat: {yhat}')
            # print(f'target: {target}')
            # print(f'target y[idx]: {y[idx]}')
            
            # Predictions: yhat with sigmoid already applied
            if torch.equal(yhat, empty):
                y_pred.append(0)
            elif torch.equal(yhat, smoke):
                y_pred.append(1)
            elif torch.equal(yhat, fire):
                y_pred.append(2)
            elif torch.equal(yhat, smoke_fire):
                y_pred.append(3)
            else:
                print("Wrong Prediction")
                raise SystemExit("Wrong Prediction")
                
            # Targets
            if torch.equal(target, empty):
                y_true.append(0)
            elif torch.equal(target, smoke):
                y_true.append(1)
            elif torch.equal(target, fire):
                y_true.append(2)
            elif torch.equal(target, smoke_fire):
                y_true.append(3)
            else:
                print("Wrong Target")
                raise SystemExit("Wrong Target")
    
    precision = precision_metric.compute()
    recall = recall_metric.compute()
    accuracy = accuracy_metric.compute()
    f1 = f1_metric.compute()
    smoke_conf_mtx = smoke_conf_mtx_metric.compute()
    fire_conf_mtx = fire_conf_mtx_metric.compute()

    print("".ljust(6) + "|Accuracy".ljust(10) + "|Precision".ljust(10) + "|Recall".ljust(10) + "|F1".ljust(10))
    print("Smoke".ljust(6) +
          f'|{accuracy[0]:.4f}'.ljust(10) +
          f'|{precision[0]:.4f}'.ljust(10) +
          f'|{recall[0]:.4f}'.ljust(10) +
          f'|{f1[0]:.4f}'.ljust(10))
    print("Fire".ljust(6) +
          f'|{accuracy[1]:.4f}'.ljust(10) +
          f'|{precision[1]:.4f}'.ljust(10) +
          f'|{recall[1]:.4f}'.ljust(10) +
          f'|{f1[1]:.4f}'.ljust(10))
        
    precision_metric.reset()
    recall_metric.reset()
    accuracy_metric.reset()
    f1_metric.reset()
    # smoke_conf_mtx_metric.reset()
    # fire_conf_mtx_metric.reset()
    
    return {'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'y_true': y_true,
            'y_hat': y_pred,
            'smoke_conf_mtx': smoke_conf_mtx,
            'fire_conf_mtx': fire_conf_mtx}





metrics = eval_fn(loader=val_loader)


metrics = eval_fn(loader=dfire_val_loader)


fig, ax = plt.subplots()
ConfusionMatrixDisplay.from_predictions(y_true=metrics['y_true'], 
                                        y_pred=metrics['y_hat'],
                                        normalize='true',
                                        display_labels=['Empty', 'Only Smoke', 'Only Fire', 'Smoke & Fire'],
                                        cmap='viridis',
                                        ax=ax)
plt.title("Confusion Matrix", fontsize=20)
ax.set_xlabel("Predicted", fontsize=15, labelpad=10)
ax.set_ylabel("True", fontsize=15,labelpad=10)
#plt.style.use("seaborn-v0_8")
plt.show()


fig, ax = smoke_conf_mtx_metric.plot(cmap='viridis')
fig.set_size_inches(3,3)
ax.set_xticks(range(2), ['empty', 'smoke'], rotation=30)
ax.set_yticks(range(2), ['empty', 'smoke'], rotation=30)


fig, ax = fire_conf_mtx_metric.plot(cmap='viridis')
fig.set_size_inches(3,3)
ax.set_xticks(range(2), ['empty', 'fire'], rotation=30)
ax.set_yticks(range(2), ['empty', 'fire'], rotation=30)





conf_mtx = confusion_matrix(y_true=metrics['y_true'], 
                            y_pred=metrics['y_hat'],
                            normalize='true')
print(type(conf_mtx))
cf_mtx_dic = {
    'Empty': conf_mtx[: , 0],
    'Only Smoke': conf_mtx[:, 1],
    'Only Fire': conf_mtx[:, 2],
    'Smoke & Fire': conf_mtx[:, 3]
}
print(conf_mtx)


pd_cf_mtx = pd.DataFrame(cf_mtx_dic, index=['Empty', 'Only Smoke', 'Only Fire', 'Smoke & Fire'])


ax = sns.heatmap(pd_cf_mtx, annot=True)
ax.set_title("Confusion Matrix", fontsize=20)
ax.set_xlabel("Predicted", fontsize=15, labelpad=12)
ax.set_ylabel("True", fontsize=15,labelpad=12)
plt.yticks(fontsize=12, rotation=0)
plt.xticks(fontsize=12, rotation=0)
plt.savefig(save_folder+'conf_mtx_4_classes.png')


metrics_dic = {
    'accuracy': np.round(metrics['accuracy'].cpu().numpy().tolist(), 4),
    'precision': np.round(metrics['precision'].cpu().numpy().tolist(), 4),
    'recall': np.round(metrics['recall'].cpu().numpy().tolist(), 4),
    'f1': np.round(metrics['f1'].cpu().numpy().tolist(), 4)
}
metrics_df = pd.DataFrame(metrics_dic, index=['Smoke', 'Fire'])
metrics_df





print(metrics['smoke_conf_mtx'].numpy())
smoke_metrics = metrics['smoke_conf_mtx'].numpy()


smoke_cf_mtx_dic = {
    'Empty': smoke_metrics[... , 0],
    'Smoke': smoke_metrics[:, 1],
}
print(smoke_cf_mtx_dic)


pd_smoke_cf_mtx = pd.DataFrame(smoke_cf_mtx_dic, index=['Empty', 'Smoke'])


ax = sns.heatmap(pd_smoke_cf_mtx, annot=True, fmt='g')
ax.set_title("Smoke Confusion Matrix", fontsize=20)
ax.set_xlabel("Predicted", fontsize=15, labelpad=12)
ax.set_ylabel("True", fontsize=15,labelpad=12)
plt.yticks(rotation=0)
plt.yticks(fontsize=12, rotation=0)
plt.xticks(fontsize=12, rotation=0)
plt.savefig(save_folder+'conf_mtx_smoke.png')





print(metrics['fire_conf_mtx'].numpy())
fire_metrics = metrics['fire_conf_mtx'].numpy()


fire_cf_mtx_dic = {
    'Empty': fire_metrics[... , 0],
    'Smoke': fire_metrics[:, 1],
}
print(fire_cf_mtx_dic)


pd_fire_cf_mtx = pd.DataFrame(fire_cf_mtx_dic, index=['Empty', 'Smoke'])


ax = sns.heatmap(pd_fire_cf_mtx, annot=True, fmt='g')
ax.set_title("Fire Confusion Matrix", fontsize=20)
ax.set_xlabel("Predicted", fontsize=15, labelpad=12)
ax.set_ylabel("True", fontsize=15,labelpad=12)
plt.yticks(fontsize=12, rotation=0)
plt.xticks(fontsize=12, rotation=0)
plt.savefig(save_folder+'conf_mtx_fire.png')



