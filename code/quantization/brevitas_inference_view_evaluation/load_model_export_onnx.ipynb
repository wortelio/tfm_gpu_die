{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68aba757-7806-498b-a250-e4bda5db2bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import utils\n",
    "\n",
    "import models\n",
    "import models_aimet_high\n",
    "import models_aimet_medium\n",
    "import models_aimet_low\n",
    "\n",
    "import config\n",
    "import dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "import validate\n",
    "\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from brevitas.export import export_onnx_qcdq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e38bbac-de94-4092-b33f-130d00b8c92f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05058347-d9f6-4d01-8d7f-c4c84c4b4ffd",
   "metadata": {},
   "source": [
    "## Model No Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace7c319-f4ac-4826-9c4f-0cdb43dadc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_comp = models.QUANT_FixedPoint_NoBN_BED_CLASSIFIER(\n",
    "    weight_bw = config.NO_COMP_WEIGHTS_BIT_WIDTH,\n",
    "    big_layers_weight_bw = config.NO_COMP_BIG_LAYERS_WEIGHTS_BIT_WIDTH,\n",
    "    act_bw = config.NO_COMP_ACTIVATIONS_BIT_WIDTH,\n",
    "    bias_bw = config.NO_COMP_BIAS_BIT_WIDTH,\n",
    "    num_classes=config.N_CLASSES).to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6a9da06-72d0-4784-8db9-bbaef8175a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_comp_folder = './models/'\n",
    "model_no_comp_name = 'BED_classifier__NOCOMP__smoke__precision=0.9025__recall=0.9021__epoch=35.pt'\n",
    "model_no_comp_pt = model_no_comp_folder + model_no_comp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b181202-2d11-48f4-b551-3bb36159cc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model. Trained during 35 epochs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.load_checkpoint(model_path = model_no_comp_pt, \n",
    "                      model = model_no_comp, \n",
    "                      optimizer= None, \n",
    "                      scheduler= None, \n",
    "                      device = config.DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb80420d-a4d7-4f6d-b8da-de28ea34aca7",
   "metadata": {},
   "source": [
    "### Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceaf577f-6379-4e29-99c5-8704f90ef065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch_brevitas/lib/python3.10/site-packages/brevitas/export/onnx/standard/manager.py:26: UserWarning: ONNX opset version set to 13, override with opset_version=\n",
      "  warnings.warn(f\"ONNX opset version set to {DEFAULT_OPSET}, override with {ka}=\")\n"
     ]
    }
   ],
   "source": [
    "export_onnx_qcdq(\n",
    "    model_no_comp, \n",
    "    torch.randn(1, 3, config.IMG_H, config.IMG_W).to(config.DEVICE), \n",
    "    export_path='./models/onnx/no_comp_model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55593e7c-dfc9-4be4-a154-6d3b5408f3da",
   "metadata": {},
   "source": [
    "## Model Low Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9629f029-b8a0-4563-b742-8191ee19bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_low_comp = models_aimet_low.QUANT_SOFT_PRUNING_AFTER_SVD_CLASSIFIER(\n",
    "    weight_bw = config.LOW_COMP_WEIGHTS_BIT_WIDTH,\n",
    "    big_layers_weight_bw = config.LOW_COMP_BIG_LAYERS_WEIGHTS_BIT_WIDTH,\n",
    "    act_bw = config.LOW_COMP_ACTIVATIONS_BIT_WIDTH,\n",
    "    bias_bw = config.LOW_COMP_BIAS_BIT_WIDTH,\n",
    "    num_classes=config.N_CLASSES).to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4383ddb-3e17-48cb-b270-7e4b683199e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_low_comp_folder = './models/'\n",
    "model_low_comp_name = 'BED_classifier__LOWCOMP__smoke__precision=0.9024__recall=0.9011__epoch=80.pt'\n",
    "model_low_comp_pt = model_low_comp_folder + model_low_comp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96e434a8-9f13-40c2-864e-a7bd7bec98f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model. Trained during 80 epochs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.load_checkpoint(model_path = model_low_comp_pt, \n",
    "                      model = model_low_comp, \n",
    "                      optimizer= None, \n",
    "                      scheduler= None, \n",
    "                      device = config.DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd391d-22d8-4fd2-b9b1-e46fe02a849f",
   "metadata": {},
   "source": [
    "### Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "779210f3-0d1f-4825-b683-1c77106bf1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch_brevitas/lib/python3.10/site-packages/brevitas/export/onnx/standard/manager.py:26: UserWarning: ONNX opset version set to 13, override with opset_version=\n",
      "  warnings.warn(f\"ONNX opset version set to {DEFAULT_OPSET}, override with {ka}=\")\n"
     ]
    }
   ],
   "source": [
    "export_onnx_qcdq(\n",
    "    model_low_comp, \n",
    "    torch.randn(1, 3, config.IMG_H, config.IMG_W).to(config.DEVICE), \n",
    "    export_path='./models/onnx/low_comp_model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82660e8-a730-4f5d-8d9a-18278079652b",
   "metadata": {},
   "source": [
    "## Model Medium Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b1a061d-78f0-45c3-9f3b-1227852cb82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_med_comp = models_aimet_medium.QUANT_MEDIUM_PRUNING_AFTER_SVD_CLASSIFIER(\n",
    "    weight_bw = config.MED_COMP_WEIGHTS_BIT_WIDTH,\n",
    "    big_layers_weight_bw = config.MED_COMP_BIG_LAYERS_WEIGHTS_BIT_WIDTH,\n",
    "    act_bw = config.MED_COMP_ACTIVATIONS_BIT_WIDTH,\n",
    "    bias_bw = config.MED_COMP_BIAS_BIT_WIDTH,\n",
    "    num_classes=config.N_CLASSES).to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fc997b4-ac65-493c-acb3-bcfb66b207ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_med_comp_folder = './models/'\n",
    "model_med_comp_name = 'BED_classifier__MEDCOMP__smoke__precision=0.9028__recall=0.9001__epoch=49.pt'\n",
    "model_med_comp_pt = model_med_comp_folder + model_med_comp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "457d9fd6-11c1-442b-9420-d6f8e45aefee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model. Trained during 49 epochs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.load_checkpoint(model_path = model_med_comp_pt, \n",
    "                      model = model_med_comp, \n",
    "                      optimizer= None, \n",
    "                      scheduler= None, \n",
    "                      device = config.DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8bfdc0-ff58-4ac3-acb4-2229327649e5",
   "metadata": {},
   "source": [
    "### Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8999f31b-b09e-4940-bdd4-0d08227b56d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch_brevitas/lib/python3.10/site-packages/brevitas/export/onnx/standard/manager.py:26: UserWarning: ONNX opset version set to 13, override with opset_version=\n",
      "  warnings.warn(f\"ONNX opset version set to {DEFAULT_OPSET}, override with {ka}=\")\n"
     ]
    }
   ],
   "source": [
    "export_onnx_qcdq(\n",
    "    model_med_comp, \n",
    "    torch.randn(1, 3, config.IMG_H, config.IMG_W).to(config.DEVICE), \n",
    "    export_path='./models/onnx/med_comp_model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73786e27-cdbd-46c3-871b-d0d2a358682c",
   "metadata": {},
   "source": [
    "## Model High Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f74ef3e-6671-4e72-ad53-1d71232a3c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_high_comp = models_aimet_high.QUANT_PRUNING_AFTER_SVD_CLASSIFIER(\n",
    "    weight_bw = config.HIGH_COMP_WEIGHTS_BIT_WIDTH,\n",
    "    big_layers_weight_bw = config.HIGH_COMP_BIG_LAYERS_WEIGHTS_BIT_WIDTH,\n",
    "    act_bw = config.HIGH_COMP_ACTIVATIONS_BIT_WIDTH,\n",
    "    bias_bw = config.HIGH_COMP_BIAS_BIT_WIDTH,\n",
    "    num_classes=config.N_CLASSES).to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49ae506c-af6f-4c13-be0c-319787107ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_high_comp_folder = './models/'\n",
    "model_high_comp_name = 'BED_classifier__HIGHCOMP__smoke__precision=0.9081__recall=0.9006__epoch=90.pt'\n",
    "model_high_comp_pt = model_high_comp_folder + model_high_comp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9e61941-1934-4733-9905-a1cba585e4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model. Trained during 90 epochs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.load_checkpoint(model_path = model_high_comp_pt, \n",
    "                      model = model_high_comp, \n",
    "                      optimizer= None, \n",
    "                      scheduler= None, \n",
    "                      device = config.DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d16b05-9f51-4b10-a058-77469cc8ed69",
   "metadata": {},
   "source": [
    "### Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7139e76c-f27b-499a-9019-d7c43e8fb044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch_brevitas/lib/python3.10/site-packages/brevitas/export/onnx/standard/manager.py:26: UserWarning: ONNX opset version set to 13, override with opset_version=\n",
      "  warnings.warn(f\"ONNX opset version set to {DEFAULT_OPSET}, override with {ka}=\")\n"
     ]
    }
   ],
   "source": [
    "export_onnx_qcdq(\n",
    "    model_high_comp, \n",
    "    torch.randn(1, 3, config.IMG_H, config.IMG_W).to(config.DEVICE), \n",
    "    export_path='./models/onnx/high_comp_model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50037001-df9f-4e4c-8467-0e63efd9813f",
   "metadata": {},
   "source": [
    "# Evaluate all Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef2e45a-4bfd-47f0-8021-2481c658e37c",
   "metadata": {},
   "source": [
    "## Val Dataset and Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d1141a7-7bbb-44ae-bacf-5ddbc992280f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST DFire dataset\n",
      "DFire Removed wrong images: 0\n",
      "DFire empty images: 2005\n",
      "DFire only smoke images: 1186\n",
      "DFire only fire images: 220\n",
      "DFire smoke and fire images: 895\n",
      "Test dataset len: 4306\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION DATASET\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(config.IMG_H, config.IMG_W, p=1),\n",
    "    ToTensorV2(p=1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nTEST DFire dataset\")\n",
    "val_dataset = dataset.DFireDataset(\n",
    "    img_h = config.IMG_H,\n",
    "    img_w = config.IMG_W,\n",
    "    img_dir = config.VAL_IMG_DIR,\n",
    "    label_dir = config.VAL_LABEL_DIR,\n",
    "    num_classes = config.N_CLASSES,\n",
    "    ds_len = config.DS_LEN,\n",
    "    transform=val_transform)\n",
    "\n",
    "print(f'Test dataset len: {len(val_dataset)}')\n",
    "\n",
    "# LOADERS\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                        batch_size=config.BATCH_SIZE,\n",
    "                        num_workers=config.NUM_WORKERS,\n",
    "                        pin_memory=config.PIN_MEMORY,\n",
    "                        shuffle=False,\n",
    "                        drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f92d5e-e35f-4497-837f-1f15c69a7b01",
   "metadata": {},
   "source": [
    "## Run Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05593ef3-fdd1-4d8e-be18-9c17f7bac67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________ NO COMPRESSION MODEL ___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:04<00:00, 15.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOKE -> Precision: 0.9025 - Recall: 0.9021 - Accuracy: 0.9060 - F1: 0.9023\n",
      "FIRE -> Precision: 0.9352 - Recall: 0.9099 - Accuracy: 0.9604 - F1: 0.9224\n",
      "Mean F1 Score: 0.9123\n",
      "___________________________ LOW COMPRESSION MODEL ___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:04<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOKE -> Precision: 0.9024 - Recall: 0.9011 - Accuracy: 0.9056 - F1: 0.9018\n",
      "FIRE -> Precision: 0.9216 - Recall: 0.9324 - Accuracy: 0.9620 - F1: 0.9270\n",
      "Mean F1 Score: 0.9144\n",
      "___________________________ MEDIUM COMPRESSION MODEL ___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:04<00:00, 16.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOKE -> Precision: 0.9028 - Recall: 0.9001 - Accuracy: 0.9053 - F1: 0.9015\n",
      "FIRE -> Precision: 0.9346 - Recall: 0.9144 - Accuracy: 0.9613 - F1: 0.9244\n",
      "Mean F1 Score: 0.9129\n",
      "___________________________ HIGH COMPRESSION MODEL ___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:04<00:00, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOKE -> Precision: 0.9081 - Recall: 0.9006 - Accuracy: 0.9083 - F1: 0.9044\n",
      "FIRE -> Precision: 0.9416 - Recall: 0.9144 - Accuracy: 0.9632 - F1: 0.9278\n",
      "Mean F1 Score: 0.9161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('___________________________ NO COMPRESSION MODEL ___________________________')\n",
    "metrics_model_no_comp = validate.eval_fn(val_loader, model_no_comp, config.DEVICE)\n",
    "print('___________________________ LOW COMPRESSION MODEL ___________________________')\n",
    "metrics_model_low_comp = validate.eval_fn(val_loader, model_low_comp, config.DEVICE)\n",
    "print('___________________________ MEDIUM COMPRESSION MODEL ___________________________')\n",
    "metrics_model_med_comp = validate.eval_fn(val_loader, model_med_comp, config.DEVICE)\n",
    "print('___________________________ HIGH COMPRESSION MODEL ___________________________')\n",
    "metrics_model_high_comp = validate.eval_fn(val_loader, model_high_comp, config.DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca036a7-1254-453e-8c23-be2603ea65ea",
   "metadata": {},
   "source": [
    "# FASDD UAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "967d51fc-d175-4310-865a-ff154f10789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uav_imgs_dir = '../../../datasets/fasdd/fasdd_cv/images/'\n",
    "# uav_imgs_list = os.listdir(uav_imgs_dir)\n",
    "# num_uav_imgs = len(uav_imgs_list)\n",
    "# print(f'Number of UAV images: {num_uav_imgs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f375acb-eb9f-41d9-b414-ef7ce9cbc6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(uav_imgs_dir + uav_imgs_list[1500])\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# img = cv2.resize(img, (config.IMG_H, config.IMG_H))\n",
    "# plt.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7825ce73-34c9-4d5c-a5b5-d7cd1033f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = img / 256.\n",
    "# img = torch.tensor(img, dtype=torch.float)\n",
    "# img = torch.permute(img, (2, 0, 1))\n",
    "# img = img.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d319711c-473c-4035-bd3d-33e2adf1e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b390dcf-ee63-4647-a976-10808b957575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = model(img.to(config.DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cb0fd64-8e81-4196-9375-2433055840e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9426a2b-2b42-4126-affa-9322e6063662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
