{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8a513a-1549-4be7-af63-4f9542994187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "from decimal import Decimal\n",
    "\n",
    "import torch\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import torch.nn as nn \n",
    "from torch.nn.utils import parameters_to_vector\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "import cv2\n",
    "\n",
    "import config\n",
    "import datasets\n",
    "import models\n",
    "import loss\n",
    "import metrics\n",
    "import train_epoch\n",
    "import val_epoch\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f7873-fc40-4e71-b3ad-7e3aadf45081",
   "metadata": {},
   "source": [
    "# AIMET imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b1b731b-4520-4b6c-8cc2-5d601081a059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-10 10:28:55,648 - root - INFO - AIMET\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.1.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"jspanel\"], function(jsPanel) {\n",
       "\twindow.jsPanel = jsPanel\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-modal\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-tooltip\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-hint\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-layout\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-contextmenu\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-dock\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 9;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      Bokeh = root.Bokeh;\n",
       "      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      if (!reloading && (!bokeh_loaded || is_dev)) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.1.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from aimet_torch.compress import ModelCompressor\n",
    "from aimet_torch.defs import SpatialSvdParameters\n",
    "from aimet_torch.defs import ChannelPruningParameters\n",
    "from aimet_torch.onnx_utils import OnnxSaver\n",
    "from aimet_common.defs import CostMetric, CompressionScheme, GreedySelectionParameters\n",
    "# from aimet_common.utils import start_bokeh_server_session\n",
    "# from aimet_torch.visualize_serialized_data import VisualizeCompression\n",
    "\n",
    "# import nest_asyncio # To run de bokeh server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8118183f-8cff-4a8c-a6cc-6466c6cdcbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nest_asyncio.apply() # Enable nested loops to start bokeh server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "423ca7c6-5d21-460f-9d55-073aceab5616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d8132b-9f5b-403d-aa2b-bfa50ecf25d5",
   "metadata": {},
   "source": [
    "# Define Matplot Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3728c53e-0c8c-4a8c-92fa-8f676e65b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpl.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfc923c-eb11-4077-88d4-82c09c17e1a1",
   "metadata": {},
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b4e5f0e-110e-4319-aeb1-ea3fcc692ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = config.LOGS_FOLDER\n",
    "\n",
    "logger = logging.getLogger(\"GonLogger\")\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.INFO)\n",
    "file_handler = logging.FileHandler(log_path + 'logfile.log')\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# add file handler to logger\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.info('BED Classifier XS Tiny.\\n' +  \n",
    "            '\\tOne Head.\\n' +\n",
    "            '\\tAdding best mean F1 save.\\n' +\n",
    "            '\\t256 Normalization.\\n' +\n",
    "            '\\tWeighted for Precision.\\n' +\n",
    "            '\\tModules.\\n'+ \n",
    "            '\\tLosses and Metrics Loggers.\\n' +\n",
    "            f'\\tSVD Compression Ratio  = {config.SVD_COMPRESSION_RATIO}\\n' +\n",
    "            f'\\tPruning Compression Ratio  = {config.PRUNING_COMPRESSION_RATIO}\\n' +\n",
    "            f'\\t{config.EPOCHS} epochs.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9374d99a-7746-4bd2-b6b5-548f2b6f95bd",
   "metadata": {},
   "source": [
    "# Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50319596-f4bd-499c-a063-7612aa2c641b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN DFIRE dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFire Removed wrong images: 0\n",
      "DFire empty images: 7833\n",
      "DFire only smoke images: 4681\n",
      "DFire only fire images: 944\n",
      "DFire smoke and fire images: 3763\n",
      "\n",
      "Train DFire dataset len: 17221\n",
      "\n",
      "TRAIN FASDD UAV dataset\n"
     ]
    }
   ],
   "source": [
    "train_loader = datasets.get_train_loader()\n",
    "val_loader = datasets.get_val_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15183310-3690-45fe-a282-d67b55e9cc4c",
   "metadata": {},
   "source": [
    "# Models Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4fcfec-6bfb-42dd-b4b3-227a40ae8469",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.MODEL == \"BED\":   \n",
    "    print(\"Using BED Classifier\")\n",
    "    logger.info(\"\\nUsing BED Classifier\")\n",
    "    fp32_model = models.FUSED_BED_CLASSIFIER(num_classes=config.N_CLASSES).to(config.DEVICE)    \n",
    "else:\n",
    "    print(\"Wrong Model\")\n",
    "    logger.info(\"Wrong Model\")\n",
    "    raise SystemExit(\"Wrong Model\")\n",
    "\n",
    "# MODEL PARAMETERS\n",
    "n_trainable = sum(p.numel() for p in fp32_model.parameters() if p.requires_grad)\n",
    "print(f'\\nTrainable parameters = {n_trainable}')\n",
    "logger.info(f'\\nTrainable parameters = {n_trainable}')\n",
    "\n",
    "n_params = parameters_to_vector(fp32_model.parameters()).numel()\n",
    "print(f'Total parameters = {n_params}\\n')\n",
    "logger.info(f'Total parameters = {n_params}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ca70e-262b-4c78-88d1-ec9e81176f4d",
   "metadata": {},
   "source": [
    "### Check Model Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce04b628-4a5b-4aa7-8668-0ad7b5a834c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_rand_np = np.random.rand(4, 3, config.IMG_H, config.IMG_W)\n",
    "in_rand = torch.tensor(in_rand_np, dtype=torch.float32, device=config.DEVICE)\n",
    "out_test = fp32_model(in_rand)\n",
    "print(f'Model shape is {out_test}')\n",
    "print(f'BED Model Arquitecture\\n{fp32_model}')\n",
    "logger.info(f'Model shape is {out_test}')\n",
    "logger.info(f'BED Model Arquitecture\\n{fp32_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0f708-5b0a-40a8-a587-89fd3ac364f8",
   "metadata": {},
   "source": [
    "# Load Pretrained or Initialize Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cf7f82-ad2c-4e60-b4cc-e71f0c676a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_trained = utils.load_checkpoint(config.LOAD_MODEL_FILE, \n",
    "                                       fp32_model, \n",
    "                                       optimizer=None, \n",
    "                                       scheduler=None, \n",
    "                                       device=config.DEVICE)\n",
    "\n",
    "logger.info(f\"Loading Model. Trained during {epochs_trained} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9011174c-9def-44c1-beb1-102bddb9f00b",
   "metadata": {},
   "source": [
    "# Torchinfo: model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67b889d-874a-4ab2-b9f5-eafc49c5ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary(fp32_model, input_size=(1, 3, config.IMG_H, config.IMG_W)))\n",
    "logger.info(\"Original FP32 Model Summary\")\n",
    "logger.info(summary(fp32_model, input_size=(config.BATCH_SIZE, 3, config.IMG_H, config.IMG_W)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb73ad-53e7-41f5-a6c7-2ed6c471b835",
   "metadata": {},
   "source": [
    "# Save ONNX original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d083d-5bff-4527-8151-81f454dfd493",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 3, config.IMG_H, config.IMG_W)\n",
    "\n",
    "torch.onnx.export(fp32_model, torch.randn(input_shape).to(config.DEVICE), config.RUN_FOLDER + 'fp32_model.onnx')\n",
    "#OnnxSaver.set_node_names('/models/fp32_model.onnx', fp32_model, input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a7b3d-ba26-4d62-a0c0-9132bb9fb35f",
   "metadata": {},
   "source": [
    "# AIMET Spatial SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c93282-2fbb-4c03-821a-0f0d0760c7f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Start Visualization Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57071f4-c17f-4319-87e1-0bb26f3a553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization_url, process = start_bokeh_server_session()\n",
    "# print(visualization_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f564b84-b70c-4e68-b8d5-6ae540ed069d",
   "metadata": {},
   "source": [
    "### Configure SVD Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43798232-a5fb-4ef5-b89c-2f5d87db0dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modules_to_ignore = [model.conv1]\n",
    "modules_to_ignore = []\n",
    "greedy_params = GreedySelectionParameters(\n",
    "    target_comp_ratio=Decimal(config.SVD_COMPRESSION_RATIO), \n",
    "    saved_eval_scores_dict=config.SVD_DIC_FILE)\n",
    "auto_params = SpatialSvdParameters.AutoModeParams(\n",
    "    greedy_params,\n",
    "    modules_to_ignore=modules_to_ignore)\n",
    "spatial_svd_params = SpatialSvdParameters(\n",
    "    mode=SpatialSvdParameters.Mode.auto,\n",
    "    params=auto_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136cbbb0-74c8-4ed1-bb30-6af7db2ea077",
   "metadata": {},
   "source": [
    "### Evaluate Model Callback\n",
    "\n",
    "Signature: (model, iterations, use_cuda)\n",
    "Return an accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce9495c-ff17-4be7-b87a-f8720087dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, iterations, use_cuda):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(val_loader):\n",
    "        if use_cuda == True:\n",
    "            x, y = x.to('cuda'), y.to('cuda')\n",
    "        else:\n",
    "            model.to('cpu')\n",
    "        out = model(x)\n",
    "        if iterations is not None:\n",
    "            if batch_idx == iterations:\n",
    "                break\n",
    "        \n",
    "        # F1 average Macro   \n",
    "        yhat = torch.sigmoid(out.detach())\n",
    "        metrics.f1_metric_mean.update(yhat, y)\n",
    "    \n",
    "    f1_mean = metrics.f1_metric_mean.compute()\n",
    "    metrics.f1_metric_mean.reset()\n",
    "\n",
    "    print(f'F1 mean: {f1_mean:.4f}')\n",
    "    \n",
    "    return f1_mean.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953badff-069f-4e95-8a9e-4f96a54ab344",
   "metadata": {},
   "source": [
    "### Baseline F1 Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1827951-a0f9-4ebf-8c7d-3be08fa1bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_f1 = evaluate_model(fp32_model, None, True)\n",
    "print(type(baseline_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e4c418-6d55-4445-985e-3b652b0bc9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model, stats = ModelCompressor.compress_model(\n",
    "    fp32_model,\n",
    "    input_shape=input_shape,\n",
    "    eval_callback=evaluate_model,\n",
    "    eval_iterations=None,\n",
    "    compress_scheme=CompressionScheme.spatial_svd,\n",
    "    cost_metric=CostMetric.mac,\n",
    "    parameters=spatial_svd_params,\n",
    "    visualization_url=None)                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a90fb-8ba0-4965-a897-9eda4cfa7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svd_model)\n",
    "logger.info(svd_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c76311-21bf-4f16-9d03-bae8220f5f6f",
   "metadata": {},
   "source": [
    "### Print Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d2c30-8733-4b30-aa77-0432f95135d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats)\n",
    "logger.info(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056036ec-672f-4876-86af-2052cbc85495",
   "metadata": {},
   "source": [
    "### Torchinfo: model compressed summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36139480-e444-4ee6-98c0-0dcec0c25f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary(svd_model, input_size=(1, 3, config.IMG_H, config.IMG_W)))\n",
    "logger.info(\"Compressed Model Summary\")\n",
    "logger.info(summary(svd_model, input_size=(1, 3, config.IMG_H, config.IMG_W)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f636c-be77-49d9-b29f-c347e3a94ebc",
   "metadata": {},
   "source": [
    "### Evaluate Compressed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beff48c7-7a18-49c3-968c-ec71743df10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_f1 = evaluate_model(svd_model, None, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bd2105-474f-439f-b84e-44f29f462b69",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a890a26-99e5-4b39-a766-1efc8842cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_ratios_file_path = './data/greedy_selection_comp_ratios_list.pkl'\n",
    "eval_scores_path = './data/greedy_selection_eval_scores_dict.pkl'\n",
    "\n",
    "unpickled_ratios = pd.read_pickle(comp_ratios_file_path)\n",
    "unpickled_scores = pd.read_pickle(eval_scores_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d644802-87ca-4321-aadd-c66c57bb8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(unpickled_scores)\n",
    "df_scores.to_csv(config.RUN_FOLDER + 'scores_svd.csv')\n",
    "print(df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac07fb2-85ac-467f-bc2d-dea822c28e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios = pd.DataFrame(unpickled_ratios)\n",
    "df_ratios.to_csv(config.RUN_FOLDER + 'ratios_svd.csv')\n",
    "print(df_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c9b36d-9a54-4ce8-8521-41eb277035e8",
   "metadata": {},
   "source": [
    "# Save Compressed Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a9d51-aea0-485c-b7af-e0bc2641d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(svd_model, torch.randn(input_shape).to(config.DEVICE), config.RUN_FOLDER + 'svd_model_noTrain.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a9b4e-cc35-497e-ae3a-4973817e85b3",
   "metadata": {},
   "source": [
    "### Optimizer and Scheduler of Compressed Model to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cd5bba-82a8-4ed5-b764-bcac6c1eb30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(svd_model.parameters(), \n",
    "                       lr=config.LEARNING_RATE, \n",
    "                       weight_decay=config.WEIGHT_DECAY)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                 mode='min',\n",
    "                                                 factor=config.FACTOR, \n",
    "                                                 patience=config.PATIENCE, \n",
    "                                                 threshold=config.THRES, \n",
    "                                                 threshold_mode='abs',\n",
    "                                                 min_lr=config.MIN_LR)\n",
    "\n",
    "utils.save_checkpoint(epoch=0, \n",
    "                      model=svd_model,\n",
    "                      optimizer=optimizer,\n",
    "                      scheduler=scheduler,\n",
    "                      checkpoint_name=config.WEIGHTS_FOLDER + 'comp_model_after_svd.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285c03d3-6401-434e-812f-f7ae3d96a09e",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8977bc-ced2-4143-9478-f41f538ff95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.LOSS_FN == \"BCE\":\n",
    "    print(f'Loss Function: BCE')\n",
    "    logger.info(f'\\nLoss Function: BCE')\n",
    "    print(f'Smoke Precision Weight: {config.SMOKE_PRECISION_WEIGHT}')\n",
    "    logger.info(f'Smoke Precision Weight: {config.SMOKE_PRECISION_WEIGHT}')\n",
    "    loss_fn = loss.BCE_LOSS(device=config.DEVICE, smoke_precision_weight=config.SMOKE_PRECISION_WEIGHT)\n",
    "else:\n",
    "    print(\"Wrong loss function\")\n",
    "    logger.info(\"Wrong loss function\")\n",
    "    raise SystemExit(\"Wrong loss function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a1175d-40d4-4b8f-8f8b-5900be1ad412",
   "metadata": {},
   "source": [
    "# Print and Log Config Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4badbe8-89c2-41bf-b5b6-abe970c053b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' ============================\n",
    "    Print Config Values\n",
    "============================ '''\n",
    "print(f'\\nDevice: {config.DEVICE}')\n",
    "print(f'Learning Rate: {config.LEARNING_RATE}')\n",
    "print(f'Weight Decay: {config.WEIGHT_DECAY}')\n",
    "print(f'Batch Size: {config.BATCH_SIZE}')\n",
    "print(f'IMG DIMS: ({config.IMG_H}, {config.IMG_W})')\n",
    "\n",
    "logger.info(f'\\nDevice: {config.DEVICE}')\n",
    "logger.info(f'Learning Rate: {config.LEARNING_RATE}')\n",
    "logger.info(f'Weight Decay: {config.WEIGHT_DECAY}')\n",
    "logger.info(f'Scheduler factor: {config.FACTOR}')\n",
    "logger.info(f'Scheduler patience: {config.PATIENCE}')\n",
    "logger.info(f'Scheduler threshold: {config.THRES}')\n",
    "logger.info(f'Scheduler min learning rate: {config.MIN_LR}')\n",
    "logger.info(f'Batch Size: {config.BATCH_SIZE}')\n",
    "logger.info(f'W: {config.IMG_W}\\nH: {config.IMG_H}')\n",
    "logger.info(f'Batch Size: {config.BATCH_SIZE}')\n",
    "logger.info(f'W: {config.IMG_W}\\nH: {config.IMG_H}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80898e59-ddee-4670-9054-d443556de710",
   "metadata": {},
   "source": [
    "# Loss and Metrics Loggers and Plotters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a61cff5-0ac7-49f0-9f10-726e07b60c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses_logger = utils.LogLosses()\n",
    "train_metrics_logger = utils.LogMetrics()\n",
    "lr_logger = utils.LogLR(log_path=config.PLOTS_FOLDER)\n",
    "\n",
    "val_losses_logger = utils.LogLosses()\n",
    "val_metrics_logger = utils.LogMetrics()\n",
    "\n",
    "loss_plotter = utils.PlotMetrics(log_path=config.PLOTS_FOLDER, model_name=config.MODEL, loss_or_metric='Loss')\n",
    "metrics_plotter = utils.PlotMetrics(log_path=config.PLOTS_FOLDER, model_name=config.MODEL, loss_or_metric='Metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ff6ca-4e1a-40a3-a173-1de75ba0ef11",
   "metadata": {},
   "source": [
    "# Train Loop Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d2348-c75c-4596-9d8f-e6da9144ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, start_epoch=0):\n",
    "\n",
    "    ''' ==============================================================\n",
    "                                TRAINING LOOP\n",
    "    ============================================================== '''\n",
    "    start = datetime.datetime.now()\n",
    "    start_time = start.strftime(\"%H:%M:%S\")\n",
    "    print(f'\\n***Start Training: {start_time}\\n')\n",
    "    logger.info(f'\\n***Start Training: {start_time}\\n')\n",
    "    \n",
    "    # Start with infinite validation loss\n",
    "    best_valid_loss = np.inf\n",
    "    best_smoke_precision = 0. #torch.tensor([0.])\n",
    "    smoke_f1_min_save = 0.9 #torch.tensor([0.9])\n",
    "    best_mean_f1 = 0.\n",
    "\n",
    "    #start_epoch = 0\n",
    "    epochs_plot = []\n",
    "        \n",
    "    for epoch in range(start_epoch, config.EPOCHS):\n",
    "\n",
    "        print(f'\\n=== EPOCH {epoch}/{config.EPOCHS-1} ===')\n",
    "        logger.info(f'\\n=== EPOCH {epoch}/{config.EPOCHS-1} ===')\n",
    "        \n",
    "        #====================== TRAINING ========================#\n",
    "        current_lr = train_epoch.get_lr(optimizer=optimizer)\n",
    "        logger.info(f'Learning Rate = {current_lr}\\n')\n",
    "        lr_logger.log_lr(current_lr)\n",
    "                \n",
    "        train_losses, train_metrics = train_epoch.train_fn(\n",
    "            loader=train_loader, \n",
    "            model=model, \n",
    "            optimizer=optimizer, \n",
    "            loss_fn=loss_fn,\n",
    "            device=config.DEVICE)\n",
    "        \n",
    "        train_losses_logger.update_metrics(train_losses)\n",
    "        train_metrics_logger.update_metrics(train_metrics)\n",
    "                \n",
    "        logger.info(utils.print_metrics_to_logger(\"TRAIN Stats\", train_losses, train_metrics))\n",
    "        \n",
    "        #===================== VALIDATING =======================#\n",
    "        with torch.no_grad():\n",
    "            val_losses, val_metrics = val_epoch.eval_fn(\n",
    "                loader=val_loader, \n",
    "                model=model,                         \n",
    "                loss_fn=loss_fn,\n",
    "                device=config.DEVICE)\n",
    "            \n",
    "            scheduler.step(val_losses['Total'])\n",
    "            \n",
    "            val_losses_logger.update_metrics(val_losses)\n",
    "            val_metrics_logger.update_metrics(val_metrics)\n",
    "\n",
    "            logger.info(utils.print_metrics_to_logger(\"VAL Stats\", val_losses, val_metrics))\n",
    "            \n",
    "        epochs_plot.append(epoch)\n",
    "\n",
    "        loss_plotter.plot_all_metrics(\n",
    "            train_losses_logger.get_metrics(),\n",
    "            val_losses_logger.get_metrics(),\n",
    "            epochs_plot)\n",
    "\n",
    "        metrics_plotter.plot_all_metrics(\n",
    "            train_metrics_logger.get_metrics(),\n",
    "            val_metrics_logger.get_metrics(),\n",
    "            epochs_plot)\n",
    "\n",
    "        lr_logger.plot_lr(epochs_plot)\n",
    "        #======================= SAVING =========================#\n",
    "        if ( (epoch+1) % 5 ) == 0:\n",
    "            save_name = config.WEIGHTS_FOLDER + config.MODEL + '_classifier__5epoch.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name) \n",
    "            \n",
    "        if best_valid_loss > val_losses['Total']:\n",
    "            best_valid_loss = val_losses['Total']\n",
    "            print(f\"\\nSaving model with new best validation loss: {best_valid_loss:.3f}\")\n",
    "            logger.info(f\"Saving model with new best validation loss: {best_valid_loss:.3f}\")\n",
    "            save_name = config.WEIGHTS_FOLDER + config.MODEL + '_classifier__' + 'best_loss'  + '.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name)  \n",
    "\n",
    "        # Save model if precision increases and F1 > 0.9\n",
    "        if ( best_smoke_precision < val_metrics['Precision'][0] ) and ( val_metrics['F1'][0] > smoke_f1_min_save ) :\n",
    "            best_smoke_precision = val_metrics['Precision'][0]\n",
    "            print(f\"\\nSaving model with new best smoke precision: {best_smoke_precision:.3f}\")\n",
    "            logger.info(f\"Saving model with new best smoke precision: {best_smoke_precision:.3f}\")\n",
    "            save_precision_name = f'best_smoke__precision={np.round(best_smoke_precision, decimals=4)}__epoch={epoch}'\n",
    "            save_name = config.WEIGHTS_FOLDER + config.MODEL + '_classifier__' + save_precision_name + '.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name)  \n",
    "            \n",
    "        # Save model if precision > 0.9 and recall > 0.9\n",
    "        if ( val_metrics['Precision'][0] > 0.9 ) and ( val_metrics['Recall'][0] > 0.9 ) :\n",
    "            print(\"\\nSaving model with precision > 0.9 and recall > 0.9\")\n",
    "            logger.info(\"Saving model with precision > 0.9 and recall > 0.9\")\n",
    "            save_pre_name = f'smoke__precision={np.round(val_metrics[\"Precision\"][0], decimals=4)}__' \n",
    "            save_rec_name = f'recall={np.round(val_metrics[\"Recall\"][0], decimals=4)}__'\n",
    "            save_pre_rec_name = save_pre_name + save_rec_name + f'epoch={epoch}'\n",
    "            save_name = config.WEIGHTS_FOLDER + config.MODEL + '_classifier__' + save_pre_rec_name + '.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name) \n",
    "\n",
    "        # Save model if best mean F1 increases\n",
    "        val_f1_mean = (val_metrics['F1'][0] + val_metrics['F1'][1]) / 2\n",
    "        if (val_f1_mean > best_mean_f1) :\n",
    "            best_mean_f1 = val_f1_mean\n",
    "            print(f'Saving model with best Mean F1: {best_mean_f1:.4f}')\n",
    "            logger.info(f'Saving model with best Mean F1: {best_mean_f1:.4f}')\n",
    "            save_f1_name = 'best_mean_F1'\n",
    "            save_name = config.WEIGHTS_FOLDER + config.MODEL + '_classifier__' + save_f1_name + '.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name) \n",
    "\n",
    "        if ( ( val_metrics['Precision'][0] > 0.9 ) and ( val_metrics['Recall'][0] > 0.9 ) and\n",
    "        ( val_metrics['Precision'][1] > 0.9 ) and ( val_metrics['Recall'][1] > 0.9 ) ):\n",
    "            print(\"SVD: all metrics > 0.9 -> break the loop and continue\")\n",
    "            logger.info(\"SVD: all metrics > 0.9 -> break the loop and continue\")\n",
    "            break\n",
    "    \n",
    "    logger.info('Saving last model')   \n",
    "    torch.save(model.state_dict(), config.WEIGHTS_FOLDER + 'last_' + config.MODEL + '_classifier.pt') \n",
    "    \n",
    "    #======================= FINISH =========================#\n",
    "    end = datetime.datetime.now()\n",
    "    end_time = end.strftime(\"%H:%M:%S\")\n",
    "    print(f'\\n***Script finished: {end_time}\\n')  \n",
    "    print(f'Time elapsed: {end-start}')\n",
    "    logger.info(f'\\n***Script finished: {end_time}\\n')  \n",
    "    logger.info(f'Time elapsed: {end-start}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405eb53c-8e16-4b14-a818-fe53e68c1637",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5957bb-da57-4e84-ae3d-a83545e04704",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start Training\\n\")\n",
    "logger.info(\"Start Training\\n\")\n",
    "\n",
    "svd_model_trained = train_loop(svd_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc7d86a-27a6-43ac-89c6-718321bfdd43",
   "metadata": {},
   "source": [
    "# Check Comp Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d0c48-20bc-425d-8a16-073bc33de6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL PARAMETERS\n",
    "n_trainable = sum(p.numel() for p in svd_model_trained.parameters() if p.requires_grad)\n",
    "print(f'\\nTrainable parameters = {n_trainable}')\n",
    "logger.info(f'\\nTrainable parameters = {n_trainable}')\n",
    "\n",
    "n_params = sum(p.numel() for p in svd_model_trained.parameters())\n",
    "print(f'Total parameters = {n_params}')\n",
    "logger.info(f'Total parameters = {n_params}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063616a4-0b56-44a1-bc64-d5cd3960e1ec",
   "metadata": {},
   "source": [
    "# Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8486f8b-283d-41a0-95d1-2ef0fbd4fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(svd_model_trained, torch.randn(input_shape).to(config.DEVICE), config.RUN_FOLDER + 'svd_model_trained.onnx')\n",
    "#OnnxSaver.set_node_names('/models/fp32_model.onnx', trained_model, input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6088e4c2-a306-4d8a-bd58-42ec8220a5b9",
   "metadata": {},
   "source": [
    "# Pruning the Model after Training the SVD one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cbf0d8-2cc8-4bc7-b091-fd36ee481bb1",
   "metadata": {},
   "source": [
    "### Supress Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd6ee31-e8ec-440b-942c-e3c938a28abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed9e594-7962-4610-ae38-c14a6d653ffb",
   "metadata": {},
   "source": [
    "### Baseline SVD Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd22493-19f4-49c9-ad46-8b610fb0c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_trained_f1 = evaluate_model(svd_model_trained, None, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59be1d98-4e7d-4f76-8324-7223a635344e",
   "metadata": {},
   "source": [
    "### Pruning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02338086-7684-4e71-84af-f235e3bb42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_to_ignore = [svd_model_trained.model.conv1]\n",
    "greedy_params = GreedySelectionParameters(\n",
    "    target_comp_ratio=Decimal(config.PRUNING_COMPRESSION_RATIO),\n",
    "    saved_eval_scores_dict=None) #config.PRUNING_DIC_FILE)\n",
    "auto_params = ChannelPruningParameters.AutoModeParams(\n",
    "    greedy_params,\n",
    "    modules_to_ignore=modules_to_ignore)\n",
    "cp_params = ChannelPruningParameters(\n",
    "    mode=ChannelPruningParameters.Mode.auto,\n",
    "    params=auto_params,\n",
    "    data_loader=val_loader,\n",
    "    num_reconstruction_samples=500,\n",
    "    allow_custom_downsample_ops=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6ce3e8-746e-4feb-a85e-f917aaf66b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_model, stats = ModelCompressor.compress_model(svd_model_trained,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   eval_callback=evaluate_model,\n",
    "                                                   eval_iterations=None,\n",
    "                                                   compress_scheme=CompressionScheme.channel_pruning,\n",
    "                                                   cost_metric=CostMetric.memory, #.mac,\n",
    "                                                   parameters=cp_params,\n",
    "                                                   visualization_url=None)                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0ef12c-a016-409d-87a0-8edcb63516a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comp_model)\n",
    "logger.info(comp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e2b3e-9a30-4f98-ba5d-2266103a3b88",
   "metadata": {},
   "source": [
    "# Print Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bcc403-1f96-40a9-8fd4-3a1b44372950",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats)\n",
    "logger.info(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591811c-f19d-4d30-acd9-143ea6685f57",
   "metadata": {},
   "source": [
    "### Torchinfo: model compressed summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec9b53-5deb-4f6b-b5f7-5bf7d61d01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary(comp_model, input_size=(1, 3, config.IMG_H, config.IMG_W)))\n",
    "logger.info(\"Compressed Model Summary\")\n",
    "logger.info(summary(comp_model, input_size=(1, 3, config.IMG_H, config.IMG_W)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21552ff8-5f05-4d06-adab-ebfaf15547f3",
   "metadata": {},
   "source": [
    "# Evaluate Compressed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9bafc-85b4-4d77-adc2-840a2ad49100",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_f1 = evaluate_model(comp_model, None, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513b69ea-faa2-4acd-ac45-6def58505bd6",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8562899f-7f8c-4778-a3aa-c636e69d1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_ratios_file_path = './data/greedy_selection_comp_ratios_list.pkl'\n",
    "eval_scores_path = './data/greedy_selection_eval_scores_dict.pkl'\n",
    "\n",
    "unpickled_ratios = pd.read_pickle(comp_ratios_file_path)\n",
    "unpickled_scores = pd.read_pickle(eval_scores_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5978656-c606-47c3-a853-c57893540fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(unpickled_scores)\n",
    "df_scores.to_csv(config.RUN_FOLDER + 'scores_pruning.csv')\n",
    "print(df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d1a37f-3705-4cab-82db-4a1be53a7ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios = pd.DataFrame(unpickled_ratios)\n",
    "df_ratios.to_csv(config.RUN_FOLDER + 'ratios_pruning.csv')\n",
    "print(df_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdcaa0e-4468-42ba-8f7d-947b329de9bd",
   "metadata": {},
   "source": [
    "# Save Compressed Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f764a-36ec-4514-9ed9-2b39d82c772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(comp_model, torch.randn(input_shape).to(config.DEVICE), config.RUN_FOLDER + 'pruned_model_noTrain.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3202ea-af8e-4fd4-8267-086b1981a5fb",
   "metadata": {},
   "source": [
    "### Optimizer and Scheduler of Compressed Model to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69e5c83-f6ce-4a59-967e-f9eee8d12c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(comp_model.parameters(), \n",
    "                       lr=config.LEARNING_RATE, \n",
    "                       weight_decay=config.WEIGHT_DECAY)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                 mode='min',\n",
    "                                                 factor=config.FACTOR, \n",
    "                                                 patience=config.PATIENCE, \n",
    "                                                 threshold=config.THRES, \n",
    "                                                 threshold_mode='abs',\n",
    "                                                 min_lr=config.MIN_LR)\n",
    "\n",
    "utils.save_checkpoint(epoch=0, \n",
    "                      model=comp_model,\n",
    "                      optimizer=optimizer,\n",
    "                      scheduler=scheduler,\n",
    "                      checkpoint_name=config.WEIGHTS_FOLDER + 'comp_model_after_pruning.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c8971f-0ed8-43ec-a5a5-fa500bde8363",
   "metadata": {},
   "source": [
    "# Define Plotters again to restart them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5831bb53-8df7-4d82-a76e-93f941f868f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_logger = utils.LogLosses()\n",
    "train_metrics_logger = utils.LogMetrics()\n",
    "lr_logger = utils.LogLR(log_path=config.PLOTS_FOLDER_2)\n",
    "\n",
    "val_losses_logger = utils.LogLosses()\n",
    "val_metrics_logger = utils.LogMetrics()\n",
    "\n",
    "loss_plotter = utils.PlotMetrics(log_path=config.PLOTS_FOLDER_2, model_name=config.MODEL, loss_or_metric='Loss')\n",
    "metrics_plotter = utils.PlotMetrics(log_path=config.PLOTS_FOLDER_2, model_name=config.MODEL, loss_or_metric='Metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da10ab6a-f4be-4e4d-b4a8-4d917b6534d9",
   "metadata": {},
   "source": [
    "# Define Train Function Again to restart it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fe082f-0783-45b4-a1bc-74dd0a8b619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svd_loop(model, start_epoch=0):\n",
    "\n",
    "    ''' ==============================================================\n",
    "                                TRAINING LOOP\n",
    "    ============================================================== '''\n",
    "    start = datetime.datetime.now()\n",
    "    start_time = start.strftime(\"%H:%M:%S\")\n",
    "    print(f'\\n***Start Training: {start_time}\\n')\n",
    "    logger.info(f'\\n***Start Training: {start_time}\\n')\n",
    "    \n",
    "    # Start with infinite validation loss\n",
    "    best_valid_loss = np.inf\n",
    "    best_smoke_precision = 0. #torch.tensor([0.])\n",
    "    smoke_f1_min_save = 0.9 #torch.tensor([0.9])\n",
    "    best_mean_f1 = 0.\n",
    "\n",
    "    #start_epoch = 0\n",
    "    epochs_plot = []\n",
    "        \n",
    "    for epoch in range(start_epoch, config.EPOCHS):\n",
    "\n",
    "        print(f'\\n=== EPOCH {epoch}/{config.EPOCHS-1} ===')\n",
    "        logger.info(f'\\n=== EPOCH {epoch}/{config.EPOCHS-1} ===')\n",
    "        \n",
    "        #====================== TRAINING ========================#\n",
    "        current_lr = train_epoch.get_lr(optimizer=optimizer)\n",
    "        logger.info(f'Learning Rate = {current_lr}\\n')\n",
    "        lr_logger.log_lr(current_lr)\n",
    "                \n",
    "        train_losses, train_metrics = train_epoch.train_fn(\n",
    "            loader=train_loader, \n",
    "            model=model, \n",
    "            optimizer=optimizer, \n",
    "            loss_fn=loss_fn,\n",
    "            device=config.DEVICE)\n",
    "        \n",
    "        train_losses_logger.update_metrics(train_losses)\n",
    "        train_metrics_logger.update_metrics(train_metrics)\n",
    "                \n",
    "        logger.info(utils.print_metrics_to_logger(\"TRAIN Stats\", train_losses, train_metrics))\n",
    "        \n",
    "        #===================== VALIDATING =======================#\n",
    "        with torch.no_grad():\n",
    "            val_losses, val_metrics = val_epoch.eval_fn(\n",
    "                loader=val_loader, \n",
    "                model=model,                         \n",
    "                loss_fn=loss_fn,\n",
    "                device=config.DEVICE)\n",
    "            \n",
    "            scheduler.step(val_losses['Total'])\n",
    "            \n",
    "            val_losses_logger.update_metrics(val_losses)\n",
    "            val_metrics_logger.update_metrics(val_metrics)\n",
    "\n",
    "            logger.info(utils.print_metrics_to_logger(\"VAL Stats\", val_losses, val_metrics))\n",
    "            \n",
    "        epochs_plot.append(epoch)\n",
    "\n",
    "        loss_plotter.plot_all_metrics(\n",
    "            train_losses_logger.get_metrics(),\n",
    "            val_losses_logger.get_metrics(),\n",
    "            epochs_plot)\n",
    "\n",
    "        metrics_plotter.plot_all_metrics(\n",
    "            train_metrics_logger.get_metrics(),\n",
    "            val_metrics_logger.get_metrics(),\n",
    "            epochs_plot)\n",
    "\n",
    "        lr_logger.plot_lr(epochs_plot)\n",
    "        #======================= SAVING =========================#\n",
    "        if ( (epoch+1) % 5 ) == 0:\n",
    "            save_name = config.WEIGHTS_FOLDER_2 + config.MODEL + '_classifier__5epoch.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name) \n",
    "            \n",
    "        if best_valid_loss > val_losses['Total']:\n",
    "            best_valid_loss = val_losses['Total']\n",
    "            print(f\"\\nSaving model with new best validation loss: {best_valid_loss:.3f}\")\n",
    "            logger.info(f\"Saving model with new best validation loss: {best_valid_loss:.3f}\")\n",
    "            save_name = config.WEIGHTS_FOLDER_2 + config.MODEL + '_classifier__' + 'best_loss'  + '.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name)  \n",
    "\n",
    "        # Save model if precision increases and F1 > 0.9\n",
    "        if ( best_smoke_precision < val_metrics['Precision'][0] ) and ( val_metrics['F1'][0] > smoke_f1_min_save ) :\n",
    "            best_smoke_precision = val_metrics['Precision'][0]\n",
    "            print(f\"\\nSaving model with new best smoke precision: {best_smoke_precision:.3f}\")\n",
    "            logger.info(f\"Saving model with new best smoke precision: {best_smoke_precision:.3f}\")\n",
    "            save_precision_name = f'best_smoke__precision={np.round(best_smoke_precision, decimals=4)}__epoch={epoch}'\n",
    "            save_name = config.WEIGHTS_FOLDER_2 + config.MODEL + '_classifier__' + save_precision_name + '.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name)  \n",
    "            \n",
    "        # Save model if precision > 0.9 and recall > 0.9\n",
    "        if ( val_metrics['Precision'][0] > 0.9 ) and ( val_metrics['Recall'][0] > 0.9 ) :\n",
    "            print(\"\\nSaving model with precision > 0.9 and recall > 0.9\")\n",
    "            logger.info(\"Saving model with precision > 0.9 and recall > 0.9\")\n",
    "            save_pre_name = f'smoke__precision={np.round(val_metrics[\"Precision\"][0], decimals=4)}__' \n",
    "            save_rec_name = f'recall={np.round(val_metrics[\"Recall\"][0], decimals=4)}__'\n",
    "            save_pre_rec_name = save_pre_name + save_rec_name + f'epoch={epoch}'\n",
    "            save_name = config.WEIGHTS_FOLDER_2 + config.MODEL + '_classifier__' + save_pre_rec_name + '.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name) \n",
    "\n",
    "        # Save model if best mean F1 increases\n",
    "        val_f1_mean = (val_metrics['F1'][0] + val_metrics['F1'][1]) / 2\n",
    "        if (val_f1_mean > best_mean_f1) :\n",
    "            best_mean_f1 = val_f1_mean\n",
    "            print(f'Saving model with best Mean F1: {best_mean_f1:.4f}')\n",
    "            logger.info(f'Saving model with best Mean F1: {best_mean_f1:.4f}')\n",
    "            save_f1_name = 'best_mean_F1'\n",
    "            save_name = config.WEIGHTS_FOLDER_2 + config.MODEL + '_classifier__' + save_f1_name + '.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name) \n",
    "\n",
    "        if ( ( val_metrics['Precision'][0] > 0.9 ) and ( val_metrics['Recall'][0] > 0.9 ) and\n",
    "        ( val_metrics['Precision'][1] > 0.9 ) and ( val_metrics['Recall'][1] > 0.9 ) ):\n",
    "            print(\"Pruning: all metrics > 0.9 -> break the loop and continue\")\n",
    "            logger.info(\"Pruning: all metrics > 0.9 -> break the loop and continue\")\n",
    "            break\n",
    "        \n",
    "    logger.info('Saving last model')   \n",
    "    torch.save(model.state_dict(), config.WEIGHTS_FOLDER_2 + 'last_' + config.MODEL + '_classifier.pt') \n",
    "    \n",
    "    #======================= FINISH =========================#\n",
    "    end = datetime.datetime.now()\n",
    "    end_time = end.strftime(\"%H:%M:%S\")\n",
    "    print(f'\\n***Script finished: {end_time}\\n')  \n",
    "    print(f'Time elapsed: {end-start}')\n",
    "    logger.info(f'\\n***Script finished: {end_time}\\n')  \n",
    "    logger.info(f'Time elapsed: {end-start}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670bf35e-fd01-4ad3-a14d-1624b3a023c6",
   "metadata": {},
   "source": [
    "# Train the model pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deeeff0-801d-410e-92b4-dd437c0dd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start Training\\n\")\n",
    "logger.info(\"Start Training\\n\")\n",
    "\n",
    "pruned_model = train_svd_loop(comp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578ea94-aa94-4033-9db3-b60eb4b48bcb",
   "metadata": {},
   "source": [
    "# Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe095c-794a-4572-9842-ed7b79cc69d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.onnx.export(pruned_model, torch.randn(input_shape).to(config.DEVICE), config.RUN_FOLDER + 'pruned_model_trained.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f871e352-cdd4-4098-8afd-70748a1de961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
