{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3bb0e23-71ed-4fdd-b119-0137520406fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from modules.model_T2T_ViT.t2t_vit import T2T_ViT\n",
    "\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca03091-ffe3-455c-94bc-54cef589faee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = T2T_ViT(\n",
    "    img_size = (3, 224, 224),\n",
    "    softsplit_kernels = (7, 3, 3),\n",
    "    preds = 2,\n",
    "    token_len = 32,\n",
    "    token_chan = 16,\n",
    "    depth = 4,\n",
    "    T2T_hidden_chan_mul = 1.,\n",
    "    Encoding_hidden_chan_mul = 4.,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4305b752-8543-4a18-b7e1-f58b693c3ee2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "T2T_ViT                                  [1, 2]                    --\n",
      "├─Tokens2Token: 1-1                      [1, 196, 32]              --\n",
      "│    └─Unfold: 2-1                       [1, 147, 3136]            --\n",
      "│    └─TokenTransformer: 2-2             [1, 3136, 16]             --\n",
      "│    │    └─LayerNorm: 3-1               [1, 3136, 147]            294\n",
      "│    │    └─Attention: 3-2               [1, 3136, 16]             7,328\n",
      "│    │    └─LayerNorm: 3-3               [1, 3136, 16]             32\n",
      "│    │    └─NeuralNet: 3-4               [1, 3136, 16]             544\n",
      "│    └─Unfold: 2-3                       [1, 144, 784]             --\n",
      "│    └─TokenTransformer: 2-4             [1, 784, 16]              --\n",
      "│    │    └─LayerNorm: 3-5               [1, 784, 144]             288\n",
      "│    │    └─Attention: 3-6               [1, 784, 16]              7,184\n",
      "│    │    └─LayerNorm: 3-7               [1, 784, 16]              32\n",
      "│    │    └─NeuralNet: 3-8               [1, 784, 16]              544\n",
      "│    └─Unfold: 2-5                       [1, 144, 196]             --\n",
      "│    └─Linear: 2-6                       [1, 196, 32]              4,640\n",
      "├─ViT_Backbone: 1-2                      [1, 2]                    6,336\n",
      "│    └─ModuleList: 2-7                   --                        --\n",
      "│    │    └─Encoding: 3-9                [1, 197, 32]              12,608\n",
      "│    │    └─Encoding: 3-10               [1, 197, 32]              12,608\n",
      "│    │    └─Encoding: 3-11               [1, 197, 32]              12,608\n",
      "│    │    └─Encoding: 3-12               [1, 197, 32]              12,608\n",
      "│    └─LayerNorm: 2-8                    [1, 197, 32]              64\n",
      "│    └─Linear: 2-9                       [1, 2]                    66\n",
      "==========================================================================================\n",
      "Total params: 77,784\n",
      "Trainable params: 71,480\n",
      "Non-trainable params: 6,304\n",
      "Total mult-adds (M): 0.07\n",
      "==========================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 10.42\n",
      "Params size (MB): 0.29\n",
      "Estimated Total Size (MB): 11.31\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, input_size=(1, 3, 224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3093133d-c20c-43cb-a1da-1e8083823ece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5741e246-de8a-4fde-a75e-68272b7c2ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21cde1b4-0753-4f7a-9099-0764481ef22a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4351f0e3-d6aa-444b-98c7-5d0a8a352e52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
