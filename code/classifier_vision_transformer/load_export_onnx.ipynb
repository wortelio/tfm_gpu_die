{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1317c2ed-dd31-4214-b084-eea10dbb5beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from modules.model_MobileViTv3.mobilevit_v3_v1 import MobileViTv3_v1\n",
    "\n",
    "import modules.utils as utils\n",
    "import torch\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d59edbf-831b-4311-b117-cbdbf5ffd4ae",
   "metadata": {},
   "source": [
    "# Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd30f917-7557-4882-88d0-5d7c4cb149dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed445a4-9a9e-4cca-b63e-bbaa86241bae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MobileViTv3_v1(\n",
    "    image_size = (224, 224),\n",
    "    mode = 'xx_small',\n",
    "    num_classes = 2,\n",
    "    patch_size = (2, 2)\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf10a64-2f3e-4bb9-82ad-cbb58906bcfb",
   "metadata": {},
   "source": [
    "### Torch Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58295e90-685f-42e2-b166-0ec9106aabb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "MobileViTv3_v1                                     [1, 2]                    --\n",
      "├─Sequential: 1-1                                  [1, 16, 111, 111]         --\n",
      "│    └─Conv2d: 2-1                                 [1, 16, 111, 111]         432\n",
      "│    └─BatchNorm2d: 2-2                            [1, 16, 111, 111]         32\n",
      "│    └─SiLU: 2-3                                   [1, 16, 111, 111]         --\n",
      "├─Sequential: 1-2                                  [1, 16, 111, 111]         --\n",
      "│    └─InvertedResidual: 2-4                       [1, 16, 111, 111]         --\n",
      "│    │    └─Sequential: 3-1                        [1, 16, 111, 111]         1,472\n",
      "├─Sequential: 1-3                                  [1, 24, 56, 56]           --\n",
      "│    └─InvertedResidual: 2-5                       [1, 24, 56, 56]           --\n",
      "│    │    └─Sequential: 3-2                        [1, 24, 56, 56]           1,744\n",
      "│    └─InvertedResidual: 2-6                       [1, 24, 56, 56]           --\n",
      "│    │    └─Sequential: 3-3                        [1, 24, 56, 56]           2,976\n",
      "│    └─InvertedResidual: 2-7                       [1, 24, 56, 56]           --\n",
      "│    │    └─Sequential: 3-4                        [1, 24, 56, 56]           2,976\n",
      "├─Sequential: 1-4                                  [1, 64, 28, 28]           --\n",
      "│    └─InvertedResidual: 2-8                       [1, 64, 28, 28]           --\n",
      "│    │    └─Sequential: 3-5                        [1, 64, 28, 28]           4,976\n",
      "│    └─MobileViTBlockV3_v1: 2-9                    [1, 64, 28, 28]           --\n",
      "│    │    └─Sequential: 3-6                        [1, 64, 28, 28]           4,800\n",
      "│    │    └─Sequential: 3-7                        [4, 196, 64]              67,072\n",
      "│    │    └─Sequential: 3-8                        [1, 64, 28, 28]           4,224\n",
      "│    │    └─Sequential: 3-9                        [1, 64, 28, 28]           8,320\n",
      "├─Sequential: 1-5                                  [1, 80, 14, 14]           --\n",
      "│    └─InvertedResidual: 2-10                      [1, 80, 14, 14]           --\n",
      "│    │    └─Sequential: 3-10                       [1, 80, 14, 14]           20,256\n",
      "│    └─MobileViTBlockV3_v1: 2-11                   [1, 80, 14, 14]           --\n",
      "│    │    └─Sequential: 3-11                       [1, 80, 14, 14]           7,280\n",
      "│    │    └─Sequential: 3-12                       [4, 49, 80]               208,480\n",
      "│    │    └─Sequential: 3-13                       [1, 80, 14, 14]           6,560\n",
      "│    │    └─Sequential: 3-14                       [1, 80, 14, 14]           12,960\n",
      "├─Sequential: 1-6                                  [1, 128, 7, 7]            --\n",
      "│    └─InvertedResidual: 2-12                      [1, 128, 7, 7]            --\n",
      "│    │    └─Sequential: 3-15                       [1, 128, 7, 7]            35,616\n",
      "│    └─MobileViTBlockV3_v1: 2-13                   [1, 128, 7, 7]            --\n",
      "│    │    └─Sequential: 3-16                       [1, 96, 7, 7]             13,696\n",
      "│    │    └─Sequential: 3-17                       [4, 16, 96]               224,544\n",
      "│    │    └─Sequential: 3-18                       [1, 128, 7, 7]            12,544\n",
      "│    │    └─Sequential: 3-19                       [1, 128, 7, 7]            28,928\n",
      "├─Sequential: 1-7                                  [1, 512, 7, 7]            --\n",
      "│    └─Conv2d: 2-14                                [1, 512, 7, 7]            65,536\n",
      "│    └─BatchNorm2d: 2-15                           [1, 512, 7, 7]            1,024\n",
      "│    └─SiLU: 2-16                                  [1, 512, 7, 7]            --\n",
      "├─Linear: 1-8                                      [1, 2]                    1,026\n",
      "====================================================================================================\n",
      "Total params: 737,474\n",
      "Trainable params: 737,474\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 93.21\n",
      "====================================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 64.96\n",
      "Params size (MB): 2.95\n",
      "Estimated Total Size (MB): 68.51\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, input_size=(1,3, 224, 224)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb48f412-abe4-4d10-983a-985cceea1a5e",
   "metadata": {},
   "source": [
    "## Load Weights and Export ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c88fcb-e2fb-4276-a707-146e4b19562a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights_path = './experiments/test_v11_MobileViTv3_v1_full_ds/weights/MobileViTv3_v1_classifier__best_mean_F1.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d79f6027-820d-4f42-b5d3-3428244cc9b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model. Trained during 80 epochs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.load_checkpoint(weights_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "909bb1db-c536-471c-bd4f-8a34a8dde98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff790aff-a3f2-4e2c-9cce-868b57ba5df8",
   "metadata": {},
   "source": [
    "#### ONNX export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df2c54b5-5625-42d5-a1ad-980aa923e008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch_input = torch.randn(1, 3, 224, 224)\n",
    "# torch.onnx.export(model, torch_input, \"MobilenetV3.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21660252-f4a6-4ddc-bda3-b6006053cd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreno/uav/code/classifier_vision_transformer/modules/model_MobileViTv3/mobilevit_v3_v1.py:131: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  new_h = int(math.ceil(orig_h / self.patch_h) * self.patch_h)\n",
      "/home/gmoreno/uav/code/classifier_vision_transformer/modules/model_MobileViTv3/mobilevit_v3_v1.py:132: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  new_w = int(math.ceil(orig_w / self.patch_w) * self.patch_w)\n",
      "/home/gmoreno/uav/code/classifier_vision_transformer/modules/model_MobileViTv3/mobilevit_v3_v1.py:135: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if new_w != orig_w or new_h != orig_h:\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(\n",
    "    model,                    # The model to be exported\n",
    "    torch_input,              # The sample input tensor\n",
    "    \"MobileViTv3_v1_Raspi.onnx\", # The output file name\n",
    "    export_params=True,       # Store the trained parameter weights inside the model file\n",
    "    do_constant_folding=True, # Whether to execute constant folding for optimization\n",
    "    input_names=['input'],    # The model's input names\n",
    "    output_names=['output'],  # The model's output names\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
