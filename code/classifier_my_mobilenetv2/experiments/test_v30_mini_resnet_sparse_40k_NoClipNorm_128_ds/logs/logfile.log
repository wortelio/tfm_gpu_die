Mobilenetv2_Mini_Resnet_Sparse Classifier.
	One Head.
	Weighted for Precision.
	Brevitas Default.
	Dataset images divided by 255.


Datasets Length
	Train and Val: 128

Load Model: False
Width Mult: 1.0

Device: cuda
Optimizer:
	Learning Rate: 0.001
	Weight Decay: 0.001
Scheduler:
	Scheduler factor: 0.8
	Scheduler patience: 2
	Scheduler threshold: 0.001
	Scheduler min learning rate: 1e-06

Batch Size: 64
Num Workers: 8
Pin Memory: True
Epochs: 5

IMG DIMS:
	Width: 224
	Height: 224

Brevitas Config:
	Fixed Point: True
	Weights Bit Width: 4
	Big Layers Weights Bit Width: 4
	Bias Bit Width: 4
	Activations Bit Width: 4

********* Datasets Length *********
Train Dataset Length: 640
Test Dataset Length: 384

Trainable parameters = 38970
Total parameters = 38970


Torch Summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
MobileNetV2_MINI_RESNET_SPARSE           [1, 2]                    --
├─Sequential: 1-1                        [1, 48, 14, 14]           --
│    └─Sequential: 2-1                   [1, 24, 112, 112]         --
│    │    └─Conv2d: 3-1                  [1, 24, 112, 112]         648
│    │    └─BatchNorm2d: 3-2             [1, 24, 112, 112]         48
│    │    └─ReLU: 3-3                    [1, 24, 112, 112]         --
│    └─InvertedBlock: 2-2                [1, 8, 112, 112]          --
│    │    └─Sequential: 3-4              [1, 8, 112, 112]          472
│    └─InvertedBlock: 2-3                [1, 16, 56, 56]           --
│    │    └─Sequential: 3-5              [1, 16, 56, 56]           624
│    └─InvertedBlock: 2-4                [1, 16, 56, 56]           --
│    │    └─Sequential: 3-6              [1, 16, 56, 56]           1,472
│    └─InvertedBlock: 2-5                [1, 24, 28, 28]           --
│    │    └─Sequential: 3-7              [1, 24, 28, 28]           1,744
│    └─InvertedBlock: 2-6                [1, 24, 28, 28]           --
│    │    └─Sequential: 3-8              [1, 24, 28, 28]           2,976
│    └─InvertedBlock: 2-7                [1, 32, 14, 14]           --
│    │    └─Sequential: 3-9              [1, 32, 14, 14]           5,032
│    └─InvertedBlock: 2-8                [1, 32, 14, 14]           --
│    │    └─Sequential: 3-10             [1, 32, 14, 14]           7,456
│    └─InvertedBlock: 2-9                [1, 32, 14, 14]           --
│    │    └─Sequential: 3-11             [1, 32, 14, 14]           7,456
│    └─InvertedBlock: 2-10               [1, 48, 14, 14]           --
│    │    └─Sequential: 3-12             [1, 48, 14, 14]           6,048
├─Sequential: 1-2                        [1, 96, 14, 14]           --
│    └─Conv2d: 2-11                      [1, 96, 14, 14]           4,608
│    └─BatchNorm2d: 2-12                 [1, 96, 14, 14]           192
│    └─ReLU: 2-13                        [1, 96, 14, 14]           --
├─AdaptiveAvgPool2d: 1-3                 [1, 96, 1, 1]             --
├─Linear: 1-4                            [1, 2]                    194
==========================================================================================
Total params: 38,970
Trainable params: 38,970
Non-trainable params: 0
Total mult-adds (M): 31.50
==========================================================================================
Input size (MB): 0.60
Forward/backward pass size (MB): 27.37
Params size (MB): 0.16
Estimated Total Size (MB): 28.13
==========================================================================================

Torch Model
MobileNetV2_MINI_RESNET_SPARSE(
  (features): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): InvertedBlock(
      (conv): Sequential(
        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Conv2d(24, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): InvertedBlock(
      (conv): Sequential(
        (0): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU()
        (6): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): InvertedBlock(
      (conv): Sequential(
        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU()
        (6): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): InvertedBlock(
      (conv): Sequential(
        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU()
        (6): Conv2d(32, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): InvertedBlock(
      (conv): Sequential(
        (0): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU()
        (6): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): InvertedBlock(
      (conv): Sequential(
        (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)
        (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU()
        (6): Conv2d(72, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): InvertedBlock(
      (conv): Sequential(
        (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU()
        (6): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (8): InvertedBlock(
      (conv): Sequential(
        (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU()
        (6): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (9): InvertedBlock(
      (conv): Sequential(
        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU()
        (6): Conv2d(64, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv): Sequential(
    (0): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=96, out_features=2, bias=True)
)

Loss Function: BCE
Smoke Precision Weight: 0.8
Starting script


***Start Training: 14:08:39


=== EPOCH 0/4 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5188   |0.5146   |0.2812   |0.3636   |
82.63      |39.60     |43.03     |    Fire   |0.6016   |0.3608   |0.2701   |0.3089   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5104   |0.0000   |0.0000   |0.0000   |
83.44      |39.84     |43.61     |    Fire   |0.6979   |0.0000   |0.0000   |0.0000   |

Saving model with new best validation loss: 83.4439

=== EPOCH 1/4 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5109   |0.0000   |0.0000   |0.0000   |
77.06      |38.47     |38.59     |    Fire   |0.6703   |0.0000   |0.0000   |0.0000   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5104   |0.0000   |0.0000   |0.0000   |
82.82      |39.84     |42.97     |    Fire   |0.6979   |0.0000   |0.0000   |0.0000   |

Saving model with new best validation loss: 82.8169

=== EPOCH 2/4 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5109   |0.5000   |0.0160   |0.0310   |
72.57      |37.79     |34.77     |    Fire   |0.6703   |0.0000   |0.0000   |0.0000   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.4896   |0.4896   |1.0000   |0.6573   |
83.75      |40.12     |43.62     |    Fire   |0.6979   |0.0000   |0.0000   |0.0000   |

Saving model with best Mean F1: 0.3287

=== EPOCH 3/4 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5766   |0.6909   |0.2428   |0.3593   |
69.20      |36.95     |32.25     |    Fire   |0.6734   |1.0000   |0.0095   |0.0188   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.4896   |0.4896   |1.0000   |0.6573   |
84.70      |40.33     |44.37     |    Fire   |0.3906   |0.3305   |0.9914   |0.4957   |

Saving model with best Mean F1: 0.5765

=== EPOCH 4/4 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5750   |0.6171   |0.3450   |0.4426   |
66.87      |36.60     |30.27     |    Fire   |0.7453   |0.8000   |0.3033   |0.4399   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5625   |0.5318   |0.8883   |0.6653   |
80.93      |39.77     |41.16     |    Fire   |0.6589   |0.4664   |0.8966   |0.6136   |

Saving model with new best validation loss: 80.9306
Saving model with best Mean F1: 0.6395
Saving last model

***Script finished: 14:09:05

Time elapsed: 0:00:25.429488

Testing with FULL TEST LOADER
{'Accuracy': [0.5625, 0.6588541865348816], 'Precision': [0.5318471193313599, 0.4663677215576172], 'Recall': [0.8882978558540344, 0.8965517282485962], 'F1': [0.6653386354446411, 0.6135693192481995]}

Testing with DFire MINI TRAIN after LOADING F1 Best Mean CHECKPOINT
{'Accuracy': [0.6600000262260437, 0.6800000071525574], 'Precision': [0.7411764860153198, 0.5283018946647644], 'Recall': [0.8399999737739563, 0.800000011920929], 'F1': [0.7875000238418579, 0.6363636255264282]}

Testing with DFire MINI TEST after LOADING F1 Best Mean CHECKPOINT
{'Accuracy': [0.5666666626930237, 0.7333333492279053], 'Precision': [0.695652186870575, 0.5882353186607361], 'Recall': [0.7272727489471436, 0.9090909361839294], 'F1': [0.7111111283302307, 0.7142857313156128]}
