Mobilenetv2_WMul01 Classifier.
	One Head.
	Weighted for Precision.
	Brevitas Default.
	Dataset images divided by 255.


Datasets Length
	Train and Val: 128

Load Model: False
Width Mult: 0.1

Device: cuda
Optimizer:
	Learning Rate: 0.001
	Weight Decay: 0.001
Scheduler:
	Scheduler factor: 0.8
	Scheduler patience: 2
	Scheduler threshold: 0.001
	Scheduler min learning rate: 1e-06

Batch Size: 64
Num Workers: 8
Pin Memory: True
Epochs: 3

IMG DIMS:
	Width: 224
	Height: 224

Brevitas Config:
	Fixed Point: True
	Weights Bit Width: 4
	Big Layers Weights Bit Width: 4
	Bias Bit Width: 4
	Activations Bit Width: 4

********* Datasets Length *********
Train Dataset Length: 640
Test Dataset Length: 384

Trainable parameters = 78258
Total parameters = 78258


Torch Summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
MobileNetV2                              [1, 2]                    --
├─Sequential: 1-1                        [1, 32, 7, 7]             --
│    └─Sequential: 2-1                   [1, 4, 112, 112]          --
│    │    └─Conv2d: 3-1                  [1, 4, 112, 112]          108
│    │    └─BatchNorm2d: 3-2             [1, 4, 112, 112]          8
│    │    └─ReLU6: 3-3                   [1, 4, 112, 112]          --
│    └─InvertedResidual: 2-2             [1, 4, 112, 112]          --
│    │    └─Sequential: 3-4              [1, 4, 112, 112]          68
│    └─InvertedResidual: 2-3             [1, 4, 56, 56]            --
│    │    └─Sequential: 3-5              [1, 4, 56, 56]            512
│    └─InvertedResidual: 2-4             [1, 4, 56, 56]            --
│    │    └─Sequential: 3-6              [1, 4, 56, 56]            512
│    └─InvertedResidual: 2-5             [1, 4, 28, 28]            --
│    │    └─Sequential: 3-7              [1, 4, 28, 28]            512
│    └─InvertedResidual: 2-6             [1, 4, 28, 28]            --
│    │    └─Sequential: 3-8              [1, 4, 28, 28]            512
│    └─InvertedResidual: 2-7             [1, 4, 28, 28]            --
│    │    └─Sequential: 3-9              [1, 4, 28, 28]            512
│    └─InvertedResidual: 2-8             [1, 8, 14, 14]            --
│    │    └─Sequential: 3-10             [1, 8, 14, 14]            616
│    └─InvertedResidual: 2-9             [1, 8, 14, 14]            --
│    │    └─Sequential: 3-11             [1, 8, 14, 14]            1,408
│    └─InvertedResidual: 2-10            [1, 8, 14, 14]            --
│    │    └─Sequential: 3-12             [1, 8, 14, 14]            1,408
│    └─InvertedResidual: 2-11            [1, 8, 14, 14]            --
│    │    └─Sequential: 3-13             [1, 8, 14, 14]            1,408
│    └─InvertedResidual: 2-12            [1, 12, 14, 14]           --
│    │    └─Sequential: 3-14             [1, 12, 14, 14]           1,608
│    └─InvertedResidual: 2-13            [1, 12, 14, 14]           --
│    │    └─Sequential: 3-15             [1, 12, 14, 14]           2,688
│    └─InvertedResidual: 2-14            [1, 12, 14, 14]           --
│    │    └─Sequential: 3-16             [1, 12, 14, 14]           2,688
│    └─InvertedResidual: 2-15            [1, 16, 7, 7]             --
│    │    └─Sequential: 3-17             [1, 16, 7, 7]             2,984
│    └─InvertedResidual: 2-16            [1, 16, 7, 7]             --
│    │    └─Sequential: 3-18             [1, 16, 7, 7]             4,352
│    └─InvertedResidual: 2-17            [1, 16, 7, 7]             --
│    │    └─Sequential: 3-19             [1, 16, 7, 7]             4,352
│    └─InvertedResidual: 2-18            [1, 32, 7, 7]             --
│    │    └─Sequential: 3-20             [1, 32, 7, 7]             5,920
├─Sequential: 1-2                        [1, 1280, 7, 7]           --
│    └─Conv2d: 2-19                      [1, 1280, 7, 7]           40,960
│    └─BatchNorm2d: 2-20                 [1, 1280, 7, 7]           2,560
│    └─ReLU6: 2-21                       [1, 1280, 7, 7]           --
├─AdaptiveAvgPool2d: 1-3                 [1, 1280, 1, 1]           --
├─Linear: 1-4                            [1, 2]                    2,562
==========================================================================================
Total params: 78,258
Trainable params: 78,258
Non-trainable params: 0
Total mult-adds (M): 11.65
==========================================================================================
Input size (MB): 0.60
Forward/backward pass size (MB): 18.60
Params size (MB): 0.31
Estimated Total Size (MB): 19.51
==========================================================================================

Torch Model
MobileNetV2(
  (features): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
    (1): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(4, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(24, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(4, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(24, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(4, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(24, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(4, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(24, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(4, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)
        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(24, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(4, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(24, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (8): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(48, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (9): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(48, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (10): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(48, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (11): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (12): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(12, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)
        (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(72, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(12, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)
        (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(72, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (14): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(12, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)
        (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(72, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (15): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (16): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (17): InvertedResidual(
      (conv): Sequential(
        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU6(inplace=True)
        (6): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv): Sequential(
    (0): Conv2d(32, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU6(inplace=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=1280, out_features=2, bias=True)
)

Loss Function: BCE
Smoke Precision Weight: 0.8
Starting script


***Start Training: 16:47:39


=== EPOCH 0/2 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5172   |0.5152   |0.2173   |0.3056   |
79.60      |39.06     |40.54     |    Fire   |0.6703   |0.0000   |0.0000   |0.0000   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.4896   |0.4896   |1.0000   |0.6573   |
84.76      |40.54     |44.22     |    Fire   |0.6979   |0.0000   |0.0000   |0.0000   |

Saving model with new best validation loss: 84.7563
Saving model with best Mean F1: 0.3287

=== EPOCH 1/2 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5594   |0.5613   |0.4537   |0.5018   |
76.59      |39.37     |37.21     |    Fire   |0.7031   |0.7442   |0.1517   |0.2520   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.4896   |0.4896   |1.0000   |0.6573   |
87.49      |40.22     |47.27     |    Fire   |0.3021   |0.3021   |1.0000   |0.4640   |

Saving model with best Mean F1: 0.5607

=== EPOCH 2/2 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5156   |0.5176   |0.1406   |0.2211   |
72.60      |38.78     |33.82     |    Fire   |0.7391   |0.6392   |0.4787   |0.5474   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.4896   |0.4896   |1.0000   |0.6573   |
92.87      |40.11     |52.76     |    Fire   |0.3021   |0.3021   |1.0000   |0.4640   |

Saving last model

***Script finished: 16:47:57

Time elapsed: 0:00:17.563471

Testing with FULL TEST LOADER
{'Accuracy': [0.4895833432674408, 0.3020833432674408], 'Precision': [0.4895833432674408, 0.3020833432674408], 'Recall': [1.0, 1.0], 'F1': [0.6573426723480225, 0.46399998664855957]}

Testing with DFire MINI TRAIN after LOADING F1 Best Mean CHECKPOINT
{'Accuracy': [0.75, 0.3499999940395355], 'Precision': [0.75, 0.3499999940395355], 'Recall': [1.0, 1.0], 'F1': [0.8571428656578064, 0.5185185074806213]}

Testing with DFire MINI TEST after LOADING F1 Best Mean CHECKPOINT
{'Accuracy': [0.7333333492279053, 0.36666667461395264], 'Precision': [0.7333333492279053, 0.36666667461395264], 'Recall': [1.0, 1.0], 'F1': [0.8461538553237915, 0.5365853905677795]}
