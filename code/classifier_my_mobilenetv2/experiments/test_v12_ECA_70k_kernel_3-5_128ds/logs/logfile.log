ECA Mobilenetv2.
	One Head.
	Weighted for Precision.
	Brevitas Default.
	Dataset images divided by 255.


Datasets Length
	Train and Val: 128

Load Model: False

Device: cuda
Optimizer:
	Learning Rate: 0.001
	Weight Decay: 0.001
Scheduler:
	Scheduler factor: 0.8
	Scheduler patience: 2
	Scheduler threshold: 0.001
	Scheduler min learning rate: 1e-06

Batch Size: 64
Num Workers: 8
Pin Memory: True
Epochs: 4

IMG DIMS:
	Width: 224
	Height: 224

Brevitas Config:
	Fixed Point: True
	Weights Bit Width: 4
	Big Layers Weights Bit Width: 4
	Bias Bit Width: 4
	Activations Bit Width: 4

Trainable parameters = 68926
Total parameters = 68926


Torch Summary
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
ECA_MobileNetV2                                    [1, 2]                    --
├─Sequential: 1-1                                  [1, 128, 14, 14]          --
│    └─ConvBNReLU: 2-1                             [1, 32, 112, 112]         --
│    │    └─Conv2d: 3-1                            [1, 32, 112, 112]         864
│    │    └─BatchNorm2d: 3-2                       [1, 32, 112, 112]         64
│    │    └─ReLU6: 3-3                             [1, 32, 112, 112]         --
│    └─InvertedResidual: 2-2                       [1, 8, 112, 112]          --
│    │    └─Sequential: 3-4                        [1, 8, 112, 112]          627
│    └─InvertedResidual: 2-3                       [1, 16, 56, 56]           --
│    │    └─Sequential: 3-5                        [1, 16, 56, 56]           627
│    └─InvertedResidual: 2-4                       [1, 16, 56, 56]           --
│    │    └─Sequential: 3-6                        [1, 16, 56, 56]           1,475
│    └─InvertedResidual: 2-5                       [1, 24, 28, 28]           --
│    │    └─Sequential: 3-7                        [1, 24, 28, 28]           1,749
│    └─InvertedResidual: 2-6                       [1, 24, 28, 28]           --
│    │    └─Sequential: 3-8                        [1, 24, 28, 28]           2,981
│    └─InvertedResidual: 2-7                       [1, 32, 14, 14]           --
│    │    └─Sequential: 3-9                        [1, 32, 14, 14]           6,693
│    └─InvertedResidual: 2-8                       [1, 32, 14, 14]           --
│    │    └─Sequential: 3-10                       [1, 32, 14, 14]           9,925
│    └─InvertedResidual: 2-9                       [1, 32, 14, 14]           --
│    │    └─Sequential: 3-11                       [1, 32, 14, 14]           9,925
│    └─InvertedResidual: 2-10                      [1, 64, 14, 14]           --
│    │    └─Sequential: 3-12                       [1, 64, 14, 14]           7,109
│    └─InvertedResidual: 2-11                      [1, 64, 14, 14]           --
│    │    └─Sequential: 3-13                       [1, 64, 14, 14]           18,181
│    └─ConvBNReLU: 2-12                            [1, 128, 14, 14]          --
│    │    └─Conv2d: 3-14                           [1, 128, 14, 14]          8,192
│    │    └─BatchNorm2d: 3-15                      [1, 128, 14, 14]          256
│    │    └─ReLU6: 3-16                            [1, 128, 14, 14]          --
├─AdaptiveAvgPool2d: 1-2                           [1, 128, 1, 1]            --
├─Sequential: 1-3                                  [1, 2]                    --
│    └─Dropout: 2-13                               [1, 128]                  --
│    └─Linear: 2-14                                [1, 2]                    258
====================================================================================================
Total params: 68,926
Trainable params: 68,926
Non-trainable params: 0
Total mult-adds (M): 41.82
====================================================================================================
Input size (MB): 0.60
Forward/backward pass size (MB): 32.52
Params size (MB): 0.28
Estimated Total Size (MB): 33.39
====================================================================================================

Torch Model
ECA_MobileNetV2(
  (features): Sequential(
    (0): ConvBNReLU(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
    (1): InvertedResidual(
      (conv): Sequential(
        (0): ConvBNReLU(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): eca_layer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (2): InvertedResidual(
      (conv): Sequential(
        (0): ConvBNReLU(
          (0): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): ConvBNReLU(
          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): eca_layer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (3): InvertedResidual(
      (conv): Sequential(
        (0): ConvBNReLU(
          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): ConvBNReLU(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): eca_layer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (4): InvertedResidual(
      (conv): Sequential(
        (0): ConvBNReLU(
          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): ConvBNReLU(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(32, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): eca_layer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (5): InvertedResidual(
      (conv): Sequential(
        (0): ConvBNReLU(
          (0): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): ConvBNReLU(
          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): eca_layer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (6): InvertedResidual(
      (conv): Sequential(
        (0): ConvBNReLU(
          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): ConvBNReLU(
          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): eca_layer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (7): InvertedResidual(
      (conv): Sequential(
        (0): ConvBNReLU(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): ConvBNReLU(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): eca_layer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (8): InvertedResidual(
      (conv): Sequential(
        (0): ConvBNReLU(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): ConvBNReLU(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): eca_layer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (9): InvertedResidual(
      (conv): Sequential(
        (0): ConvBNReLU(
          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): ConvBNReLU(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): eca_layer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (10): InvertedResidual(
      (conv): Sequential(
        (0): ConvBNReLU(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): ConvBNReLU(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): eca_layer(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
          (sigmoid): Sigmoid()
        )
      )
    )
    (11): ConvBNReLU(
      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Sequential(
    (0): Dropout(p=0.25, inplace=False)
    (1): Linear(in_features=128, out_features=2, bias=True)
  )
)

Loss Function: BCE
Smoke Precision Weight: 0.8
Starting script


***Start Training: 12:31:14


=== EPOCH 0/3 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.4984   |0.3571   |0.0319   |0.0587   |
80.64      |39.17     |41.47     |    Fire   |0.6656   |0.2857   |0.0095   |0.0183   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5104   |0.0000   |0.0000   |0.0000   |
82.67      |40.01     |42.65     |    Fire   |0.6979   |0.0000   |0.0000   |0.0000   |

Saving model with new best validation loss: 82.6651

=== EPOCH 1/3 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5188   |0.8571   |0.0192   |0.0375   |
74.05      |37.93     |36.12     |    Fire   |0.6703   |0.0000   |0.0000   |0.0000   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.4896   |0.4896   |1.0000   |0.6573   |
82.57      |40.31     |42.25     |    Fire   |0.6979   |0.0000   |0.0000   |0.0000   |

Saving model with new best validation loss: 82.5677
Saving model with best Mean F1: 0.3287

=== EPOCH 2/3 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5609   |0.6096   |0.2843   |0.3878   |
69.97      |37.45     |32.52     |    Fire   |0.6859   |0.9167   |0.0521   |0.0987   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.4896   |0.4896   |1.0000   |0.6573   |
83.67      |40.60     |43.07     |    Fire   |0.6979   |0.0000   |0.0000   |0.0000   |


=== EPOCH 3/3 ===
Learning Rate = 0.001

TRAIN Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5688   |0.5959   |0.3674   |0.4545   |
68.23      |37.70     |30.53     |    Fire   |0.7609   |0.8372   |0.3412   |0.4848   |

VAL Stats
Total Loss |Smoke Loss|Fire Loss |    _______|Accuracy |Precision|Recall   |F1       |
-----------|----------|----------|    Smoke  |0.5495   |0.5231   |0.9043   |0.6628   |
80.57      |39.90     |40.68     |    Fire   |0.6927   |0.4944   |0.7586   |0.5986   |

Saving model with new best validation loss: 80.5741
Saving model with best Mean F1: 0.6307
Saving last model

***Script finished: 12:31:37

Time elapsed: 0:00:22.693454

Testing with FULL TEST LOADER
{'Accuracy': [0.5494791865348816, 0.6927083134651184], 'Precision': [0.5230769515037537, 0.49438202381134033], 'Recall': [0.9042553305625916, 0.7586206793785095], 'F1': [0.6627680063247681, 0.5986394286155701]}

Testing with DFire MINI TRAIN after LOADING F1 Best Mean CHECKPOINT
{'Accuracy': [0.7300000190734863, 0.6499999761581421], 'Precision': [0.760869562625885, 0.5], 'Recall': [0.9333333373069763, 0.4571428596973419], 'F1': [0.8383233547210693, 0.4776119291782379]}

Testing with DFire MINI TEST after LOADING F1 Best Mean CHECKPOINT
{'Accuracy': [0.6333333253860474, 0.6666666865348816], 'Precision': [0.7037037014961243, 0.5384615659713745], 'Recall': [0.8636363744735718, 0.6363636255264282], 'F1': [0.7755101919174194, 0.5833333134651184]}
