{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ced39284-e77a-4bb4-b4f4-1e32f8dc378b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 2.0.0 (you have 1.4.10). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import config\n",
    "import modules.dataloaders as dataloaders\n",
    "\n",
    "import modules.models.eca_mobilenetv2 as cnv_model\n",
    "\n",
    "import modules.loss as loss\n",
    "import modules.metrics as metrics\n",
    "import modules.train_epoch as train_epoch\n",
    "import modules.val_epoch as val_epoch\n",
    "import modules.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c9f1ed9-bdb0-4417-ac3d-cec7acef5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from brevitas.export import export_onnx_qcdq\n",
    "# from brevitas.export import export_qonnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41561148-0730-471e-85f3-f6baff142607",
   "metadata": {},
   "source": [
    "# Reimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc1fffe-379c-4e1d-bf8c-82e51fbc7ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2413f4-083b-4ddd-bf51-0332c1166d47",
   "metadata": {},
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9006bcad-639b-4775-b5a6-2fd13420cbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = config.LOGS_FOLDER\n",
    "\n",
    "logger = logging.getLogger(\"GonLogger\")\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.INFO)\n",
    "file_handler = logging.FileHandler(log_path + 'logfile.log')\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# add file handler to logger\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.info('ECA Mobilenetv2.\\n' +  \n",
    "            '\\tOne Head.\\n' +\n",
    "            '\\tWeighted for Precision.\\n' +\n",
    "            '\\tBrevitas Default.\\n'+ \n",
    "            '\\tDataset images divided by 255.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3884364d-ec36-4e80-a0d5-c5d259f4b313",
   "metadata": {},
   "source": [
    "# Hyperparameters Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25fe6b1d-7f69-48d4-80a2-219e19c33016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datasets Length\n",
      "\tTrain and Val: Full\n",
      "\n",
      "Load Model: False\n",
      "Device: cuda\n",
      "Optimizer:\n",
      "\tLearning Rate: 0.001\n",
      "\tWeight Decay: 0.001\n",
      "Scheduler:\n",
      "\tScheduler factor: 0.8\n",
      "\tScheduler patience: 2\n",
      "\tScheduler threshold: 0.001\n",
      "\tScheduler min learning rate: 1e-06\n",
      "Batch Size: 64\n",
      "Num Workers: 8\n",
      "Pin Memory: True\n",
      "Epochs: 100\n",
      "\n",
      "IMG DIMS:\n",
      "\tWidth: 224\n",
      "\tHeight: 224\n",
      "\n",
      "Brevitas Config:\n",
      "\tFixed Point: True\n",
      "\tWeights Bit Width: 4\n",
      "\tBig Layers Weights Bit Width: 4\n",
      "\tBias Bit Width: 4\n",
      "\tActivations Bit Width: 4\n"
     ]
    }
   ],
   "source": [
    "''' ============================\n",
    "    Print Config Values\n",
    "============================ '''\n",
    "print('\\nDatasets Length')\n",
    "print(f'\\tTrain and Val: {\"Full\" if config.DS_LEN == None else config.DS_LEN}')\n",
    "print(f'\\nLoad Model: {config.LOAD_MODEL}')\n",
    "if (config.LOAD_MODEL == True):\n",
    "    print(f'\\tModel: {config.LOAD_MODEL_FILE}')\n",
    "print(f'Device: {config.DEVICE}')\n",
    "print('Optimizer:')\n",
    "print(f'\\tLearning Rate: {config.LEARNING_RATE}')\n",
    "print(f'\\tWeight Decay: {config.WEIGHT_DECAY}')\n",
    "print('Scheduler:')\n",
    "print(f'\\tScheduler factor: {config.FACTOR}')\n",
    "print(f'\\tScheduler patience: {config.PATIENCE}')\n",
    "print(f'\\tScheduler threshold: {config.THRES}')\n",
    "print(f'\\tScheduler min learning rate: {config.MIN_LR}')\n",
    "print(f'Batch Size: {config.BATCH_SIZE}')\n",
    "print(f'Num Workers: {config.NUM_WORKERS}')\n",
    "print(f'Pin Memory: {config.PIN_MEMORY}')\n",
    "print(f'Epochs: {config.EPOCHS}')\n",
    "print('\\nIMG DIMS:')\n",
    "print(f'\\tWidth: {config.IMG_W}\\n\\tHeight: {config.IMG_H}')\n",
    "print('\\nBrevitas Config:')\n",
    "print(f'\\tFixed Point: {config.FIXED_POINT}')\n",
    "print(f'\\tWeights Bit Width: {config.WEIGHTS_BIT_WIDTH}')\n",
    "print(f'\\tBig Layers Weights Bit Width: {config.BIG_LAYERS_WEIGHTS_BIT_WIDTH}')\n",
    "print(f'\\tBias Bit Width: {config.BIAS_BIT_WIDTH}')\n",
    "print(f'\\tActivations Bit Width: {config.ACTIVATIONS_BIT_WIDTH}')\n",
    "\n",
    "logger.info('\\nDatasets Length')\n",
    "logger.info(f'\\tTrain and Val: {\"Full\" if config.DS_LEN == None else config.DS_LEN}')\n",
    "logger.info(f'\\nLoad Model: {config.LOAD_MODEL}')\n",
    "if (config.LOAD_MODEL == True):\n",
    "    logger.info(f'\\tModel: {config.LOAD_MODEL_FILE}')\n",
    "logger.info(f'\\nDevice: {config.DEVICE}')\n",
    "logger.info('Optimizer:')\n",
    "logger.info(f'\\tLearning Rate: {config.LEARNING_RATE}')\n",
    "logger.info(f'\\tWeight Decay: {config.WEIGHT_DECAY}')\n",
    "logger.info('Scheduler:')\n",
    "logger.info(f'\\tScheduler factor: {config.FACTOR}')\n",
    "logger.info(f'\\tScheduler patience: {config.PATIENCE}')\n",
    "logger.info(f'\\tScheduler threshold: {config.THRES}')\n",
    "logger.info(f'\\tScheduler min learning rate: {config.MIN_LR}')\n",
    "logger.info(f'\\nBatch Size: {config.BATCH_SIZE}')\n",
    "logger.info(f'Num Workers: {config.NUM_WORKERS}')\n",
    "logger.info(f'Pin Memory: {config.PIN_MEMORY}')\n",
    "logger.info(f'Epochs: {config.EPOCHS}')\n",
    "logger.info('\\nIMG DIMS:')\n",
    "logger.info(f'\\tWidth: {config.IMG_W}\\n\\tHeight: {config.IMG_H}')\n",
    "logger.info('\\nBrevitas Config:')\n",
    "logger.info(f'\\tFixed Point: {config.FIXED_POINT}')\n",
    "logger.info(f'\\tWeights Bit Width: {config.WEIGHTS_BIT_WIDTH}')\n",
    "logger.info(f'\\tBig Layers Weights Bit Width: {config.BIG_LAYERS_WEIGHTS_BIT_WIDTH}')\n",
    "logger.info(f'\\tBias Bit Width: {config.BIAS_BIT_WIDTH}')\n",
    "logger.info(f'\\tActivations Bit Width: {config.ACTIVATIONS_BIT_WIDTH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48611bc-7a36-41f5-a80c-5cc442bd40fd",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "125fadde-618b-4a0d-8d1e-86f4b46a35a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "TRAIN DFIRE dataset\n",
      "DFire Removed wrong images: 0\n",
      "DFire empty images: 7833\n",
      "DFire only smoke images: 4681\n",
      "DFire only fire images: 944\n",
      "DFire smoke and fire images: 3763\n",
      "\n",
      "Train DFire dataset len: 17221\n",
      "\n",
      "====================\n",
      "TRAIN FASDD UAV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD empty images: 5994\n",
      "FASDD only smoke images: 2541\n",
      "FASDD only fire images: 105\n",
      "FASDD smoke and fire images: 3911\n",
      "\n",
      "Train FASDD UAV dataset len: 12551\n",
      "\n",
      "====================\n",
      "VAL FASDD UAV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD empty images: 3995\n",
      "FASDD only smoke images: 1693\n",
      "FASDD only fire images: 70\n",
      "FASDD smoke and fire images: 2607\n",
      "\n",
      "Val FASDD UAV dataset len: 8365\n",
      "\n",
      "====================\n",
      "TRAIN FASDD CV dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: unknown JFIF revision number 32.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASDD Removed wrong images: 0\n",
      "FASDD empty images: 19600\n",
      "FASDD only smoke images: 11708\n",
      "FASDD only fire images: 6276\n",
      "FASDD smoke and fire images: 10076\n",
      "\n",
      "Train FASDD CV dataset len: 47660\n",
      "\n",
      "====================\n",
      "Val FASDD CV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD empty images: 13066\n",
      "FASDD only smoke images: 7804\n",
      "FASDD only fire images: 4183\n",
      "FASDD smoke and fire images: 6717\n",
      "\n",
      "Val FASDD CV dataset len: 31770\n",
      "\n",
      "==================== CONCATENATE\n",
      "\n",
      "Concatenate Train DFire and Train FASDD UAV datasets\n",
      "Train dataset len: 29772\n",
      "Concatenate with Val FASDD UAV dataset\n",
      "Train dataset len: 38137\n",
      "Concatenate with Train FASDD CV dataset\n",
      "Train dataset len: 85797\n",
      "Concatenate with Val FASDD CV dataset\n",
      "Train dataset len: 117567\n",
      "\n",
      "====================\n",
      "TEST DFire dataset\n",
      "DFire Removed wrong images: 0\n",
      "DFire empty images: 2005\n",
      "DFire only smoke images: 1186\n",
      "DFire only fire images: 220\n",
      "DFire smoke and fire images: 895\n",
      "\n",
      "Test dataset len: 4306\n",
      "\n",
      "====================\n",
      "TEST FASDD UAV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD empty images: 1997\n",
      "FASDD only smoke images: 846\n",
      "FASDD only fire images: 35\n",
      "FASDD smoke and fire images: 1303\n",
      "\n",
      "Test FASDD UAV dataset len: 4181\n",
      "\n",
      "====================\n",
      "TEST FASDD CV dataset\n",
      "FASDD Removed wrong images: 0\n",
      "FASDD empty images: 6533\n",
      "FASDD only smoke images: 3902\n",
      "FASDD only fire images: 2091\n",
      "FASDD smoke and fire images: 3358\n",
      "\n",
      "Test FASDD CV dataset len: 15884\n",
      "\n",
      "==================== CONCATENATE\n",
      "Concatenate Test DFire and FASDD UAV datasets\n",
      "Test dataset len: 8487\n",
      "Concatenate with FASDD CV dataset\n",
      "Test dataset len: 24371\n"
     ]
    }
   ],
   "source": [
    "train_loader = dataloaders.get_train_loader(add_clouds=False)\n",
    "val_loader = dataloaders.get_val_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841b4bfc-55f6-4692-a5de-8f457d17472c",
   "metadata": {},
   "source": [
    "### Plot Some Train Pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f18dab26-cb88-4c13-ad66-a5cc8176a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (img, label) in enumerate(train_loader):\n",
    "\n",
    "    plt.subplots(8,4, figsize=(8, 16))\n",
    "    \n",
    "    for idx in range(config.BATCH_SIZE):\n",
    "        plt.subplot(8, 4, idx+1)\n",
    "        plt.imshow(img[idx].permute(1, 2, 0))\n",
    "        title = \"\"\n",
    "        if label[idx][0] == 1 and label[idx][1] == 1:\n",
    "            title += \"Smoke and Fire\"\n",
    "        elif label[idx][0] == 1 and label[idx][1] == 0:\n",
    "            title += \"Only Smoke\"\n",
    "        elif label[idx][0] == 0 and label[idx][1] == 1:\n",
    "            title += \"Only Fire\"\n",
    "        else:\n",
    "            title += \"Empty\"\n",
    "        plt.title(title)\n",
    "        \n",
    "        if (idx == 31):\n",
    "            break\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(config.RUN_FOLDER + 'train_pictures.png')\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f38c400-7e28-46fd-8cab-fb537e5bb248",
   "metadata": {},
   "source": [
    "### Plot Some Val Pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60efe557-e316-4ec3-a850-3e671f04b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (img, label) in enumerate(val_loader):\n",
    "\n",
    "    plt.subplots(8,4, figsize=(8, 16))\n",
    "    \n",
    "    for idx in range(config.BATCH_SIZE):\n",
    "        plt.subplot(8, 4, idx+1)\n",
    "        plt.imshow(img[idx].permute(1, 2, 0))\n",
    "        title = \"\"\n",
    "        if label[idx][0] == 1 and label[idx][1] == 1:\n",
    "            title += \"Smoke and Fire\"\n",
    "        elif label[idx][0] == 1 and label[idx][1] == 0:\n",
    "            title += \"Only Smoke\"\n",
    "        elif label[idx][0] == 0 and label[idx][1] == 1:\n",
    "            title += \"Only Fire\"\n",
    "        else:\n",
    "            title += \"Empty\"\n",
    "        plt.title(title)\n",
    "        \n",
    "        if (idx == 31):\n",
    "            break\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(config.RUN_FOLDER + 'val_pictures.png')\n",
    "    plt.close()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32673ea5-65c2-418d-b4bb-dc52d5fc0cb5",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65f05240-0c38-4f73-b06d-bf9ceefcb369",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnv_model.ECA_MobileNetV2().to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578c963b-1a73-4b8b-9646-8ad392dd4eee",
   "metadata": {},
   "source": [
    "### Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2284272-f9fc-4adb-a7c4-81ac3956d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=config.LEARNING_RATE, \n",
    "                       weight_decay=config.WEIGHT_DECAY)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                 mode='min',\n",
    "                                                 factor=config.FACTOR, \n",
    "                                                 patience=config.PATIENCE, \n",
    "                                                 threshold=config.THRES, \n",
    "                                                 threshold_mode='abs',\n",
    "                                                 min_lr=config.MIN_LR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0bac02-ea2e-40b6-9f71-456b3f3cf943",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce30cdae-4cb8-4399-9766-49932d6a4bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable parameters = 68926\n",
      "Total parameters = 68926\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'\\nTrainable parameters = {n_trainable}')\n",
    "logger.info(f'\\nTrainable parameters = {n_trainable}')\n",
    "\n",
    "n_params = parameters_to_vector(model.parameters()).numel()\n",
    "print(f'Total parameters = {n_params}\\n')\n",
    "logger.info(f'Total parameters = {n_params}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb33a7e-b560-4446-bd60-8621483adfdc",
   "metadata": {},
   "source": [
    "### Check Model Shape: Random Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d80f00c5-183d-431b-bf8a-26551c390cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model shape is tensor([[0.0912, 0.0391],\n",
      "        [0.0525, 0.0439],\n",
      "        [0.0838, 0.0790],\n",
      "        [0.0492, 0.0549]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dummy_input = np.random.rand(4, config.NUM_CHANNELS, config.IMG_H, config.IMG_W)\n",
    "dummy_input = torch.tensor(dummy_input, dtype=torch.float32, device=config.DEVICE)\n",
    "out_test = model(dummy_input)\n",
    "print(f'Model shape is {out_test}')\n",
    "#print(f'BED Model Arquitecture\\n{cnv_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a769672-efb0-4727-8322-8c68795d0efb",
   "metadata": {},
   "source": [
    "### Torchinfo and Print Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "607141f0-be35-4feb-8635-c63724d1503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "ECA_MobileNetV2                                    [1, 2]                    --\n",
      "├─Sequential: 1-1                                  [1, 128, 14, 14]          --\n",
      "│    └─ConvBNReLU: 2-1                             [1, 32, 112, 112]         --\n",
      "│    │    └─Conv2d: 3-1                            [1, 32, 112, 112]         864\n",
      "│    │    └─BatchNorm2d: 3-2                       [1, 32, 112, 112]         64\n",
      "│    │    └─ReLU6: 3-3                             [1, 32, 112, 112]         --\n",
      "│    └─InvertedResidual: 2-2                       [1, 8, 112, 112]          --\n",
      "│    │    └─Sequential: 3-4                        [1, 8, 112, 112]          627\n",
      "│    └─InvertedResidual: 2-3                       [1, 16, 56, 56]           --\n",
      "│    │    └─Sequential: 3-5                        [1, 16, 56, 56]           627\n",
      "│    └─InvertedResidual: 2-4                       [1, 16, 56, 56]           --\n",
      "│    │    └─Sequential: 3-6                        [1, 16, 56, 56]           1,475\n",
      "│    └─InvertedResidual: 2-5                       [1, 24, 28, 28]           --\n",
      "│    │    └─Sequential: 3-7                        [1, 24, 28, 28]           1,749\n",
      "│    └─InvertedResidual: 2-6                       [1, 24, 28, 28]           --\n",
      "│    │    └─Sequential: 3-8                        [1, 24, 28, 28]           2,981\n",
      "│    └─InvertedResidual: 2-7                       [1, 32, 14, 14]           --\n",
      "│    │    └─Sequential: 3-9                        [1, 32, 14, 14]           6,693\n",
      "│    └─InvertedResidual: 2-8                       [1, 32, 14, 14]           --\n",
      "│    │    └─Sequential: 3-10                       [1, 32, 14, 14]           9,925\n",
      "│    └─InvertedResidual: 2-9                       [1, 32, 14, 14]           --\n",
      "│    │    └─Sequential: 3-11                       [1, 32, 14, 14]           9,925\n",
      "│    └─InvertedResidual: 2-10                      [1, 64, 14, 14]           --\n",
      "│    │    └─Sequential: 3-12                       [1, 64, 14, 14]           7,109\n",
      "│    └─InvertedResidual: 2-11                      [1, 64, 14, 14]           --\n",
      "│    │    └─Sequential: 3-13                       [1, 64, 14, 14]           18,181\n",
      "│    └─ConvBNReLU: 2-12                            [1, 128, 14, 14]          --\n",
      "│    │    └─Conv2d: 3-14                           [1, 128, 14, 14]          8,192\n",
      "│    │    └─BatchNorm2d: 3-15                      [1, 128, 14, 14]          256\n",
      "│    │    └─ReLU6: 3-16                            [1, 128, 14, 14]          --\n",
      "├─AdaptiveAvgPool2d: 1-2                           [1, 128, 1, 1]            --\n",
      "├─Sequential: 1-3                                  [1, 2]                    --\n",
      "│    └─Dropout: 2-13                               [1, 128]                  --\n",
      "│    └─Linear: 2-14                                [1, 2]                    258\n",
      "====================================================================================================\n",
      "Total params: 68,926\n",
      "Trainable params: 68,926\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 41.82\n",
      "====================================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 32.52\n",
      "Params size (MB): 0.28\n",
      "Estimated Total Size (MB): 33.39\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, input_size=(1, config.NUM_CHANNELS, config.IMG_H, config.IMG_W)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d7096a2-e624-44b2-88fe-1e13e1ef6f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info(\"\\nTorch Summary\")\n",
    "logger.info(summary(model, input_size=(1, config.NUM_CHANNELS, config.IMG_H, config.IMG_W)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48f5d604-3a80-497a-a710-f0dcf9c6f465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info(\"\\nTorch Model\")\n",
    "logger.info(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d74ed9-984a-4f66-8121-d1152fecad98",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6efb3c84-4076-4694-8505-2c3c0ee9aa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function: BCE\n",
      "Smoke Precision Weight: 0.8\n"
     ]
    }
   ],
   "source": [
    "if config.LOSS_FN == \"BCE\":\n",
    "    print(f'Loss Function: BCE')\n",
    "    logger.info(f'\\nLoss Function: BCE')\n",
    "    print(f'Smoke Precision Weight: {config.SMOKE_PRECISION_WEIGHT}')\n",
    "    logger.info(f'Smoke Precision Weight: {config.SMOKE_PRECISION_WEIGHT}')\n",
    "    loss_fn = loss.BCE_LOSS(device=config.DEVICE, smoke_precision_weight=config.SMOKE_PRECISION_WEIGHT)\n",
    "else:\n",
    "    print(\"Wrong loss function\")\n",
    "    logger.info(\"Wrong loss function\")\n",
    "    raise SystemExit(\"Wrong loss function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f25227-bbcd-43e9-a41b-70a324900a21",
   "metadata": {},
   "source": [
    "# Loggers and Plotters for Losses and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb75d214-f372-4aee-a196-c43276145a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_logger = utils.LogLosses()\n",
    "train_metrics_logger = utils.LogMetrics()\n",
    "lr_logger = utils.LogLR(log_path=config.PLOTS_FOLDER)\n",
    "\n",
    "val_losses_logger = utils.LogLosses()\n",
    "val_metrics_logger = utils.LogMetrics()\n",
    "\n",
    "loss_plotter = utils.PlotMetrics(log_path=config.PLOTS_FOLDER, model_name=config.MODEL, loss_or_metric='Loss')\n",
    "metrics_plotter = utils.PlotMetrics(log_path=config.PLOTS_FOLDER, model_name=config.MODEL, loss_or_metric='Metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f38d11-6099-48cd-9f95-f5b0be87d804",
   "metadata": {},
   "source": [
    "# Main Function to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "180683fc-5a55-4f1c-9d6e-c8ffa10be16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, start_epoch=0, epochs_to_train=config.EPOCHS):\n",
    "\n",
    "    ''' ==============================================================\n",
    "                                TRAINING LOOP\n",
    "    ============================================================== '''\n",
    "    start = datetime.datetime.now()\n",
    "    start_time = start.strftime(\"%H:%M:%S\")\n",
    "    print(f'\\n***Start Training: {start_time}\\n')\n",
    "    logger.info(f'\\n***Start Training: {start_time}\\n')\n",
    "    \n",
    "    # Start with infinite validation loss\n",
    "    best_valid_loss = np.inf\n",
    "    best_smoke_precision = 0. #torch.tensor([0.])\n",
    "    smoke_f1_min_save = 0.9 #torch.tensor([0.9])\n",
    "    best_mean_f1 = 0.\n",
    "\n",
    "    if start_epoch == 0:\n",
    "        epochs_plot = []\n",
    "    else:\n",
    "        epochs_plot = [i for i in range(start_epoch)]    \n",
    "\n",
    "    end_epoch = start_epoch + epochs_to_train\n",
    "        \n",
    "    for epoch in range(start_epoch, end_epoch):\n",
    "\n",
    "        print(f'\\n=== EPOCH {epoch}/{end_epoch-1} ===')\n",
    "        logger.info(f'\\n=== EPOCH {epoch}/{end_epoch-1} ===')\n",
    "        \n",
    "        #====================== TRAINING ========================#\n",
    "        current_lr = train_epoch.get_lr(optimizer=optimizer)\n",
    "        logger.info(f'Learning Rate = {current_lr}\\n')\n",
    "        lr_logger.log_lr(current_lr)\n",
    "                \n",
    "        train_losses, train_metrics = train_epoch.train_fn(\n",
    "            loader=train_loader, \n",
    "            model=model, \n",
    "            optimizer=optimizer, \n",
    "            loss_fn=loss_fn,\n",
    "            device=config.DEVICE)\n",
    "        \n",
    "        train_losses_logger.update_metrics(train_losses)\n",
    "        train_metrics_logger.update_metrics(train_metrics)\n",
    "                \n",
    "        logger.info(utils.print_metrics_to_logger(\"TRAIN Stats\", train_losses, train_metrics))\n",
    "        \n",
    "        #===================== VALIDATING =======================#\n",
    "        with torch.no_grad():\n",
    "            val_losses, val_metrics = val_epoch.eval_fn(\n",
    "                loader=val_loader, \n",
    "                model=model,                         \n",
    "                loss_fn=loss_fn,\n",
    "                device=config.DEVICE)\n",
    "            \n",
    "            scheduler.step(val_losses['Total'])\n",
    "            \n",
    "            val_losses_logger.update_metrics(val_losses)\n",
    "            val_metrics_logger.update_metrics(val_metrics)\n",
    "\n",
    "            logger.info(utils.print_metrics_to_logger(\"VAL Stats\", val_losses, val_metrics))\n",
    "            \n",
    "        epochs_plot.append(epoch)\n",
    "\n",
    "        loss_plotter.plot_all_metrics(\n",
    "            train_losses_logger.get_metrics(),\n",
    "            val_losses_logger.get_metrics(),\n",
    "            epochs_plot)\n",
    "\n",
    "        metrics_plotter.plot_all_metrics(\n",
    "            train_metrics_logger.get_metrics(),\n",
    "            val_metrics_logger.get_metrics(),\n",
    "            epochs_plot)\n",
    "\n",
    "        lr_logger.plot_lr(epochs_plot)\n",
    "        #======================= SAVING =========================#\n",
    "        if ( (epoch+1) % 5 ) == 0:\n",
    "            save_name = config.WEIGHTS_FOLDER + config.MODEL + '_classifier__5epoch.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name) \n",
    "            \n",
    "        if best_valid_loss > val_losses['Total']:\n",
    "            best_valid_loss = val_losses['Total']\n",
    "            print(f\"\\nSaving model with new best validation loss: {best_valid_loss:.4f}\")\n",
    "            logger.info(f\"Saving model with new best validation loss: {best_valid_loss:.4f}\")\n",
    "            save_name = config.WEIGHTS_FOLDER + config.MODEL + '_classifier__' + 'best_loss'  + '.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name) \n",
    "            save_onnx = config.ONNX_FOLDER + config.MODEL + '_classifier__' + 'best_loss'  #+ '.onnx'\n",
    "            # utils.export_onnx(model, (1, config.NUM_CHANNELS, config.IMG_H, config.IMG_W), save_onnx, config.DEVICE)\n",
    "\n",
    "        # # Save model if precision increases and F1 > 0.9\n",
    "        # if ( best_smoke_precision < val_metrics['Precision'][0] ) and ( val_metrics['F1'][0] > smoke_f1_min_save ) :\n",
    "        #     best_smoke_precision = val_metrics['Precision'][0]\n",
    "        #     print(f\"\\nSaving model with new best smoke precision: {best_smoke_precision:.4f}\")\n",
    "        #     logger.info(f\"Saving model with new best smoke precision: {best_smoke_precision:.4f}\")\n",
    "        #     save_precision_name = f'best_smoke__precision={np.round(best_smoke_precision, decimals=4)}__epoch={epoch}'\n",
    "        #     save_name = config.WEIGHTS_FOLDER + config.MODEL + '_classifier__' + save_precision_name + '.pt'\n",
    "        #     utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name)  \n",
    "        #     save_onnx = config.ONNX_FOLDER + config.MODEL + '_classifier__' + save_precision_name #+ '.onnx'\n",
    "        #     utils.export_onnx(model, (1, config.NUM_CHANNELS, config.IMG_H, config.IMG_W), save_onnx, config.DEVICE)\n",
    "            \n",
    "        # Save model if precision > 0.9 and recall > 0.9\n",
    "        # if ( val_metrics['Precision'][0] > 0.9 ) and ( val_metrics['Recall'][0] > 0.9 ) :\n",
    "        #     print(\"\\nSaving model with precision > 0.9 and recall > 0.9\")\n",
    "        #     logger.info(\"Saving model with precision > 0.9 and recall > 0.9\")\n",
    "        #     save_pre_name = f'smoke__precision={np.round(val_metrics[\"Precision\"][0], decimals=4)}__' \n",
    "        #     save_rec_name = f'recall={np.round(val_metrics[\"Recall\"][0], decimals=4)}__'\n",
    "        #     save_pre_rec_name = save_pre_name + save_rec_name + f'epoch={epoch}'\n",
    "        #     save_name = config.WEIGHTS_FOLDER + config.MODEL + '_classifier__' + save_pre_rec_name + '.pt'\n",
    "        #     utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name) \n",
    "        #     save_onnx = config.ONNX_FOLDER + config.MODEL + '_classifier__' + save_pre_rec_name #+ '.onnx'\n",
    "        #     # utils.export_onnx(model, (1, config.NUM_CHANNELS, config.IMG_H, config.IMG_W), save_onnx, config.DEVICE)\n",
    "\n",
    "        # Save model if best mean F1 increases\n",
    "        val_f1_mean = (val_metrics['F1'][0] + val_metrics['F1'][1]) / 2\n",
    "        if (val_f1_mean > best_mean_f1) :\n",
    "            best_mean_f1 = val_f1_mean\n",
    "            print(f'Saving model with best Mean F1: {best_mean_f1:.4f}')\n",
    "            logger.info(f'Saving model with best Mean F1: {best_mean_f1:.4f}')\n",
    "            save_f1_name = 'best_mean_F1'\n",
    "            save_name = config.WEIGHTS_FOLDER + config.MODEL + '_classifier__' + save_f1_name + '.pt'\n",
    "            utils.save_checkpoint(epoch, model, optimizer, scheduler, save_name) \n",
    "            save_onnx = config.ONNX_FOLDER + config.MODEL + '_classifier__' + save_f1_name #+ '.onnx'\n",
    "            # utils.export_onnx(model, (1, config.NUM_CHANNELS, config.IMG_H, config.IMG_W), save_onnx, config.DEVICE)\n",
    "        \n",
    "    logger.info('Saving last model')   \n",
    "    torch.save(model.state_dict(), config.WEIGHTS_FOLDER + 'last_' + config.MODEL + '_classifier.pt') \n",
    "    \n",
    "    #======================= FINISH =========================#\n",
    "    end = datetime.datetime.now()\n",
    "    end_time = end.strftime(\"%H:%M:%S\")\n",
    "    print(f'\\n***Script finished: {end_time}\\n')  \n",
    "    print(f'Time elapsed: {end-start}')\n",
    "    logger.info(f'\\n***Script finished: {end_time}\\n')  \n",
    "    logger.info(f'Time elapsed: {end-start}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70cfebac-da9f-4c54-98da-0fccfdf9c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(val_losses_logger.total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb71ba5-1f21-4a7b-9ebe-6b50a5d38ed8",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd3a8768-03a8-44f3-829f-58045dbfea7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting script\n",
      "\n",
      "\n",
      "***Start Training: 13:56:44\n",
      "\n",
      "\n",
      "=== EPOCH 0/99 ===\n",
      "Learning Rate = 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|█████████████████████████████████████████████████████████▍                                                                                 | 758/1836 [02:29<02:54,  6.17it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1836/1836 [06:00<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Smoke Loss  |Fire Loss   \n",
      "------------ ------------ ------------\n",
      "47.845      |26.443      |21.402      \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 380/380 [00:24<00:00, 15.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss  |Smoke Loss  |Fire Loss   \n",
      "------------ ------------ ------------\n",
      "34.416      |21.305      |13.110      \n",
      "SMOKE -> Precision: 0.8705 - Recall: 0.7161 - Accuracy: 0.8160 - F1: 0.7858\n",
      "FIRE -> Precision: 0.8524 - Recall: 0.8937 - Accuracy: 0.9154 - F1: 0.8726\n",
      "\n",
      "Saving model with new best validation loss: 34.4156\n",
      "Saving model with best Mean F1: 0.8292\n",
      "\n",
      "=== EPOCH 1/99 ===\n",
      "Learning Rate = 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██████████████████████████████▍                                                                                                            | 402/1836 [01:19<03:24,  7.00it/s]Warning: unknown JFIF revision number 32.23\n",
      "Training:  43%|███████████████████████████████████████████████████████████▎                                                                               | 784/1836 [02:34<03:27,  5.08it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting script\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting script\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 34\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(model, start_epoch, epochs_to_train)\u001b[0m\n\u001b[1;32m     31\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearning Rate = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_lr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m lr_logger\u001b[38;5;241m.\u001b[39mlog_lr(current_lr)\n\u001b[0;32m---> 34\u001b[0m train_losses, train_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m train_losses_logger\u001b[38;5;241m.\u001b[39mupdate_metrics(train_losses)\n\u001b[1;32m     42\u001b[0m train_metrics_logger\u001b[38;5;241m.\u001b[39mupdate_metrics(train_metrics)\n",
      "File \u001b[0;32m~/uav/code/classifier_my_mobilenetv2/modules/train_epoch.py:27\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(loader, model, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Gradient Descent\u001b[39;00m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10.0\u001b[39m)\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch_23/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch_23/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch_23/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"Starting script\\n\")\n",
    "    logger.info(\"Starting script\\n\")\n",
    "    \n",
    "    model = train_loop(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0eaad5-d3f2-48e4-9922-505d025372b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "#     print(\"Train More script\\n\")\n",
    "#     logger.info(\"Train More\\n\")\n",
    "    \n",
    "#     model = train_loop(model, start_epoch=75, epochs_to_train=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5e0386-520e-4452-a4bd-217a39e3478f",
   "metadata": {},
   "source": [
    "# Test with DFire MINI Dataset: Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9c8bf2-dce8-4ac5-82a9-abbd30a20b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(config)\n",
    "# importlib.reload(dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7cc77c-6bdf-4d83-9358-61038a8b23bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfire_mini_loader = dataloaders.get_dfire_mini_train_loader()\n",
    "test_dfire_mini_loader = dataloaders.get_dfire_mini_test_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c18474-8bc6-4f26-9479-529412e9c71d",
   "metadata": {},
   "source": [
    "### Load Checkpoint with Best F1 Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b517a297-edea-4d37-9e5b-90ca2512c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = config.WEIGHTS_FOLDER + config.MODEL + '_classifier__best_mean_F1.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0959a9-9b84-4fd6-85a3-67fb519f6b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.load_checkpoint(\n",
    "    model_path, \n",
    "    model=model, \n",
    "    optimizer=optimizer, \n",
    "    scheduler=scheduler, \n",
    "    device=config.DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eb53e5-0b75-4bb0-8f45-d2e104d25a13",
   "metadata": {},
   "source": [
    "### Whole Test Loader, to check it is the same as training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ae050-a816-407d-9569-5e5b6f84af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    val_losses, val_metrics = val_epoch.eval_fn(\n",
    "        loader=val_loader, \n",
    "        model=model,                         \n",
    "        loss_fn=loss_fn,\n",
    "        device=config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf582d94-1848-4729-8816-86f1211e9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('\\nTesting with FULL TEST LOADER')  \n",
    "#logger.info(val_losses)\n",
    "logger.info(val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36662803-7b09-4c43-9e14-5045635f86ab",
   "metadata": {},
   "source": [
    "### Train DFire MINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40dff6c-50a6-4fa9-af36-496730a81fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    val_losses, val_metrics = val_epoch.eval_fn(\n",
    "        loader=train_dfire_mini_loader, \n",
    "        model=model,                         \n",
    "        loss_fn=loss_fn,\n",
    "        device=config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f864d7c-7da2-4c7c-b99a-f1943d722b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('\\nTesting with DFire MINI TRAIN after LOADING F1 Best Mean CHECKPOINT')  \n",
    "#logger.info(val_losses)\n",
    "logger.info(val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c77cd9-05ef-4771-8707-82ba5f16ef0c",
   "metadata": {},
   "source": [
    "### Test DFire MINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c237df0-9726-42e9-8ebe-d738948fb047",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    val_losses, val_metrics = val_epoch.eval_fn(\n",
    "        loader=test_dfire_mini_loader, \n",
    "        model=model,                         \n",
    "        loss_fn=loss_fn,\n",
    "        device=config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fdf6f8-b716-4ee3-a29a-ea9972387cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('\\nTesting with DFire MINI TEST after LOADING F1 Best Mean CHECKPOINT')  \n",
    "#logger.info(val_losses)\n",
    "logger.info(val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b39d52-262f-47ba-9793-80bac83f92bb",
   "metadata": {},
   "source": [
    "# Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1117cc-5daf-4352-a4a0-015ddba077c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38182ac-9d8c-4325-99da-645cf5240ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch_input = torch.randn(1, 3, 224, 224)\n",
    "torch.onnx.export(model, torch_input, config.ONNX_FOLDER + \"mbnet_eca_mini.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
